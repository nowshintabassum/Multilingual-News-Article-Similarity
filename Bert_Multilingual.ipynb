{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bhj8tK3WESKl"
      },
      "source": [
        "0. Install and import libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4OUvVfQLgR4"
      },
      "source": [
        "\n",
        "XLM-Roberta on multilingual text\n",
        "\n",
        "- Training data + augmentation data\n",
        "- Weighted loss = 25% Overall + (50% / 6 = 12.5%) for each of the remaining 6 labels\n",
        "- Model parameter file: Multilingual_Bert_0.50_overall_loss.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using testing_set.csv and training_data.csv file for this task and both are stored in the same folder with this .ipynb file. In case you have different location , please update the path."
      ],
      "metadata": {
        "id": "cGNVMtmuS5QS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Attach your google drive if you are running this file using google colab.\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE4n2nHy5kgv",
        "outputId": "34348272-5edb-483f-e17c-db0463077a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-Mlm41yMmLS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ac1b98b-3f33-4f1c-cd2d-a5a509ef67b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "#In case you are running this notebook using google colab then uncomment the below lines otherwiese make sure it is installed in your system if running using VS code.\n",
        "\n",
        "#!pip install transformers\n",
        "#!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH_HtKSJLeWh"
      },
      "outputs": [],
      "source": [
        "#Imporint required packages.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import regex as re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sentencepiece\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import XLMRobertaConfig, XLMRobertaModel, XLMRobertaTokenizer\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# LIBRARY_PATH = '/content/drive/MyDrive/Colab Notebooks/training_data.csv'\n",
        "\n",
        "# Seed\n",
        "seed = 123\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading csv file using pandas from gogole drive location\n",
        "training_data = pd.read_csv('training_data.csv')\n",
        "training_data = training_data.dropna() #Removing null rows from training data frame.\n",
        "training_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ix5rLCPFh-iU",
        "outputId": "9d5b30e5-8a34-4e4b-8a0c-d547c2b9114a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0 url1_lang url2_lang  \\\n",
              "3              3        en        en   \n",
              "5              5        en        en   \n",
              "6              6        en        en   \n",
              "7              7        en        en   \n",
              "8              8        en        en   \n",
              "...          ...       ...       ...   \n",
              "2926        2926        ar        ar   \n",
              "2928        2928        ar        ar   \n",
              "2929        2929        ar        ar   \n",
              "2931        2931        ar        ar   \n",
              "2932        2932        ar        ar   \n",
              "\n",
              "                                                  link1  \\\n",
              "3     https://gadgets.ndtv.com/apps/news/zomato-uber...   \n",
              "5     https://jewishjournal.com/news/nation/309033/w...   \n",
              "6     https://www.financialexpress.com/market/commod...   \n",
              "7     https://www.opednews.com/articles/The-biggest-...   \n",
              "8     https://www.amazon.com/dp/154173016X/?tag=slat...   \n",
              "...                                                 ...   \n",
              "2926                 https://www.omandaily.om/?p=786245   \n",
              "2928               https://www.albawabhnews.com/3962000   \n",
              "2929  https://www.masrawy.com/news/news_egypt/detail...   \n",
              "2931  http://www.ahewar.org/news/s.news.asp?nid=3945815   \n",
              "2932  https://www.arabstoday.net/329/201953-%D8%A7%D...   \n",
              "\n",
              "                                                  link2  \\\n",
              "3     https://gadgets.ndtv.com/internet/news/indian-...   \n",
              "5     https://jewishjournal.com/online/309000/jewish...   \n",
              "6     https://www.financialexpress.com/india-news/de...   \n",
              "7     https://nypost.com/2019/12/31/the-lefts-consta...   \n",
              "8     https://www.amazon.com/dp/1610399579/?tag=slat...   \n",
              "...                                                 ...   \n",
              "2926  https://www.masrawy.com/news/news_publicaffair...   \n",
              "2928  https://www.vetogate.com/3959908/%D8%B6%D8%A8%...   \n",
              "2929   https://www.elwatannews.com/news/details/4728427   \n",
              "2931  https://arabic.sputniknews.com/arab_world/2020...   \n",
              "2932  https://www.al-madina.com/article/678086/دولية...   \n",
              "\n",
              "                                               ia_link1  \\\n",
              "3     https://web.archive.org/web/gadgets.ndtv.com/a...   \n",
              "5     https://web.archive.org/web/jewishjournal.com/...   \n",
              "6     https://web.archive.org/web/www.financialexpre...   \n",
              "7     https://web.archive.org/web/www.opednews.com/a...   \n",
              "8     https://web.archive.org/web/www.amazon.com/dp/...   \n",
              "...                                                 ...   \n",
              "2926  https://web.archive.org/web/www.omandaily.om/?...   \n",
              "2928  https://web.archive.org/web/www.albawabhnews.c...   \n",
              "2929  https://web.archive.org/web/www.masrawy.com/ne...   \n",
              "2931  https://web.archive.org/web/www.ahewar.org/new...   \n",
              "2932  https://web.archive.org/web/www.arabstoday.net...   \n",
              "\n",
              "                                               ia_link2  Geography  Entities  \\\n",
              "3     https://web.archive.org/web/gadgets.ndtv.com/i...   1.000000  2.333333   \n",
              "5     https://web.archive.org/web/jewishjournal.com/...   1.250000  1.750000   \n",
              "6     https://web.archive.org/web/www.financialexpre...   3.000000  4.000000   \n",
              "7     https://web.archive.org/web/nypost.com/2019/12...   2.333333  3.666667   \n",
              "8     https://web.archive.org/web/www.amazon.com/dp/...   1.000000  4.000000   \n",
              "...                                                 ...        ...       ...   \n",
              "2926  https://web.archive.org/web/www.masrawy.com/ne...   1.000000  1.000000   \n",
              "2928  https://web.archive.org/web/www.vetogate.com/3...   2.000000  3.000000   \n",
              "2929  https://web.archive.org/web/www.elwatannews.co...   1.000000  2.000000   \n",
              "2931  https://web.archive.org/web/arabic.sputniknews...   1.000000  2.000000   \n",
              "2932  https://web.archive.org/web/www.al-madina.com/...   1.000000  1.000000   \n",
              "\n",
              "          Time  Narrative   Overall     Style      Tone        id_1  \\\n",
              "3     2.666667   1.666667  2.000000  1.666667  1.666667  1576314516   \n",
              "5     1.250000   1.750000  2.000000  1.000000  1.250000  1484189120   \n",
              "6     1.333333   4.000000  3.666667  1.333333  1.333333  1484034982   \n",
              "7     1.333333   3.666667  3.333333  1.333333  1.333333  1484188439   \n",
              "8     4.000000   1.000000  4.000000  1.000000  1.000000  1484011751   \n",
              "...        ...        ...       ...       ...       ...         ...   \n",
              "2926  3.000000   1.000000  1.000000  1.000000  1.000000  1592085965   \n",
              "2928  3.000000   2.000000  4.000000  1.000000  1.000000  1566447642   \n",
              "2929  4.000000   4.000000  4.000000  1.000000  1.000000  1644102363   \n",
              "2931  1.000000   1.000000  1.000000  1.000000  3.000000  1640724079   \n",
              "2932  1.000000   1.000000  1.000000  1.000000  2.000000  1552392654   \n",
              "\n",
              "            id_2                                             text_1  \\\n",
              "3     1576455088  Uber has sold its online food-ordering busines...   \n",
              "5     1484113136  The Simon Wiesenthal Center called on the Whit...   \n",
              "6     1483785560  The government on Wednesday slashed import dut...   \n",
              "7     1484378177  From The Guardian\\n\\nFrom Boeing to Whole Food...   \n",
              "8     1483920335  Review\\n\\nCrimeReads best nonfiction crime boo...   \n",
              "...          ...                                                ...   \n",
              "2926  1567830952  الطيران العماني يواصل رحلات الشحن لتعزيز الأمن...   \n",
              "2928  1582626838  تمكن رجال مباحث القاهرة تحت إشراف اللواء أشرف ...   \n",
              "2929  1594269711  كتب- مصراوي:\\n\\nأكدت الشركة المتحدة للخدمات ال...   \n",
              "2931  1641509405  التبرع للموقع - ادعمونا\\n\\n\\n\\n\\n\\nالموقع الرئ...   \n",
              "2932  1552514260  حكمت محكمة جنايات مدينة طشقند على غولنارا كريم...   \n",
              "\n",
              "                                                 text_2  \\\n",
              "3     Rapid digitisation and growth in both online b...   \n",
              "5     Jewish groups have expressed shock and horror ...   \n",
              "6     Delhiites continued to remain in grip of cold ...   \n",
              "7     Police have arrested a 38-year-old black man f...   \n",
              "8     Enter the characters you see below\\n\\nSorry, w...   \n",
              "...                                                 ...   \n",
              "2926  مسقط - أ ش أ\\n\\nقام الطيران العماني، الناقل ال...   \n",
              "2928  ألقى رجال المباحث بمديرية أمن القاهرة برئاسة ا...   \n",
              "2929  قال الإمام الأكبر الدكتور أحمد الطيب، شيخ الأز...   \n",
              "2931  وقال نصر الله في الشريط المصور: \"إننا اليوم لس...   \n",
              "2932  حكمت محكمة جنايات مدينة طشقند على غولنارا كريم...   \n",
              "\n",
              "                                                title_1  \\\n",
              "3     Zomato Buys Uber's Food Delivery Business in I...   \n",
              "5     Wiesenthal Center Calls for FBI Task Force to ...   \n",
              "6     Big cut on import duty on crude and refined pa...   \n",
              "7     The biggest business con of 2019: fleecing wor...   \n",
              "8     The Compatriots: The Brutal and Chaotic Histor...   \n",
              "...                                                 ...   \n",
              "2926  الطيران العماني يواصل رحلات الشحن لتعزيز الأمن...   \n",
              "2928  القبض على عنصر إجرامي تخصص في سرقة السيارات با...   \n",
              "2929  المتحدة للخدمات الإعلامية: نثمن دور الأزهر كإش...   \n",
              "2931                                 وكالة أنباء اليسار   \n",
              "2932   الحكم على ابنة أول رئيس لأوزبكستان بالسجن 13عاما   \n",
              "\n",
              "                                                title_2  \n",
              "3     Indian Online Food Delivery Market to Hit $8 B...  \n",
              "5               Jewish Groups React to Monsey Stabbings  \n",
              "6     Delhi weather update: Delhiites shiver at 2.4 ...  \n",
              "7     The left’s constant victimhood olympics is a g...  \n",
              "8                                            Amazon.com  \n",
              "...                                                 ...  \n",
              "2926  الطيران العماني يسيّر رحلات شحن إلى الهند لتوف...  \n",
              "2928  ضبط ترزى لتصنيعه 1600 كمامة ورداء طبى بدون تصر...  \n",
              "2929  شيخ الأزهر: التوكل على الله دون أخذٍ بالأسباب ...  \n",
              "2931  \"انتهى الأمر\"... \"حزب الله\" ينشر فيديو لأهداف ...  \n",
              "2932         13عاما بالسجن على ابنة أول رئيس لأوزبكستان  \n",
              "\n",
              "[1580 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d04079e-8b4a-4c77-94ce-f63d41682a60\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>url1_lang</th>\n",
              "      <th>url2_lang</th>\n",
              "      <th>link1</th>\n",
              "      <th>link2</th>\n",
              "      <th>ia_link1</th>\n",
              "      <th>ia_link2</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Entities</th>\n",
              "      <th>Time</th>\n",
              "      <th>Narrative</th>\n",
              "      <th>Overall</th>\n",
              "      <th>Style</th>\n",
              "      <th>Tone</th>\n",
              "      <th>id_1</th>\n",
              "      <th>id_2</th>\n",
              "      <th>text_1</th>\n",
              "      <th>text_2</th>\n",
              "      <th>title_1</th>\n",
              "      <th>title_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>https://gadgets.ndtv.com/apps/news/zomato-uber...</td>\n",
              "      <td>https://gadgets.ndtv.com/internet/news/indian-...</td>\n",
              "      <td>https://web.archive.org/web/gadgets.ndtv.com/a...</td>\n",
              "      <td>https://web.archive.org/web/gadgets.ndtv.com/i...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>1576314516</td>\n",
              "      <td>1576455088</td>\n",
              "      <td>Uber has sold its online food-ordering busines...</td>\n",
              "      <td>Rapid digitisation and growth in both online b...</td>\n",
              "      <td>Zomato Buys Uber's Food Delivery Business in I...</td>\n",
              "      <td>Indian Online Food Delivery Market to Hit $8 B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>https://jewishjournal.com/news/nation/309033/w...</td>\n",
              "      <td>https://jewishjournal.com/online/309000/jewish...</td>\n",
              "      <td>https://web.archive.org/web/jewishjournal.com/...</td>\n",
              "      <td>https://web.archive.org/web/jewishjournal.com/...</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1484189120</td>\n",
              "      <td>1484113136</td>\n",
              "      <td>The Simon Wiesenthal Center called on the Whit...</td>\n",
              "      <td>Jewish groups have expressed shock and horror ...</td>\n",
              "      <td>Wiesenthal Center Calls for FBI Task Force to ...</td>\n",
              "      <td>Jewish Groups React to Monsey Stabbings</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>https://www.financialexpress.com/market/commod...</td>\n",
              "      <td>https://www.financialexpress.com/india-news/de...</td>\n",
              "      <td>https://web.archive.org/web/www.financialexpre...</td>\n",
              "      <td>https://web.archive.org/web/www.financialexpre...</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1484034982</td>\n",
              "      <td>1483785560</td>\n",
              "      <td>The government on Wednesday slashed import dut...</td>\n",
              "      <td>Delhiites continued to remain in grip of cold ...</td>\n",
              "      <td>Big cut on import duty on crude and refined pa...</td>\n",
              "      <td>Delhi weather update: Delhiites shiver at 2.4 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>https://www.opednews.com/articles/The-biggest-...</td>\n",
              "      <td>https://nypost.com/2019/12/31/the-lefts-consta...</td>\n",
              "      <td>https://web.archive.org/web/www.opednews.com/a...</td>\n",
              "      <td>https://web.archive.org/web/nypost.com/2019/12...</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1484188439</td>\n",
              "      <td>1484378177</td>\n",
              "      <td>From The Guardian\\n\\nFrom Boeing to Whole Food...</td>\n",
              "      <td>Police have arrested a 38-year-old black man f...</td>\n",
              "      <td>The biggest business con of 2019: fleecing wor...</td>\n",
              "      <td>The left’s constant victimhood olympics is a g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>https://www.amazon.com/dp/154173016X/?tag=slat...</td>\n",
              "      <td>https://www.amazon.com/dp/1610399579/?tag=slat...</td>\n",
              "      <td>https://web.archive.org/web/www.amazon.com/dp/...</td>\n",
              "      <td>https://web.archive.org/web/www.amazon.com/dp/...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1484011751</td>\n",
              "      <td>1483920335</td>\n",
              "      <td>Review\\n\\nCrimeReads best nonfiction crime boo...</td>\n",
              "      <td>Enter the characters you see below\\n\\nSorry, w...</td>\n",
              "      <td>The Compatriots: The Brutal and Chaotic Histor...</td>\n",
              "      <td>Amazon.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2926</th>\n",
              "      <td>2926</td>\n",
              "      <td>ar</td>\n",
              "      <td>ar</td>\n",
              "      <td>https://www.omandaily.om/?p=786245</td>\n",
              "      <td>https://www.masrawy.com/news/news_publicaffair...</td>\n",
              "      <td>https://web.archive.org/web/www.omandaily.om/?...</td>\n",
              "      <td>https://web.archive.org/web/www.masrawy.com/ne...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1592085965</td>\n",
              "      <td>1567830952</td>\n",
              "      <td>الطيران العماني يواصل رحلات الشحن لتعزيز الأمن...</td>\n",
              "      <td>مسقط - أ ش أ\\n\\nقام الطيران العماني، الناقل ال...</td>\n",
              "      <td>الطيران العماني يواصل رحلات الشحن لتعزيز الأمن...</td>\n",
              "      <td>الطيران العماني يسيّر رحلات شحن إلى الهند لتوف...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2928</th>\n",
              "      <td>2928</td>\n",
              "      <td>ar</td>\n",
              "      <td>ar</td>\n",
              "      <td>https://www.albawabhnews.com/3962000</td>\n",
              "      <td>https://www.vetogate.com/3959908/%D8%B6%D8%A8%...</td>\n",
              "      <td>https://web.archive.org/web/www.albawabhnews.c...</td>\n",
              "      <td>https://web.archive.org/web/www.vetogate.com/3...</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1566447642</td>\n",
              "      <td>1582626838</td>\n",
              "      <td>تمكن رجال مباحث القاهرة تحت إشراف اللواء أشرف ...</td>\n",
              "      <td>ألقى رجال المباحث بمديرية أمن القاهرة برئاسة ا...</td>\n",
              "      <td>القبض على عنصر إجرامي تخصص في سرقة السيارات با...</td>\n",
              "      <td>ضبط ترزى لتصنيعه 1600 كمامة ورداء طبى بدون تصر...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2929</th>\n",
              "      <td>2929</td>\n",
              "      <td>ar</td>\n",
              "      <td>ar</td>\n",
              "      <td>https://www.masrawy.com/news/news_egypt/detail...</td>\n",
              "      <td>https://www.elwatannews.com/news/details/4728427</td>\n",
              "      <td>https://web.archive.org/web/www.masrawy.com/ne...</td>\n",
              "      <td>https://web.archive.org/web/www.elwatannews.co...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1644102363</td>\n",
              "      <td>1594269711</td>\n",
              "      <td>كتب- مصراوي:\\n\\nأكدت الشركة المتحدة للخدمات ال...</td>\n",
              "      <td>قال الإمام الأكبر الدكتور أحمد الطيب، شيخ الأز...</td>\n",
              "      <td>المتحدة للخدمات الإعلامية: نثمن دور الأزهر كإش...</td>\n",
              "      <td>شيخ الأزهر: التوكل على الله دون أخذٍ بالأسباب ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2931</th>\n",
              "      <td>2931</td>\n",
              "      <td>ar</td>\n",
              "      <td>ar</td>\n",
              "      <td>http://www.ahewar.org/news/s.news.asp?nid=3945815</td>\n",
              "      <td>https://arabic.sputniknews.com/arab_world/2020...</td>\n",
              "      <td>https://web.archive.org/web/www.ahewar.org/new...</td>\n",
              "      <td>https://web.archive.org/web/arabic.sputniknews...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1640724079</td>\n",
              "      <td>1641509405</td>\n",
              "      <td>التبرع للموقع - ادعمونا\\n\\n\\n\\n\\n\\nالموقع الرئ...</td>\n",
              "      <td>وقال نصر الله في الشريط المصور: \"إننا اليوم لس...</td>\n",
              "      <td>وكالة أنباء اليسار</td>\n",
              "      <td>\"انتهى الأمر\"... \"حزب الله\" ينشر فيديو لأهداف ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2932</th>\n",
              "      <td>2932</td>\n",
              "      <td>ar</td>\n",
              "      <td>ar</td>\n",
              "      <td>https://www.arabstoday.net/329/201953-%D8%A7%D...</td>\n",
              "      <td>https://www.al-madina.com/article/678086/دولية...</td>\n",
              "      <td>https://web.archive.org/web/www.arabstoday.net...</td>\n",
              "      <td>https://web.archive.org/web/www.al-madina.com/...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1552392654</td>\n",
              "      <td>1552514260</td>\n",
              "      <td>حكمت محكمة جنايات مدينة طشقند على غولنارا كريم...</td>\n",
              "      <td>حكمت محكمة جنايات مدينة طشقند على غولنارا كريم...</td>\n",
              "      <td>الحكم على ابنة أول رئيس لأوزبكستان بالسجن 13عاما</td>\n",
              "      <td>13عاما بالسجن على ابنة أول رئيس لأوزبكستان</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1580 rows × 20 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d04079e-8b4a-4c77-94ce-f63d41682a60')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1d04079e-8b4a-4c77-94ce-f63d41682a60 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1d04079e-8b4a-4c77-94ce-f63d41682a60');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-50051368-2671-4ad7-8f81-328542bd3642\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-50051368-2671-4ad7-8f81-328542bd3642')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-50051368-2671-4ad7-8f81-328542bd3642 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5af7108d-e8c0-4f6c-9abf-c7b87e9204b8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('training_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5af7108d-e8c0-4f6c-9abf-c7b87e9204b8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('training_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "training_data",
              "summary": "{\n  \"name\": \"training_data\",\n  \"rows\": 1580,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 856,\n        \"min\": 3,\n        \"max\": 2932,\n        \"num_unique_values\": 1580,\n        \"samples\": [\n          2352,\n          1548,\n          2250\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url1_lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"en\",\n          \"de\",\n          \"fr\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url2_lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"en\",\n          \"de\",\n          \"fr\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"link1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1576,\n        \"samples\": [\n          \"https://euobserver.com/green-deal/147691?utm_source=euobs&utm_medium=rss\",\n          \"https://www.thestar.com.my/news/regional/2020/01/02/halim-perdanakusuma-airport-back-to-normal-after-massive-flooding\",\n          \"https://wiadomosci.wp.pl/ptasia-grypa-wykryto-ognisko-grozne-dla-ludzi-6462996770326657a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"link2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1453,\n        \"samples\": [\n          \"https://www.wp.de/staedte/bottrop/bottrop-100-stunden-im-einsatz-fuer-die-gute-sache-id228033781.html\",\n          \"http://kcpw.org/blog/local-news/politics-local-news/2020-01-02/senate-impeachment-trial-and-a-citizen-referendum-on-state-tax-reform/\",\n          \"http://www.capitalcoahuila.com.mx/show/comediante-kathy-griffin-se-casa-en-ao-nuevo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ia_link1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1576,\n        \"samples\": [\n          \"https://web.archive.org/web/euobserver.com/green-deal/147691?utm_source=euobs&utm_medium=rss\",\n          \"https://web.archive.org/web/www.thestar.com.my/news/regional/2020/01/02/halim-perdanakusuma-airport-back-to-normal-after-massive-flooding\",\n          \"https://web.archive.org/web/wiadomosci.wp.pl/ptasia-grypa-wykryto-ognisko-grozne-dla-ludzi-6462996770326657a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ia_link2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1453,\n        \"samples\": [\n          \"https://web.archive.org/web/www.wp.de/staedte/bottrop/bottrop-100-stunden-im-einsatz-fuer-die-gute-sache-id228033781.html\",\n          \"https://web.archive.org/web/kcpw.org/blog/local-news/politics-local-news/2020-01-02/senate-impeachment-trial-and-a-citizen-referendum-on-state-tax-reform/\",\n          \"https://web.archive.org/web/www.capitalcoahuila.com.mx/show/comediante-kathy-griffin-se-casa-en-ao-nuevo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Geography\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1627291610939356,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          2.0,\n          3.25,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Entities\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1108191597266168,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          3.0,\n          1.2,\n          2.333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9267573379331435,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          1.571428571,\n          1.75,\n          2.666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Narrative\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0832544110268651,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          2.0,\n          3.25,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Overall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.121045402352774,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          3.0,\n          3.857142857,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Style\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8835547860040831,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          4.0,\n          1.285714286,\n          1.666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tone\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8407367153486796,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          3.666666667,\n          2.142857143,\n          1.666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29615206,\n        \"min\": 1483758771,\n        \"max\": 1766871114,\n        \"num_unique_values\": 1580,\n        \"samples\": [\n          1512801291,\n          1484759168,\n          1483758774\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30883255,\n        \"min\": 1469729742,\n        \"max\": 1766951389,\n        \"num_unique_values\": 1463,\n        \"samples\": [\n          1580472854,\n          1483993058,\n          1484106773\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1500,\n        \"samples\": [\n          \"Rok 2019 przeszed\\u0142 do historii. W nocy powitali\\u015bmy 2020, w zwi\\u0105zku z czym gwiazdy ch\\u0119tnie chwali\\u0142y si\\u0119 na Instagramie zdj\\u0119ciami i relacjami z imprez, na kt\\u00f3rych si\\u0119 bawi\\u0142y. Zalicza si\\u0119 do nich m.in. Ma\\u0142gorzata Rozenek, kt\\u00f3ra od kilku dni jest w Zakopanem. Nasz\\u0105 uwag\\u0119 zwr\\u00f3ci\\u0142a stylizacja prezenterki. Naprawd\\u0119 nale\\u017c\\u0105 jej si\\u0119 wielkie brawa.\\n\\nREKLAMA\\n\\nSylwestrowa stylizacja Ma\\u0142gorzaty Rozenek\\n\\nOdk\\u0105d wysz\\u0142o na jaw, \\u017ce Ma\\u0142gorzata jest w ci\\u0105\\u017cy, nie ma dnia, by w sieci nie powsta\\u0142 news na jej temat. Jest obecnie wyj\\u0105tkowo popularn\\u0105 gwiazd\\u0105, a co za tym idzie, bardzo dobrze op\\u0142acan\\u0105 je\\u015bli chodzi o wsp\\u00f3\\u0142prace na Instagramie. Nie dziwi wi\\u0119c fakt, \\u017ce na jednym z ostatnich zdj\\u0119\\u0107 oznaczy\\u0142a mark\\u0119, w kt\\u00f3rej sukience sp\\u0119dzi\\u0142a sylwestrow\\u0105 noc.\\n\\nW lata 20. wkraczamy w klimacie lat 20., \\u017cycz\\u0105c Wam wszelkiej pomy\\u015blno\\u015bci i \\u017ceby ten rok by\\u0142 dla Was tak szczeg\\u00f3lny jak dla nas. Szampa\\u0144skiej zabawy i trudnego poranka. Do siego roku - podpisa\\u0142a post.\\n\\nMusimy przyzna\\u0107, \\u017ce Rozenek wygl\\u0105da\\u0142a naprawd\\u0119 \\u015bwietnie! Kreacja nie by\\u0142a przesadzona, a elegancka suknia idealnie wpasowa\\u0142a si\\u0119 w klimat sylwestra. Nasz\\u0105 uwag\\u0119 zwr\\u00f3ci\\u0142o r\\u00f3wnie\\u017c rozci\\u0119cie po lewej stronie. Nie ka\\u017cda kobieta by si\\u0119 na to odwa\\u017cy\\u0142a. Fani nie kryli zachwyt\\u00f3w. Suknia oczywi\\u015bcie delikatnie podkre\\u015bli\\u0142a ci\\u0105\\u017cowy brzuszek gwiazdy.\\n\\nPani Ma\\u0142gosiu, wygl\\u0105da pani jak milion dolar\\u00f3w.\\n\\nPi\\u0119knie!\\n\\nWow!\\n\\nA Wy jak oceniacie look Ma\\u0142gorzaty?\\n\\nCW\\n\\nMa\\u0142gorzata Rozenek w wywiadzie na temat in vitro.\",\n          \"\\n\\n\\n\\n\\u201cVamos a trabajar estos 16 meses 24x7, sin vacaciones que se toman usualmente en diciembre, enero y febrero (\\u2026) tenemos que trabajar estos 16 meses para el pa\\u00eds y lo mejor y es hacerlo sin receso parlamentario\\u201d, dijo Roel al programa Elecciones 2020 de Andina Canal Online.\\n\\n\\n\\n\\n\\nEl candidato dijo tambi\\u00e9n que de tener una bancada, Acci\\u00f3n Popular, plantear\\u00e1 que la elecci\\u00f3n de los miembros del Tribunal Constitucional (TC) se realice mediante un concurso p\\u00fablico de m\\u00e9ritos a fin que no haya \\u201crepartija o dedocracia\\u201d. \\\"Eso tiene que cambiar\\\", afirm\\u00f3.\\n\\n\\n\\n\\n\\nOtra de las iniciativas que impulsar\\u00e1 su partido, indic\\u00f3, ser\\u00e1 la eliminaci\\u00f3n de la inmunidad parlamentaria de arresto y de proceso para evitar el mal uso que se ha hecho de esta prerrogativa.\\n\\n\\n\\n\\n\\n\\u201cVamos a cambiar la noci\\u00f3n de inmunidad que se asocia mucho con la impunidad. Vamos a cambiar este concepto de figura jur\\u00eddica a fin que quienes entren al Congreso con procesos penales e investigaciones y si son arrestados o condenados, se vayan inmediatamente\\u201d, expres\\u00f3.\\n\\n\\n\\n\\n\\nLa reforma de las Administradoras de Fondos de Pensiones (AFP) es otra de las iniciativas que impulsar\\u00e1 Acci\\u00f3n Popular de llegar al pr\\u00f3ximo Parlamento. En este caso, la propuesta que estas compa\\u00f1\\u00edas funcionen conforme a gesti\\u00f3n por resultados.\\n\\n\\n\\n\\n\\n\\u201cSi tu fondo gana, ellos ganan su comisi\\u00f3n, pero si tu fondo no genera ganancias ellos no tendr\\u00e1n beneficios. Por qu\\u00e9 solo las AFP van a tener utilidades, por qu\\u00e9 van ser las \\u00fanicas que rentabilicen sobre nuestra pensi\\u00f3n\\u201d, cuestion\\u00f3.\\n\\n\\n\\n\\n\\nEn cuanto a la lucha contra la corrupci\\u00f3n, Roel Alva, resalt\\u00f3 que se pierden millones de soles por este flagelo que afecta el buen funcionamiento de todo el aparato estatal. En sentido, sostuvo que se debe perfeccionar el art\\u00edculo 41 de la Constituci\\u00f3n para que todos los delitos de corrupci\\u00f3n sean imprescriptibles.\\n\\n\\n\\n\\n\\nDe igual forma, indic\\u00f3, la declaraci\\u00f3n de intereses debe ser obligatoria para todos los altos funcionario como los miembros del TC, presidente de la Rep\\u00fablica, congresistas o ministros.\\n\\n\\n\\n\\n\\n(FIN) RMCH/CVC\\n\\n\\n\\n\\n\\nM\\u00e1s en Andina\\n\\n\\n\\n\\n\\nLa @FiscaliaPeru allana local de la universidad Alas Peruanas en el marco de la investigaci\\u00f3n fiscal al exsecretario general de Fuerza Popular, Joaqu\\u00edn Ram\\u00edrez https://t.co/4RG7ktlACy pic.twitter.com/49xYsbhWAg \\u2014 Agencia Andina (@Agencia_Andina) January 15, 2020\\n\\n\\n\\nEl candidato por Lima con el n\\u00famero 5 por Acci\\u00f3n Popular (AP), Luis Roel Alva, propuso que el pr\\u00f3ximo Congreso, que completar\\u00e1 el periodo del anterior hasta julio de 2021, trabaje sin receso durante 16 meses.Publicado: 15/1/2020\",\n          \"Enjoy your new year weekend with some street food and exhibitions happening around Doha. We have listed a few of the interesting events happening in Qatar.\\n\\nMetro Street Food \\u2013 Food Fest\\n\\nFirst ever outdoor metro event hosted by Q sports, with combination of food, beverages and a mini golf course setup at the DECC Metro station.\\n\\nWhen: Jan 1 \\u2013 April 2020\\n\\nWeekdays: 12:30 pm \\u2013 11 pm; Weekends: 2 pm \\u2013 12 midnight\\n\\nWhere: DECC Metro Station\\n\\nFor details, click here\\n\\n\\\"It is our right to dream\\\" exhibition\\n\\nKatara will host \\\"It is our right to dream\\\" exhibition by the sculptor Sabhi Chtioui\\n\\nWhen: Until January 18, 2020; 10 am - 10pm\\n\\nWhere: Building 47, Katara Cultural Village\\n\\nFor details, click here\\n\\nQatar, India & the Gulf: History, Culture and Society Exhibition\\n\\nQatar National library to exhibit connections between India, Qatar and the Gulf over 4,600 years as a part of the Qatar India 2019 Year of the Culture. The exhibition reveals hows this ancient relationship has influenced their history, culture and society in profound and surprising ways.\\n\\nWhen: Until February 29, 2020; 3pm \\u2013 8pm\\n\\nWhere: Qatar National Library\\n\\nFor details, click here\\n\\n\\\"Suspicion\\\" Exhibition\\n\\nKatara Culutural Village welcomes everyone one to attend the opening of the \\\"Suspicion\\\"exhibition by the Palestinian artist Nameer Qassim.\\n\\nWhen: 2 January, 2020; 12:00pm\\n\\nWhere: Building 18, Gallery 2; Katara\\n\\nFor details, click here\\n\\nSpring Festival at Souq Waqif and Souq Al Wakrah\\n\\nThe festival includes circus show, parades and mind and skills games. Popular groups from different countries entertain visitors with cultural presentation such as folk dances and songs with the accompaniment of native musical instruments. The festival features around 60 games and rides in the two souqs. Visitors can see wild animals like lion and tiger at the circus shows.\\n\\nWhen: Until January 4; 4pm until 10pm.\\n\\nWhere: Souq Waqif and Souq Al Wakrah\\n\\nFor details click here\\n\\nMahaseel Festival\\n\\nThe biggest edition of Mahaseel Festival is going on at Katara with more than 40 stalls to buy vegetables, flowers, honey, dairy and meat products offered by local companies at discounted prices. There is also a large area where children can enjoy inflatables in addition to a giant tent where they can play various computer games such as VR games making the festival a one-stop-shop for families.\\n\\nWhen: Open every day from 9am to 9pm until December 28, after which it will be open on Thursdays, Fridays and Saturdays until March 31.\\n\\nWhere: Building 22, Katara\\n\\nFor details, click here\\n\\nDifferent Dimension: An Energetic Place\\n\\nThe exhibition showcases 11 fascinating works by contemporary abstract artist Hala El Attar and marks a number of firsts for the young artist. El Attar visually manifests energy through her unique take on fluid art integrating different mediums and styles to achieve artworks that burst with colour and life.\\n\\nWhen: The exhibition is open for public viewing until January 20 from 10am to 10pm\\n\\nWhere: W Doha\\u2019s Art 29 gallery\\n\\nFor details click here\\n\\nStar Wars Activation Booth\\n\\nDiscover your side at the Star Wars Activation booth with the launch of Star Wars: The Rise of Sky-walker! Doha Festival City has set up a total of eight zones with each zone having different activities. The booth is open to all ages and no purchase is required. It requires registration and is on first come first served.\\n\\nWhen: December 12 \\u2013 January 12, 2020; 3pm-10pm\\n\\nWhere: Doha Festival City - Center Court Ground floor\\n\\nFor details, click here\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1402,\n        \"samples\": [\n          \"STATEN ISLAND, N.Y. \\u2013 A Graniteville man cut his losses midway through jury selection on Monday and pleaded guilty to sexually abusing a young girl two years ago.\\n\\nMarco Rodriguez, 43, subjected the victim to sexual contact between May 28 and 30, 2018, an indictment said.\\n\\nThe defendant touched the girl\\u2019s private parts, said a criminal complaint.\\n\\nThe girl was under age 13 then.\\n\\nRodriguez was arrested about a month later on June 26, 2018, based on an investigation.\\n\\nShe and the defendant knew each other, said police.\\n\\nRodriguez was charged with felony and misdemeanor counts of sexual abuse, and misdemeanor counts of forcible touching and child endangerment.\\n\\nRodriguez, over prosecutors\\u2019 objection, accepted the court\\u2019s offer to plead guilty to the top count of first-degree sexual abuse. In exchange, he\\u2019ll be sentenced to two years in prison and 10 years\\u2019 post-release supervision.\\n\\nThe defendant must register with state authorities as a sexual offender, and a full order of protection will be issued in the victim\\u2019s favor.\\n\\nProsecutors had originally offered the defendant a two-year sentence to plead guilty to the felony sex-abuse charge but withdrew the offer before the start of jury selection, said a source familiar with the case.\\n\\nRodriguez had shown no interest in the offer before Monday with jury selection underway, the source said.\\n\\nThe defendant also pleaded guilty to a misdemeanor count of criminal contempt for violating an order of protection in a separate case in September 2018.\\n\\nHe will be sentenced to one year behind bars to run concurrently to the sex-abuse conviction.\\n\\nThe defendant will be sentenced on March 23 in state Supreme Court, St. George.\\n\\nRodriguez, who is not a U.S. citizen, could face deportation after serving his sentence.\\n\\nDefense lawyer Michael Cirigliano declined comment on the cases.\\n\\nAssistant District Attorney John Signoriello is prosecuting them.\",\n          \"\\n\\n\\n\\n\\n\\nZamora, Mich, 01 de enero de 2020.- Los cuerpos sin vida de dos hombres que presentaban orificios producidos por proyectil de arma de fuego fueron localizados en una brecha que conduce al Relleno Sanitario, hecho que ya investigan las autoridades.\\n\\n\\n\\nEl hallazgo fue realizado el \\u00faltimo d\\u00eda del 2019 por conductores que circulaban sobre la carretera Zamora-La Barca, reportaron al 911 dos personas tiradas, por lo que se movilizaron los elementos de la Polic\\u00eda Municipal y localizaron a los dos hombres sin vida.\\n\\n\\n\\nPosteriormente se acordon\\u00f3 dicho sitio y comenzaron los peritajes donde se dijo que uno de los fallecidos, vest\\u00eda pantal\\u00f3n camuflado, as\\u00ed playera color azul y botas t\\u00e1cticas, mientras el otro estaba sin camisa y tra\\u00eda un pantal\\u00f3n azul y botas t\\u00e1cticas color negro.\\n\\n\\n\\nLos cuerpos fueron trasladados en al servicio m\\u00e9dico forense para realizar la autopsia que indica la ley.\\n\\n\\n\\nAsimismo se detall\\u00f3 que ambas v\\u00edctimas est\\u00e1n en calidad de desconocidas hasta el momento.\\n\\n\",\n          \"ST. PETERSBURG, Fla. \\u2014 It's been a perfect weather start to 2020 for the Tampa Bay region.\\n\\nWarmer Thursday/Friday\\n\\nRain early Saturday\\n\\nSEE BELOW: See our 7-day forecast \\u25bc\\n\\nSkies will be mostly clear overnight into early Thursday. Temperatures will be seasonably cool, dropping to the 50s to mid 40s.\\n\\nThursday will be mostly sunny with warmer highs in the upper 70s due to a southeast breeze.\\n\\nFriday will be partly cloudy and warm with highs in the low 80s.\\n\\nThe next cold front will push a line of showers through late Friday night into early Saturday morning.\\n\\nThat will set us up for a cooler weekend ahead.\\n\\n7-day forecast\\n\\nWe want your pictures!\\n\\nShow us what the weather looks like in your neighborhood. Your photo could end up on Spectrum Bay News 9.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1529,\n        \"samples\": [\n          \"'It Warmed My Heart': Sachin Tendulkar Rings in New Year With an Inspirational Message on Twitter\",\n          \"Providence Lost by Paul Lay review \\u2013 the rise and fall of Oliver Cromwell\\u2019s Protectorate\",\n          \"Regierung verabschiedet Stellungnahme betreffend die Ab\\u00e4nderung des Krankenversicherungsgesetzes und des Unfallversicherungsgesetzes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1420,\n        \"samples\": [\n          \"Iran Summons Swiss Envoy over US \\u2018Warmongering Statements\\u2019\",\n          \"Amid opposition, Centre planning to make process of granting citizenship online to bypass states\",\n          \"The future is bamboo - Jamaicans encouraged to go green with multiuse wonder plant\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to merge columns and returning the transformed data frame.\n",
        "def merge_clean_columns(df):\n",
        "    \"\"\"\n",
        "    Merge multiple columns into one and clean text\n",
        "    \"\"\"\n",
        "    df['merge1'] = df['text_1'].astype(str) + ', ' \\\n",
        "        + df['title_1'].astype(str)\n",
        "\n",
        "    df['merge2'] = df['text_2'].astype(str) + ', ' \\\n",
        "        + df['title_2'].astype(str)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V1JWq5jymzwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data = merge_clean_columns(training_data) #Calling merge_clean_columns function.\n",
        "# split into train and development\n",
        "train, dev = train_test_split(processed_data, test_size=0.1, random_state = 42) #spliting processed data frame in to train and dev using train_test_split method from sklearn.model_selection"
      ],
      "metadata": {
        "id": "KNWWDBCcmwSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZMXmR0_QNzQ"
      },
      "source": [
        "## 2. Model on data text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NYsKPM8QKjF"
      },
      "outputs": [],
      "source": [
        "\n",
        "# set parameters\n",
        "max_len = 512\n",
        "batch_size = 5\n",
        "lr = 5e-6\n",
        "weight_decay = 1e-4\n",
        "num_epochs = 8\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LM33gaFg7rRE"
      },
      "outputs": [],
      "source": [
        "#Defining function get_data_loader for modeling\n",
        "def get_data_loader(data, batch_size_flg = True):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "  input_ids, attention_masks, labels = [], [], []\n",
        "  for idx, row in data.iterrows():\n",
        "      text1, text2 = row['merge1'], row['merge2']\n",
        "      encode_dict = tokenizer(text1,text2,\n",
        "                                  max_length=max_len,\n",
        "                                  padding='max_length',\n",
        "                                  truncation=True,\n",
        "                                  add_special_tokens=True\n",
        "                                  )\n",
        "\n",
        "      input_ids.append(encode_dict['input_ids'])\n",
        "      attention_masks.append(encode_dict['attention_mask'])\n",
        "      # model is used to predict all labels?? -> should we convert to only 1 label\n",
        "      labels.append([float(x) for x in [row['Geography'],row['Entities'],row['Time'],row['Narrative'],row['Overall'],row['Style'],row['Tone']]])\n",
        "\n",
        "  input_ids = torch.tensor(input_ids)\n",
        "  attention_masks = torch.tensor(attention_masks)\n",
        "  labels = torch.tensor(labels)\n",
        "\n",
        "  data = TensorDataset(input_ids, attention_masks, labels)\n",
        "  if(batch_size_flg):\n",
        "      data_loader = DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "  else:\n",
        "      data_loader = DataLoader(data)\n",
        "  return data_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vg56V9t08atc"
      },
      "outputs": [],
      "source": [
        "train_data_loader = get_data_loader(train)\n",
        "eval_data_loader = get_data_loader(dev, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTDTaFQmsA8O"
      },
      "outputs": [],
      "source": [
        "#Defining class Custom_BERT with construction and one formward method.\n",
        "class Custom_BERT(nn.Module):\n",
        "    def __init__(self, model, hidden_size):\n",
        "        super(Custom_BERT, self).__init__()\n",
        "        self.reg_model = model\n",
        "        self.fc1 = nn.Linear(hidden_size, 512)\n",
        "        # self.dropout = nn.Dropout(0.2)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 100)\n",
        "        self.fc4 = nn.Linear(100,7) # currently processes the 7 labels that we have defined for 7 output types\n",
        "        self.activation1 = nn.GELU()\n",
        "        self.activation2 = nn.GELU()\n",
        "        self.activation3 = nn.GELU()\n",
        "\n",
        "    def forward(self, input_ids, attention_masks):\n",
        "        output1 = self.reg_model(input_ids, attention_masks)[1]\n",
        "        # output2 =\n",
        "        # x = self.dropout(x)\n",
        "        # logits1= s\n",
        "        logits1= self.fc3(self.activation2(self.fc2(self.activation1(self.fc1(output1)))))\n",
        "        logits1 = self.fc4(logits1)\n",
        "\n",
        "        return logits1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "#Functing to calculate pearson values.\n",
        "def calculate_pearson_per_aspect(predictions, labels):\n",
        "    \"\"\"\n",
        "    Calculates Pearson correlation for each aspect (output dimension).\n",
        "\n",
        "    Args:\n",
        "    - predictions: numpy array of shape (N, 7) containing model predictions.\n",
        "    - labels: numpy array of shape (N, 7) containing ground truth scores.\n",
        "\n",
        "    Returns:\n",
        "    - correlations: List of Pearson correlation coefficients for each aspect.\n",
        "    \"\"\"\n",
        "    correlations = []\n",
        "    predictions = np.array(predictions)\n",
        "    labels = np.array(labels)\n",
        "    for i in range(predictions.shape[1]):  # Loop through each of the 7 output scores\n",
        "        r, _ = pearsonr(predictions[:, i], labels[:, i])\n",
        "        correlations.append(r)\n",
        "    return correlations\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1qwnWRlUanEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWuuxWC9wvSs"
      },
      "outputs": [],
      "source": [
        "train_losses=[]\n",
        "val_losses =[]\n",
        "pearson_scores = []\n",
        "#Defining function to evaluate.\n",
        "def evaluate(model, data_loader,criterion):\n",
        "  model.eval()\n",
        "  overall_pred, overall_true = [], []\n",
        "  with torch.no_grad():\n",
        "    val_loss_sum=0\n",
        "    for idx, (ids, att_msks, y) in enumerate(data_loader):\n",
        "      ids, att_msks, y = ids.to(device), att_msks.to(device), y.to(device)\n",
        "      y_pred = model(ids, att_msks)\n",
        "      loss = criterion(torch.squeeze(y_pred),torch.squeeze(y))\n",
        "      val_loss_sum += loss.item()\n",
        "\n",
        "      y_pred, y = torch.squeeze(y_pred).cpu().numpy().tolist(), torch.squeeze(y).cpu().numpy().tolist()\n",
        "      overall_pred.append(y_pred)\n",
        "      overall_true.append(y)\n",
        "  val_losses.append(val_loss_sum/len(data_loader))\n",
        "  return overall_pred, overall_true\n",
        "\n",
        "\n",
        "\n",
        "#Defining function to train the data.\n",
        "def train(model, model_path, train_data_loader, eval_data_loader, optimizer, loss_weights, epochs):\n",
        "  model.train()\n",
        "  criterion = nn.MSELoss()\n",
        "  best_pearson = 0\n",
        "  for i in range(epochs):\n",
        "    train_loss_sum = 0\n",
        "    for idx, (ids, att_msks, y) in enumerate(train_data_loader):\n",
        "      print(idx)\n",
        "      ids, att_msks, y = ids.to(device), att_msks.to(device), y.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      y_pred = model(ids, att_msks)\n",
        "      y_pred, y = torch.squeeze(y_pred), torch.squeeze(y) ## required because y is a vector\n",
        "      # loss = weighted_loss(y_pred, y, criterion, loss_weights)\n",
        "      print(y_pred)\n",
        "      loss = criterion(y_pred,y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_loss_sum += loss.item()\n",
        "\n",
        "    train_losses.append(train_loss_sum/len(train_data_loader))\n",
        "    print(f\"Loss at epoch {i}: {train_loss_sum:.4f}\")\n",
        "\n",
        "    ## Determine best epoch model using correlation coefficient for Overall in dev data\n",
        "    eval_pred_overall, eval_true_overall = evaluate(model, eval_data_loader,criterion)\n",
        "\n",
        "    pearson_correlations = calculate_pearson_per_aspect(eval_pred_overall, eval_true_overall)\n",
        "    for i, r in enumerate(pearson_correlations):\n",
        "        print(f\"Pearson correlation for aspect {i+1}: {r:.4f}\")\n",
        "\n",
        "    # Optionally, calculate the mean Pearson correlation\n",
        "    curr_pearson = np.mean(pearson_correlations)\n",
        "    print(f\"Mean Pearson correlation: {curr_pearson:.4f}\")\n",
        "    pearson_scores.append(curr_pearson)\n",
        "\n",
        "\n",
        "    # curr_pearson = np.corrcoef(eval_pred_overall, eval_true_overall)[0][1]\n",
        "    # print(curr_pearson)\n",
        "    if curr_pearson > best_pearson:\n",
        "      best_pearson = curr_pearson\n",
        "      torch.save(model.state_dict(), model_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training model"
      ],
      "metadata": {
        "id": "loEOryJU53q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IWCRvSxyPE29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, BertConfig, BertTokenizer\n",
        "\n",
        "# Load pre-trained multilingual BERT model and configuration\n",
        "pre_trained_model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "config = BertConfig.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Get the hidden size from the model configuration\n",
        "hidden_size = config.hidden_size\n",
        "\n",
        "# Define loss weights (assume 7 output classes)\n",
        "overall_weight = 0.25\n",
        "loss_weights = [overall_weight if i == 4 else (1-overall_weight)/6 for i in range(7)]\n",
        "\n",
        "# Initialize custom model\n",
        "model = Custom_BERT(pre_trained_model, hidden_size)\n",
        "model.to(device)\n",
        "\n",
        "# Path  to save the trained model\n",
        "model_path = \"BERT_Multilingual_0.25_overall_loss.pth\"\n"
      ],
      "metadata": {
        "id": "LgNiobCSPrwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ldBSUrA68uK",
        "outputId": "13981577-5aae-4dee-a508-26593de6c83d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        [1.0389, 1.5559, 0.9239, 1.5406, 1.4873, 1.0168, 1.0229],\n",
            "        [1.5454, 2.2096, 1.2543, 2.1931, 2.1464, 1.3842, 1.3854]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "142\n",
            "tensor([[2.8955, 3.8429, 2.0774, 3.8524, 3.8337, 2.2286, 2.3074],\n",
            "        [3.0595, 4.0384, 2.1746, 4.0449, 4.0127, 2.3499, 2.4247],\n",
            "        [1.9368, 2.7028, 1.4992, 2.6889, 2.6508, 1.6421, 1.6588],\n",
            "        [2.0771, 2.8739, 1.5863, 2.8643, 2.8268, 1.7352, 1.7553],\n",
            "        [3.0477, 4.0192, 2.1669, 4.0292, 3.9995, 2.3320, 2.4149]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "143\n",
            "tensor([[1.3445, 1.9563, 1.1263, 1.9371, 1.8882, 1.2437, 1.2440],\n",
            "        [1.1188, 1.6625, 0.9792, 1.6464, 1.5941, 1.0793, 1.0817],\n",
            "        [3.0548, 4.0349, 2.1710, 4.0371, 4.0029, 2.3476, 2.4234],\n",
            "        [1.1805, 1.7433, 1.0196, 1.7256, 1.6745, 1.1244, 1.1255],\n",
            "        [2.6472, 3.5585, 1.9302, 3.5612, 3.5383, 2.0804, 2.1419]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "144\n",
            "tensor([[1.0953, 1.6315, 0.9635, 1.6143, 1.5632, 1.0599, 1.0622],\n",
            "        [2.8382, 3.7790, 2.0428, 3.7857, 3.7664, 2.1989, 2.2670],\n",
            "        [2.9488, 3.9085, 2.1095, 3.9155, 3.8933, 2.2815, 2.3461],\n",
            "        [3.0540, 4.0322, 2.1703, 4.0368, 4.0097, 2.3439, 2.4170],\n",
            "        [2.6954, 3.6126, 1.9577, 3.6146, 3.5926, 2.1169, 2.1720]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "145\n",
            "tensor([[1.4133, 2.0439, 1.1700, 2.0218, 1.9782, 1.2899, 1.2882],\n",
            "        [0.8753, 1.3410, 0.8155, 1.3252, 1.2737, 0.8891, 0.8999],\n",
            "        [2.4016, 3.2649, 1.7834, 3.2603, 3.2332, 1.9387, 1.9726],\n",
            "        [1.0544, 1.5785, 0.9358, 1.5601, 1.5095, 1.0297, 1.0327],\n",
            "        [2.7524, 3.6797, 1.9933, 3.6834, 3.6633, 2.1524, 2.2070]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "146\n",
            "tensor([[2.5679, 3.4643, 1.8842, 3.4635, 3.4380, 2.0424, 2.0846],\n",
            "        [0.8571, 1.3179, 0.8038, 1.3036, 1.2508, 0.8780, 0.8879],\n",
            "        [1.0269, 1.5416, 0.9190, 1.5256, 1.4749, 1.0104, 1.0116],\n",
            "        [2.1934, 3.0146, 1.6593, 3.0043, 2.9741, 1.8102, 1.8298],\n",
            "        [1.0370, 1.5553, 0.9264, 1.5381, 1.4881, 1.0184, 1.0204]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "147\n",
            "tensor([[0.8583, 1.3190, 0.8039, 1.3031, 1.2528, 0.8755, 0.8873],\n",
            "        [2.3022, 3.1458, 1.7249, 3.1391, 3.1098, 1.8796, 1.9043],\n",
            "        [2.6170, 3.5192, 1.9130, 3.5207, 3.4976, 2.0657, 2.1157],\n",
            "        [0.9808, 1.4800, 0.8894, 1.4650, 1.4130, 0.9764, 0.9791],\n",
            "        [2.7857, 3.7158, 2.0150, 3.7201, 3.7017, 2.1667, 2.2269]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "148\n",
            "tensor([[1.9642, 2.7350, 1.5208, 2.7223, 2.6868, 1.6657, 1.6742],\n",
            "        [1.1417, 1.6937, 0.9981, 1.6772, 1.6275, 1.1013, 1.0974],\n",
            "        [2.9823, 3.9419, 2.1303, 3.9511, 3.9333, 2.2966, 2.3604],\n",
            "        [2.7838, 3.7160, 2.0142, 3.7210, 3.7025, 2.1723, 2.2271],\n",
            "        [1.9068, 2.6632, 1.4845, 2.6491, 2.6139, 1.6294, 1.6332]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "149\n",
            "tensor([[2.7644, 3.6958, 2.0068, 3.7022, 3.6794, 2.1668, 2.2168],\n",
            "        [0.9818, 1.4824, 0.8910, 1.4678, 1.4177, 0.9778, 0.9796],\n",
            "        [1.9972, 2.7775, 1.5436, 2.7650, 2.7324, 1.6865, 1.6977],\n",
            "        [0.9919, 1.4962, 0.8993, 1.4819, 1.4307, 0.9863, 0.9875],\n",
            "        [2.4941, 3.3789, 1.8460, 3.3787, 3.3542, 2.0042, 2.0355]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "150\n",
            "tensor([[1.3880, 2.0142, 1.1619, 1.9964, 1.9531, 1.2821, 1.2732],\n",
            "        [0.8639, 1.3280, 0.8126, 1.3150, 1.2634, 0.8844, 0.8939],\n",
            "        [2.7571, 3.6876, 2.0050, 3.6930, 3.6799, 2.1556, 2.2100],\n",
            "        [0.9188, 1.4021, 0.8500, 1.3884, 1.3366, 0.9308, 0.9344],\n",
            "        [1.1948, 1.7627, 1.0350, 1.7457, 1.6984, 1.1388, 1.1343]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "151\n",
            "tensor([[2.7653, 3.6959, 2.0118, 3.7041, 3.6874, 2.1720, 2.2150],\n",
            "        [3.0438, 4.0172, 2.1750, 4.0263, 4.0073, 2.3410, 2.4031],\n",
            "        [1.1423, 1.6953, 1.0027, 1.6811, 1.6319, 1.1033, 1.0987],\n",
            "        [0.9511, 1.4430, 0.8738, 1.4288, 1.3791, 0.9535, 0.9567],\n",
            "        [3.0510, 4.0278, 2.1807, 4.0384, 4.0158, 2.3507, 2.4126]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "152\n",
            "tensor([[1.9328, 2.6999, 1.5082, 2.6885, 2.6546, 1.6488, 1.6533],\n",
            "        [2.8632, 3.8098, 2.0724, 3.8220, 3.8074, 2.2231, 2.2807],\n",
            "        [2.7247, 3.6498, 1.9912, 3.6574, 3.6414, 2.1508, 2.1877],\n",
            "        [0.9134, 1.3949, 0.8478, 1.3802, 1.3300, 0.9244, 0.9294],\n",
            "        [1.5279, 2.1902, 1.2552, 2.1741, 2.1343, 1.3839, 1.3725]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "153\n",
            "tensor([[2.5934, 3.4936, 1.9149, 3.4991, 3.4757, 2.0600, 2.0986],\n",
            "        [1.5577, 2.2296, 1.2756, 2.2148, 2.1732, 1.4030, 1.3928],\n",
            "        [0.9784, 1.4784, 0.8939, 1.4660, 1.4146, 0.9781, 0.9782],\n",
            "        [1.5521, 2.2219, 1.2716, 2.2062, 2.1648, 1.3996, 1.3885],\n",
            "        [1.8371, 2.5768, 1.4525, 2.5667, 2.5307, 1.5894, 1.5862]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "154\n",
            "tensor([[3.0578, 4.0312, 2.1922, 4.0435, 4.0192, 2.3561, 2.4136],\n",
            "        [1.1880, 1.7519, 1.0368, 1.7383, 1.6889, 1.1379, 1.1293],\n",
            "        [1.5703, 2.2453, 1.2861, 2.2319, 2.1893, 1.4119, 1.4024],\n",
            "        [2.9418, 3.8962, 2.1252, 3.9121, 3.8952, 2.2764, 2.3329],\n",
            "        [1.0351, 1.5551, 0.9294, 1.5375, 1.4906, 1.0184, 1.0155]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "155\n",
            "tensor([[0.9374, 1.4231, 0.8690, 1.4115, 1.3596, 0.9449, 0.9476],\n",
            "        [2.7318, 3.6533, 2.0028, 3.6631, 3.6471, 2.1442, 2.1889],\n",
            "        [2.2446, 3.0767, 1.7092, 3.0741, 3.0446, 1.8493, 1.8627],\n",
            "        [3.0487, 4.0186, 2.1903, 4.0323, 4.0097, 2.3482, 2.4058],\n",
            "        [2.0289, 2.8152, 1.5762, 2.8060, 2.7717, 1.7143, 1.7182]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "156\n",
            "tensor([[1.2218, 1.7971, 1.0608, 1.7824, 1.7330, 1.1594, 1.1537],\n",
            "        [2.8817, 3.8270, 2.0920, 3.8404, 3.8189, 2.2407, 2.2915],\n",
            "        [1.1160, 1.6589, 0.9924, 1.6451, 1.5957, 1.0849, 1.0790],\n",
            "        [2.7355, 3.6571, 2.0050, 3.6671, 3.6489, 2.1484, 2.1916],\n",
            "        [1.0022, 1.5092, 0.9127, 1.4961, 1.4458, 0.9953, 0.9932]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "157\n",
            "tensor([[2.5059, 3.3891, 1.8694, 3.3920, 3.3681, 2.0095, 2.0381],\n",
            "        [2.8901, 3.8326, 2.0964, 3.8445, 3.8278, 2.2397, 2.2909],\n",
            "        [1.2889, 1.8833, 1.1056, 1.8675, 1.8200, 1.2088, 1.1989],\n",
            "        [3.0714, 4.0450, 2.2044, 4.0555, 4.0291, 2.3617, 2.4195],\n",
            "        [2.0960, 2.8955, 1.6178, 2.8907, 2.8572, 1.7538, 1.7618]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "158\n",
            "tensor([[1.1104, 1.6496, 0.9868, 1.6350, 1.5847, 1.0723, 1.0708],\n",
            "        [3.0231, 3.9817, 2.1733, 3.9941, 3.9756, 2.3105, 2.3783],\n",
            "        [1.0998, 1.6367, 0.9791, 1.6219, 1.5715, 1.0678, 1.0639],\n",
            "        [2.9811, 3.9396, 2.1497, 3.9526, 3.9344, 2.2926, 2.3521],\n",
            "        [2.3973, 3.2568, 1.8017, 3.2565, 3.2348, 1.9361, 1.9606]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "159\n",
            "tensor([[2.9676, 3.9161, 2.1394, 3.9297, 3.9145, 2.2717, 2.3371],\n",
            "        [0.9144, 1.3888, 0.8547, 1.3788, 1.3257, 0.9229, 0.9266],\n",
            "        [2.8329, 3.7676, 2.0620, 3.7777, 3.7631, 2.1926, 2.2486],\n",
            "        [0.9243, 1.4031, 0.8605, 1.3914, 1.3393, 0.9303, 0.9336],\n",
            "        [2.9301, 3.8765, 2.1175, 3.8903, 3.8737, 2.2528, 2.3130]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "160\n",
            "tensor([[2.7571, 3.6800, 2.0134, 3.6885, 3.6687, 2.1486, 2.1995],\n",
            "        [2.5329, 3.4175, 1.8814, 3.4209, 3.3970, 2.0167, 2.0497],\n",
            "        [1.1803, 1.7391, 1.0307, 1.7223, 1.6731, 1.1210, 1.1177],\n",
            "        [2.8310, 3.7647, 2.0584, 3.7739, 3.7579, 2.1992, 2.2479],\n",
            "        [1.6961, 2.3979, 1.3652, 2.3836, 2.3422, 1.4893, 1.4826]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "161\n",
            "tensor([[2.1110, 2.9116, 1.6235, 2.9057, 2.8707, 1.7544, 1.7685],\n",
            "        [2.6931, 3.6036, 1.9755, 3.6126, 3.5924, 2.1106, 2.1566],\n",
            "        [3.0619, 4.0299, 2.1912, 4.0410, 4.0190, 2.3403, 2.4052],\n",
            "        [1.1713, 1.7282, 1.0254, 1.7130, 1.6617, 1.1175, 1.1139],\n",
            "        [0.9847, 1.4833, 0.9019, 1.4706, 1.4188, 0.9767, 0.9783]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "162\n",
            "tensor([[3.0706, 4.0397, 2.1975, 4.0512, 4.0266, 2.3462, 2.4115],\n",
            "        [2.3514, 3.2017, 1.7698, 3.2013, 3.1735, 1.9038, 1.9286],\n",
            "        [2.1968, 3.0156, 1.6756, 3.0112, 2.9788, 1.8076, 1.8242],\n",
            "        [1.0427, 1.5590, 0.9399, 1.5470, 1.4937, 1.0187, 1.0215],\n",
            "        [0.9338, 1.4159, 0.8658, 1.4036, 1.3502, 0.9341, 0.9414]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "163\n",
            "tensor([[1.3850, 2.0035, 1.1652, 1.9896, 1.9416, 1.2726, 1.2661],\n",
            "        [3.0734, 4.0465, 2.1968, 4.0560, 4.0233, 2.3546, 2.4194],\n",
            "        [3.0657, 4.0321, 2.1923, 4.0471, 4.0263, 2.3441, 2.4067],\n",
            "        [3.0620, 4.0301, 2.1916, 4.0452, 4.0238, 2.3451, 2.4069],\n",
            "        [1.4208, 2.0505, 1.1871, 2.0350, 1.9877, 1.2985, 1.2910]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "164\n",
            "tensor([[2.3318, 3.1816, 1.7569, 3.1818, 3.1501, 1.8960, 1.9200],\n",
            "        [1.7767, 2.5002, 1.4136, 2.4889, 2.4483, 1.5440, 1.5401],\n",
            "        [1.4217, 2.0532, 1.1898, 2.0388, 1.9923, 1.3003, 1.2932],\n",
            "        [3.0364, 4.0001, 2.1737, 4.0124, 3.9915, 2.3148, 2.3889],\n",
            "        [1.2569, 1.8390, 1.0830, 1.8261, 1.7756, 1.1810, 1.1766]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "165\n",
            "tensor([[2.5717, 3.4616, 1.9018, 3.4706, 3.4484, 2.0364, 2.0784],\n",
            "        [3.0815, 4.0553, 2.2001, 4.0664, 4.0365, 2.3607, 2.4251],\n",
            "        [1.4316, 2.0658, 1.1969, 2.0516, 2.0038, 1.3067, 1.3007],\n",
            "        [2.6962, 3.6067, 1.9745, 3.6193, 3.5989, 2.1151, 2.1606],\n",
            "        [0.7342, 1.1523, 0.7273, 1.1430, 1.0914, 0.7761, 0.7941]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "166\n",
            "tensor([[3.0540, 4.0226, 2.1853, 4.0392, 4.0123, 2.3499, 2.4057],\n",
            "        [2.2098, 3.0306, 1.6835, 3.0309, 3.0001, 1.8206, 1.8366],\n",
            "        [1.3497, 1.9599, 1.1430, 1.9472, 1.8989, 1.2523, 1.2440],\n",
            "        [2.8017, 3.7314, 2.0374, 3.7477, 3.7302, 2.1801, 2.2334],\n",
            "        [3.0611, 4.0305, 2.1905, 4.0443, 4.0223, 2.3438, 2.4094]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "167\n",
            "tensor([[1.7865, 2.5108, 1.4227, 2.5028, 2.4639, 1.5501, 1.5497],\n",
            "        [1.1496, 1.7008, 1.0128, 1.6901, 1.6381, 1.1052, 1.1027],\n",
            "        [2.2342, 3.0624, 1.6995, 3.0637, 3.0326, 1.8425, 1.8550],\n",
            "        [1.8847, 2.6335, 1.4855, 2.6268, 2.5885, 1.6150, 1.6182],\n",
            "        [0.9445, 1.4299, 0.8762, 1.4207, 1.3672, 0.9471, 0.9520]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "168\n",
            "tensor([[3.0864, 4.0599, 2.2059, 4.0782, 4.0503, 2.3707, 2.4320],\n",
            "        [3.0542, 4.0207, 2.1853, 4.0371, 4.0142, 2.3447, 2.4089],\n",
            "        [2.6138, 3.5112, 1.9278, 3.5237, 3.5001, 2.0648, 2.1095],\n",
            "        [2.8787, 3.8184, 2.0844, 3.8391, 3.8183, 2.2366, 2.2896],\n",
            "        [1.2073, 1.7752, 1.0516, 1.7642, 1.7139, 1.1492, 1.1436]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "169\n",
            "tensor([[3.0552, 4.0190, 2.1850, 4.0402, 4.0180, 2.3443, 2.4060],\n",
            "        [2.7455, 3.6645, 2.0044, 3.6807, 3.6617, 2.1439, 2.1979],\n",
            "        [2.6073, 3.5031, 1.9228, 3.5154, 3.4895, 2.0626, 2.1072],\n",
            "        [2.8972, 3.8394, 2.0946, 3.8596, 3.8400, 2.2396, 2.3002],\n",
            "        [1.2017, 1.7682, 1.0472, 1.7556, 1.7057, 1.1428, 1.1393]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "170\n",
            "tensor([[2.8128, 3.7380, 2.0410, 3.7561, 3.7352, 2.1871, 2.2426],\n",
            "        [2.9362, 3.8832, 2.1160, 3.9042, 3.8827, 2.2663, 2.3287],\n",
            "        [1.5745, 2.2463, 1.2888, 2.2372, 2.1906, 1.4087, 1.4041],\n",
            "        [1.1362, 1.6827, 1.0030, 1.6723, 1.6191, 1.0944, 1.0932],\n",
            "        [3.0907, 4.0622, 2.2059, 4.0805, 4.0497, 2.3652, 2.4345]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "171\n",
            "tensor([[2.7703, 3.6923, 2.0168, 3.7098, 3.6877, 2.1560, 2.2148],\n",
            "        [2.0373, 2.8186, 1.5765, 2.8159, 2.7794, 1.7093, 1.7207],\n",
            "        [3.0882, 4.0611, 2.2032, 4.0776, 4.0449, 2.3664, 2.4324],\n",
            "        [1.8604, 2.6020, 1.4669, 2.5958, 2.5542, 1.5978, 1.6004],\n",
            "        [1.1545, 1.7041, 1.0151, 1.6955, 1.6407, 1.1068, 1.1054]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "172\n",
            "tensor([[1.5724, 2.2392, 1.2840, 2.2286, 2.1819, 1.4002, 1.4006],\n",
            "        [0.8973, 1.3668, 0.8417, 1.3587, 1.3043, 0.9104, 0.9177],\n",
            "        [2.8949, 3.8286, 2.0863, 3.8483, 3.8282, 2.2209, 2.2931],\n",
            "        [2.7021, 3.6108, 1.9744, 3.6261, 3.6042, 2.1086, 2.1659],\n",
            "        [3.0850, 4.0553, 2.1975, 4.0690, 4.0380, 2.3612, 2.4279]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "173\n",
            "tensor([[0.9655, 1.4569, 0.8878, 1.4476, 1.3910, 0.9628, 0.9681],\n",
            "        [1.2324, 1.8049, 1.0650, 1.7949, 1.7417, 1.1610, 1.1597],\n",
            "        [1.4441, 2.0807, 1.1984, 2.0665, 2.0180, 1.3159, 1.3102],\n",
            "        [2.3584, 3.2070, 1.7685, 3.2102, 3.1811, 1.9032, 1.9369],\n",
            "        [2.7249, 3.6352, 1.9870, 3.6483, 3.6250, 2.1152, 2.1777]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "174\n",
            "tensor([[3.0394, 3.9961, 2.1705, 4.0126, 3.9844, 2.3149, 2.3906],\n",
            "        [3.0666, 4.0264, 2.1857, 4.0478, 4.0200, 2.3381, 2.4101],\n",
            "        [2.7214, 3.6341, 1.9846, 3.6469, 3.6214, 2.1248, 2.1782],\n",
            "        [1.2320, 1.8043, 1.0640, 1.7916, 1.7378, 1.1582, 1.1566],\n",
            "        [2.9918, 3.9373, 2.1425, 3.9583, 3.9336, 2.2797, 2.3563]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "175\n",
            "tensor([[3.0591, 4.0160, 2.1810, 4.0361, 4.0088, 2.3288, 2.4041],\n",
            "        [1.7651, 2.4803, 1.4045, 2.4726, 2.4279, 1.5264, 1.5323],\n",
            "        [1.9661, 2.7297, 1.5310, 2.7264, 2.6839, 1.6565, 1.6701],\n",
            "        [2.9461, 3.8874, 2.1153, 3.9087, 3.8828, 2.2529, 2.3279],\n",
            "        [3.0796, 4.0413, 2.1935, 4.0603, 4.0304, 2.3470, 2.4185]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "176\n",
            "tensor([[0.9643, 1.4538, 0.8877, 1.4455, 1.3879, 0.9582, 0.9669],\n",
            "        [2.4897, 3.3591, 1.8481, 3.3679, 3.3404, 1.9727, 2.0214],\n",
            "        [2.0582, 2.8424, 1.5858, 2.8391, 2.8010, 1.7124, 1.7320],\n",
            "        [2.8631, 3.7940, 2.0663, 3.8123, 3.7892, 2.2016, 2.2711],\n",
            "        [1.0213, 1.5280, 0.9245, 1.5189, 1.4622, 1.0023, 1.0074]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "177\n",
            "tensor([[1.4547, 2.0885, 1.2098, 2.0781, 2.0263, 1.3174, 1.3159],\n",
            "        [2.8169, 3.7371, 2.0414, 3.7557, 3.7352, 2.1656, 2.2371],\n",
            "        [0.7487, 1.1687, 0.7385, 1.1613, 1.1048, 0.7867, 0.8053],\n",
            "        [3.0796, 4.0427, 2.1943, 4.0560, 4.0238, 2.3485, 2.4191],\n",
            "        [1.7483, 2.4588, 1.3945, 2.4504, 2.4032, 1.5156, 1.5193]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "178\n",
            "tensor([[1.3519, 1.9584, 1.1449, 1.9462, 1.8946, 1.2428, 1.2421],\n",
            "        [1.6352, 2.3196, 1.3290, 2.3097, 2.2625, 1.4423, 1.4418],\n",
            "        [2.4456, 3.3054, 1.8238, 3.3124, 3.2770, 1.9472, 1.9903],\n",
            "        [3.0474, 4.0023, 2.1770, 4.0217, 3.9917, 2.3221, 2.3932],\n",
            "        [1.2324, 1.8043, 1.0671, 1.7944, 1.7394, 1.1612, 1.1598]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "179\n",
            "tensor([[0.9785, 1.4737, 0.8998, 1.4644, 1.4076, 0.9703, 0.9754],\n",
            "        [1.2185, 1.7859, 1.0599, 1.7751, 1.7213, 1.1495, 1.1466],\n",
            "        [2.3466, 3.1856, 1.7658, 3.1896, 3.1558, 1.8918, 1.9234],\n",
            "        [1.3866, 2.0049, 1.1682, 1.9918, 1.9393, 1.2711, 1.2665],\n",
            "        [3.0663, 4.0232, 2.1911, 4.0409, 4.0129, 2.3351, 2.4047]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "180\n",
            "tensor([[2.9574, 3.8972, 2.1280, 3.9177, 3.8923, 2.2594, 2.3292],\n",
            "        [3.0284, 3.9790, 2.1692, 3.9964, 3.9705, 2.3099, 2.3745],\n",
            "        [0.9319, 1.4133, 0.8668, 1.4033, 1.3462, 0.9325, 0.9406],\n",
            "        [1.4663, 2.1034, 1.2199, 2.0926, 2.0412, 1.3239, 1.3213],\n",
            "        [3.0046, 3.9538, 2.1559, 3.9704, 3.9461, 2.2929, 2.3596]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "181\n",
            "tensor([[1.5516, 2.2121, 1.2761, 2.1989, 2.1503, 1.3823, 1.3781],\n",
            "        [1.9901, 2.7574, 1.5512, 2.7518, 2.7108, 1.6672, 1.6791],\n",
            "        [1.0719, 1.5947, 0.9637, 1.5839, 1.5281, 1.0391, 1.0403],\n",
            "        [2.8213, 3.7443, 2.0498, 3.7612, 3.7387, 2.1702, 2.2351],\n",
            "        [3.0815, 4.0407, 2.2016, 4.0568, 4.0277, 2.3436, 2.4109]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "182\n",
            "tensor([[1.3102, 1.9055, 1.1221, 1.8911, 1.8407, 1.2134, 1.2081],\n",
            "        [2.5980, 3.4852, 1.9198, 3.4934, 3.4665, 2.0398, 2.0836],\n",
            "        [1.6674, 2.3579, 1.3494, 2.3470, 2.2993, 1.4619, 1.4578],\n",
            "        [3.0901, 4.0510, 2.2080, 4.0677, 4.0339, 2.3494, 2.4155],\n",
            "        [2.5321, 3.4098, 1.8808, 3.4171, 3.3863, 2.0004, 2.0409]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "183\n",
            "tensor([[1.5809, 2.2512, 1.2960, 2.2373, 2.1906, 1.4008, 1.3963],\n",
            "        [2.9489, 3.8881, 2.1272, 3.9045, 3.8846, 2.2560, 2.3140],\n",
            "        [2.6302, 3.5233, 1.9401, 3.5329, 3.5077, 2.0567, 2.1040],\n",
            "        [1.2526, 1.8329, 1.0851, 1.8174, 1.7644, 1.1713, 1.1671],\n",
            "        [2.5591, 3.4436, 1.8993, 3.4519, 3.4241, 2.0152, 2.0581]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "184\n",
            "tensor([[2.3878, 3.2390, 1.7955, 3.2396, 3.2106, 1.9119, 1.9392],\n",
            "        [3.0952, 4.0615, 2.2119, 4.0717, 4.0423, 2.3559, 2.4121],\n",
            "        [2.7809, 3.6994, 2.0270, 3.7086, 3.6864, 2.1483, 2.1980],\n",
            "        [2.6740, 3.5757, 1.9657, 3.5828, 3.5569, 2.0918, 2.1294],\n",
            "        [2.7074, 3.6138, 1.9847, 3.6228, 3.6010, 2.1004, 2.1497]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "185\n",
            "tensor([[2.9530, 3.8946, 2.1284, 3.9069, 3.8868, 2.2515, 2.3064],\n",
            "        [1.7785, 2.4986, 1.4230, 2.4858, 2.4432, 1.5334, 1.5269],\n",
            "        [1.1458, 1.6938, 1.0154, 1.6793, 1.6260, 1.0942, 1.0875],\n",
            "        [1.6624, 2.3546, 1.3486, 2.3387, 2.2948, 1.4575, 1.4471],\n",
            "        [3.0136, 3.9622, 2.1648, 3.9749, 3.9534, 2.2961, 2.3483]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "186\n",
            "tensor([[2.9598, 3.9022, 2.1329, 3.9155, 3.8949, 2.2634, 2.3101],\n",
            "        [2.9740, 3.9188, 2.1397, 3.9295, 3.9067, 2.2762, 2.3200],\n",
            "        [1.1114, 1.6496, 0.9921, 1.6351, 1.5810, 1.0683, 1.0620],\n",
            "        [1.0457, 1.5632, 0.9484, 1.5498, 1.4947, 1.0213, 1.0143],\n",
            "        [2.9764, 3.9203, 2.1430, 3.9322, 3.9117, 2.2706, 2.3198]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "187\n",
            "tensor([[1.4319, 2.0621, 1.2004, 2.0459, 1.9966, 1.3014, 1.2856],\n",
            "        [1.4097, 2.0348, 1.1859, 2.0173, 1.9703, 1.2844, 1.2696],\n",
            "        [2.5189, 3.3947, 1.8702, 3.3956, 3.3703, 1.9920, 2.0170],\n",
            "        [3.0717, 4.0359, 2.1925, 4.0398, 4.0094, 2.3363, 2.3862],\n",
            "        [2.1605, 2.9670, 1.6573, 2.9594, 2.9254, 1.7760, 1.7793]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "188\n",
            "tensor([[2.6410, 3.5401, 1.9423, 3.5425, 3.5202, 2.0646, 2.0944],\n",
            "        [3.0601, 4.0146, 2.1844, 4.0248, 3.9978, 2.3165, 2.3707],\n",
            "        [2.8628, 3.7921, 2.0702, 3.7999, 3.7806, 2.2005, 2.2390],\n",
            "        [0.9995, 1.5023, 0.9146, 1.4881, 1.4338, 0.9861, 0.9781],\n",
            "        [1.1321, 1.6764, 1.0027, 1.6604, 1.6071, 1.0865, 1.0738]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "189\n",
            "tensor([[3.0512, 4.0008, 2.1765, 4.0114, 3.9895, 2.3159, 2.3611],\n",
            "        [1.5541, 2.2171, 1.2750, 2.2005, 2.1541, 1.3854, 1.3655],\n",
            "        [1.6151, 2.2934, 1.3129, 2.2758, 2.2307, 1.4214, 1.4060],\n",
            "        [1.4539, 2.0895, 1.2107, 2.0724, 2.0239, 1.3156, 1.2965],\n",
            "        [2.8499, 3.7736, 2.0588, 3.7829, 3.7608, 2.1884, 2.2271]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "190\n",
            "tensor([[2.6655, 3.5591, 1.9478, 3.5633, 3.5389, 2.0760, 2.1031],\n",
            "        [1.8363, 2.5666, 1.4477, 2.5520, 2.5103, 1.5674, 1.5546],\n",
            "        [2.1023, 2.8920, 1.6118, 2.8835, 2.8458, 1.7362, 1.7318],\n",
            "        [2.9225, 3.8527, 2.0962, 3.8608, 3.8407, 2.2329, 2.2692],\n",
            "        [3.0867, 4.0360, 2.1921, 4.0474, 4.0192, 2.3323, 2.3804]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "191\n",
            "tensor([[3.0192, 3.9578, 2.1477, 3.9702, 3.9466, 2.2913, 2.3317],\n",
            "        [1.9771, 2.7359, 1.5304, 2.7221, 2.6826, 1.6556, 1.6446],\n",
            "        [2.2603, 3.0813, 1.7031, 3.0738, 3.0407, 1.8296, 1.8339],\n",
            "        [1.1607, 1.7100, 1.0154, 1.6926, 1.6398, 1.1018, 1.0875],\n",
            "        [3.0912, 4.0439, 2.1890, 4.0494, 4.0256, 2.3358, 2.3772]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "192\n",
            "tensor([[2.4606, 3.3189, 1.8179, 3.3146, 3.2828, 1.9466, 1.9634],\n",
            "        [2.9841, 3.9167, 2.1211, 3.9237, 3.9057, 2.2597, 2.3011],\n",
            "        [3.0073, 3.9410, 2.1343, 3.9511, 3.9327, 2.2753, 2.3169],\n",
            "        [1.9238, 2.6696, 1.4963, 2.6543, 2.6153, 1.6140, 1.6061],\n",
            "        [1.4492, 2.0785, 1.1998, 2.0597, 2.0112, 1.3029, 1.2865]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "193\n",
            "tensor([[1.9783, 2.7380, 1.5251, 2.7227, 2.6831, 1.6481, 1.6430],\n",
            "        [2.2482, 3.0624, 1.6884, 3.0526, 3.0182, 1.8134, 1.8197],\n",
            "        [2.8055, 3.7149, 2.0144, 3.7174, 3.6930, 2.1514, 2.1862],\n",
            "        [2.1081, 2.8934, 1.6048, 2.8808, 2.8428, 1.7307, 1.7276],\n",
            "        [0.9995, 1.4982, 0.9059, 1.4830, 1.4276, 0.9781, 0.9723]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "194\n",
            "tensor([[1.5958, 2.2621, 1.2890, 2.2421, 2.1967, 1.3967, 1.3831],\n",
            "        [2.1880, 2.9893, 1.6522, 2.9773, 2.9437, 1.7711, 1.7797],\n",
            "        [3.0665, 4.0083, 2.1631, 4.0160, 3.9930, 2.3038, 2.3550],\n",
            "        [1.7420, 2.4432, 1.3779, 2.4226, 2.3801, 1.4924, 1.4798],\n",
            "        [1.5995, 2.2658, 1.2912, 2.2457, 2.2002, 1.3996, 1.3864]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "195\n",
            "tensor([[3.1258, 4.0756, 2.1969, 4.0763, 4.0476, 2.3424, 2.3945],\n",
            "        [2.6661, 3.5530, 1.9320, 3.5506, 3.5266, 2.0546, 2.0916],\n",
            "        [3.1167, 4.0674, 2.1920, 4.0672, 4.0398, 2.3339, 2.3881],\n",
            "        [0.9901, 1.4846, 0.8989, 1.4690, 1.4143, 0.9679, 0.9650],\n",
            "        [2.3206, 3.1473, 1.7289, 3.1355, 3.1046, 1.8487, 1.8657]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "196\n",
            "tensor([[1.4925, 2.1302, 1.2235, 2.1083, 2.0627, 1.3253, 1.3130],\n",
            "        [1.5858, 2.2490, 1.2817, 2.2278, 2.1840, 1.3879, 1.3780],\n",
            "        [0.8839, 1.3449, 0.8270, 1.3292, 1.2754, 0.8838, 0.8873],\n",
            "        [3.0944, 4.0331, 2.1752, 4.0381, 4.0184, 2.3063, 2.3683],\n",
            "        [1.8072, 2.5227, 1.4195, 2.5038, 2.4635, 1.5313, 1.5256]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "197\n",
            "tensor([[3.0896, 4.0329, 2.1747, 4.0340, 4.0120, 2.3112, 2.3697],\n",
            "        [3.1020, 4.0459, 2.1788, 4.0467, 4.0178, 2.3178, 2.3785],\n",
            "        [1.7517, 2.4554, 1.3841, 2.4331, 2.3942, 1.4926, 1.4869],\n",
            "        [2.2258, 3.0333, 1.6711, 3.0186, 2.9873, 1.7912, 1.8052],\n",
            "        [1.9277, 2.6714, 1.4920, 2.6519, 2.6153, 1.6061, 1.6064]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "198\n",
            "tensor([[1.1507, 1.6938, 1.0032, 1.6717, 1.6228, 1.0827, 1.0766],\n",
            "        [2.2908, 3.1088, 1.7106, 3.0954, 3.0673, 1.8267, 1.8459],\n",
            "        [1.3277, 1.9203, 1.1195, 1.8993, 1.8510, 1.2111, 1.1993],\n",
            "        [0.9123, 1.3815, 0.8462, 1.3646, 1.3124, 0.9045, 0.9076],\n",
            "        [1.0558, 1.5694, 0.9425, 1.5505, 1.4991, 1.0141, 1.0104]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "199\n",
            "tensor([[2.6590, 3.5382, 1.9250, 3.5316, 3.5182, 2.0327, 2.0834],\n",
            "        [1.1079, 1.6372, 0.9764, 1.6181, 1.5679, 1.0520, 1.0483],\n",
            "        [1.2735, 1.8508, 1.0836, 1.8287, 1.7812, 1.1704, 1.1628],\n",
            "        [2.1258, 2.9092, 1.6105, 2.8910, 2.8628, 1.7240, 1.7370],\n",
            "        [2.8842, 3.7973, 2.0545, 3.7943, 3.7785, 2.1770, 2.2344]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "200\n",
            "tensor([[2.0599, 2.8291, 1.5704, 2.8095, 2.7785, 1.6818, 1.6940],\n",
            "        [2.6796, 3.5641, 1.9358, 3.5568, 3.5356, 2.0491, 2.1023],\n",
            "        [2.5418, 3.3996, 1.8564, 3.3889, 3.3703, 1.9735, 2.0075],\n",
            "        [2.3409, 3.1611, 1.7387, 3.1472, 3.1235, 1.8510, 1.8748],\n",
            "        [2.1661, 2.9557, 1.6361, 2.9383, 2.9125, 1.7424, 1.7610]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "201\n",
            "tensor([[2.4187, 3.2547, 1.7850, 3.2418, 3.2211, 1.8982, 1.9285],\n",
            "        [3.0297, 3.9551, 2.1387, 3.9537, 3.9412, 2.2634, 2.3260],\n",
            "        [1.9968, 2.7488, 1.5322, 2.7273, 2.6968, 1.6399, 1.6505],\n",
            "        [2.9970, 3.9186, 2.1181, 3.9172, 3.9064, 2.2325, 2.3037],\n",
            "        [0.9201, 1.3891, 0.8521, 1.3719, 1.3200, 0.9081, 0.9141]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "202\n",
            "tensor([[1.9544, 2.6964, 1.5058, 2.6756, 2.6420, 1.6150, 1.6236],\n",
            "        [2.9121, 3.8204, 2.0676, 3.8174, 3.8073, 2.1785, 2.2488],\n",
            "        [1.5645, 2.2160, 1.2677, 2.1933, 2.1530, 1.3653, 1.3632],\n",
            "        [1.4021, 2.0104, 1.1655, 1.9862, 1.9438, 1.2543, 1.2505],\n",
            "        [3.0489, 3.9728, 2.1454, 3.9714, 3.9619, 2.2686, 2.3373]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "203\n",
            "tensor([[3.0333, 3.9553, 2.1381, 3.9524, 3.9449, 2.2637, 2.3312],\n",
            "        [3.0877, 4.0164, 2.1668, 4.0144, 4.0036, 2.2882, 2.3667],\n",
            "        [1.9860, 2.7332, 1.5246, 2.7108, 2.6831, 1.6344, 1.6449],\n",
            "        [3.1237, 4.0567, 2.1889, 4.0543, 4.0413, 2.3200, 2.3910],\n",
            "        [2.5045, 3.3531, 1.8325, 3.3407, 3.3265, 1.9432, 1.9856]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "204\n",
            "tensor([[2.8005, 3.6910, 2.0022, 3.6864, 3.6787, 2.1228, 2.1809],\n",
            "        [0.9778, 1.4627, 0.8893, 1.4439, 1.3956, 0.9522, 0.9564],\n",
            "        [2.7052, 3.5805, 1.9481, 3.5739, 3.5658, 2.0656, 2.1178],\n",
            "        [2.1519, 2.9302, 1.6228, 2.9131, 2.8902, 1.7368, 1.7573],\n",
            "        [3.0681, 3.9901, 2.1554, 3.9906, 3.9852, 2.2804, 2.3549]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "205\n",
            "tensor([[2.4900, 3.3326, 1.8222, 3.3216, 3.3096, 1.9391, 1.9812],\n",
            "        [2.7026, 3.5767, 1.9446, 3.5709, 3.5656, 2.0589, 2.1191],\n",
            "        [2.5871, 3.4409, 1.8764, 3.4335, 3.4233, 1.9974, 2.0446],\n",
            "        [2.1736, 2.9536, 1.6349, 2.9376, 2.9179, 1.7524, 1.7730],\n",
            "        [2.2653, 3.0681, 1.6884, 3.0528, 3.0343, 1.8029, 1.8352]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "206\n",
            "tensor([[2.5581, 3.4081, 1.8613, 3.4019, 3.3935, 1.9813, 2.0280],\n",
            "        [1.1000, 1.6224, 0.9696, 1.6020, 1.5594, 1.0441, 1.0473],\n",
            "        [1.6402, 2.3057, 1.3123, 2.2843, 2.2518, 1.4169, 1.4197],\n",
            "        [2.5680, 3.4207, 1.8667, 3.4141, 3.4078, 1.9876, 2.0357],\n",
            "        [3.1158, 4.0425, 2.1806, 4.0431, 4.0382, 2.3167, 2.3957]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "207\n",
            "tensor([[2.8228, 3.7111, 2.0094, 3.7109, 3.7095, 2.1337, 2.2021],\n",
            "        [2.6042, 3.4618, 1.8882, 3.4566, 3.4521, 2.0067, 2.0583],\n",
            "        [3.0975, 4.0182, 2.1663, 4.0232, 4.0233, 2.3073, 2.3835],\n",
            "        [1.4497, 2.0670, 1.1901, 2.0451, 2.0082, 1.2871, 1.2902],\n",
            "        [1.2915, 1.8666, 1.0914, 1.8451, 1.8057, 1.1837, 1.1828]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "208\n",
            "tensor([[2.1589, 2.9364, 1.6239, 2.9250, 2.9106, 1.7436, 1.7704],\n",
            "        [3.1070, 4.0310, 2.1714, 4.0354, 4.0330, 2.3152, 2.3941],\n",
            "        [0.8829, 1.3372, 0.8245, 1.3243, 1.2778, 0.8848, 0.8950],\n",
            "        [1.2474, 1.8098, 1.0639, 1.7922, 1.7513, 1.1569, 1.1534],\n",
            "        [2.9287, 3.8269, 2.0703, 3.8340, 3.8372, 2.2069, 2.2737]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "209\n",
            "tensor([[3.0693, 3.9801, 2.1472, 3.9937, 3.9942, 2.2916, 2.3694],\n",
            "        [1.0522, 1.5574, 0.9366, 1.5411, 1.4983, 1.0133, 1.0157],\n",
            "        [1.4194, 2.0304, 1.1679, 2.0077, 1.9772, 1.2703, 1.2701],\n",
            "        [3.0880, 4.0066, 2.1583, 4.0166, 4.0135, 2.3110, 2.3838],\n",
            "        [3.0848, 4.0006, 2.1566, 4.0110, 4.0115, 2.3053, 2.3798]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "210\n",
            "tensor([[3.0424, 3.9522, 2.1283, 3.9629, 3.9658, 2.2809, 2.3544],\n",
            "        [1.3868, 1.9864, 1.1460, 1.9691, 1.9334, 1.2530, 1.2493],\n",
            "        [3.0032, 3.9041, 2.1063, 3.9159, 3.9236, 2.2458, 2.3227],\n",
            "        [3.0669, 3.9780, 2.1436, 3.9910, 3.9957, 2.2983, 2.3689],\n",
            "        [1.0645, 1.5722, 0.9435, 1.5586, 1.5166, 1.0260, 1.0264]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "211\n",
            "tensor([[0.9622, 1.4372, 0.8759, 1.4251, 1.3809, 0.9501, 0.9528],\n",
            "        [1.7909, 2.4848, 1.3979, 2.4720, 2.4489, 1.5262, 1.5279],\n",
            "        [2.8234, 3.6992, 2.0034, 3.7108, 3.7204, 2.1468, 2.2064],\n",
            "        [2.9156, 3.8040, 2.0555, 3.8155, 3.8216, 2.2117, 2.2685],\n",
            "        [1.2598, 1.8207, 1.0704, 1.8051, 1.7696, 1.1689, 1.1633]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "212\n",
            "tensor([[2.2616, 3.0499, 1.6766, 3.0470, 3.0372, 1.8238, 1.8420],\n",
            "        [2.7058, 3.5665, 1.9354, 3.5770, 3.5794, 2.0840, 2.1357],\n",
            "        [1.0610, 1.5649, 0.9405, 1.5534, 1.5120, 1.0287, 1.0254],\n",
            "        [1.9949, 2.7325, 1.5200, 2.7249, 2.7075, 1.6620, 1.6664],\n",
            "        [3.1139, 4.0302, 2.1662, 4.0389, 4.0370, 2.3400, 2.4079]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "213\n",
            "tensor([[2.7551, 3.6226, 1.9627, 3.6361, 3.6457, 2.1197, 2.1680],\n",
            "        [2.6115, 3.4589, 1.8806, 3.4663, 3.4698, 2.0356, 2.0742],\n",
            "        [1.8752, 2.5865, 1.4492, 2.5776, 2.5594, 1.5875, 1.5875],\n",
            "        [2.9217, 3.8080, 2.0568, 3.8262, 3.8365, 2.2263, 2.2770],\n",
            "        [2.9562, 3.8475, 2.0766, 3.8659, 3.8736, 2.2454, 2.3014]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "214\n",
            "tensor([[2.6750, 3.5310, 1.9179, 3.5423, 3.5478, 2.0884, 2.1172],\n",
            "        [0.8580, 1.3025, 0.8069, 1.2944, 1.2492, 0.8786, 0.8810],\n",
            "        [1.7704, 2.4622, 1.3859, 2.4521, 2.4302, 1.5269, 1.5194],\n",
            "        [2.1692, 2.9434, 1.6251, 2.9418, 2.9324, 1.7793, 1.7859],\n",
            "        [0.9203, 1.3845, 0.8479, 1.3739, 1.3318, 0.9258, 0.9256]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "215\n",
            "tensor([[2.7313, 3.5976, 1.9511, 3.6127, 3.6191, 2.1247, 2.1552],\n",
            "        [1.6811, 2.3507, 1.3336, 2.3423, 2.3186, 1.4733, 1.4599],\n",
            "        [1.4792, 2.0998, 1.2099, 2.0893, 2.0597, 1.3387, 1.3207],\n",
            "        [2.9229, 3.8125, 2.0580, 3.8319, 3.8446, 2.2309, 2.2779],\n",
            "        [3.1213, 4.0369, 2.1705, 4.0572, 4.0603, 2.3699, 2.4148]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "216\n",
            "tensor([[2.3897, 3.2042, 1.7547, 3.2113, 3.2088, 1.9215, 1.9333],\n",
            "        [3.0346, 3.9404, 2.1241, 3.9616, 3.9720, 2.3143, 2.3563],\n",
            "        [2.9048, 3.7979, 2.0493, 3.8164, 3.8259, 2.2382, 2.2720],\n",
            "        [2.9962, 3.8963, 2.1016, 3.9180, 3.9303, 2.2835, 2.3294],\n",
            "        [2.2851, 3.0803, 1.6951, 3.0838, 3.0776, 1.8570, 1.8642]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "217\n",
            "tensor([[2.1514, 2.9254, 1.6168, 2.9261, 2.9181, 1.7799, 1.7778],\n",
            "        [1.0898, 1.6073, 0.9622, 1.5978, 1.5590, 1.0671, 1.0510],\n",
            "        [2.9609, 3.8582, 2.0835, 3.8833, 3.8954, 2.2762, 2.3094],\n",
            "        [1.2516, 1.8121, 1.0672, 1.8043, 1.7676, 1.1862, 1.1654],\n",
            "        [1.3199, 1.9017, 1.1109, 1.8918, 1.8571, 1.2343, 1.2130]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "218\n",
            "tensor([[1.3932, 1.9948, 1.1579, 1.9878, 1.9546, 1.2919, 1.2661],\n",
            "        [2.1365, 2.9126, 1.6123, 2.9154, 2.9048, 1.7805, 1.7722],\n",
            "        [1.1974, 1.7468, 1.0332, 1.7388, 1.7001, 1.1510, 1.1306],\n",
            "        [1.4677, 2.0888, 1.2047, 2.0799, 2.0497, 1.3424, 1.3183],\n",
            "        [3.0465, 3.9558, 2.1341, 3.9801, 3.9853, 2.3266, 2.3711]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "219\n",
            "tensor([[1.8918, 2.6161, 1.4650, 2.6147, 2.5964, 1.6312, 1.6090],\n",
            "        [2.7238, 3.5976, 1.9519, 3.6168, 3.6219, 2.1438, 2.1603],\n",
            "        [1.0510, 1.5582, 0.9402, 1.5513, 1.5086, 1.0444, 1.0262],\n",
            "        [3.0878, 4.0110, 2.1561, 4.0306, 4.0292, 2.3737, 2.4063],\n",
            "        [2.8696, 3.7616, 2.0356, 3.7861, 3.7958, 2.2359, 2.2559]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "220\n",
            "tensor([[3.1064, 4.0286, 2.1706, 4.0562, 4.0609, 2.3914, 2.4165],\n",
            "        [2.5343, 3.3813, 1.8449, 3.3986, 3.3987, 2.0327, 2.0380],\n",
            "        [1.0757, 1.5916, 0.9547, 1.5837, 1.5443, 1.0616, 1.0437],\n",
            "        [2.5193, 3.3609, 1.8362, 3.3787, 3.3782, 2.0227, 2.0277],\n",
            "        [1.0739, 1.5881, 0.9544, 1.5810, 1.5398, 1.0638, 1.0426]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "221\n",
            "tensor([[1.6210, 2.2826, 1.3026, 2.2785, 2.2524, 1.4555, 1.4269],\n",
            "        [1.2931, 1.8699, 1.0955, 1.8643, 1.8271, 1.2279, 1.1991],\n",
            "        [2.2673, 3.0662, 1.6894, 3.0762, 3.0672, 1.8692, 1.8632],\n",
            "        [1.3894, 1.9909, 1.1589, 1.9861, 1.9523, 1.2976, 1.2672],\n",
            "        [1.7266, 2.4133, 1.3668, 2.4117, 2.3865, 1.5287, 1.4995]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "222\n",
            "tensor([[1.1579, 1.6974, 1.0110, 1.6915, 1.6510, 1.1303, 1.1046],\n",
            "        [2.2339, 3.0244, 1.6720, 3.0335, 3.0241, 1.8552, 1.8384],\n",
            "        [2.9347, 3.8325, 2.0762, 3.8624, 3.8739, 2.2732, 2.3003],\n",
            "        [2.2810, 3.0823, 1.7005, 3.0925, 3.0871, 1.8809, 1.8710],\n",
            "        [0.9692, 1.4517, 0.8866, 1.4474, 1.4028, 0.9852, 0.9698]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "223\n",
            "tensor([[2.5202, 3.3631, 1.8436, 3.3813, 3.3803, 2.0308, 2.0292],\n",
            "        [2.7386, 3.6132, 1.9692, 3.6388, 3.6433, 2.1617, 2.1730],\n",
            "        [2.7810, 3.6630, 1.9926, 3.6897, 3.6950, 2.1899, 2.2015],\n",
            "        [1.0052, 1.4986, 0.9126, 1.4929, 1.4487, 1.0125, 0.9943],\n",
            "        [3.0368, 3.9476, 2.1385, 3.9793, 3.9856, 2.3520, 2.3694]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "224\n",
            "tensor([[3.0942, 4.0078, 2.1700, 4.0413, 4.0449, 2.3878, 2.4078],\n",
            "        [2.8201, 3.7050, 2.0165, 3.7342, 3.7410, 2.2097, 2.2242],\n",
            "        [1.8384, 2.5489, 1.4393, 2.5493, 2.5266, 1.6028, 1.5752],\n",
            "        [3.0579, 3.9665, 2.1489, 3.9993, 4.0059, 2.3517, 2.3767],\n",
            "        [1.0878, 1.6066, 0.9676, 1.5999, 1.5583, 1.0767, 1.0539]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "225\n",
            "tensor([[2.3791, 3.1971, 1.7650, 3.2127, 3.2058, 1.9454, 1.9370],\n",
            "        [3.0844, 3.9977, 2.1666, 4.0296, 4.0320, 2.3750, 2.3988],\n",
            "        [3.1194, 4.0351, 2.1865, 4.0683, 4.0694, 2.4038, 2.4230],\n",
            "        [3.0528, 3.9617, 2.1504, 3.9949, 4.0016, 2.3634, 2.3776],\n",
            "        [3.1077, 4.0213, 2.1787, 4.0550, 4.0577, 2.3931, 2.4142]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "226\n",
            "tensor([[1.2975, 1.8697, 1.1059, 1.8663, 1.8274, 1.2319, 1.1996],\n",
            "        [1.9613, 2.6956, 1.5166, 2.6995, 2.6797, 1.6800, 1.6556],\n",
            "        [3.0489, 3.9498, 2.1503, 3.9854, 3.9910, 2.3528, 2.3718],\n",
            "        [1.3529, 1.9398, 1.1404, 1.9354, 1.8980, 1.2719, 1.2374],\n",
            "        [1.9422, 2.6711, 1.5054, 2.6741, 2.6546, 1.6711, 1.6422]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "227\n",
            "tensor([[2.9274, 3.8113, 2.0834, 3.8445, 3.8524, 2.2742, 2.2895],\n",
            "        [3.0831, 3.9925, 2.1709, 4.0196, 4.0146, 2.3740, 2.3976],\n",
            "        [1.7094, 2.3839, 1.3647, 2.3822, 2.3571, 1.5144, 1.4823],\n",
            "        [1.7991, 2.4940, 1.4218, 2.4975, 2.4710, 1.5782, 1.5461],\n",
            "        [0.9725, 1.4506, 0.8939, 1.4473, 1.4011, 0.9873, 0.9691]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "228\n",
            "tensor([[3.1306, 4.0397, 2.2004, 4.0708, 4.0683, 2.4100, 2.4245],\n",
            "        [3.1236, 4.0277, 2.1962, 4.0614, 4.0639, 2.4002, 2.4177],\n",
            "        [1.1521, 1.6833, 1.0128, 1.6779, 1.6361, 1.1229, 1.0967],\n",
            "        [1.4496, 2.0594, 1.2054, 2.0553, 2.0206, 1.3389, 1.3037],\n",
            "        [1.7911, 2.4837, 1.4173, 2.4844, 2.4593, 1.5707, 1.5388]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "229\n",
            "tensor([[1.2789, 1.8414, 1.0952, 1.8371, 1.7973, 1.2153, 1.1845],\n",
            "        [2.9441, 3.8268, 2.0946, 3.8609, 3.8669, 2.2813, 2.2969],\n",
            "        [2.9691, 3.8541, 2.1103, 3.8860, 3.8935, 2.2877, 2.3120],\n",
            "        [1.0730, 1.5798, 0.9627, 1.5769, 1.5318, 1.0659, 1.0397],\n",
            "        [3.0604, 3.9527, 2.1625, 3.9882, 3.9955, 2.3510, 2.3723]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "230\n",
            "tensor([[3.0494, 3.9391, 2.1569, 3.9739, 3.9812, 2.3336, 2.3634],\n",
            "        [2.2286, 3.0038, 1.6834, 3.0173, 3.0021, 1.8465, 1.8284],\n",
            "        [1.0509, 1.5491, 0.9480, 1.5460, 1.4995, 1.0459, 1.0227],\n",
            "        [1.6350, 2.2864, 1.3228, 2.2865, 2.2547, 1.4625, 1.4312],\n",
            "        [0.8468, 1.2849, 0.8083, 1.2817, 1.2347, 0.8850, 0.8761]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "231\n",
            "tensor([[1.0526, 1.5506, 0.9499, 1.5461, 1.5032, 1.0447, 1.0220],\n",
            "        [2.5898, 3.4213, 1.8976, 3.4458, 3.4436, 2.0627, 2.0616],\n",
            "        [2.7589, 3.6162, 1.9944, 3.6442, 3.6487, 2.1599, 2.1736],\n",
            "        [1.4897, 2.1055, 1.2322, 2.1015, 2.0685, 1.3607, 1.3278],\n",
            "        [2.4843, 3.2982, 1.8354, 3.3212, 3.3149, 1.9956, 1.9942]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "232\n",
            "tensor([[1.4694, 2.0782, 1.2221, 2.0744, 2.0397, 1.3464, 1.3140],\n",
            "        [2.1087, 2.8566, 1.6162, 2.8678, 2.8488, 1.7656, 1.7447],\n",
            "        [2.8602, 3.7265, 2.0578, 3.7601, 3.7662, 2.2206, 2.2353],\n",
            "        [3.1353, 4.0344, 2.2130, 4.0668, 4.0591, 2.4002, 2.4215],\n",
            "        [1.3615, 1.9430, 1.1532, 1.9406, 1.9020, 1.2731, 1.2394]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "233\n",
            "tensor([[1.7801, 2.4597, 1.4178, 2.4610, 2.4329, 1.5561, 1.5227],\n",
            "        [3.0681, 3.9553, 2.1796, 3.9925, 3.9947, 2.3475, 2.3693],\n",
            "        [2.7451, 3.5956, 1.9951, 3.6262, 3.6265, 2.1438, 2.1557],\n",
            "        [3.1359, 4.0325, 2.2165, 4.0666, 4.0626, 2.3944, 2.4171],\n",
            "        [1.9886, 2.7161, 1.5457, 2.7219, 2.6995, 1.6911, 1.6645]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "234\n",
            "tensor([[3.0161, 3.8982, 2.1544, 3.9344, 3.9352, 2.3094, 2.3331],\n",
            "        [2.6459, 3.4810, 1.9413, 3.5083, 3.5032, 2.0896, 2.0924],\n",
            "        [1.2355, 1.7828, 1.0779, 1.7789, 1.7373, 1.1803, 1.1493],\n",
            "        [1.0566, 1.5543, 0.9587, 1.5511, 1.5054, 1.0461, 1.0231],\n",
            "        [0.8158, 1.2433, 0.7947, 1.2414, 1.1913, 0.8598, 0.8511]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "235\n",
            "tensor([[2.8490, 3.7094, 2.0627, 3.7419, 3.7402, 2.2175, 2.2207],\n",
            "        [1.2401, 1.7878, 1.0830, 1.7842, 1.7430, 1.1849, 1.1500],\n",
            "        [3.0675, 3.9521, 2.1876, 3.9893, 3.9910, 2.3480, 2.3639],\n",
            "        [2.7241, 3.5688, 1.9911, 3.5976, 3.5942, 2.1362, 2.1381],\n",
            "        [3.1130, 4.0012, 2.2139, 4.0411, 4.0381, 2.3751, 2.3943]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "236\n",
            "tensor([[1.0553, 1.5514, 0.9632, 1.5517, 1.5029, 1.0495, 1.0222],\n",
            "        [3.0402, 3.9215, 2.1745, 3.9580, 3.9607, 2.3239, 2.3426],\n",
            "        [2.0755, 2.8149, 1.6091, 2.8238, 2.8009, 1.7431, 1.7138],\n",
            "        [2.2413, 3.0135, 1.7084, 3.0278, 3.0075, 1.8516, 1.8264],\n",
            "        [2.8373, 3.6948, 2.0554, 3.7254, 3.7189, 2.2166, 2.2118]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "237\n",
            "tensor([[2.2070, 2.9705, 1.6914, 2.9851, 2.9642, 1.8246, 1.8001],\n",
            "        [2.8786, 3.7406, 2.0840, 3.7750, 3.7757, 2.2210, 2.2341],\n",
            "        [0.7683, 1.1797, 0.7662, 1.1796, 1.1287, 0.8203, 0.8146],\n",
            "        [1.2177, 1.7584, 1.0730, 1.7570, 1.7127, 1.1684, 1.1338],\n",
            "        [2.1519, 2.9075, 1.6575, 2.9203, 2.8991, 1.7926, 1.7661]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "238\n",
            "tensor([[0.8257, 1.2549, 0.8073, 1.2540, 1.2030, 0.8680, 0.8549],\n",
            "        [0.8812, 1.3266, 0.8449, 1.3251, 1.2744, 0.9110, 0.8943],\n",
            "        [0.9024, 1.3546, 0.8612, 1.3534, 1.3035, 0.9282, 0.9109],\n",
            "        [2.9404, 3.8099, 2.1234, 3.8483, 3.8459, 2.2674, 2.2725],\n",
            "        [2.1493, 2.9043, 1.6598, 2.9179, 2.8989, 1.7894, 1.7618]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "239\n",
            "tensor([[1.6822, 2.3372, 1.3733, 2.3432, 2.3080, 1.4925, 1.4494],\n",
            "        [0.7716, 1.1833, 0.7706, 1.1830, 1.1316, 0.8227, 0.8144],\n",
            "        [0.8076, 1.2307, 0.7963, 1.2312, 1.1797, 0.8532, 0.8411],\n",
            "        [2.5801, 3.4054, 1.9164, 3.4350, 3.4226, 2.0524, 2.0403],\n",
            "        [1.1640, 1.6901, 1.0388, 1.6901, 1.6428, 1.1286, 1.0949]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "240\n",
            "tensor([[2.4217, 3.2204, 1.8252, 3.2442, 3.2303, 1.9545, 1.9320],\n",
            "        [2.7241, 3.5701, 2.0017, 3.6052, 3.5947, 2.1303, 2.1314],\n",
            "        [0.9261, 1.3839, 0.8811, 1.3860, 1.3331, 0.9520, 0.9263],\n",
            "        [1.5132, 2.1305, 1.2672, 2.1331, 2.0918, 1.3796, 1.3348],\n",
            "        [0.9333, 1.3928, 0.8846, 1.3951, 1.3429, 0.9538, 0.9319]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "241\n",
            "tensor([[1.1606, 1.6851, 1.0375, 1.6860, 1.6363, 1.1240, 1.0895],\n",
            "        [1.2115, 1.7511, 1.0716, 1.7516, 1.7065, 1.1628, 1.1251],\n",
            "        [2.0970, 2.8383, 1.6318, 2.8550, 2.8276, 1.7575, 1.7207],\n",
            "        [2.9693, 3.8418, 2.1454, 3.8837, 3.8741, 2.2847, 2.2866],\n",
            "        [1.6840, 2.3394, 1.3761, 2.3454, 2.3095, 1.4873, 1.4471]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "242\n",
            "tensor([[2.5113, 3.3243, 1.8818, 3.3540, 3.3350, 2.0065, 1.9885],\n",
            "        [2.7652, 3.6124, 2.0290, 3.6504, 3.6381, 2.1593, 2.1507],\n",
            "        [2.8387, 3.6957, 2.0715, 3.7350, 3.7242, 2.2025, 2.1996],\n",
            "        [3.0974, 3.9837, 2.2214, 4.0283, 4.0164, 2.3664, 2.3679],\n",
            "        [1.0904, 1.5956, 0.9936, 1.5969, 1.5471, 1.0743, 1.0400]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "243\n",
            "tensor([[1.5475, 2.1724, 1.2929, 2.1774, 2.1360, 1.3974, 1.3529],\n",
            "        [3.1216, 4.0089, 2.2363, 4.0554, 4.0424, 2.3823, 2.3801],\n",
            "        [1.3005, 1.8628, 1.1328, 1.8658, 1.8173, 1.2254, 1.1853],\n",
            "        [1.0488, 1.5427, 0.9668, 1.5464, 1.4924, 1.0440, 1.0110],\n",
            "        [2.8727, 3.7339, 2.0927, 3.7751, 3.7674, 2.2212, 2.2183]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "244\n",
            "tensor([[2.0955, 2.8349, 1.6331, 2.8537, 2.8233, 1.7507, 1.7137],\n",
            "        [1.6085, 2.2453, 1.3319, 2.2536, 2.2122, 1.4413, 1.3926],\n",
            "        [1.5834, 2.2161, 1.3177, 2.2238, 2.1813, 1.4250, 1.3777],\n",
            "        [0.7401, 1.1412, 0.7530, 1.1438, 1.0896, 0.7970, 0.7891],\n",
            "        [2.4895, 3.2976, 1.8711, 3.3296, 3.3126, 1.9890, 1.9709]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "245\n",
            "tensor([[0.9961, 1.4738, 0.9301, 1.4769, 1.4230, 1.0012, 0.9715],\n",
            "        [3.0868, 3.9703, 2.2190, 4.0178, 4.0052, 2.3554, 2.3572],\n",
            "        [2.7158, 3.5501, 2.0024, 3.5910, 3.5768, 2.1277, 2.1134],\n",
            "        [1.0510, 1.5442, 0.9694, 1.5468, 1.4947, 1.0431, 1.0093],\n",
            "        [3.1302, 4.0138, 2.2416, 4.0635, 4.0501, 2.3784, 2.3822]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "246\n",
            "tensor([[2.5173, 3.3277, 1.8886, 3.3635, 3.3402, 2.0110, 1.9860],\n",
            "        [1.5220, 2.1381, 1.2795, 2.1464, 2.1026, 1.3795, 1.3322],\n",
            "        [3.0789, 3.9616, 2.2143, 4.0112, 3.9940, 2.3576, 2.3501],\n",
            "        [1.6430, 2.2852, 1.3556, 2.2979, 2.2560, 1.4627, 1.4142],\n",
            "        [3.1111, 3.9917, 2.2307, 4.0435, 4.0319, 2.3638, 2.3695]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "247\n",
            "tensor([[2.6579, 3.4839, 1.9697, 3.5264, 3.5104, 2.0910, 2.0745],\n",
            "        [1.1320, 1.6479, 1.0237, 1.6521, 1.6010, 1.1031, 1.0659],\n",
            "        [1.3208, 1.8866, 1.1475, 1.8928, 1.8442, 1.2425, 1.1967],\n",
            "        [2.3731, 3.1590, 1.8026, 3.1897, 3.1696, 1.9156, 1.8913],\n",
            "        [1.5460, 2.1677, 1.2953, 2.1771, 2.1335, 1.3973, 1.3504]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "248\n",
            "tensor([[3.0483, 3.9226, 2.1931, 3.9760, 3.9642, 2.3348, 2.3268],\n",
            "        [1.4789, 2.0829, 1.2515, 2.0951, 2.0475, 1.3541, 1.3047],\n",
            "        [3.0895, 3.9696, 2.2181, 4.0222, 4.0048, 2.3590, 2.3545],\n",
            "        [1.2804, 1.8344, 1.1207, 1.8405, 1.7910, 1.2086, 1.1669],\n",
            "        [2.8791, 3.7366, 2.0973, 3.7848, 3.7736, 2.2249, 2.2168]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "249\n",
            "tensor([[2.0018, 2.7203, 1.5755, 2.7431, 2.7077, 1.6945, 1.6520],\n",
            "        [1.1162, 1.6248, 1.0121, 1.6331, 1.5789, 1.0920, 1.0542],\n",
            "        [3.0182, 3.8863, 2.1736, 3.9404, 3.9255, 2.3099, 2.3055],\n",
            "        [2.0900, 2.8243, 1.6306, 2.8495, 2.8155, 1.7509, 1.7080],\n",
            "        [2.7456, 3.5815, 2.0167, 3.6295, 3.6181, 2.1370, 2.1272]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "250\n",
            "tensor([[0.9648, 1.4311, 0.9101, 1.4404, 1.3839, 0.9793, 0.9500],\n",
            "        [2.8810, 3.7326, 2.0944, 3.7867, 3.7721, 2.2233, 2.2183],\n",
            "        [1.6137, 2.2504, 1.3334, 2.2641, 2.2204, 1.4452, 1.3948],\n",
            "        [2.9438, 3.8019, 2.1292, 3.8569, 3.8414, 2.2708, 2.2596],\n",
            "        [1.0334, 1.5194, 0.9569, 1.5283, 1.4718, 1.0307, 0.9981]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "251\n",
            "tensor([[2.3529, 3.1312, 1.7842, 3.1685, 3.1380, 1.9107, 1.8800],\n",
            "        [2.3635, 3.1453, 1.7907, 3.1820, 3.1564, 1.9136, 1.8861],\n",
            "        [1.9540, 2.6617, 1.5431, 2.6846, 2.6461, 1.6692, 1.6192],\n",
            "        [1.7857, 2.4615, 1.4429, 2.4798, 2.4398, 1.5590, 1.5103],\n",
            "        [1.3766, 1.9543, 1.1835, 1.9675, 1.9168, 1.2853, 1.2362]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "252\n",
            "tensor([[1.4522, 2.0469, 1.2307, 2.0608, 2.0103, 1.3349, 1.2865],\n",
            "        [1.1082, 1.6151, 1.0072, 1.6242, 1.5692, 1.0890, 1.0506],\n",
            "        [1.9915, 2.7064, 1.5671, 2.7317, 2.6926, 1.6902, 1.6443],\n",
            "        [2.5168, 3.3206, 1.8797, 3.3637, 3.3382, 2.0126, 1.9857],\n",
            "        [1.0950, 1.5982, 0.9997, 1.6090, 1.5517, 1.0819, 1.0414]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "253\n",
            "tensor([[0.9091, 1.3602, 0.8715, 1.3683, 1.3109, 0.9359, 0.9112],\n",
            "        [1.8361, 2.5194, 1.4711, 2.5412, 2.5000, 1.5894, 1.5418],\n",
            "        [1.2058, 1.7394, 1.0712, 1.7488, 1.6955, 1.1596, 1.1170],\n",
            "        [2.3150, 3.0887, 1.7616, 3.1263, 3.0967, 1.8884, 1.8562],\n",
            "        [1.9833, 2.6968, 1.5627, 2.7247, 2.6861, 1.6861, 1.6411]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "254\n",
            "tensor([[2.2945, 3.0649, 1.7503, 3.1038, 3.0728, 1.8797, 1.8448],\n",
            "        [0.9926, 1.4646, 0.9281, 1.4770, 1.4182, 1.0037, 0.9700],\n",
            "        [2.7404, 3.5720, 2.0095, 3.6263, 3.6036, 2.1453, 2.1276],\n",
            "        [2.9523, 3.8104, 2.1327, 3.8700, 3.8543, 2.2835, 2.2659],\n",
            "        [3.0621, 3.9315, 2.1941, 3.9938, 3.9758, 2.3431, 2.3366]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "255\n",
            "tensor([[1.8121, 2.4894, 1.4575, 2.5137, 2.4700, 1.5759, 1.5278],\n",
            "        [1.9278, 2.6276, 1.5275, 2.6546, 2.6139, 1.6516, 1.6020],\n",
            "        [2.4480, 3.2437, 1.8420, 3.2897, 3.2598, 1.9720, 1.9435],\n",
            "        [1.2704, 1.8185, 1.1122, 1.8326, 1.7781, 1.2109, 1.1630],\n",
            "        [1.8314, 2.5117, 1.4685, 2.5369, 2.4934, 1.5896, 1.5393]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "256\n",
            "tensor([[3.0346, 3.8997, 2.1793, 3.9662, 3.9470, 2.3291, 2.3175],\n",
            "        [3.0439, 3.9116, 2.1850, 3.9762, 3.9567, 2.3321, 2.3264],\n",
            "        [1.0516, 1.5410, 0.9708, 1.5554, 1.4970, 1.0508, 1.0131],\n",
            "        [3.0859, 3.9565, 2.2107, 4.0232, 4.0020, 2.3622, 2.3532],\n",
            "        [1.3041, 1.8602, 1.1380, 1.8784, 1.8242, 1.2356, 1.1878]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "257\n",
            "tensor([[1.0314, 1.5167, 0.9560, 1.5312, 1.4719, 1.0355, 0.9989],\n",
            "        [2.6675, 3.4904, 1.9737, 3.5473, 3.5239, 2.0988, 2.0822],\n",
            "        [2.7332, 3.5604, 2.0056, 3.6196, 3.5906, 2.1387, 2.1240],\n",
            "        [2.9274, 3.7823, 2.1182, 3.8467, 3.8287, 2.2589, 2.2492],\n",
            "        [0.9711, 1.4360, 0.9163, 1.4516, 1.3913, 0.9884, 0.9552]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "258\n",
            "tensor([[1.3295, 1.8960, 1.1532, 1.9129, 1.8588, 1.2530, 1.2052],\n",
            "        [1.0516, 1.5413, 0.9672, 1.5559, 1.4991, 1.0494, 1.0123],\n",
            "        [1.5826, 2.2065, 1.3170, 2.2305, 2.1806, 1.4297, 1.3760],\n",
            "        [1.0058, 1.4808, 0.9368, 1.4951, 1.4351, 1.0098, 0.9779],\n",
            "        [2.4467, 3.2374, 1.8433, 3.2893, 3.2621, 1.9703, 1.9422]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "259\n",
            "tensor([[3.0288, 3.8925, 2.1780, 3.9642, 3.9406, 2.3306, 2.3183],\n",
            "        [1.2209, 1.7563, 1.0845, 1.7757, 1.7197, 1.1778, 1.1320],\n",
            "        [2.7321, 3.5631, 2.0066, 3.6244, 3.5912, 2.1369, 2.1286],\n",
            "        [1.7520, 2.4151, 1.4270, 2.4447, 2.3987, 1.5414, 1.4908],\n",
            "        [2.7680, 3.6034, 2.0315, 3.6691, 3.6463, 2.1695, 2.1525]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "260\n",
            "tensor([[3.0094, 3.8705, 2.1690, 3.9458, 3.9252, 2.3136, 2.3063],\n",
            "        [3.1293, 4.0057, 2.2370, 4.0779, 4.0520, 2.3949, 2.3866],\n",
            "        [3.0842, 3.9558, 2.2125, 4.0293, 4.0053, 2.3679, 2.3565],\n",
            "        [2.6153, 3.4310, 1.9437, 3.4930, 3.4701, 2.0680, 2.0516],\n",
            "        [3.1038, 3.9729, 2.2224, 4.0500, 4.0243, 2.3669, 2.3682]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "261\n",
            "tensor([[3.1257, 3.9976, 2.2335, 4.0743, 4.0494, 2.3882, 2.3828],\n",
            "        [1.8296, 2.5069, 1.4700, 2.5407, 2.4962, 1.5932, 1.5422],\n",
            "        [3.0077, 3.8654, 2.1668, 3.9414, 3.9235, 2.3041, 2.3026],\n",
            "        [2.8205, 3.6584, 2.0615, 3.7314, 3.7113, 2.1872, 2.1820],\n",
            "        [2.0509, 2.7714, 1.6052, 2.8141, 2.7766, 1.7316, 1.6869]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "262\n",
            "tensor([[1.9433, 2.6428, 1.5379, 2.6804, 2.6386, 1.6644, 1.6132],\n",
            "        [2.1502, 2.8897, 1.6648, 2.9356, 2.8970, 1.7943, 1.7510],\n",
            "        [3.1077, 3.9817, 2.2211, 4.0578, 4.0333, 2.3805, 2.3720],\n",
            "        [1.6677, 2.3119, 1.3709, 2.3418, 2.2930, 1.4817, 1.4360],\n",
            "        [3.1171, 3.9889, 2.2270, 4.0659, 4.0410, 2.3803, 2.3761]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "263\n",
            "tensor([[2.7014, 3.5295, 1.9906, 3.5980, 3.5782, 2.1199, 2.1051],\n",
            "        [3.1205, 3.9954, 2.2258, 4.0719, 4.0459, 2.3866, 2.3797],\n",
            "        [0.8728, 1.3091, 0.8467, 1.3269, 1.2676, 0.9103, 0.8856],\n",
            "        [0.9945, 1.4664, 0.9329, 1.4860, 1.4260, 1.0063, 0.9731],\n",
            "        [2.0699, 2.7993, 1.6194, 2.8447, 2.8069, 1.7479, 1.7014]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "264\n",
            "tensor([[0.9336, 1.3875, 0.8911, 1.4064, 1.3469, 0.9608, 0.9289],\n",
            "        [1.0482, 1.5344, 0.9692, 1.5563, 1.4979, 1.0478, 1.0109],\n",
            "        [3.1264, 4.0033, 2.2294, 4.0791, 4.0483, 2.3898, 2.3841],\n",
            "        [2.7820, 3.6180, 2.0320, 3.6887, 3.6646, 2.1649, 2.1540],\n",
            "        [2.7418, 3.5744, 2.0141, 3.6448, 3.6235, 2.1494, 2.1285]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "265\n",
            "tensor([[3.0939, 3.9655, 2.2088, 4.0428, 4.0129, 2.3687, 2.3600],\n",
            "        [2.1849, 2.9324, 1.6866, 2.9833, 2.9476, 1.8189, 1.7732],\n",
            "        [3.1118, 3.9842, 2.2227, 4.0620, 4.0371, 2.3765, 2.3719],\n",
            "        [1.0707, 1.5640, 0.9827, 1.5861, 1.5272, 1.0664, 1.0276],\n",
            "        [1.7695, 2.4366, 1.4347, 2.4740, 2.4270, 1.5567, 1.5017]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "266\n",
            "tensor([[2.5613, 3.3687, 1.9089, 3.4366, 3.4109, 2.0443, 2.0159],\n",
            "        [2.0035, 2.7161, 1.5778, 2.7602, 2.7197, 1.7054, 1.6544],\n",
            "        [2.4035, 3.1875, 1.8166, 3.2488, 3.2170, 1.9476, 1.9141],\n",
            "        [3.1101, 3.9811, 2.2189, 4.0625, 4.0359, 2.3775, 2.3698],\n",
            "        [3.1242, 3.9964, 2.2287, 4.0763, 4.0508, 2.3901, 2.3772]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "267\n",
            "tensor([[2.2062, 2.9556, 1.6987, 3.0086, 2.9745, 1.8325, 1.7867],\n",
            "        [1.6390, 2.2774, 1.3514, 2.3101, 2.2639, 1.4742, 1.4141],\n",
            "        [3.0911, 3.9568, 2.2085, 4.0376, 4.0201, 2.3571, 2.3528],\n",
            "        [2.1060, 2.8374, 1.6394, 2.8850, 2.8492, 1.7710, 1.7200],\n",
            "        [1.0400, 1.5252, 0.9636, 1.5473, 1.4896, 1.0460, 1.0054]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "268\n",
            "tensor([[0.9965, 1.4700, 0.9350, 1.4920, 1.4331, 1.0127, 0.9753],\n",
            "        [0.9930, 1.4634, 0.9326, 1.4846, 1.4273, 1.0083, 0.9720],\n",
            "        [1.0853, 1.5823, 0.9951, 1.6058, 1.5483, 1.0798, 1.0372],\n",
            "        [2.9349, 3.7959, 2.1143, 3.8597, 3.8298, 2.2793, 2.2579],\n",
            "        [1.8240, 2.5017, 1.4673, 2.5398, 2.4986, 1.5906, 1.5351]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "269\n",
            "tensor([[1.6772, 2.3224, 1.3781, 2.3572, 2.3116, 1.4974, 1.4408],\n",
            "        [1.7336, 2.3908, 1.4128, 2.4266, 2.3829, 1.5359, 1.4773],\n",
            "        [1.5314, 2.1416, 1.2864, 2.1722, 2.1236, 1.3996, 1.3428],\n",
            "        [1.4043, 1.9848, 1.2035, 2.0116, 1.9625, 1.3080, 1.2562],\n",
            "        [1.1095, 1.6149, 1.0111, 1.6352, 1.5798, 1.0977, 1.0540]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "270\n",
            "tensor([[1.3377, 1.9020, 1.1621, 1.9268, 1.8767, 1.2633, 1.2093],\n",
            "        [1.0721, 1.5651, 0.9877, 1.5881, 1.5317, 1.0710, 1.0272],\n",
            "        [0.9945, 1.4683, 0.9363, 1.4882, 1.4313, 1.0113, 0.9736],\n",
            "        [2.7284, 3.5562, 2.0066, 3.6279, 3.6113, 2.1427, 2.1204],\n",
            "        [3.1237, 3.9953, 2.2297, 4.0702, 4.0529, 2.3891, 2.3775]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "271\n",
            "tensor([[1.6154, 2.2449, 1.3399, 2.2770, 2.2331, 1.4577, 1.3962],\n",
            "        [1.8894, 2.5767, 1.5109, 2.6162, 2.5784, 1.6366, 1.5765],\n",
            "        [2.2588, 3.0140, 1.7331, 3.0671, 3.0374, 1.8674, 1.8174],\n",
            "        [0.8175, 1.2374, 0.8132, 1.2566, 1.1993, 0.8731, 0.8479],\n",
            "        [3.0238, 3.8789, 2.1758, 3.9603, 3.9492, 2.3242, 2.3058]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "272\n",
            "tensor([[0.8218, 1.2434, 0.8167, 1.2607, 1.2049, 0.8752, 0.8487],\n",
            "        [1.1801, 1.7022, 1.0626, 1.7276, 1.6731, 1.1537, 1.1024],\n",
            "        [1.0220, 1.5023, 0.9552, 1.5217, 1.4670, 1.0317, 0.9914],\n",
            "        [1.6030, 2.2312, 1.3336, 2.2613, 2.2183, 1.4493, 1.3888],\n",
            "        [3.0291, 3.8909, 2.1707, 3.9616, 3.9352, 2.3320, 2.3165]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "273\n",
            "tensor([[2.3036, 3.0722, 1.7652, 3.1258, 3.1036, 1.8970, 1.8483],\n",
            "        [3.1291, 3.9982, 2.2373, 4.0753, 4.0596, 2.3968, 2.3794],\n",
            "        [0.8459, 1.2745, 0.8339, 1.2929, 1.2365, 0.8933, 0.8657],\n",
            "        [3.1154, 3.9851, 2.2290, 4.0586, 4.0426, 2.3875, 2.3700],\n",
            "        [2.4073, 3.1868, 1.8231, 3.2461, 3.2233, 1.9566, 1.9120]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "274\n",
            "tensor([[1.2246, 1.7579, 1.0912, 1.7845, 1.7343, 1.1847, 1.1336],\n",
            "        [3.0420, 3.9004, 2.1894, 3.9825, 3.9740, 2.3400, 2.3201],\n",
            "        [2.1750, 2.9199, 1.6900, 2.9706, 2.9454, 1.8171, 1.7656],\n",
            "        [1.5397, 2.1545, 1.2969, 2.1846, 2.1412, 1.4102, 1.3474],\n",
            "        [2.8194, 3.6564, 2.0634, 3.7315, 3.7207, 2.2015, 2.1779]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "275\n",
            "tensor([[3.0939, 3.9639, 2.2206, 4.0398, 4.0234, 2.3802, 2.3579],\n",
            "        [1.1630, 1.6810, 1.0539, 1.7053, 1.6544, 1.1413, 1.0904],\n",
            "        [1.3877, 1.9667, 1.1990, 1.9936, 1.9473, 1.3054, 1.2447],\n",
            "        [2.6729, 3.4964, 1.9840, 3.5661, 3.5531, 2.1151, 2.0856],\n",
            "        [2.2302, 2.9842, 1.7211, 3.0362, 3.0128, 1.8474, 1.7994]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "276\n",
            "tensor([[2.1048, 2.8417, 1.6484, 2.8897, 2.8618, 1.7724, 1.7213],\n",
            "        [1.3629, 1.9360, 1.1857, 1.9616, 1.9164, 1.2841, 1.2271],\n",
            "        [2.5045, 3.3045, 1.8854, 3.3689, 3.3506, 2.0152, 1.9777],\n",
            "        [3.1026, 3.9752, 2.2280, 4.0536, 4.0433, 2.3846, 2.3607],\n",
            "        [0.9668, 1.4332, 0.9217, 1.4542, 1.4003, 0.9921, 0.9539]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "277\n",
            "tensor([[3.0062, 3.8631, 2.1741, 3.9427, 3.9424, 2.3021, 2.2896],\n",
            "        [1.4539, 2.0508, 1.2482, 2.0809, 2.0358, 1.3485, 1.2905],\n",
            "        [3.1124, 3.9869, 2.2350, 4.0656, 4.0529, 2.3878, 2.3669],\n",
            "        [2.9353, 3.7897, 2.1367, 3.8683, 3.8629, 2.2694, 2.2480],\n",
            "        [0.9794, 1.4478, 0.9325, 1.4712, 1.4176, 1.0028, 0.9621]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "278\n",
            "tensor([[2.6182, 3.4395, 1.9591, 3.5095, 3.4965, 2.0744, 2.0478],\n",
            "        [3.1026, 3.9776, 2.2335, 4.0566, 4.0454, 2.3755, 2.3584],\n",
            "        [3.1200, 3.9983, 2.2429, 4.0766, 4.0617, 2.3931, 2.3734],\n",
            "        [0.9620, 1.4283, 0.9222, 1.4505, 1.3957, 0.9898, 0.9509],\n",
            "        [2.8847, 3.7351, 2.1122, 3.8127, 3.8108, 2.2308, 2.2138]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "279\n",
            "tensor([[3.0957, 3.9701, 2.2309, 4.0489, 4.0363, 2.3723, 2.3551],\n",
            "        [2.4682, 3.2684, 1.8729, 3.3325, 3.3155, 1.9947, 1.9537],\n",
            "        [0.9124, 1.3646, 0.8887, 1.3852, 1.3293, 0.9474, 0.9160],\n",
            "        [1.3004, 1.8616, 1.1481, 1.8855, 1.8367, 1.2368, 1.1823],\n",
            "        [2.9612, 3.8204, 2.1556, 3.9014, 3.8976, 2.2774, 2.2651]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "280\n",
            "tensor([[1.7468, 2.4144, 1.4396, 2.4530, 2.4144, 1.5473, 1.4891],\n",
            "        [2.5863, 3.4038, 1.9445, 3.4735, 3.4581, 2.0605, 2.0314],\n",
            "        [3.1002, 3.9814, 2.2374, 4.0572, 4.0421, 2.3790, 2.3632],\n",
            "        [3.1167, 3.9960, 2.2475, 4.0747, 4.0615, 2.3894, 2.3714],\n",
            "        [1.9683, 2.6801, 1.5735, 2.7253, 2.6907, 1.6871, 1.6316]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "281\n",
            "tensor([[2.8721, 3.7273, 2.1114, 3.8050, 3.7944, 2.2354, 2.2147],\n",
            "        [2.9958, 3.8595, 2.1805, 3.9448, 3.9364, 2.3031, 2.2932],\n",
            "        [1.0281, 1.5137, 0.9714, 1.5378, 1.4821, 1.0389, 0.9994],\n",
            "        [0.8833, 1.3276, 0.8704, 1.3487, 1.2926, 0.9265, 0.8963],\n",
            "        [1.5496, 2.1720, 1.3151, 2.2055, 2.1621, 1.4169, 1.3555]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "282\n",
            "tensor([[2.5032, 3.3112, 1.8973, 3.3775, 3.3593, 2.0097, 1.9811],\n",
            "        [1.0030, 1.4818, 0.9558, 1.5067, 1.4497, 1.0205, 0.9832],\n",
            "        [1.8949, 2.5950, 1.5326, 2.6382, 2.6037, 1.6391, 1.5870],\n",
            "        [3.1163, 3.9978, 2.2489, 4.0773, 4.0609, 2.3899, 2.3763],\n",
            "        [1.8844, 2.5830, 1.5249, 2.6246, 2.5897, 1.6348, 1.5795]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "283\n",
            "tensor([[1.1942, 1.7275, 1.0846, 1.7540, 1.7005, 1.1615, 1.1176],\n",
            "        [2.3145, 3.0925, 1.7890, 3.1504, 3.1262, 1.8969, 1.8610],\n",
            "        [2.5320, 3.3435, 1.9163, 3.4102, 3.3908, 2.0323, 2.0020],\n",
            "        [3.0772, 3.9517, 2.2297, 4.0361, 4.0256, 2.3637, 2.3515],\n",
            "        [3.0019, 3.8663, 2.1863, 3.9486, 3.9455, 2.3055, 2.2971]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "Loss at epoch 5: 128.7169\n",
            "Pearson correlation for aspect 1: 0.6094\n",
            "Pearson correlation for aspect 2: 0.6857\n",
            "Pearson correlation for aspect 3: 0.2389\n",
            "Pearson correlation for aspect 4: 0.7030\n",
            "Pearson correlation for aspect 5: 0.7043\n",
            "Pearson correlation for aspect 6: 0.2972\n",
            "Pearson correlation for aspect 7: 0.3899\n",
            "Mean Pearson correlation: 0.5183\n",
            "0\n",
            "tensor([[1.0944, 1.5991, 1.0171, 1.6223, 1.5691, 1.0857, 1.0469],\n",
            "        [1.7478, 2.4173, 1.4417, 2.4554, 2.4165, 1.5447, 1.4929],\n",
            "        [2.3203, 3.0993, 1.7916, 3.1572, 3.1363, 1.8957, 1.8646],\n",
            "        [2.8428, 3.6963, 2.0972, 3.7746, 3.7678, 2.2027, 2.1994],\n",
            "        [0.8838, 1.3277, 0.8715, 1.3495, 1.2926, 0.9241, 0.8983]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "1\n",
            "tensor([[2.0847, 2.8212, 1.6488, 2.8706, 2.8405, 1.7548, 1.7135],\n",
            "        [3.0612, 3.9366, 2.2196, 4.0168, 4.0061, 2.3483, 2.3437],\n",
            "        [2.4314, 3.2286, 1.8550, 3.2905, 3.2672, 1.9672, 1.9400],\n",
            "        [1.1052, 1.6141, 1.0238, 1.6391, 1.5863, 1.0946, 1.0565],\n",
            "        [3.0754, 3.9536, 2.2274, 4.0311, 4.0216, 2.3459, 2.3534]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "2\n",
            "tensor([[1.3653, 1.9448, 1.1978, 1.9747, 1.9245, 1.2863, 1.2374],\n",
            "        [1.0998, 1.6095, 1.0202, 1.6323, 1.5817, 1.0904, 1.0529],\n",
            "        [3.1144, 3.9991, 2.2463, 4.0762, 4.0631, 2.3761, 2.3822],\n",
            "        [1.0143, 1.4983, 0.9647, 1.5228, 1.4659, 1.0268, 0.9947],\n",
            "        [3.0714, 3.9465, 2.2225, 4.0275, 4.0195, 2.3418, 2.3487]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "3\n",
            "tensor([[3.1114, 3.9987, 2.2456, 4.0770, 4.0630, 2.3802, 2.3842],\n",
            "        [1.0727, 1.5760, 1.0026, 1.5989, 1.5445, 1.0704, 1.0367],\n",
            "        [3.0849, 3.9664, 2.2279, 4.0409, 4.0272, 2.3479, 2.3632],\n",
            "        [1.2225, 1.7650, 1.1037, 1.7927, 1.7392, 1.1814, 1.1410],\n",
            "        [2.9502, 3.8166, 2.1557, 3.8959, 3.8884, 2.2685, 2.2731]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "4\n",
            "tensor([[3.1145, 4.0017, 2.2470, 4.0772, 4.0618, 2.3752, 2.3863],\n",
            "        [1.2175, 1.7622, 1.1018, 1.7870, 1.7340, 1.1805, 1.1390],\n",
            "        [2.4396, 3.2467, 1.8639, 3.3073, 3.2866, 1.9684, 1.9517],\n",
            "        [1.1443, 1.6667, 1.0520, 1.6917, 1.6367, 1.1230, 1.0887],\n",
            "        [2.7596, 3.6079, 2.0486, 3.6817, 3.6691, 2.1572, 2.1570]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "5\n",
            "tensor([[2.8922, 3.7543, 2.1227, 3.8338, 3.8218, 2.2340, 2.2446],\n",
            "        [0.8755, 1.3206, 0.8700, 1.3437, 1.2845, 0.9250, 0.8993],\n",
            "        [1.5067, 2.1256, 1.2902, 2.1561, 2.1096, 1.3806, 1.3385],\n",
            "        [0.8710, 1.3147, 0.8654, 1.3379, 1.2782, 0.9181, 0.8962],\n",
            "        [1.5098, 2.1292, 1.2910, 2.1599, 2.1133, 1.3862, 1.3406]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "6\n",
            "tensor([[3.1054, 3.9947, 2.2445, 4.0764, 4.0574, 2.3789, 2.3909],\n",
            "        [0.7032, 1.0968, 0.7458, 1.1156, 1.0571, 0.7805, 0.7746],\n",
            "        [3.1074, 4.0003, 2.2447, 4.0798, 4.0617, 2.3869, 2.3923],\n",
            "        [2.1757, 2.9392, 1.7077, 2.9931, 2.9607, 1.8156, 1.7863],\n",
            "        [1.1749, 1.7072, 1.0725, 1.7327, 1.6770, 1.1505, 1.1126]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "7\n",
            "tensor([[3.0350, 3.9193, 2.2062, 4.0020, 3.9876, 2.3382, 2.3469],\n",
            "        [1.4511, 2.0579, 1.2542, 2.0899, 2.0388, 1.3515, 1.3062],\n",
            "        [0.9643, 1.4385, 0.9314, 1.4626, 1.4038, 0.9950, 0.9671],\n",
            "        [3.0936, 3.9831, 2.2387, 4.0650, 4.0503, 2.3791, 2.3859],\n",
            "        [0.9930, 1.4754, 0.9494, 1.4986, 1.4404, 1.0139, 0.9849]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "8\n",
            "tensor([[2.8145, 3.6758, 2.0826, 3.7541, 3.7411, 2.2069, 2.2037],\n",
            "        [1.0266, 1.5196, 0.9751, 1.5455, 1.4859, 1.0443, 1.0121],\n",
            "        [2.3375, 3.1298, 1.7983, 3.1849, 3.1513, 1.9326, 1.8942],\n",
            "        [1.2506, 1.8074, 1.1254, 1.8359, 1.7808, 1.2150, 1.1705],\n",
            "        [3.1103, 4.0076, 2.2479, 4.0878, 4.0625, 2.3981, 2.4057]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "9\n",
            "tensor([[2.3482, 3.1482, 1.8107, 3.2108, 3.1781, 1.9359, 1.9094],\n",
            "        [1.4272, 2.0321, 1.2413, 2.0634, 2.0105, 1.3421, 1.2947],\n",
            "        [1.7587, 2.4412, 1.4518, 2.4816, 2.4359, 1.5663, 1.5185],\n",
            "        [2.0670, 2.8161, 1.6418, 2.8665, 2.8297, 1.7588, 1.7236],\n",
            "        [1.0551, 1.5565, 0.9948, 1.5813, 1.5233, 1.0691, 1.0331]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "10\n",
            "tensor([[1.4035, 2.0013, 1.2263, 2.0331, 1.9805, 1.3266, 1.2774],\n",
            "        [2.6331, 3.4791, 1.9804, 3.5518, 3.5278, 2.1125, 2.0951],\n",
            "        [3.0894, 3.9844, 2.2410, 4.0677, 4.0443, 2.3992, 2.3933],\n",
            "        [2.9922, 3.8765, 2.1842, 3.9580, 3.9424, 2.3147, 2.3261],\n",
            "        [2.9148, 3.7937, 2.1419, 3.8772, 3.8554, 2.2843, 2.2800]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "11\n",
            "tensor([[1.8685, 2.5773, 1.5221, 2.6225, 2.5784, 1.6446, 1.5966],\n",
            "        [3.0628, 3.9575, 2.2247, 4.0435, 4.0214, 2.3789, 2.3797],\n",
            "        [2.5863, 3.4228, 1.9522, 3.4950, 3.4701, 2.0876, 2.0676],\n",
            "        [2.2925, 3.0838, 1.7806, 3.1445, 3.1116, 1.9103, 1.8770],\n",
            "        [3.0436, 3.9425, 2.2116, 4.0256, 3.9958, 2.3689, 2.3728]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "12\n",
            "tensor([[3.1057, 4.0106, 2.2474, 4.0928, 4.0673, 2.4159, 2.4125],\n",
            "        [2.8616, 3.7351, 2.1081, 3.8149, 3.7945, 2.2404, 2.2459],\n",
            "        [1.7279, 2.4084, 1.4333, 2.4468, 2.3997, 1.5544, 1.5041],\n",
            "        [2.3258, 3.1261, 1.7999, 3.1865, 3.1541, 1.9280, 1.9009],\n",
            "        [1.0340, 1.5323, 0.9805, 1.5570, 1.4978, 1.0584, 1.0215]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "13\n",
            "tensor([[2.6831, 3.5415, 2.0058, 3.6157, 3.5894, 2.1492, 2.1375],\n",
            "        [3.1045, 4.0137, 2.2454, 4.0931, 4.0635, 2.4192, 2.4172],\n",
            "        [2.7672, 3.6342, 2.0559, 3.7122, 3.6904, 2.1941, 2.1900],\n",
            "        [0.8858, 1.3413, 0.8775, 1.3659, 1.3021, 0.9444, 0.9176],\n",
            "        [2.3689, 3.1793, 1.8223, 3.2414, 3.2103, 1.9573, 1.9326]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "14\n",
            "tensor([[1.2448, 1.8075, 1.1239, 1.8360, 1.7778, 1.2229, 1.1765],\n",
            "        [1.5715, 2.2182, 1.3333, 2.2526, 2.1991, 1.4548, 1.4026],\n",
            "        [2.6221, 3.4741, 1.9726, 3.5469, 3.5182, 2.1204, 2.1006],\n",
            "        [1.2338, 1.7925, 1.1155, 1.8211, 1.7637, 1.2141, 1.1680],\n",
            "        [0.9330, 1.4027, 0.9117, 1.4279, 1.3639, 0.9845, 0.9535]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "15\n",
            "tensor([[1.0743, 1.5889, 1.0064, 1.6143, 1.5511, 1.0901, 1.0553],\n",
            "        [2.4255, 3.2495, 1.8592, 3.3141, 3.2816, 2.0019, 1.9753],\n",
            "        [3.0978, 4.0107, 2.2441, 4.0925, 4.0633, 2.4233, 2.4187],\n",
            "        [1.1054, 1.6286, 1.0314, 1.6560, 1.5937, 1.1224, 1.0795],\n",
            "        [2.0993, 2.8616, 1.6628, 2.9142, 2.8722, 1.8035, 1.7599]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "16\n",
            "tensor([[3.0427, 3.9511, 2.2158, 4.0385, 4.0132, 2.3868, 2.3847],\n",
            "        [0.9795, 1.4660, 0.9451, 1.4938, 1.4292, 1.0274, 0.9909],\n",
            "        [0.8485, 1.2952, 0.8549, 1.3203, 1.2565, 0.9197, 0.8948],\n",
            "        [1.2233, 1.7826, 1.1109, 1.8137, 1.7527, 1.2121, 1.1658],\n",
            "        [1.7208, 2.4085, 1.4313, 2.4489, 2.3984, 1.5627, 1.5102]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "17\n",
            "tensor([[2.6366, 3.4980, 1.9847, 3.5749, 3.5465, 2.1410, 2.1198],\n",
            "        [0.9125, 1.3816, 0.8989, 1.4087, 1.3430, 0.9749, 0.9454],\n",
            "        [2.1332, 2.9078, 1.6847, 2.9642, 2.9209, 1.8333, 1.7896],\n",
            "        [1.7005, 2.3853, 1.4215, 2.4306, 2.3760, 1.5550, 1.5018],\n",
            "        [2.5057, 3.3505, 1.9082, 3.4236, 3.3899, 2.0662, 2.0384]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "18\n",
            "tensor([[2.5005, 3.3467, 1.9060, 3.4188, 3.3839, 2.0664, 2.0354],\n",
            "        [2.6039, 3.4645, 1.9654, 3.5423, 3.5091, 2.1292, 2.1046],\n",
            "        [1.2551, 1.8282, 1.1321, 1.8591, 1.7983, 1.2415, 1.1921],\n",
            "        [2.2917, 3.1058, 1.7812, 3.1684, 3.1292, 1.9359, 1.9011],\n",
            "        [2.9918, 3.8980, 2.1861, 3.9898, 3.9637, 2.3609, 2.3575]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "19\n",
            "tensor([[3.0698, 3.9954, 2.2327, 4.0831, 4.0475, 2.4271, 2.4168],\n",
            "        [2.7603, 3.6468, 2.0571, 3.7291, 3.7001, 2.2295, 2.2090],\n",
            "        [2.0331, 2.7971, 1.6272, 2.8520, 2.8055, 1.7766, 1.7295],\n",
            "        [1.5714, 2.2295, 1.3396, 2.2702, 2.2121, 1.4699, 1.4163],\n",
            "        [3.0018, 3.9205, 2.1939, 4.0079, 3.9763, 2.3796, 2.3717]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "20\n",
            "tensor([[2.0443, 2.8173, 1.6349, 2.8724, 2.8256, 1.7849, 1.7413],\n",
            "        [1.1645, 1.7156, 1.0734, 1.7465, 1.6824, 1.1760, 1.1318],\n",
            "        [1.5680, 2.2269, 1.3371, 2.2675, 2.2089, 1.4685, 1.4152],\n",
            "        [2.8291, 3.7289, 2.0968, 3.8137, 3.7838, 2.2694, 2.2588],\n",
            "        [2.4891, 3.3422, 1.8983, 3.4141, 3.3763, 2.0632, 2.0355]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "21\n",
            "tensor([[2.2398, 3.0524, 1.7528, 3.1151, 3.0691, 1.9081, 1.8737],\n",
            "        [1.8598, 2.5925, 1.5202, 2.6380, 2.5876, 1.6627, 1.6159],\n",
            "        [1.8750, 2.6121, 1.5322, 2.6609, 2.6082, 1.6781, 1.6279],\n",
            "        [1.5586, 2.2211, 1.3326, 2.2593, 2.2019, 1.4640, 1.4109],\n",
            "        [2.9356, 3.8536, 2.1566, 3.9391, 3.9062, 2.3413, 2.3320]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "22\n",
            "tensor([[2.2445, 3.0614, 1.7546, 3.1211, 3.0762, 1.9125, 1.8779],\n",
            "        [3.0478, 3.9825, 2.2233, 4.0696, 4.0353, 2.4207, 2.4092],\n",
            "        [2.9105, 3.8276, 2.1464, 3.9134, 3.8799, 2.3243, 2.3170],\n",
            "        [1.0477, 1.5672, 0.9946, 1.5947, 1.5280, 1.0869, 1.0491],\n",
            "        [3.0376, 3.9711, 2.2167, 4.0564, 4.0188, 2.4096, 2.4043]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "23\n",
            "tensor([[2.1038, 2.8963, 1.6750, 2.9526, 2.9032, 1.8296, 1.7858],\n",
            "        [2.9508, 3.8767, 2.1698, 3.9635, 3.9283, 2.3502, 2.3479],\n",
            "        [1.0438, 1.5636, 0.9936, 1.5923, 1.5246, 1.0855, 1.0476],\n",
            "        [0.9366, 1.4234, 0.9182, 1.4503, 1.3824, 1.0016, 0.9713],\n",
            "        [2.5470, 3.4184, 1.9386, 3.4898, 3.4531, 2.0931, 2.0773]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "24\n",
            "tensor([[1.9663, 2.7349, 1.5935, 2.7867, 2.7337, 1.7410, 1.6962],\n",
            "        [2.3615, 3.2050, 1.8290, 3.2712, 3.2263, 1.9961, 1.9603],\n",
            "        [1.8249, 2.5585, 1.5039, 2.6056, 2.5499, 1.6490, 1.6003],\n",
            "        [2.8017, 3.7124, 2.0878, 3.7943, 3.7614, 2.2587, 2.2492],\n",
            "        [2.2634, 3.0897, 1.7736, 3.1518, 3.1086, 1.9244, 1.8925]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "25\n",
            "tensor([[1.4898, 2.1419, 1.2919, 2.1769, 2.1148, 1.4210, 1.3682],\n",
            "        [2.6363, 3.5287, 1.9920, 3.6048, 3.5677, 2.1589, 2.1431],\n",
            "        [0.9367, 1.4263, 0.9217, 1.4529, 1.3832, 1.0052, 0.9733],\n",
            "        [1.5468, 2.2130, 1.3259, 2.2506, 2.1884, 1.4612, 1.4087],\n",
            "        [2.1231, 2.9239, 1.6883, 2.9801, 2.9312, 1.8405, 1.8023]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "26\n",
            "tensor([[3.0575, 4.0095, 2.2323, 4.0915, 4.0503, 2.4265, 2.4262],\n",
            "        [1.5317, 2.1959, 1.3190, 2.2331, 2.1704, 1.4506, 1.3985],\n",
            "        [1.8053, 2.5395, 1.4920, 2.5829, 2.5249, 1.6354, 1.5884],\n",
            "        [1.0769, 1.6118, 1.0191, 1.6401, 1.5708, 1.1137, 1.0761],\n",
            "        [3.0569, 4.0059, 2.2347, 4.0906, 4.0528, 2.4293, 2.4225]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "27\n",
            "tensor([[1.4507, 2.0943, 1.2684, 2.1306, 2.0672, 1.3930, 1.3442],\n",
            "        [2.0072, 2.7879, 1.6164, 2.8378, 2.7822, 1.7664, 1.7250],\n",
            "        [3.0464, 3.9942, 2.2260, 4.0802, 4.0423, 2.4227, 2.4159],\n",
            "        [2.6494, 3.5493, 2.0011, 3.6246, 3.5868, 2.1658, 2.1535],\n",
            "        [2.8856, 3.8130, 2.1345, 3.8977, 3.8664, 2.3121, 2.3067]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "28\n",
            "tensor([[1.5726, 2.2511, 1.3457, 2.2864, 2.2261, 1.4789, 1.4275],\n",
            "        [2.7043, 3.6130, 2.0330, 3.6910, 3.6540, 2.1942, 2.1883],\n",
            "        [2.6586, 3.5600, 2.0067, 3.6344, 3.5985, 2.1681, 2.1591],\n",
            "        [1.6126, 2.3009, 1.3712, 2.3382, 2.2773, 1.5061, 1.4569],\n",
            "        [1.7987, 2.5317, 1.4878, 2.5741, 2.5154, 1.6298, 1.5842]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "29\n",
            "tensor([[3.0320, 3.9849, 2.2191, 4.0678, 4.0261, 2.4152, 2.4105],\n",
            "        [3.0580, 4.0111, 2.2329, 4.0944, 4.0547, 2.4228, 2.4275],\n",
            "        [2.6825, 3.5880, 2.0179, 3.6620, 3.6246, 2.1864, 2.1758],\n",
            "        [3.0526, 4.0043, 2.2299, 4.0867, 4.0494, 2.4174, 2.4204],\n",
            "        [3.0752, 4.0326, 2.2416, 4.1122, 4.0697, 2.4421, 2.4393]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "30\n",
            "tensor([[2.2487, 3.0838, 1.7620, 3.1418, 3.0924, 1.9174, 1.8913],\n",
            "        [2.4552, 3.3277, 1.8854, 3.3942, 3.3515, 2.0473, 2.0278],\n",
            "        [2.7505, 3.6697, 2.0570, 3.7454, 3.7087, 2.2283, 2.2228],\n",
            "        [2.9742, 3.9166, 2.1842, 4.0008, 3.9653, 2.3666, 2.3695],\n",
            "        [3.0634, 4.0191, 2.2340, 4.1021, 4.0615, 2.4303, 2.4308]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "31\n",
            "tensor([[1.2821, 1.8806, 1.1539, 1.9103, 1.8433, 1.2671, 1.2245],\n",
            "        [3.0740, 4.0286, 2.2392, 4.1140, 4.0691, 2.4357, 2.4417],\n",
            "        [2.8378, 3.7646, 2.1065, 3.8470, 3.8116, 2.2767, 2.2796],\n",
            "        [2.0505, 2.8460, 1.6427, 2.8983, 2.8448, 1.7951, 1.7598],\n",
            "        [2.7063, 3.6169, 2.0309, 3.6932, 3.6556, 2.1914, 2.1932]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "32\n",
            "tensor([[1.3925, 2.0232, 1.2273, 2.0581, 1.9907, 1.3496, 1.3066],\n",
            "        [1.7645, 2.4936, 1.4629, 2.5346, 2.4759, 1.6056, 1.5648],\n",
            "        [2.3722, 3.2296, 1.8339, 3.2951, 3.2474, 1.9931, 1.9773],\n",
            "        [1.7246, 2.4444, 1.4396, 2.4865, 2.4254, 1.5814, 1.5390],\n",
            "        [1.9619, 2.7363, 1.5852, 2.7856, 2.7285, 1.7331, 1.7009]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "33\n",
            "tensor([[2.7262, 3.6414, 2.0385, 3.7207, 3.6821, 2.1990, 2.2132],\n",
            "        [2.8992, 3.8379, 2.1387, 3.9228, 3.8842, 2.3200, 2.3303],\n",
            "        [3.0786, 4.0365, 2.2398, 4.1225, 4.0793, 2.4416, 2.4499],\n",
            "        [2.7173, 3.6329, 2.0342, 3.7125, 3.6700, 2.1982, 2.2091],\n",
            "        [3.0386, 3.9912, 2.2181, 4.0780, 4.0386, 2.4142, 2.4222]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "34\n",
            "tensor([[2.3618, 3.2177, 1.8246, 3.2834, 3.2364, 1.9869, 1.9735],\n",
            "        [2.9602, 3.9025, 2.1687, 3.9890, 3.9497, 2.3609, 2.3695],\n",
            "        [3.0536, 4.0060, 2.2217, 4.0952, 4.0515, 2.4134, 2.4329],\n",
            "        [2.2365, 3.0724, 1.7496, 3.1306, 3.0791, 1.9058, 1.8897],\n",
            "        [2.5569, 3.4495, 1.9373, 3.5221, 3.4781, 2.1045, 2.1048]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "35\n",
            "tensor([[1.3972, 2.0320, 1.2247, 2.0648, 1.9975, 1.3483, 1.3126],\n",
            "        [3.0880, 4.0480, 2.2389, 4.1328, 4.0872, 2.4416, 2.4589],\n",
            "        [3.0911, 4.0515, 2.2413, 4.1346, 4.0914, 2.4477, 2.4602],\n",
            "        [0.8065, 1.2579, 0.8259, 1.2819, 1.2120, 0.8940, 0.8804],\n",
            "        [1.5416, 2.2152, 1.3170, 2.2503, 2.1862, 1.4520, 1.4128]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "36\n",
            "tensor([[2.6435, 3.5486, 1.9853, 3.6234, 3.5813, 2.1630, 2.1619],\n",
            "        [2.4380, 3.3088, 1.8653, 3.3755, 3.3302, 2.0367, 2.0246],\n",
            "        [2.3401, 3.1932, 1.8070, 3.2548, 3.2069, 1.9740, 1.9596],\n",
            "        [2.3227, 3.1758, 1.7974, 3.2365, 3.1850, 1.9633, 1.9491],\n",
            "        [3.0733, 4.0288, 2.2279, 4.1153, 4.0704, 2.4262, 2.4471]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "37\n",
            "tensor([[2.7824, 3.7086, 2.0651, 3.7865, 3.7544, 2.2330, 2.2501],\n",
            "        [1.6727, 2.3804, 1.3988, 2.4192, 2.3570, 1.5436, 1.5052],\n",
            "        [2.9699, 3.9184, 2.1705, 4.0008, 3.9615, 2.3648, 2.3795],\n",
            "        [2.9845, 3.9325, 2.1759, 4.0136, 3.9746, 2.3621, 2.3841],\n",
            "        [2.3455, 3.2061, 1.8110, 3.2655, 3.2188, 1.9754, 1.9651]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "38\n",
            "tensor([[2.4274, 3.2985, 1.8564, 3.3605, 3.3156, 2.0298, 2.0158],\n",
            "        [2.5527, 3.4503, 1.9323, 3.5179, 3.4771, 2.1046, 2.1013],\n",
            "        [1.3010, 1.9117, 1.1603, 1.9388, 1.8721, 1.2780, 1.2439],\n",
            "        [3.0778, 4.0414, 2.2294, 4.1225, 4.0793, 2.4368, 2.4519],\n",
            "        [2.5461, 3.4424, 1.9276, 3.5092, 3.4690, 2.0934, 2.0968]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "39\n",
            "tensor([[1.3229, 1.9418, 1.1744, 1.9688, 1.9023, 1.2969, 1.2593],\n",
            "        [2.0601, 2.8628, 1.6365, 2.9090, 2.8587, 1.7966, 1.7676],\n",
            "        [3.0638, 4.0285, 2.2194, 4.1064, 4.0615, 2.4258, 2.4395],\n",
            "        [1.1166, 1.6731, 1.0381, 1.6991, 1.6296, 1.1442, 1.1108],\n",
            "        [2.9507, 3.9049, 2.1543, 3.9810, 3.9397, 2.3506, 2.3656]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "40\n",
            "tensor([[1.7277, 2.4570, 1.4311, 2.4919, 2.4328, 1.5818, 1.5415],\n",
            "        [2.7756, 3.7116, 2.0555, 3.7817, 3.7439, 2.2406, 2.2478],\n",
            "        [1.2009, 1.7863, 1.0925, 1.8094, 1.7422, 1.2067, 1.1712],\n",
            "        [1.0731, 1.6180, 1.0064, 1.6401, 1.5724, 1.1106, 1.0781],\n",
            "        [2.9917, 3.9476, 2.1777, 4.0247, 3.9896, 2.3749, 2.3850]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "41\n",
            "tensor([[3.0356, 4.0004, 2.1982, 4.0728, 4.0273, 2.4028, 2.4166],\n",
            "        [2.2928, 3.1499, 1.7734, 3.2013, 3.1547, 1.9451, 1.9245],\n",
            "        [3.0739, 4.0430, 2.2229, 4.1160, 4.0741, 2.4343, 2.4423],\n",
            "        [1.1756, 1.7542, 1.0748, 1.7758, 1.7089, 1.1903, 1.1520],\n",
            "        [1.1955, 1.7798, 1.0873, 1.8023, 1.7352, 1.2060, 1.1657]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "42\n",
            "tensor([[1.0526, 1.5934, 0.9919, 1.6153, 1.5463, 1.0974, 1.0631],\n",
            "        [2.4380, 3.3204, 1.8560, 3.3761, 3.3318, 2.0356, 2.0186],\n",
            "        [0.8665, 1.3445, 0.8643, 1.3652, 1.2943, 0.9464, 0.9250],\n",
            "        [1.4599, 2.1193, 1.2551, 2.1443, 2.0801, 1.3947, 1.3516],\n",
            "        [1.0768, 1.6246, 1.0097, 1.6460, 1.5777, 1.1128, 1.0792]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "43\n",
            "tensor([[1.0302, 1.5643, 0.9763, 1.5857, 1.5148, 1.0788, 1.0469],\n",
            "        [2.8112, 3.7557, 2.0711, 3.8215, 3.7820, 2.2714, 2.2669],\n",
            "        [1.1540, 1.7274, 1.0608, 1.7484, 1.6811, 1.1733, 1.1354],\n",
            "        [1.6608, 2.3767, 1.3843, 2.4051, 2.3446, 1.5379, 1.4920],\n",
            "        [2.7057, 3.6314, 2.0101, 3.6952, 3.6549, 2.2066, 2.1957]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "44\n",
            "tensor([[3.0418, 4.0123, 2.2001, 4.0836, 4.0432, 2.4159, 2.4163],\n",
            "        [0.7945, 1.2518, 0.8123, 1.2705, 1.1998, 0.8858, 0.8713],\n",
            "        [0.9964, 1.5219, 0.9512, 1.5397, 1.4696, 1.0521, 1.0203],\n",
            "        [2.9989, 3.9611, 2.1753, 4.0329, 3.9932, 2.3774, 2.3864],\n",
            "        [2.1775, 3.0149, 1.7010, 3.0603, 3.0068, 1.8720, 1.8440]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "45\n",
            "tensor([[2.7487, 3.6851, 2.0330, 3.7468, 3.7051, 2.2261, 2.2212],\n",
            "        [1.7650, 2.5087, 1.4490, 2.5386, 2.4795, 1.6056, 1.5617],\n",
            "        [3.0200, 3.9882, 2.1874, 4.0562, 4.0197, 2.3981, 2.3997],\n",
            "        [1.5339, 2.2189, 1.3022, 2.2409, 2.1783, 1.4475, 1.4004],\n",
            "        [2.9530, 3.9137, 2.1518, 3.9833, 3.9452, 2.3567, 2.3570]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "46\n",
            "tensor([[2.7625, 3.7024, 2.0410, 3.7632, 3.7290, 2.2230, 2.2256],\n",
            "        [2.1375, 2.9691, 1.6769, 3.0092, 2.9568, 1.8494, 1.8156],\n",
            "        [3.0149, 3.9829, 2.1844, 4.0491, 4.0096, 2.3988, 2.3940],\n",
            "        [1.0660, 1.6130, 1.0005, 1.6329, 1.5626, 1.1062, 1.0695],\n",
            "        [3.0078, 3.9746, 2.1790, 4.0411, 4.0032, 2.3859, 2.3891]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "47\n",
            "tensor([[3.0536, 4.0222, 2.2031, 4.0880, 4.0453, 2.4112, 2.4189],\n",
            "        [2.5021, 3.3999, 1.8914, 3.4515, 3.4081, 2.0744, 2.0541],\n",
            "        [0.7639, 1.2098, 0.7887, 1.2259, 1.1571, 0.8596, 0.8447],\n",
            "        [1.5874, 2.2846, 1.3364, 2.3081, 2.2456, 1.4831, 1.4370],\n",
            "        [0.9517, 1.4598, 0.9206, 1.4764, 1.4075, 1.0125, 0.9834]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "48\n",
            "tensor([[2.8520, 3.7974, 2.0887, 3.8591, 3.8255, 2.2771, 2.2801],\n",
            "        [2.1014, 2.9194, 1.6533, 2.9559, 2.9047, 1.8180, 1.7859],\n",
            "        [2.1770, 3.0122, 1.6969, 3.0514, 3.0000, 1.8658, 1.8369],\n",
            "        [0.7708, 1.2167, 0.7938, 1.2335, 1.1642, 0.8634, 0.8486],\n",
            "        [1.5405, 2.2245, 1.3073, 2.2477, 2.1846, 1.4512, 1.4037]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "49\n",
            "tensor([[2.1183, 2.9405, 1.6620, 2.9757, 2.9240, 1.8257, 1.7954],\n",
            "        [2.5234, 3.4224, 1.9024, 3.4714, 3.4294, 2.0724, 2.0635],\n",
            "        [2.7338, 3.6637, 2.0203, 3.7202, 3.6755, 2.2099, 2.2039],\n",
            "        [2.7754, 3.7111, 2.0457, 3.7685, 3.7347, 2.2283, 2.2267],\n",
            "        [2.4366, 3.3207, 1.8484, 3.3674, 3.3218, 2.0225, 2.0074]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "50\n",
            "tensor([[3.0893, 4.0633, 2.2198, 4.1232, 4.0826, 2.4310, 2.4359],\n",
            "        [1.4346, 2.0893, 1.2375, 2.1074, 2.0437, 1.3651, 1.3266],\n",
            "        [1.3658, 2.0012, 1.1953, 2.0205, 1.9541, 1.3224, 1.2792],\n",
            "        [2.4226, 3.3039, 1.8396, 3.3480, 3.3057, 2.0100, 1.9944],\n",
            "        [1.0843, 1.6342, 1.0098, 1.6506, 1.5817, 1.1107, 1.0794]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "51\n",
            "tensor([[1.8650, 2.6335, 1.5068, 2.6582, 2.6050, 1.6574, 1.6221],\n",
            "        [1.1894, 1.7748, 1.0795, 1.7873, 1.7218, 1.1872, 1.1513],\n",
            "        [2.9143, 3.8676, 2.1212, 3.9269, 3.8916, 2.3124, 2.3160],\n",
            "        [2.5539, 3.4614, 1.9156, 3.5077, 3.4638, 2.0882, 2.0807],\n",
            "        [1.5631, 2.2533, 1.3197, 2.2724, 2.2107, 1.4581, 1.4165]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "52\n",
            "tensor([[1.5752, 2.2708, 1.3270, 2.2861, 2.2272, 1.4618, 1.4215],\n",
            "        [1.6632, 2.3829, 1.3842, 2.4017, 2.3420, 1.5241, 1.4834],\n",
            "        [1.3094, 1.9319, 1.1580, 1.9449, 1.8819, 1.2761, 1.2364],\n",
            "        [0.7956, 1.2529, 0.8099, 1.2652, 1.1975, 0.8791, 0.8651],\n",
            "        [2.0046, 2.8094, 1.5940, 2.8364, 2.7857, 1.7494, 1.7170]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "53\n",
            "tensor([[2.6992, 3.6376, 2.0008, 3.6827, 3.6486, 2.1620, 2.1737],\n",
            "        [3.0792, 4.0577, 2.2149, 4.1120, 4.0736, 2.4155, 2.4248],\n",
            "        [1.7881, 2.5423, 1.4605, 2.5608, 2.5068, 1.5998, 1.5671],\n",
            "        [3.0329, 4.0046, 2.1890, 4.0604, 4.0253, 2.3809, 2.3931],\n",
            "        [2.5361, 3.4483, 1.9057, 3.4874, 3.4484, 2.0687, 2.0681]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "54\n",
            "tensor([[3.0251, 3.9992, 2.1838, 4.0491, 4.0152, 2.3727, 2.3868],\n",
            "        [1.6650, 2.3881, 1.3840, 2.4033, 2.3450, 1.5163, 1.4816],\n",
            "        [1.7190, 2.4547, 1.4186, 2.4722, 2.4165, 1.5553, 1.5193],\n",
            "        [1.9907, 2.7946, 1.5844, 2.8167, 2.7649, 1.7318, 1.7049],\n",
            "        [0.9804, 1.5020, 0.9395, 1.5116, 1.4449, 1.0222, 0.9996]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "55\n",
            "tensor([[2.2281, 3.0824, 1.7260, 3.1107, 3.0649, 1.8759, 1.8629],\n",
            "        [2.8990, 3.8593, 2.1123, 3.9062, 3.8780, 2.2746, 2.2998],\n",
            "        [3.0910, 4.0717, 2.2198, 4.1188, 4.0825, 2.4108, 2.4275],\n",
            "        [1.9745, 2.7741, 1.5739, 2.7931, 2.7436, 1.7142, 1.6904],\n",
            "        [2.5279, 3.4366, 1.9014, 3.4723, 3.4346, 2.0567, 2.0569]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "56\n",
            "tensor([[0.9153, 1.4153, 0.8951, 1.4240, 1.3576, 0.9684, 0.9500],\n",
            "        [2.4775, 3.3765, 1.8704, 3.4091, 3.3696, 2.0307, 2.0232],\n",
            "        [1.5208, 2.2086, 1.2947, 2.2195, 2.1597, 1.4168, 1.3829],\n",
            "        [1.0568, 1.6032, 0.9905, 1.6127, 1.5449, 1.0798, 1.0537],\n",
            "        [3.0009, 3.9703, 2.1669, 4.0164, 3.9899, 2.3314, 2.3610]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "57\n",
            "tensor([[2.9491, 3.9166, 2.1360, 3.9565, 3.9315, 2.2883, 2.3277],\n",
            "        [1.6929, 2.4256, 1.3996, 2.4355, 2.3815, 1.5265, 1.4986],\n",
            "        [2.8941, 3.8559, 2.1086, 3.8996, 3.8669, 2.2785, 2.2957],\n",
            "        [1.9656, 2.7653, 1.5696, 2.7830, 2.7338, 1.7041, 1.6836],\n",
            "        [2.0262, 2.8378, 1.6040, 2.8548, 2.8084, 1.7414, 1.7226]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "58\n",
            "tensor([[1.7707, 2.5236, 1.4484, 2.5344, 2.4820, 1.5769, 1.5504],\n",
            "        [1.9854, 2.7894, 1.5769, 2.8060, 2.7573, 1.7136, 1.6973],\n",
            "        [0.9753, 1.4968, 0.9345, 1.5037, 1.4378, 1.0109, 0.9932],\n",
            "        [2.1540, 2.9973, 1.6811, 3.0189, 2.9740, 1.8199, 1.8098],\n",
            "        [2.3567, 3.2374, 1.8000, 3.2630, 3.2208, 1.9377, 1.9419]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "59\n",
            "tensor([[1.0846, 1.6426, 1.0114, 1.6497, 1.5821, 1.0970, 1.0739],\n",
            "        [2.3101, 3.1858, 1.7748, 3.2089, 3.1692, 1.9104, 1.9119],\n",
            "        [2.7885, 3.7423, 2.0487, 3.7789, 3.7515, 2.1921, 2.2246],\n",
            "        [2.2458, 3.1104, 1.7341, 3.1317, 3.0879, 1.8750, 1.8721],\n",
            "        [0.9299, 1.4368, 0.9045, 1.4439, 1.3759, 0.9751, 0.9602]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "60\n",
            "tensor([[3.0246, 4.0075, 2.1851, 4.0482, 4.0176, 2.3510, 2.3793],\n",
            "        [1.2927, 1.9188, 1.1474, 1.9242, 1.8604, 1.2483, 1.2227],\n",
            "        [2.1906, 3.0463, 1.7034, 3.0654, 3.0216, 1.8364, 1.8353],\n",
            "        [3.0290, 4.0133, 2.1891, 4.0549, 4.0238, 2.3589, 2.3867],\n",
            "        [2.6417, 3.5787, 1.9706, 3.6090, 3.5761, 2.1044, 2.1282]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "61\n",
            "tensor([[1.3544, 2.0008, 1.1896, 2.0049, 1.9430, 1.2912, 1.2660],\n",
            "        [3.0623, 4.0511, 2.2060, 4.0912, 4.0550, 2.3710, 2.4091],\n",
            "        [2.6005, 3.5331, 1.9467, 3.5623, 3.5288, 2.0849, 2.1046],\n",
            "        [2.7250, 3.6746, 2.0179, 3.7084, 3.6749, 2.1584, 2.1859],\n",
            "        [2.3527, 3.2409, 1.8013, 3.2637, 3.2204, 1.9403, 1.9425]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "62\n",
            "tensor([[1.4836, 2.1673, 1.2739, 2.1714, 2.1118, 1.3814, 1.3546],\n",
            "        [2.9847, 3.9682, 2.1678, 4.0080, 3.9742, 2.3217, 2.3563],\n",
            "        [3.0942, 4.0904, 2.2298, 4.1259, 4.0904, 2.3969, 2.4272],\n",
            "        [2.3126, 3.1969, 1.7811, 3.2164, 3.1739, 1.9132, 1.9158],\n",
            "        [1.3777, 2.0310, 1.2042, 2.0333, 1.9716, 1.3044, 1.2803]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "63\n",
            "tensor([[0.7984, 1.2638, 0.8166, 1.2690, 1.2016, 0.8693, 0.8628],\n",
            "        [1.3882, 2.0476, 1.2100, 2.0458, 1.9836, 1.3114, 1.2857],\n",
            "        [3.1050, 4.1034, 2.2356, 4.1380, 4.0991, 2.4058, 2.4345],\n",
            "        [2.5185, 3.4397, 1.9030, 3.4646, 3.4259, 2.0369, 2.0495],\n",
            "        [0.7864, 1.2477, 0.8076, 1.2513, 1.1852, 0.8585, 0.8528]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "64\n",
            "tensor([[1.8404, 2.6223, 1.4993, 2.6273, 2.5752, 1.6193, 1.5973],\n",
            "        [2.8832, 3.8590, 2.1128, 3.8905, 3.8598, 2.2552, 2.2858],\n",
            "        [2.2346, 3.1012, 1.7372, 3.1161, 3.0735, 1.8608, 1.8600],\n",
            "        [1.1398, 1.7205, 1.0517, 1.7226, 1.6569, 1.1359, 1.1112],\n",
            "        [1.0279, 1.5734, 0.9780, 1.5764, 1.5095, 1.0525, 1.0326]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "65\n",
            "tensor([[3.0600, 4.0520, 2.2118, 4.0825, 4.0525, 2.3710, 2.3976],\n",
            "        [0.8811, 1.3769, 0.8752, 1.3793, 1.3120, 0.9360, 0.9233],\n",
            "        [0.8644, 1.3545, 0.8630, 1.3566, 1.2904, 0.9215, 0.9117],\n",
            "        [1.1529, 1.7402, 1.0616, 1.7395, 1.6737, 1.1435, 1.1202],\n",
            "        [0.7799, 1.2401, 0.8039, 1.2427, 1.1753, 0.8525, 0.8475]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "66\n",
            "tensor([[2.3857, 3.2852, 1.8284, 3.2994, 3.2602, 1.9600, 1.9570],\n",
            "        [1.4933, 2.1827, 1.2821, 2.1808, 2.1214, 1.3871, 1.3580],\n",
            "        [1.7786, 2.5441, 1.4614, 2.5452, 2.4909, 1.5778, 1.5524],\n",
            "        [2.1660, 3.0184, 1.6962, 3.0268, 2.9809, 1.8227, 1.8102],\n",
            "        [1.7849, 2.5506, 1.4642, 2.5511, 2.4976, 1.5767, 1.5549]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "67\n",
            "tensor([[1.3401, 1.9855, 1.1834, 1.9811, 1.9190, 1.2798, 1.2489],\n",
            "        [1.0377, 1.5884, 0.9832, 1.5869, 1.5211, 1.0597, 1.0364],\n",
            "        [0.9699, 1.4979, 0.9378, 1.4983, 1.4302, 1.0068, 0.9879],\n",
            "        [1.7342, 2.4889, 1.4339, 2.4872, 2.4323, 1.5507, 1.5210],\n",
            "        [1.0862, 1.6528, 1.0169, 1.6514, 1.5849, 1.0952, 1.0715]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "68\n",
            "tensor([[2.7162, 3.6752, 2.0178, 3.6916, 3.6587, 2.1456, 2.1709],\n",
            "        [1.1949, 1.7987, 1.0893, 1.7934, 1.7286, 1.1739, 1.1481],\n",
            "        [1.5678, 2.2810, 1.3282, 2.2735, 2.2193, 1.4340, 1.4042],\n",
            "        [3.0076, 4.0032, 2.1838, 4.0239, 3.9922, 2.3418, 2.3618],\n",
            "        [2.2519, 3.1337, 1.7481, 3.1371, 3.0969, 1.8733, 1.8686]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "69\n",
            "tensor([[2.8724, 3.8527, 2.1060, 3.8694, 3.8416, 2.2494, 2.2698],\n",
            "        [2.8804, 3.8583, 2.1094, 3.8742, 3.8440, 2.2507, 2.2742],\n",
            "        [2.2220, 3.0942, 1.7293, 3.0961, 3.0519, 1.8547, 1.8466],\n",
            "        [2.5313, 3.4597, 1.9108, 3.4696, 3.4338, 2.0457, 2.0484],\n",
            "        [1.4835, 2.1734, 1.2780, 2.1669, 2.1079, 1.3804, 1.3496]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "70\n",
            "tensor([[2.6317, 3.5783, 1.9697, 3.5895, 3.5576, 2.1032, 2.1132],\n",
            "        [2.5436, 3.4770, 1.9188, 3.4826, 3.4513, 2.0495, 2.0538],\n",
            "        [0.8519, 1.3423, 0.8560, 1.3389, 1.2724, 0.9122, 0.9000],\n",
            "        [3.0777, 4.0805, 2.2183, 4.0946, 4.0559, 2.3816, 2.4073],\n",
            "        [1.1985, 1.8032, 1.0910, 1.7955, 1.7328, 1.1759, 1.1483]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "71\n",
            "tensor([[3.0257, 4.0241, 2.1929, 4.0371, 4.0067, 2.3475, 2.3690],\n",
            "        [2.9765, 3.9680, 2.1656, 3.9794, 3.9555, 2.3098, 2.3320],\n",
            "        [0.8242, 1.3073, 0.8282, 1.2954, 1.2370, 0.8811, 0.8737],\n",
            "        [1.7765, 2.5505, 1.4592, 2.5389, 2.4886, 1.5727, 1.5475],\n",
            "        [2.1178, 2.9683, 1.6654, 2.9617, 2.9186, 1.7890, 1.7741]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "72\n",
            "tensor([[0.9447, 1.4661, 0.9213, 1.4600, 1.3937, 0.9842, 0.9661],\n",
            "        [0.9966, 1.5363, 0.9579, 1.5280, 1.4632, 1.0261, 1.0051],\n",
            "        [1.7188, 2.4736, 1.4259, 2.4624, 2.4099, 1.5321, 1.5060],\n",
            "        [2.1025, 2.9524, 1.6630, 2.9463, 2.9044, 1.7759, 1.7657],\n",
            "        [1.8905, 2.6924, 1.5334, 2.6814, 2.6350, 1.6455, 1.6230]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "73\n",
            "tensor([[2.9184, 3.9023, 2.1362, 3.9129, 3.8880, 2.2750, 2.2953],\n",
            "        [0.8200, 1.2985, 0.8346, 1.2920, 1.2254, 0.8817, 0.8748],\n",
            "        [0.9062, 1.4146, 0.8951, 1.4077, 1.3410, 0.9526, 0.9383],\n",
            "        [2.3730, 3.2762, 1.8230, 3.2721, 3.2413, 1.9384, 1.9397],\n",
            "        [0.9544, 1.4789, 0.9305, 1.4733, 1.4060, 0.9921, 0.9736]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "74\n",
            "tensor([[2.6697, 3.6252, 1.9951, 3.6287, 3.5987, 2.1191, 2.1356],\n",
            "        [2.2337, 3.1082, 1.7397, 3.1012, 3.0595, 1.8552, 1.8499],\n",
            "        [1.6492, 2.3879, 1.3877, 2.3739, 2.3201, 1.4877, 1.4593],\n",
            "        [1.4675, 2.1534, 1.2708, 2.1397, 2.0821, 1.3646, 1.3349],\n",
            "        [0.9358, 1.4552, 0.9164, 1.4461, 1.3803, 0.9762, 0.9585]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "75\n",
            "tensor([[1.0401, 1.5945, 0.9877, 1.5831, 1.5189, 1.0546, 1.0341],\n",
            "        [2.0664, 2.9082, 1.6407, 2.8965, 2.8507, 1.7586, 1.7401],\n",
            "        [1.8643, 2.6561, 1.5185, 2.6435, 2.5952, 1.6296, 1.6047],\n",
            "        [2.6767, 3.6308, 2.0013, 3.6326, 3.6070, 2.1160, 2.1358],\n",
            "        [3.0422, 4.0406, 2.2093, 4.0482, 4.0227, 2.3510, 2.3751]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "76\n",
            "tensor([[1.1711, 1.7698, 1.0775, 1.7563, 1.6924, 1.1555, 1.1280],\n",
            "        [1.0003, 1.5423, 0.9640, 1.5329, 1.4659, 1.0292, 1.0074],\n",
            "        [3.0948, 4.1013, 2.2384, 4.1029, 4.0700, 2.3887, 2.4148],\n",
            "        [1.4975, 2.1941, 1.2900, 2.1773, 2.1207, 1.3855, 1.3559],\n",
            "        [2.5321, 3.4623, 1.9185, 3.4611, 3.4278, 2.0395, 2.0458]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "77\n",
            "tensor([[2.7651, 3.7333, 2.0502, 3.7353, 3.7090, 2.1740, 2.1958],\n",
            "        [0.7888, 1.2579, 0.8129, 1.2499, 1.1844, 0.8590, 0.8522],\n",
            "        [3.1070, 4.1125, 2.2455, 4.1186, 4.0902, 2.3976, 2.4214],\n",
            "        [1.1830, 1.7870, 1.0855, 1.7735, 1.7094, 1.1663, 1.1386],\n",
            "        [2.0847, 2.9302, 1.6535, 2.9201, 2.8758, 1.7700, 1.7526]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "78\n",
            "tensor([[2.6240, 3.5742, 1.9715, 3.5755, 3.5444, 2.0950, 2.1089],\n",
            "        [3.0130, 4.0141, 2.1934, 4.0192, 3.9958, 2.3374, 2.3615],\n",
            "        [1.5953, 2.3208, 1.3534, 2.3065, 2.2505, 1.4549, 1.4254],\n",
            "        [1.2501, 1.8751, 1.1303, 1.8623, 1.7978, 1.2156, 1.1876],\n",
            "        [2.5429, 3.4845, 1.9253, 3.4814, 3.4477, 2.0433, 2.0571]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "79\n",
            "tensor([[2.9787, 3.9734, 2.1728, 3.9829, 3.9577, 2.3136, 2.3408],\n",
            "        [1.0610, 1.6266, 1.0023, 1.6134, 1.5469, 1.0738, 1.0517],\n",
            "        [2.6079, 3.5566, 1.9606, 3.5568, 3.5272, 2.0789, 2.0995],\n",
            "        [2.7661, 3.7372, 2.0507, 3.7409, 3.7082, 2.1867, 2.2059],\n",
            "        [3.0859, 4.0936, 2.2317, 4.1034, 4.0714, 2.3834, 2.4153]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "80\n",
            "tensor([[3.0970, 4.1082, 2.2354, 4.1151, 4.0822, 2.3907, 2.4235],\n",
            "        [0.8180, 1.3001, 0.8337, 1.2923, 1.2249, 0.8843, 0.8776],\n",
            "        [2.6873, 3.6507, 2.0056, 3.6544, 3.6223, 2.1340, 2.1570],\n",
            "        [3.0755, 4.0840, 2.2214, 4.0897, 4.0565, 2.3775, 2.4094],\n",
            "        [1.8555, 2.6520, 1.5117, 2.6397, 2.5869, 1.6285, 1.6074]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "81\n",
            "tensor([[2.1137, 2.9704, 1.6679, 2.9623, 2.9146, 1.7891, 1.7822],\n",
            "        [3.0492, 4.0530, 2.2074, 4.0654, 4.0356, 2.3531, 2.3946],\n",
            "        [3.0901, 4.1002, 2.2286, 4.1075, 4.0747, 2.3876, 2.4233],\n",
            "        [1.5179, 2.2268, 1.3009, 2.2129, 2.1525, 1.4045, 1.3821],\n",
            "        [2.0661, 2.9130, 1.6396, 2.9025, 2.8583, 1.7554, 1.7496]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "82\n",
            "tensor([[0.8450, 1.3359, 0.8533, 1.3296, 1.2599, 0.9062, 0.9013],\n",
            "        [2.6954, 3.6577, 2.0036, 3.6602, 3.6310, 2.1236, 2.1630],\n",
            "        [1.0096, 1.5575, 0.9659, 1.5498, 1.4803, 1.0367, 1.0216],\n",
            "        [2.8525, 3.8395, 2.0947, 3.8463, 3.8185, 2.2249, 2.2675],\n",
            "        [1.6298, 2.3686, 1.3692, 2.3528, 2.2949, 1.4773, 1.4564]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "83\n",
            "tensor([[2.0553, 2.8944, 1.6245, 2.8852, 2.8363, 1.7478, 1.7431],\n",
            "        [2.0468, 2.8871, 1.6204, 2.8775, 2.8269, 1.7417, 1.7402],\n",
            "        [3.1045, 4.1113, 2.2285, 4.1153, 4.0793, 2.3893, 2.4350],\n",
            "        [0.8518, 1.3457, 0.8553, 1.3394, 1.2696, 0.9125, 0.9070],\n",
            "        [2.3718, 3.2767, 1.8135, 3.2740, 3.2319, 1.9376, 1.9548]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "84\n",
            "tensor([[3.0006, 3.9988, 2.1676, 4.0052, 3.9706, 2.3140, 2.3648],\n",
            "        [3.1106, 4.1191, 2.2281, 4.1247, 4.0838, 2.3931, 2.4413],\n",
            "        [0.9864, 1.5271, 0.9469, 1.5175, 1.4487, 1.0147, 1.0047],\n",
            "        [1.6443, 2.3839, 1.3741, 2.3704, 2.3114, 1.4793, 1.4684],\n",
            "        [2.4851, 3.4157, 1.8775, 3.4144, 3.3751, 2.0001, 2.0309]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "85\n",
            "tensor([[1.2078, 1.8211, 1.0923, 1.8064, 1.7405, 1.1770, 1.1640],\n",
            "        [3.0582, 4.0569, 2.1921, 4.0678, 4.0344, 2.3459, 2.4046],\n",
            "        [1.7384, 2.5061, 1.4278, 2.4904, 2.4340, 1.5417, 1.5342],\n",
            "        [3.0769, 4.0789, 2.2046, 4.0883, 4.0530, 2.3597, 2.4177],\n",
            "        [1.9354, 2.7496, 1.5475, 2.7362, 2.6828, 1.6674, 1.6662]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "86\n",
            "tensor([[3.0523, 4.0535, 2.1848, 4.0610, 4.0289, 2.3378, 2.4023],\n",
            "        [2.0710, 2.9165, 1.6246, 2.9045, 2.8562, 1.7462, 1.7585],\n",
            "        [3.1042, 4.1098, 2.2143, 4.1162, 4.0788, 2.3785, 2.4361],\n",
            "        [3.0632, 4.0665, 2.1888, 4.0681, 4.0270, 2.3463, 2.4133],\n",
            "        [0.8328, 1.3196, 0.8349, 1.3115, 1.2422, 0.8931, 0.8934]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "87\n",
            "tensor([[2.3711, 3.2765, 1.7953, 3.2704, 3.2280, 1.9257, 1.9568],\n",
            "        [3.1062, 4.1152, 2.2074, 4.1161, 4.0738, 2.3817, 2.4427],\n",
            "        [0.9991, 1.5426, 0.9476, 1.5310, 1.4617, 1.0188, 1.0148],\n",
            "        [2.5451, 3.4811, 1.8955, 3.4768, 3.4362, 2.0286, 2.0729],\n",
            "        [2.0210, 2.8522, 1.5889, 2.8408, 2.7866, 1.7145, 1.7264]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "88\n",
            "tensor([[3.1130, 4.1195, 2.2057, 4.1229, 4.0818, 2.3801, 2.4469],\n",
            "        [1.7836, 2.5599, 1.4448, 2.5452, 2.4877, 1.5675, 1.5659],\n",
            "        [1.2610, 1.8923, 1.1175, 1.8780, 1.8105, 1.2158, 1.2064],\n",
            "        [2.6016, 3.5469, 1.9225, 3.5456, 3.5066, 2.0613, 2.1101],\n",
            "        [2.7569, 3.7235, 2.0091, 3.7277, 3.6928, 2.1505, 2.2105]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "89\n",
            "tensor([[1.9396, 2.7533, 1.5347, 2.7399, 2.6860, 1.6603, 1.6715],\n",
            "        [0.8326, 1.3184, 0.8318, 1.3099, 1.2386, 0.8885, 0.8941],\n",
            "        [1.3891, 2.0572, 1.1981, 2.0402, 1.9750, 1.2998, 1.2936],\n",
            "        [3.0923, 4.0935, 2.1907, 4.0981, 4.0587, 2.3551, 2.4315],\n",
            "        [2.3575, 3.2621, 1.7801, 3.2553, 3.2087, 1.9125, 1.9513]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "90\n",
            "tensor([[1.0087, 1.5551, 0.9484, 1.5436, 1.4722, 1.0261, 1.0236],\n",
            "        [1.8835, 2.6842, 1.4983, 2.6678, 2.6144, 1.6221, 1.6344],\n",
            "        [2.7318, 3.6939, 1.9848, 3.6949, 3.6607, 2.1227, 2.1946],\n",
            "        [2.1789, 3.0426, 1.6695, 3.0308, 2.9806, 1.8044, 1.8304],\n",
            "        [2.7574, 3.7249, 2.0010, 3.7262, 3.6917, 2.1433, 2.2113]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "91\n",
            "tensor([[1.7401, 2.5050, 1.4107, 2.4875, 2.4289, 1.5300, 1.5382],\n",
            "        [0.9129, 1.4286, 0.8817, 1.4188, 1.3465, 0.9530, 0.9552],\n",
            "        [1.4582, 2.1453, 1.2351, 2.1282, 2.0643, 1.3477, 1.3438],\n",
            "        [1.8478, 2.6363, 1.4712, 2.6198, 2.5645, 1.5972, 1.6090],\n",
            "        [1.5255, 2.2329, 1.2785, 2.2170, 2.1533, 1.3920, 1.3922]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "92\n",
            "tensor([[3.1060, 4.1034, 2.1799, 4.1082, 4.0701, 2.3533, 2.4427],\n",
            "        [0.7744, 1.2388, 0.7841, 1.2311, 1.1610, 0.8388, 0.8503],\n",
            "        [3.0493, 4.0417, 2.1517, 4.0488, 4.0141, 2.3191, 2.4040],\n",
            "        [2.7769, 3.7391, 2.0008, 3.7415, 3.7037, 2.1520, 2.2235],\n",
            "        [3.1101, 4.1093, 2.1838, 4.1139, 4.0727, 2.3645, 2.4470]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "93\n",
            "tensor([[0.6774, 1.1071, 0.7168, 1.1005, 1.0310, 0.7604, 0.7763],\n",
            "        [3.0829, 4.0793, 2.1649, 4.0830, 4.0438, 2.3400, 2.4255],\n",
            "        [2.0381, 2.8719, 1.5784, 2.8582, 2.8040, 1.7121, 1.7387],\n",
            "        [3.1011, 4.0999, 2.1730, 4.0997, 4.0525, 2.3584, 2.4419],\n",
            "        [0.9716, 1.5056, 0.9199, 1.4960, 1.4239, 0.9955, 0.9973]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "94\n",
            "tensor([[2.4608, 3.3734, 1.8167, 3.3686, 3.3254, 1.9633, 2.0160],\n",
            "        [1.0082, 1.5533, 0.9409, 1.5420, 1.4695, 1.0224, 1.0240],\n",
            "        [1.7299, 2.4886, 1.3939, 2.4731, 2.4121, 1.5195, 1.5321],\n",
            "        [2.4148, 3.3268, 1.7940, 3.3200, 3.2764, 1.9335, 1.9893],\n",
            "        [1.4382, 2.1181, 1.2162, 2.1017, 2.0375, 1.3255, 1.3303]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "95\n",
            "tensor([[2.5821, 3.5178, 1.8844, 3.5160, 3.4741, 2.0293, 2.0979],\n",
            "        [1.4273, 2.1055, 1.2084, 2.0882, 2.0215, 1.3199, 1.3214],\n",
            "        [1.4655, 2.1539, 1.2323, 2.1370, 2.0716, 1.3474, 1.3493],\n",
            "        [1.5458, 2.2558, 1.2828, 2.2381, 2.1765, 1.3967, 1.4038],\n",
            "        [1.1036, 1.6816, 1.0046, 1.6698, 1.5972, 1.0946, 1.0938]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "96\n",
            "tensor([[1.8779, 2.6736, 1.4781, 2.6565, 2.6005, 1.6099, 1.6297],\n",
            "        [2.3715, 3.2765, 1.7660, 3.2668, 3.2212, 1.9060, 1.9601],\n",
            "        [2.2402, 3.1160, 1.6900, 3.1078, 3.0558, 1.8309, 1.8736],\n",
            "        [1.4852, 2.1754, 1.2445, 2.1575, 2.0947, 1.3588, 1.3613],\n",
            "        [2.7748, 3.7374, 1.9881, 3.7386, 3.7045, 2.1383, 2.2215]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "97\n",
            "tensor([[2.9050, 3.8855, 2.0593, 3.8890, 3.8596, 2.2122, 2.3052],\n",
            "        [1.2186, 1.8331, 1.0771, 1.8194, 1.7500, 1.1716, 1.1753],\n",
            "        [3.0945, 4.0940, 2.1616, 4.0954, 4.0540, 2.3430, 2.4348],\n",
            "        [2.0935, 2.9424, 1.6062, 2.9290, 2.8800, 1.7344, 1.7766],\n",
            "        [3.1013, 4.0997, 2.1645, 4.0999, 4.0592, 2.3488, 2.4416]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "98\n",
            "tensor([[3.0959, 4.0918, 2.1592, 4.0981, 4.0627, 2.3316, 2.4339],\n",
            "        [0.9658, 1.4995, 0.9127, 1.4879, 1.4180, 0.9839, 0.9935],\n",
            "        [2.9189, 3.9006, 2.0637, 3.9027, 3.8741, 2.2111, 2.3146],\n",
            "        [2.7367, 3.6957, 1.9654, 3.6968, 3.6608, 2.1178, 2.1976],\n",
            "        [3.0926, 4.0926, 2.1579, 4.0902, 4.0489, 2.3413, 2.4344]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "99\n",
            "tensor([[1.4035, 2.0742, 1.1940, 2.0593, 1.9946, 1.2996, 1.3066],\n",
            "        [2.3077, 3.1996, 1.7277, 3.1910, 3.1485, 1.8602, 1.9186],\n",
            "        [2.9875, 3.9729, 2.1020, 3.9791, 3.9528, 2.2543, 2.3601],\n",
            "        [2.3398, 3.2396, 1.7456, 3.2291, 3.1859, 1.8898, 1.9416],\n",
            "        [0.8546, 1.3492, 0.8392, 1.3411, 1.2687, 0.8980, 0.9132]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "100\n",
            "tensor([[0.9937, 1.5369, 0.9319, 1.5259, 1.4556, 1.0082, 1.0147],\n",
            "        [2.0247, 2.8581, 1.5633, 2.8436, 2.7907, 1.6911, 1.7316],\n",
            "        [0.6908, 1.1261, 0.7228, 1.1202, 1.0511, 0.7673, 0.7894],\n",
            "        [1.1286, 1.7144, 1.0196, 1.7036, 1.6331, 1.1072, 1.1124],\n",
            "        [0.8714, 1.3727, 0.8503, 1.3638, 1.2928, 0.9136, 0.9251]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "101\n",
            "tensor([[1.6036, 2.3341, 1.3107, 2.3147, 2.2523, 1.4315, 1.4437],\n",
            "        [1.0177, 1.5693, 0.9473, 1.5556, 1.4866, 1.0228, 1.0317],\n",
            "        [2.0903, 2.9390, 1.6002, 2.9239, 2.8772, 1.7335, 1.7747],\n",
            "        [2.1244, 2.9799, 1.6169, 2.9648, 2.9155, 1.7569, 1.7997],\n",
            "        [3.1030, 4.1016, 2.1603, 4.1049, 4.0670, 2.3378, 2.4427]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "102\n",
            "tensor([[1.8668, 2.6648, 1.4707, 2.6488, 2.5941, 1.5957, 1.6266],\n",
            "        [3.0867, 4.0860, 2.1522, 4.0880, 4.0530, 2.3214, 2.4318],\n",
            "        [0.6891, 1.1237, 0.7239, 1.1175, 1.0479, 0.7651, 0.7871],\n",
            "        [1.3422, 1.9963, 1.1538, 1.9803, 1.9158, 1.2563, 1.2643],\n",
            "        [1.1342, 1.7225, 1.0228, 1.7096, 1.6403, 1.1076, 1.1164]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "103\n",
            "tensor([[2.7624, 3.7320, 1.9754, 3.7319, 3.7025, 2.1138, 2.2176],\n",
            "        [2.2682, 3.1543, 1.7009, 3.1439, 3.0994, 1.8371, 1.8952],\n",
            "        [1.9967, 2.8217, 1.5446, 2.8076, 2.7550, 1.6735, 1.7138],\n",
            "        [0.8210, 1.3045, 0.8150, 1.2970, 1.2249, 0.8732, 0.8895],\n",
            "        [1.3853, 2.0537, 1.1785, 2.0359, 1.9708, 1.2837, 1.2964]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "104\n",
            "tensor([[1.6323, 2.3718, 1.3310, 2.3519, 2.2945, 1.4449, 1.4667],\n",
            "        [0.9878, 1.5308, 0.9271, 1.5183, 1.4475, 0.9998, 1.0117],\n",
            "        [2.0986, 2.9474, 1.6022, 2.9313, 2.8845, 1.7334, 1.7802],\n",
            "        [1.4990, 2.2020, 1.2492, 2.1811, 2.1190, 1.3599, 1.3736],\n",
            "        [0.7944, 1.2670, 0.7973, 1.2590, 1.1871, 0.8483, 0.8683]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "105\n",
            "tensor([[1.6140, 2.3478, 1.3173, 2.3258, 2.2681, 1.4334, 1.4527],\n",
            "        [0.8524, 1.3483, 0.8367, 1.3375, 1.2680, 0.8967, 0.9107],\n",
            "        [0.7573, 1.2183, 0.7721, 1.2108, 1.1401, 0.8209, 0.8412],\n",
            "        [1.5632, 2.2835, 1.2909, 2.2637, 2.2043, 1.3993, 1.4181],\n",
            "        [1.3300, 1.9810, 1.1448, 1.9642, 1.9011, 1.2420, 1.2556]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "106\n",
            "tensor([[2.4904, 3.4228, 1.8262, 3.4111, 3.3793, 1.9591, 2.0389],\n",
            "        [0.8611, 1.3607, 0.8442, 1.3491, 1.2803, 0.9018, 0.9169],\n",
            "        [0.8805, 1.3854, 0.8584, 1.3737, 1.3043, 0.9154, 0.9311],\n",
            "        [2.0585, 2.9038, 1.5815, 2.8851, 2.8382, 1.7073, 1.7544],\n",
            "        [2.8887, 3.8717, 2.0449, 3.8680, 3.8458, 2.1830, 2.2947]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "107\n",
            "tensor([[3.0182, 4.0171, 2.1083, 4.0093, 3.9705, 2.2882, 2.3887],\n",
            "        [1.7891, 2.5728, 1.4253, 2.5494, 2.4986, 1.5414, 1.5715],\n",
            "        [2.1997, 3.0757, 1.6643, 3.0595, 3.0168, 1.7952, 1.8498],\n",
            "        [2.9309, 3.9208, 2.0689, 3.9167, 3.8931, 2.2228, 2.3280],\n",
            "        [0.8057, 1.2853, 0.8078, 1.2756, 1.2065, 0.8602, 0.8755]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "108\n",
            "tensor([[3.0219, 4.0189, 2.1188, 4.0170, 3.9966, 2.2794, 2.3826],\n",
            "        [0.9802, 1.5215, 0.9224, 1.5044, 1.4381, 0.9885, 1.0023],\n",
            "        [3.0345, 4.0357, 2.1234, 4.0305, 4.0104, 2.2740, 2.3917],\n",
            "        [2.7569, 3.7334, 1.9753, 3.7235, 3.6980, 2.1096, 2.2124],\n",
            "        [1.6922, 2.4514, 1.3714, 2.4292, 2.3752, 1.4851, 1.5082]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "109\n",
            "tensor([[1.3938, 2.0676, 1.1872, 2.0460, 1.9841, 1.2846, 1.2988],\n",
            "        [2.2255, 3.1075, 1.6813, 3.0892, 3.0508, 1.8024, 1.8614],\n",
            "        [2.8214, 3.7983, 2.0077, 3.7923, 3.7758, 2.1373, 2.2464],\n",
            "        [2.3653, 3.2781, 1.7614, 3.2624, 3.2280, 1.8850, 1.9555],\n",
            "        [1.6456, 2.3923, 1.3444, 2.3685, 2.3153, 1.4514, 1.4742]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "110\n",
            "tensor([[2.8910, 3.8778, 2.0480, 3.8726, 3.8518, 2.1835, 2.2958],\n",
            "        [2.9978, 3.9919, 2.1054, 3.9892, 3.9672, 2.2521, 2.3651],\n",
            "        [2.0482, 2.8926, 1.5796, 2.8721, 2.8305, 1.6979, 1.7438],\n",
            "        [1.2571, 1.8895, 1.1069, 1.8700, 1.8070, 1.1912, 1.2014],\n",
            "        [2.9476, 3.9344, 2.0760, 3.9310, 3.9075, 2.2288, 2.3310]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "111\n",
            "tensor([[3.0570, 4.0543, 2.1346, 4.0515, 4.0285, 2.2802, 2.3999],\n",
            "        [3.0908, 4.0884, 2.1535, 4.0854, 4.0598, 2.3098, 2.4226],\n",
            "        [1.0876, 1.6614, 0.9953, 1.6448, 1.5806, 1.0681, 1.0770],\n",
            "        [2.7536, 3.7234, 1.9730, 3.7150, 3.6964, 2.0944, 2.1983],\n",
            "        [2.2890, 3.1786, 1.7155, 3.1606, 3.1270, 1.8337, 1.8959]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "112\n",
            "tensor([[2.6228, 3.5702, 1.9016, 3.5570, 3.5343, 2.0180, 2.1113],\n",
            "        [1.4517, 2.1396, 1.2256, 2.1156, 2.0612, 1.3202, 1.3310],\n",
            "        [1.0595, 1.6225, 0.9771, 1.6068, 1.5427, 1.0445, 1.0553],\n",
            "        [2.3267, 3.2198, 1.7347, 3.2019, 3.1711, 1.8511, 1.9160],\n",
            "        [0.9630, 1.4941, 0.9139, 1.4811, 1.4147, 0.9756, 0.9872]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "113\n",
            "tensor([[3.0695, 4.0624, 2.1395, 4.0553, 4.0377, 2.2845, 2.3980],\n",
            "        [1.2214, 1.8398, 1.0751, 1.8139, 1.7579, 1.1523, 1.1650],\n",
            "        [2.8325, 3.8031, 2.0122, 3.7958, 3.7773, 2.1367, 2.2433],\n",
            "        [1.4343, 2.1134, 1.2143, 2.0904, 2.0365, 1.3026, 1.3150],\n",
            "        [3.1102, 4.1057, 2.1612, 4.0979, 4.0782, 2.3144, 2.4240]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "114\n",
            "tensor([[0.9763, 1.5082, 0.9223, 1.4920, 1.4280, 0.9806, 0.9912],\n",
            "        [0.9067, 1.4166, 0.8763, 1.4029, 1.3372, 0.9290, 0.9418],\n",
            "        [1.6191, 2.3476, 1.3239, 2.3217, 2.2743, 1.4180, 1.4398],\n",
            "        [2.3886, 3.2903, 1.7665, 3.2718, 3.2468, 1.8748, 1.9491],\n",
            "        [2.4132, 3.3197, 1.7805, 3.3004, 3.2742, 1.8928, 1.9659]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "115\n",
            "tensor([[2.1081, 2.9511, 1.6099, 2.9287, 2.8936, 1.7117, 1.7645],\n",
            "        [2.3003, 3.1802, 1.7176, 3.1602, 3.1308, 1.8256, 1.8896],\n",
            "        [2.8542, 3.8188, 2.0209, 3.8099, 3.7998, 2.1336, 2.2446],\n",
            "        [1.7925, 2.5632, 1.4263, 2.5378, 2.4942, 1.5300, 1.5548],\n",
            "        [2.1622, 3.0161, 1.6400, 2.9934, 2.9610, 1.7438, 1.7976]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "116\n",
            "tensor([[1.0787, 1.6438, 0.9905, 1.6263, 1.5654, 1.0531, 1.0630],\n",
            "        [2.8022, 3.7580, 1.9928, 3.7481, 3.7375, 2.1052, 2.2111],\n",
            "        [3.0589, 4.0404, 2.1303, 4.0331, 4.0222, 2.2570, 2.3759],\n",
            "        [1.0524, 1.6080, 0.9729, 1.5904, 1.5294, 1.0317, 1.0419],\n",
            "        [2.3422, 3.2314, 1.7435, 3.2121, 3.1870, 1.8469, 1.9151]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "117\n",
            "tensor([[3.1041, 4.0870, 2.1555, 4.0787, 4.0663, 2.2988, 2.4059],\n",
            "        [2.1417, 2.9861, 1.6260, 2.9637, 2.9347, 1.7302, 1.7808],\n",
            "        [2.2665, 3.1412, 1.6980, 3.1211, 3.0933, 1.7977, 1.8639],\n",
            "        [2.9739, 3.9454, 2.0842, 3.9398, 3.9295, 2.2048, 2.3210],\n",
            "        [1.9690, 2.7773, 1.5292, 2.7552, 2.7182, 1.6313, 1.6687]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "118\n",
            "tensor([[2.0252, 2.8427, 1.5623, 2.8211, 2.7871, 1.6637, 1.7021],\n",
            "        [2.7582, 3.7057, 1.9698, 3.6958, 3.6840, 2.0797, 2.1772],\n",
            "        [2.4101, 3.2998, 1.7789, 3.2840, 3.2621, 1.8825, 1.9517],\n",
            "        [2.5433, 3.4608, 1.8542, 3.4460, 3.4288, 1.9605, 2.0402],\n",
            "        [0.8263, 1.3032, 0.8208, 1.2907, 1.2291, 0.8638, 0.8777]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "119\n",
            "tensor([[1.2426, 1.8557, 1.0920, 1.8339, 1.7778, 1.1646, 1.1716],\n",
            "        [2.8407, 3.7929, 2.0144, 3.7838, 3.7749, 2.1259, 2.2228],\n",
            "        [1.0139, 1.5512, 0.9480, 1.5356, 1.4752, 1.0028, 1.0104],\n",
            "        [2.0445, 2.8639, 1.5722, 2.8394, 2.8073, 1.6656, 1.7097],\n",
            "        [3.0197, 3.9880, 2.1091, 3.9804, 3.9720, 2.2356, 2.3424]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "120\n",
            "tensor([[3.0310, 3.9962, 2.1152, 3.9873, 3.9787, 2.2354, 2.3404],\n",
            "        [2.0616, 2.8825, 1.5820, 2.8598, 2.8275, 1.6746, 1.7180],\n",
            "        [0.7407, 1.1823, 0.7615, 1.1723, 1.1105, 0.7904, 0.8098],\n",
            "        [1.8525, 2.6244, 1.4604, 2.5984, 2.5639, 1.5528, 1.5794],\n",
            "        [2.0887, 2.9117, 1.5966, 2.8905, 2.8573, 1.6947, 1.7356]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "121\n",
            "tensor([[2.9696, 3.9214, 2.0782, 3.9135, 3.9094, 2.1884, 2.2923],\n",
            "        [1.0584, 1.6047, 0.9754, 1.5894, 1.5289, 1.0309, 1.0366],\n",
            "        [2.6823, 3.6044, 1.9264, 3.5914, 3.5816, 2.0275, 2.1106],\n",
            "        [3.0743, 4.0378, 2.1359, 4.0282, 4.0210, 2.2619, 2.3646],\n",
            "        [3.0825, 4.0448, 2.1414, 4.0384, 4.0313, 2.2586, 2.3693]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "122\n",
            "tensor([[1.4843, 2.1538, 1.2416, 2.1303, 2.0814, 1.3198, 1.3262],\n",
            "        [1.5150, 2.1953, 1.2599, 2.1703, 2.1225, 1.3388, 1.3470],\n",
            "        [2.4513, 3.3369, 1.7980, 3.3162, 3.2991, 1.8880, 1.9590],\n",
            "        [2.6342, 3.5505, 1.9003, 3.5334, 3.5240, 1.9949, 2.0749],\n",
            "        [2.8048, 3.7399, 1.9904, 3.7253, 3.7194, 2.0930, 2.1836]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "123\n",
            "tensor([[1.8869, 2.6551, 1.4783, 2.6277, 2.5929, 1.5677, 1.5889],\n",
            "        [3.1453, 4.1081, 2.1696, 4.0927, 4.0854, 2.2973, 2.3982],\n",
            "        [3.0539, 4.0035, 2.1203, 3.9885, 3.9885, 2.2212, 2.3328],\n",
            "        [3.0811, 4.0373, 2.1378, 4.0250, 4.0244, 2.2582, 2.3522],\n",
            "        [1.4722, 2.1393, 1.2337, 2.1119, 2.0660, 1.3098, 1.3136]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "124\n",
            "tensor([[2.0463, 2.8486, 1.5684, 2.8169, 2.7940, 1.6548, 1.6859],\n",
            "        [2.9649, 3.9094, 2.0714, 3.8904, 3.8930, 2.1617, 2.2683],\n",
            "        [1.3036, 1.9201, 1.1279, 1.8934, 1.8432, 1.1947, 1.1959],\n",
            "        [2.7704, 3.7006, 1.9694, 3.6781, 3.6792, 2.0630, 2.1477],\n",
            "        [0.8959, 1.3857, 0.8672, 1.3692, 1.3101, 0.9085, 0.9139]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "125\n",
            "tensor([[2.7247, 3.6435, 1.9449, 3.6181, 3.6198, 2.0325, 2.1133],\n",
            "        [3.0270, 3.9712, 2.1033, 3.9521, 3.9594, 2.2134, 2.3030],\n",
            "        [1.0256, 1.5561, 0.9521, 1.5358, 1.4803, 1.0022, 1.0028],\n",
            "        [1.2443, 1.8416, 1.0921, 1.8145, 1.7631, 1.1527, 1.1514],\n",
            "        [1.0347, 1.5680, 0.9587, 1.5474, 1.4890, 1.0084, 1.0096]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "126\n",
            "tensor([[3.1317, 4.0846, 2.1584, 4.0554, 4.0534, 2.2806, 2.3727],\n",
            "        [3.0077, 3.9511, 2.0962, 3.9257, 3.9337, 2.1989, 2.2836],\n",
            "        [2.6593, 3.5680, 1.9094, 3.5379, 3.5383, 1.9953, 2.0672],\n",
            "        [2.8884, 3.8163, 2.0298, 3.7886, 3.7977, 2.1130, 2.2038],\n",
            "        [1.4350, 2.0847, 1.2094, 2.0541, 2.0084, 1.2796, 1.2783]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "127\n",
            "tensor([[2.6383, 3.5356, 1.8964, 3.5033, 3.5027, 1.9778, 2.0479],\n",
            "        [1.3775, 2.0095, 1.1728, 1.9763, 1.9322, 1.2355, 1.2352],\n",
            "        [1.0104, 1.5315, 0.9407, 1.5085, 1.4525, 0.9866, 0.9865],\n",
            "        [1.0677, 1.6076, 0.9814, 1.5817, 1.5290, 1.0297, 1.0252],\n",
            "        [1.4755, 2.1320, 1.2346, 2.0997, 2.0581, 1.3025, 1.3015]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "128\n",
            "tensor([[2.2531, 3.0857, 1.6851, 3.0495, 3.0346, 1.7656, 1.8037],\n",
            "        [2.5634, 3.4465, 1.8555, 3.4122, 3.4092, 1.9397, 1.9970],\n",
            "        [0.8253, 1.2844, 0.8187, 1.2658, 1.2079, 0.8470, 0.8543],\n",
            "        [3.1617, 4.1077, 2.1751, 4.0754, 4.0795, 2.2943, 2.3784],\n",
            "        [0.8751, 1.3505, 0.8523, 1.3326, 1.2740, 0.8863, 0.8912]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "129\n",
            "tensor([[0.7725, 1.2140, 0.7828, 1.1963, 1.1378, 0.8054, 0.8157],\n",
            "        [1.6390, 2.3369, 1.3329, 2.2966, 2.2623, 1.4038, 1.4047],\n",
            "        [0.8113, 1.2643, 0.8092, 1.2469, 1.1897, 0.8363, 0.8443],\n",
            "        [1.7214, 2.4362, 1.3791, 2.3975, 2.3647, 1.4517, 1.4569],\n",
            "        [0.9384, 1.4320, 0.8963, 1.4119, 1.3544, 0.9313, 0.9337]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "130\n",
            "tensor([[3.0964, 4.0267, 2.1408, 3.9991, 4.0125, 2.2382, 2.3259],\n",
            "        [0.8982, 1.3790, 0.8663, 1.3572, 1.3006, 0.9005, 0.9038],\n",
            "        [1.6527, 2.3480, 1.3414, 2.3119, 2.2759, 1.4107, 1.4129],\n",
            "        [0.9315, 1.4208, 0.8901, 1.4003, 1.3430, 0.9260, 0.9281],\n",
            "        [1.4235, 2.0613, 1.2030, 2.0259, 1.9839, 1.2642, 1.2611]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "131\n",
            "tensor([[3.0717, 3.9944, 2.1268, 3.9640, 3.9814, 2.2139, 2.3025],\n",
            "        [1.7596, 2.4776, 1.4022, 2.4373, 2.4082, 1.4698, 1.4793],\n",
            "        [1.9473, 2.7093, 1.5125, 2.6671, 2.6470, 1.5787, 1.5983],\n",
            "        [2.7898, 3.6961, 1.9802, 3.6601, 3.6737, 2.0434, 2.1268],\n",
            "        [1.0556, 1.5829, 0.9728, 1.5566, 1.5045, 1.0142, 1.0117]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "132\n",
            "tensor([[1.7009, 2.4032, 1.3686, 2.3644, 2.3320, 1.4368, 1.4391],\n",
            "        [2.7330, 3.6251, 1.9481, 3.5884, 3.5958, 2.0210, 2.0899],\n",
            "        [2.5799, 3.4532, 1.8667, 3.4162, 3.4181, 1.9352, 1.9958],\n",
            "        [3.0611, 3.9804, 2.1217, 3.9489, 3.9675, 2.2023, 2.2932],\n",
            "        [3.1309, 4.0584, 2.1569, 4.0246, 4.0399, 2.2560, 2.3416]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "133\n",
            "tensor([[0.9505, 1.4425, 0.9036, 1.4201, 1.3648, 0.9398, 0.9376],\n",
            "        [0.9901, 1.4951, 0.9300, 1.4702, 1.4158, 0.9673, 0.9642],\n",
            "        [2.3955, 3.2374, 1.7668, 3.1984, 3.1945, 1.8321, 1.8773],\n",
            "        [0.9209, 1.4031, 0.8852, 1.3825, 1.3261, 0.9185, 0.9166],\n",
            "        [1.5020, 2.1523, 1.2498, 2.1136, 2.0777, 1.3085, 1.3063]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "134\n",
            "tensor([[2.3567, 3.1887, 1.7436, 3.1488, 3.1429, 1.8128, 1.8530],\n",
            "        [0.9148, 1.3940, 0.8809, 1.3730, 1.3175, 0.9147, 0.9123],\n",
            "        [2.2661, 3.0822, 1.6947, 3.0420, 3.0336, 1.7656, 1.7962],\n",
            "        [1.0588, 1.5833, 0.9735, 1.5571, 1.5052, 1.0165, 1.0117],\n",
            "        [3.0859, 3.9997, 2.1353, 3.9685, 3.9853, 2.2261, 2.3053]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "135\n",
            "tensor([[2.7463, 3.6321, 1.9583, 3.5935, 3.6056, 2.0279, 2.0891],\n",
            "        [2.3846, 3.2178, 1.7602, 3.1766, 3.1717, 1.8281, 1.8658],\n",
            "        [0.8606, 1.3211, 0.8435, 1.3012, 1.2431, 0.8718, 0.8726],\n",
            "        [1.4052, 2.0264, 1.1926, 1.9906, 1.9487, 1.2491, 1.2413],\n",
            "        [1.8971, 2.6387, 1.4863, 2.5972, 2.5721, 1.5525, 1.5601]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "136\n",
            "tensor([[2.7281, 3.6100, 1.9451, 3.5701, 3.5804, 2.0154, 2.0762],\n",
            "        [2.4568, 3.2992, 1.8004, 3.2574, 3.2562, 1.8679, 1.9075],\n",
            "        [1.5430, 2.1988, 1.2767, 2.1594, 2.1225, 1.3369, 1.3302],\n",
            "        [2.5087, 3.3621, 1.8286, 3.3202, 3.3217, 1.8969, 1.9426],\n",
            "        [1.5970, 2.2657, 1.3088, 2.2259, 2.1904, 1.3703, 1.3642]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "137\n",
            "tensor([[1.4776, 2.1157, 1.2358, 2.0776, 2.0370, 1.2961, 1.2865],\n",
            "        [2.9920, 3.8947, 2.0854, 3.8581, 3.8774, 2.1666, 2.2352],\n",
            "        [3.1111, 4.0230, 2.1489, 3.9877, 4.0046, 2.2386, 2.3131],\n",
            "        [2.6885, 3.5641, 1.9248, 3.5229, 3.5339, 1.9859, 2.0476],\n",
            "        [3.1173, 4.0298, 2.1525, 3.9924, 4.0125, 2.2470, 2.3160]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "138\n",
            "tensor([[2.9689, 3.8671, 2.0715, 3.8277, 3.8483, 2.1432, 2.2173],\n",
            "        [3.1670, 4.0827, 2.1777, 4.0399, 4.0548, 2.2722, 2.3452],\n",
            "        [3.1075, 4.0151, 2.1443, 3.9765, 3.9970, 2.2290, 2.3038],\n",
            "        [2.4401, 3.2763, 1.7889, 3.2328, 3.2282, 1.8596, 1.8937],\n",
            "        [3.1700, 4.0831, 2.1787, 4.0415, 4.0584, 2.2727, 2.3464]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "139\n",
            "tensor([[1.3198, 1.9136, 1.1378, 1.8772, 1.8313, 1.1956, 1.1786],\n",
            "        [3.0867, 3.9915, 2.1336, 3.9531, 3.9686, 2.2115, 2.2891],\n",
            "        [2.4596, 3.2954, 1.7993, 3.2511, 3.2500, 1.8690, 1.9013],\n",
            "        [0.8565, 1.3118, 0.8411, 1.2914, 1.2329, 0.8697, 0.8661],\n",
            "        [1.7711, 2.4780, 1.4112, 2.4344, 2.4069, 1.4762, 1.4713]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "140\n",
            "tensor([[2.4002, 3.2263, 1.7671, 3.1810, 3.1795, 1.8308, 1.8614],\n",
            "        [3.1459, 4.0540, 2.1639, 4.0141, 4.0270, 2.2690, 2.3268],\n",
            "        [2.2475, 3.0466, 1.6804, 3.0002, 2.9901, 1.7523, 1.7674],\n",
            "        [2.0778, 2.8500, 1.5870, 2.8018, 2.7847, 1.6609, 1.6625],\n",
            "        [0.8840, 1.3498, 0.8590, 1.3252, 1.2696, 0.8888, 0.8846]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "141\n",
            "tensor([[3.1532, 4.0592, 2.1658, 4.0171, 4.0347, 2.2640, 2.3270],\n",
            "        [3.1715, 4.0797, 2.1756, 4.0382, 4.0517, 2.2780, 2.3409],\n",
            "        [1.2898, 1.8710, 1.1191, 1.8367, 1.7892, 1.1761, 1.1564],\n",
            "        [0.9609, 1.4485, 0.9100, 1.4248, 1.3688, 0.9487, 0.9364],\n",
            "        [1.3120, 1.9008, 1.1354, 1.8650, 1.8202, 1.1893, 1.1707]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "142\n",
            "tensor([[1.2534, 1.8268, 1.0966, 1.7932, 1.7450, 1.1558, 1.1324],\n",
            "        [1.1314, 1.6710, 1.0189, 1.6396, 1.5880, 1.0702, 1.0518],\n",
            "        [1.1144, 1.6493, 1.0093, 1.6202, 1.5674, 1.0606, 1.0419],\n",
            "        [2.9766, 3.8718, 2.0724, 3.8290, 3.8462, 2.1510, 2.2134],\n",
            "        [3.1787, 4.0880, 2.1785, 4.0468, 4.0596, 2.2816, 2.3441]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "143\n",
            "tensor([[1.1645, 1.7130, 1.0408, 1.6821, 1.6307, 1.0965, 1.0739],\n",
            "        [1.8139, 2.5282, 1.4356, 2.4829, 2.4554, 1.5059, 1.4940],\n",
            "        [2.7865, 3.6672, 1.9740, 3.6241, 3.6360, 2.0523, 2.0982],\n",
            "        [1.4640, 2.0934, 1.2262, 2.0544, 2.0124, 1.2963, 1.2713],\n",
            "        [1.0316, 1.5419, 0.9567, 1.5147, 1.4593, 1.0018, 0.9855]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "144\n",
            "tensor([[0.8345, 1.2838, 0.8258, 1.2626, 1.2044, 0.8596, 0.8494],\n",
            "        [1.2324, 1.8007, 1.0866, 1.7691, 1.7171, 1.1461, 1.1206],\n",
            "        [2.4272, 3.2616, 1.7806, 3.2161, 3.2111, 1.8648, 1.8810],\n",
            "        [2.2416, 3.0412, 1.6771, 2.9962, 2.9823, 1.7599, 1.7651],\n",
            "        [3.1018, 4.0064, 2.1409, 3.9664, 3.9815, 2.2442, 2.2955]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "145\n",
            "tensor([[1.6571, 2.3354, 1.3432, 2.2937, 2.2580, 1.4225, 1.3972],\n",
            "        [1.0334, 1.5438, 0.9585, 1.5187, 1.4619, 1.0101, 0.9883],\n",
            "        [3.1058, 4.0094, 2.1432, 3.9726, 3.9875, 2.2499, 2.2979],\n",
            "        [1.6365, 2.3103, 1.3321, 2.2697, 2.2323, 1.4116, 1.3846],\n",
            "        [2.6521, 3.5176, 1.9042, 3.4753, 3.4785, 1.9884, 2.0185]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "146\n",
            "tensor([[3.0864, 3.9871, 2.1345, 3.9533, 3.9667, 2.2468, 2.2889],\n",
            "        [1.4354, 2.0582, 1.2111, 2.0209, 1.9778, 1.2822, 1.2542],\n",
            "        [2.0472, 2.8051, 1.5682, 2.7626, 2.7402, 1.6566, 1.6435],\n",
            "        [1.5872, 2.2478, 1.3014, 2.2084, 2.1700, 1.3779, 1.3512],\n",
            "        [3.1659, 4.0727, 2.1723, 4.0311, 4.0372, 2.3039, 2.3438]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "147\n",
            "tensor([[2.4749, 3.3063, 1.8088, 3.2693, 3.2613, 1.8985, 1.9107],\n",
            "        [2.7747, 3.6468, 1.9711, 3.6123, 3.6166, 2.0683, 2.0948],\n",
            "        [3.1776, 4.0827, 2.1818, 4.0482, 4.0574, 2.3075, 2.3472],\n",
            "        [1.1804, 1.7298, 1.0517, 1.7022, 1.6486, 1.1161, 1.0866],\n",
            "        [0.7572, 1.1802, 0.7742, 1.1645, 1.1032, 0.8052, 0.7976]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "148\n",
            "tensor([[2.4064, 3.2262, 1.7699, 3.1884, 3.1783, 1.8604, 1.8662],\n",
            "        [2.3706, 3.1849, 1.7499, 3.1471, 3.1345, 1.8391, 1.8431],\n",
            "        [2.6025, 3.4503, 1.8776, 3.4144, 3.4125, 1.9627, 1.9858],\n",
            "        [1.8886, 2.6135, 1.4802, 2.5754, 2.5459, 1.5642, 1.5440],\n",
            "        [1.9813, 2.7232, 1.5318, 2.6864, 2.6583, 1.6245, 1.6031]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "149\n",
            "tensor([[1.8845, 2.6088, 1.4766, 2.5715, 2.5391, 1.5636, 1.5414],\n",
            "        [1.2054, 1.7617, 1.0719, 1.7363, 1.6801, 1.1375, 1.1026],\n",
            "        [0.6625, 1.0516, 0.7075, 1.0404, 0.9791, 0.7294, 0.7289],\n",
            "        [1.9773, 2.7165, 1.5280, 2.6801, 2.6506, 1.6205, 1.5988],\n",
            "        [3.0981, 3.9899, 2.1406, 3.9618, 3.9745, 2.2495, 2.2879]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "150\n",
            "tensor([[3.0001, 3.8884, 2.0899, 3.8594, 3.8708, 2.1933, 2.2271],\n",
            "        [2.8126, 3.6876, 1.9905, 3.6572, 3.6603, 2.0797, 2.1138],\n",
            "        [0.9328, 1.4068, 0.8893, 1.3879, 1.3266, 0.9340, 0.9156],\n",
            "        [2.1434, 2.9138, 1.6230, 2.8781, 2.8547, 1.7174, 1.7009],\n",
            "        [3.1991, 4.0989, 2.1935, 4.0699, 4.0750, 2.3226, 2.3549]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "151\n",
            "tensor([[1.3657, 1.9599, 1.1640, 1.9315, 1.8816, 1.2348, 1.2043],\n",
            "        [2.4095, 3.2246, 1.7739, 3.1917, 3.1815, 1.8613, 1.8620],\n",
            "        [2.4009, 3.2155, 1.7686, 3.1832, 3.1686, 1.8610, 1.8604],\n",
            "        [2.0924, 2.8537, 1.5961, 2.8189, 2.7943, 1.6867, 1.6673],\n",
            "        [0.8667, 1.3178, 0.8494, 1.3034, 1.2413, 0.8900, 0.8704]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "152\n",
            "tensor([[2.2625, 3.0534, 1.6937, 3.0207, 3.0014, 1.7820, 1.7703],\n",
            "        [2.9512, 3.8316, 2.0659, 3.8059, 3.8123, 2.1645, 2.1941],\n",
            "        [1.1284, 1.6592, 1.0226, 1.6393, 1.5795, 1.0835, 1.0490],\n",
            "        [2.9194, 3.7990, 2.0499, 3.7729, 3.7791, 2.1448, 2.1733],\n",
            "        [0.8505, 1.2985, 0.8386, 1.2834, 1.2219, 0.8763, 0.8595]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "153\n",
            "tensor([[3.1978, 4.0905, 2.1959, 4.0683, 4.0706, 2.3168, 2.3488],\n",
            "        [2.7312, 3.5908, 1.9511, 3.5626, 3.5580, 2.0416, 2.0580],\n",
            "        [3.2111, 4.1063, 2.2029, 4.0815, 4.0780, 2.3326, 2.3614],\n",
            "        [0.8231, 1.2622, 0.8224, 1.2498, 1.1862, 0.8585, 0.8414],\n",
            "        [2.8597, 3.7312, 2.0177, 3.7055, 3.7060, 2.1183, 2.1396]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "154\n",
            "tensor([[3.0784, 3.9659, 2.1391, 3.9463, 3.9525, 2.2480, 2.2731],\n",
            "        [0.9451, 1.4214, 0.9055, 1.4076, 1.3447, 0.9526, 0.9263],\n",
            "        [1.8984, 2.6194, 1.4913, 2.5910, 2.5538, 1.5821, 1.5478],\n",
            "        [0.9893, 1.4794, 0.9342, 1.4642, 1.4020, 0.9868, 0.9560],\n",
            "        [2.4517, 3.2697, 1.7973, 3.2412, 3.2214, 1.8869, 1.8893]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "155\n",
            "tensor([[2.6534, 3.5042, 1.9169, 3.4831, 3.4763, 2.0018, 2.0130],\n",
            "        [1.5044, 2.1357, 1.2598, 2.1107, 2.0616, 1.3387, 1.2972],\n",
            "        [1.3405, 1.9291, 1.1575, 1.9072, 1.8536, 1.2331, 1.1901],\n",
            "        [3.1254, 4.0143, 2.1640, 3.9974, 3.9994, 2.2700, 2.3026],\n",
            "        [3.1822, 4.0712, 2.1938, 4.0552, 4.0578, 2.3123, 2.3383]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "156\n",
            "tensor([[1.9491, 2.6794, 1.5227, 2.6530, 2.6199, 1.6080, 1.5779],\n",
            "        [2.3991, 3.2077, 1.7775, 3.1853, 3.1646, 1.8670, 1.8582],\n",
            "        [3.1787, 4.0673, 2.1954, 4.0541, 4.0550, 2.3129, 2.3378],\n",
            "        [0.9383, 1.4108, 0.9015, 1.3991, 1.3352, 0.9493, 0.9217],\n",
            "        [2.8235, 3.6904, 2.0082, 3.6714, 3.6706, 2.1004, 2.1168]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "157\n",
            "tensor([[2.8899, 3.7577, 2.0453, 3.7440, 3.7430, 2.1400, 2.1565],\n",
            "        [1.0469, 1.5506, 0.9761, 1.5386, 1.4761, 1.0301, 0.9950],\n",
            "        [2.8519, 3.7179, 2.0251, 3.7044, 3.7012, 2.1175, 2.1339],\n",
            "        [2.9445, 3.8165, 2.0750, 3.8055, 3.8074, 2.1598, 2.1864],\n",
            "        [2.5495, 3.3833, 1.8642, 3.3657, 3.3505, 1.9525, 1.9503]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "158\n",
            "tensor([[1.3689, 1.9607, 1.1820, 1.9453, 1.8878, 1.2557, 1.2084],\n",
            "        [1.7487, 2.4332, 1.4096, 2.4132, 2.3691, 1.4930, 1.4535],\n",
            "        [3.2000, 4.0881, 2.2094, 4.0776, 4.0735, 2.3314, 2.3499],\n",
            "        [2.0624, 2.8098, 1.5920, 2.7890, 2.7547, 1.6801, 1.6489],\n",
            "        [3.1391, 4.0185, 2.1772, 4.0151, 4.0126, 2.2844, 2.3104]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "159\n",
            "tensor([[1.5351, 2.1672, 1.2815, 2.1498, 2.0979, 1.3619, 1.3151],\n",
            "        [2.3724, 3.1727, 1.7667, 3.1559, 3.1325, 1.8525, 1.8379],\n",
            "        [3.1771, 4.0587, 2.1981, 4.0540, 4.0503, 2.3128, 2.3325],\n",
            "        [1.2323, 1.7856, 1.0944, 1.7720, 1.7117, 1.1602, 1.1187],\n",
            "        [2.3270, 3.1222, 1.7421, 3.1079, 3.0813, 1.8286, 1.8143]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "160\n",
            "tensor([[3.1946, 4.0748, 2.2088, 4.0706, 4.0621, 2.3281, 2.3454],\n",
            "        [1.6042, 2.2508, 1.3263, 2.2361, 2.1846, 1.4063, 1.3593],\n",
            "        [3.1471, 4.0217, 2.1823, 4.0194, 4.0197, 2.2836, 2.3082],\n",
            "        [2.3259, 3.1181, 1.7443, 3.1034, 3.0794, 1.8239, 1.8082],\n",
            "        [1.2824, 1.8517, 1.1284, 1.8368, 1.7759, 1.1939, 1.1508]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "161\n",
            "tensor([[0.9070, 1.3655, 0.8843, 1.3604, 1.2927, 0.9264, 0.8979],\n",
            "        [0.7651, 1.1804, 0.7875, 1.1787, 1.1115, 0.8176, 0.8021],\n",
            "        [2.7150, 3.5569, 1.9561, 3.5529, 3.5384, 2.0370, 2.0456],\n",
            "        [3.0635, 3.9354, 2.1414, 3.9369, 3.9288, 2.2311, 2.2599],\n",
            "        [2.2567, 3.0348, 1.7053, 3.0235, 2.9915, 1.7940, 1.7675]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "162\n",
            "tensor([[2.0522, 2.7917, 1.5913, 2.7811, 2.7409, 1.6764, 1.6403],\n",
            "        [1.9869, 2.7152, 1.5529, 2.7022, 2.6614, 1.6334, 1.5993],\n",
            "        [0.6278, 1.0003, 0.6884, 0.9991, 0.9337, 0.7077, 0.7043],\n",
            "        [1.1290, 1.6539, 1.0316, 1.6469, 1.5818, 1.0932, 1.0513],\n",
            "        [1.0840, 1.5951, 1.0032, 1.5884, 1.5213, 1.0583, 1.0207]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "163\n",
            "tensor([[0.8489, 1.2895, 0.8463, 1.2868, 1.2178, 0.8822, 0.8597],\n",
            "        [2.0209, 2.7532, 1.5733, 2.7433, 2.7018, 1.6608, 1.6223],\n",
            "        [2.7953, 3.6458, 2.0034, 3.6456, 3.6304, 2.0970, 2.0961],\n",
            "        [3.0116, 3.8770, 2.1184, 3.8798, 3.8719, 2.2140, 2.2257],\n",
            "        [3.0361, 3.9082, 2.1316, 3.9111, 3.9025, 2.2249, 2.2424]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "164\n",
            "tensor([[0.9566, 1.4305, 0.9207, 1.4284, 1.3575, 0.9680, 0.9351],\n",
            "        [1.3307, 1.9093, 1.1607, 1.8988, 1.8374, 1.2282, 1.1825],\n",
            "        [0.7188, 1.1205, 0.7581, 1.1209, 1.0513, 0.7853, 0.7703],\n",
            "        [2.5570, 3.3804, 1.8758, 3.3775, 3.3549, 1.9552, 1.9503],\n",
            "        [1.0075, 1.4977, 0.9543, 1.4945, 1.4240, 1.0084, 0.9705]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "165\n",
            "tensor([[3.2088, 4.0884, 2.2258, 4.0943, 4.0775, 2.3451, 2.3555],\n",
            "        [1.2379, 1.7926, 1.1033, 1.7856, 1.7191, 1.1683, 1.1248],\n",
            "        [1.3154, 1.8894, 1.1555, 1.8801, 1.8166, 1.2202, 1.1746],\n",
            "        [3.1805, 4.0585, 2.2108, 4.0688, 4.0507, 2.3241, 2.3391],\n",
            "        [3.1824, 4.0596, 2.2101, 4.0695, 4.0517, 2.3236, 2.3400]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "166\n",
            "tensor([[2.4571, 3.2637, 1.8230, 3.2646, 3.2315, 1.9120, 1.8947],\n",
            "        [3.2228, 4.1003, 2.2323, 4.1105, 4.0874, 2.3570, 2.3698],\n",
            "        [2.8170, 3.6685, 2.0184, 3.6743, 3.6562, 2.1050, 2.1116],\n",
            "        [1.3745, 1.9622, 1.1897, 1.9565, 1.8923, 1.2600, 1.2146],\n",
            "        [3.2083, 4.0865, 2.2271, 4.0938, 4.0757, 2.3421, 2.3575]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "167\n",
            "tensor([[1.0374, 1.5323, 0.9753, 1.5317, 1.4596, 1.0298, 0.9926],\n",
            "        [1.6317, 2.2816, 1.3487, 2.2765, 2.2163, 1.4304, 1.3821],\n",
            "        [1.1488, 1.6761, 1.0488, 1.6722, 1.6035, 1.1094, 1.0673],\n",
            "        [2.0601, 2.7979, 1.5993, 2.7945, 2.7480, 1.6855, 1.6502],\n",
            "        [1.2372, 1.7866, 1.1040, 1.7833, 1.7139, 1.1712, 1.1248]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "168\n",
            "tensor([[3.2246, 4.0974, 2.2344, 4.1112, 4.0864, 2.3640, 2.3737],\n",
            "        [1.9167, 2.6255, 1.5152, 2.6210, 2.5720, 1.6034, 1.5626],\n",
            "        [3.1859, 4.0569, 2.2154, 4.0748, 4.0504, 2.3293, 2.3494],\n",
            "        [1.9432, 2.6563, 1.5335, 2.6551, 2.6030, 1.6206, 1.5804],\n",
            "        [3.0750, 3.9393, 2.1583, 3.9581, 3.9399, 2.2617, 2.2765]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "169\n",
            "tensor([[3.1536, 4.0191, 2.1986, 4.0417, 4.0189, 2.3107, 2.3273],\n",
            "        [0.9555, 1.4253, 0.9212, 1.4284, 1.3536, 0.9711, 0.9396],\n",
            "        [1.0218, 1.5113, 0.9668, 1.5136, 1.4396, 1.0210, 0.9842],\n",
            "        [2.7229, 3.5581, 1.9710, 3.5728, 3.5418, 2.0571, 2.0633],\n",
            "        [1.7330, 2.4026, 1.4089, 2.4004, 2.3403, 1.4961, 1.4501]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "170\n",
            "tensor([[1.4297, 2.0281, 1.2274, 2.0285, 1.9586, 1.3040, 1.2564],\n",
            "        [1.2204, 1.7653, 1.0949, 1.7676, 1.6931, 1.1611, 1.1196],\n",
            "        [1.1925, 1.7277, 1.0774, 1.7310, 1.6575, 1.1438, 1.1008],\n",
            "        [1.1679, 1.6990, 1.0618, 1.6996, 1.6264, 1.1250, 1.0839],\n",
            "        [1.8114, 2.4969, 1.4577, 2.4994, 2.4392, 1.5439, 1.5016]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "171\n",
            "tensor([[2.9390, 3.7928, 2.0889, 3.8182, 3.7911, 2.1790, 2.1994],\n",
            "        [1.1349, 1.6569, 1.0404, 1.6584, 1.5835, 1.1031, 1.0624],\n",
            "        [2.9684, 3.8254, 2.1064, 3.8506, 3.8234, 2.2084, 2.2193],\n",
            "        [1.8435, 2.5359, 1.4791, 2.5393, 2.4796, 1.5681, 1.5236],\n",
            "        [3.2165, 4.0848, 2.2344, 4.1091, 4.0694, 2.3662, 2.3822]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "172\n",
            "tensor([[3.2121, 4.0827, 2.2347, 4.1084, 4.0678, 2.3622, 2.3797],\n",
            "        [2.2054, 2.9643, 1.6885, 2.9772, 2.9221, 1.7831, 1.7542],\n",
            "        [3.1881, 4.0546, 2.2243, 4.0845, 4.0505, 2.3433, 2.3600],\n",
            "        [2.0879, 2.8257, 1.6206, 2.8342, 2.7773, 1.7120, 1.6782],\n",
            "        [1.8650, 2.5591, 1.4905, 2.5637, 2.5017, 1.5810, 1.5377]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "173\n",
            "tensor([[0.9775, 1.4531, 0.9393, 1.4599, 1.3816, 0.9939, 0.9587],\n",
            "        [3.1695, 4.0324, 2.2128, 4.0630, 4.0276, 2.3218, 2.3480],\n",
            "        [3.2242, 4.0947, 2.2427, 4.1241, 4.0865, 2.3786, 2.3871],\n",
            "        [2.5372, 3.3482, 1.8757, 3.3670, 3.3231, 1.9683, 1.9593],\n",
            "        [1.0535, 1.5503, 0.9909, 1.5563, 1.4790, 1.0478, 1.0103]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "174\n",
            "tensor([[3.1562, 4.0176, 2.2094, 4.0525, 4.0175, 2.3259, 2.3422],\n",
            "        [0.9835, 1.4597, 0.9462, 1.4692, 1.3888, 1.0010, 0.9642],\n",
            "        [1.0221, 1.5091, 0.9706, 1.5177, 1.4386, 1.0293, 0.9902],\n",
            "        [2.9234, 3.7733, 2.0868, 3.8020, 3.7687, 2.1884, 2.1967],\n",
            "        [3.0999, 3.9611, 2.1807, 3.9933, 3.9600, 2.3010, 2.3089]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "175\n",
            "tensor([[2.1051, 2.8488, 1.6384, 2.8606, 2.8044, 1.7304, 1.6954],\n",
            "        [3.0378, 3.8943, 2.1501, 3.9286, 3.8951, 2.2604, 2.2711],\n",
            "        [2.9443, 3.7958, 2.0993, 3.8277, 3.7943, 2.2054, 2.2128],\n",
            "        [1.3467, 1.9231, 1.1818, 1.9288, 1.8538, 1.2592, 1.2098],\n",
            "        [2.9130, 3.7636, 2.0830, 3.7943, 3.7617, 2.1830, 2.1932]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "176\n",
            "tensor([[1.9025, 2.6039, 1.5189, 2.6149, 2.5498, 1.6173, 1.5687],\n",
            "        [3.0692, 3.9303, 2.1695, 3.9651, 3.9324, 2.2847, 2.2944],\n",
            "        [2.4376, 3.2317, 1.8262, 3.2516, 3.2034, 1.9325, 1.9035],\n",
            "        [0.9550, 1.4238, 0.9289, 1.4328, 1.3522, 0.9821, 0.9469],\n",
            "        [1.5079, 2.1241, 1.2833, 2.1321, 2.0605, 1.3705, 1.3162]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "177\n",
            "tensor([[1.8957, 2.5971, 1.5184, 2.6079, 2.5447, 1.6127, 1.5662],\n",
            "        [3.1091, 3.9679, 2.1917, 4.0046, 3.9767, 2.3106, 2.3157],\n",
            "        [1.0549, 1.5531, 0.9970, 1.5622, 1.4841, 1.0602, 1.0163],\n",
            "        [3.0288, 3.8811, 2.1462, 3.9170, 3.8890, 2.2487, 2.2631],\n",
            "        [2.7518, 3.5900, 2.0028, 3.6176, 3.5817, 2.1001, 2.0968]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "178\n",
            "tensor([[2.9404, 3.7893, 2.1047, 3.8243, 3.7908, 2.2130, 2.2126],\n",
            "        [1.4262, 2.0225, 1.2377, 2.0323, 1.9570, 1.3231, 1.2658],\n",
            "        [2.6360, 3.4578, 1.9400, 3.4849, 3.4421, 2.0408, 2.0270],\n",
            "        [1.7071, 2.3691, 1.4070, 2.3777, 2.3095, 1.5042, 1.4459],\n",
            "        [3.2102, 4.0760, 2.2475, 4.1112, 4.0730, 2.3856, 2.3846]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "179\n",
            "tensor([[1.2753, 1.8313, 1.1432, 1.8405, 1.7649, 1.2184, 1.1639],\n",
            "        [1.6270, 2.2681, 1.3591, 2.2784, 2.2089, 1.4556, 1.3942],\n",
            "        [3.2215, 4.0850, 2.2533, 4.1214, 4.0842, 2.3986, 2.3928],\n",
            "        [1.1887, 1.7218, 1.0856, 1.7302, 1.6542, 1.1579, 1.1057],\n",
            "        [2.9783, 3.8272, 2.1244, 3.8624, 3.8289, 2.2491, 2.2379]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "180\n",
            "tensor([[1.9479, 2.6565, 1.5524, 2.6725, 2.6106, 1.6554, 1.6004],\n",
            "        [1.7030, 2.3603, 1.4053, 2.3720, 2.3046, 1.5069, 1.4444],\n",
            "        [1.0776, 1.5788, 1.0142, 1.5912, 1.5122, 1.0825, 1.0331],\n",
            "        [2.0617, 2.7921, 1.6168, 2.8071, 2.7519, 1.7225, 1.6715],\n",
            "        [2.5335, 3.3382, 1.8849, 3.3661, 3.3202, 1.9937, 1.9660]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "181\n",
            "tensor([[3.1056, 3.9601, 2.1911, 3.9998, 3.9709, 2.3286, 2.3170],\n",
            "        [2.1545, 2.8995, 1.6707, 2.9164, 2.8624, 1.7822, 1.7296],\n",
            "        [1.2963, 1.8559, 1.1561, 1.8654, 1.7915, 1.2379, 1.1783],\n",
            "        [1.1024, 1.6108, 1.0292, 1.6219, 1.5439, 1.1002, 1.0486],\n",
            "        [1.0831, 1.5856, 1.0162, 1.5974, 1.5190, 1.0885, 1.0371]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "182\n",
            "tensor([[3.1872, 4.0493, 2.2345, 4.0871, 4.0533, 2.3876, 2.3743],\n",
            "        [0.9471, 1.4127, 0.9281, 1.4248, 1.3456, 0.9885, 0.9444],\n",
            "        [3.0088, 3.8565, 2.1396, 3.8930, 3.8677, 2.2703, 2.2548],\n",
            "        [2.0162, 2.7372, 1.5904, 2.7530, 2.6940, 1.7013, 1.6444],\n",
            "        [3.1741, 4.0314, 2.2270, 4.0714, 4.0404, 2.3735, 2.3632]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "183\n",
            "tensor([[2.5443, 3.3512, 1.8889, 3.3766, 3.3379, 2.0047, 1.9731],\n",
            "        [2.3396, 3.1198, 1.7748, 3.1410, 3.0908, 1.8960, 1.8497],\n",
            "        [1.0902, 1.5958, 1.0220, 1.6080, 1.5286, 1.0980, 1.0432],\n",
            "        [3.1973, 4.0591, 2.2401, 4.0956, 4.0654, 2.3987, 2.3794],\n",
            "        [3.1684, 4.0258, 2.2234, 4.0667, 4.0357, 2.3694, 2.3605]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "184\n",
            "tensor([[1.7761, 2.4500, 1.4474, 2.4617, 2.3978, 1.5596, 1.4940],\n",
            "        [1.0267, 1.5182, 0.9809, 1.5278, 1.4497, 1.0515, 1.0008],\n",
            "        [1.5257, 2.1460, 1.2953, 2.1549, 2.0849, 1.3977, 1.3327],\n",
            "        [2.6563, 3.4774, 1.9494, 3.5055, 3.4674, 2.0768, 2.0436],\n",
            "        [2.3167, 3.0911, 1.7603, 3.1108, 3.0592, 1.8836, 1.8344]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "185\n",
            "tensor([[3.2203, 4.0818, 2.2461, 4.1196, 4.0852, 2.4111, 2.3979],\n",
            "        [2.2336, 2.9962, 1.7128, 3.0150, 2.9626, 1.8355, 1.7845],\n",
            "        [1.4695, 2.0760, 1.2584, 2.0820, 2.0115, 1.3580, 1.2940],\n",
            "        [0.9982, 1.4793, 0.9596, 1.4912, 1.4110, 1.0297, 0.9814],\n",
            "        [2.8101, 3.6486, 2.0297, 3.6784, 3.6477, 2.1561, 2.1379]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "186\n",
            "tensor([[1.5592, 2.1884, 1.3168, 2.1987, 2.1288, 1.4245, 1.3572],\n",
            "        [1.9369, 2.6470, 1.5422, 2.6622, 2.5996, 1.6612, 1.6003],\n",
            "        [3.1831, 4.0454, 2.2233, 4.0848, 4.0517, 2.3871, 2.3740],\n",
            "        [1.1928, 1.7304, 1.0880, 1.7421, 1.6629, 1.1794, 1.1156],\n",
            "        [2.4024, 3.1949, 1.8064, 3.2173, 3.1697, 1.9336, 1.8917]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "187\n",
            "tensor([[2.9794, 3.8345, 2.1172, 3.8714, 3.8379, 2.2726, 2.2502],\n",
            "        [2.7366, 3.5737, 1.9870, 3.6054, 3.5658, 2.1264, 2.1016],\n",
            "        [3.0738, 3.9322, 2.1663, 3.9702, 3.9419, 2.3164, 2.3062],\n",
            "        [2.4987, 3.3042, 1.8572, 3.3298, 3.2821, 1.9899, 1.9521],\n",
            "        [3.1010, 3.9601, 2.1810, 3.9995, 3.9677, 2.3294, 2.3237]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "188\n",
            "tensor([[3.1642, 4.0292, 2.2129, 4.0678, 4.0345, 2.3893, 2.3688],\n",
            "        [1.3293, 1.9029, 1.1722, 1.9139, 1.8369, 1.2736, 1.2073],\n",
            "        [3.1959, 4.0609, 2.2294, 4.1026, 4.0671, 2.4054, 2.3884],\n",
            "        [1.9970, 2.7211, 1.5747, 2.7386, 2.6770, 1.7012, 1.6431],\n",
            "        [2.9872, 3.8433, 2.1197, 3.8807, 3.8506, 2.2673, 2.2534]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "189\n",
            "tensor([[3.0101, 3.8662, 2.1305, 3.9067, 3.8734, 2.2911, 2.2718],\n",
            "        [2.9901, 3.8417, 2.1173, 3.8843, 3.8523, 2.2704, 2.2583],\n",
            "        [2.9117, 3.7610, 2.0775, 3.8003, 3.7658, 2.2309, 2.2121],\n",
            "        [1.3712, 1.9560, 1.1980, 1.9666, 1.8911, 1.3032, 1.2372],\n",
            "        [3.2187, 4.0869, 2.2382, 4.1259, 4.0844, 2.4232, 2.4089]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "190\n",
            "tensor([[2.8153, 3.6574, 2.0216, 3.6938, 3.6573, 2.1724, 2.1547],\n",
            "        [3.1987, 4.0622, 2.2246, 4.1056, 4.0713, 2.4046, 2.3945],\n",
            "        [1.4184, 2.0179, 1.2261, 2.0309, 1.9550, 1.3379, 1.2734],\n",
            "        [2.7802, 3.6212, 2.0036, 3.6563, 3.6208, 2.1425, 2.1322],\n",
            "        [1.0617, 1.5631, 0.9994, 1.5777, 1.4968, 1.0850, 1.0310]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "191\n",
            "tensor([[2.7250, 3.5589, 1.9719, 3.5926, 3.5508, 2.1206, 2.0997],\n",
            "        [3.1846, 4.0498, 2.2150, 4.0943, 4.0602, 2.3955, 2.3882],\n",
            "        [2.1269, 2.8755, 1.6434, 2.8981, 2.8395, 1.7798, 1.7291],\n",
            "        [1.7645, 2.4432, 1.4327, 2.4588, 2.3911, 1.5605, 1.4984],\n",
            "        [3.1222, 3.9843, 2.1819, 4.0282, 3.9973, 2.3504, 2.3459]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "192\n",
            "tensor([[3.0502, 3.9107, 2.1428, 3.9560, 3.9229, 2.3057, 2.3048],\n",
            "        [3.1193, 3.9822, 2.1804, 4.0265, 3.9950, 2.3545, 2.3470],\n",
            "        [3.1967, 4.0646, 2.2187, 4.1095, 4.0750, 2.4052, 2.3995],\n",
            "        [1.9282, 2.6427, 1.5282, 2.6585, 2.5982, 1.6571, 1.6029],\n",
            "        [3.2014, 4.0700, 2.2202, 4.1095, 4.0677, 2.4132, 2.4058]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "193\n",
            "tensor([[1.3429, 1.9243, 1.1774, 1.9380, 1.8600, 1.2837, 1.2250],\n",
            "        [1.8604, 2.5616, 1.4850, 2.5774, 2.5115, 1.6188, 1.5618],\n",
            "        [0.9235, 1.3867, 0.9068, 1.4027, 1.3210, 0.9803, 0.9375],\n",
            "        [2.5183, 3.3321, 1.8573, 3.3634, 3.3149, 2.0041, 1.9781],\n",
            "        [3.0362, 3.8953, 2.1349, 3.9380, 3.9068, 2.3036, 2.2968]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "194\n",
            "tensor([[2.7467, 3.5832, 1.9769, 3.6186, 3.5783, 2.1310, 2.1195],\n",
            "        [2.8292, 3.6778, 2.0228, 3.7149, 3.6805, 2.1678, 2.1686],\n",
            "        [1.2541, 1.8111, 1.1200, 1.8249, 1.7453, 1.2226, 1.1654],\n",
            "        [0.7399, 1.1463, 0.7789, 1.1620, 1.0812, 0.8327, 0.8058],\n",
            "        [1.1005, 1.6171, 1.0201, 1.6294, 1.5497, 1.1127, 1.0614]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "195\n",
            "tensor([[1.7382, 2.4144, 1.4125, 2.4297, 2.3629, 1.5387, 1.4845],\n",
            "        [2.3756, 3.1689, 1.7764, 3.1968, 3.1441, 1.9216, 1.8912],\n",
            "        [3.0262, 3.8882, 2.1240, 3.9300, 3.8983, 2.2855, 2.2929],\n",
            "        [0.8894, 1.3429, 0.8810, 1.3589, 1.2772, 0.9535, 0.9137],\n",
            "        [3.2162, 4.0849, 2.2223, 4.1313, 4.0918, 2.4178, 2.4178]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "196\n",
            "tensor([[0.8591, 1.3051, 0.8598, 1.3215, 1.2399, 0.9291, 0.8951],\n",
            "        [2.8666, 3.7160, 2.0394, 3.7547, 3.7175, 2.1880, 2.1944],\n",
            "        [2.4152, 3.2152, 1.7972, 3.2434, 3.1961, 1.9359, 1.9152],\n",
            "        [1.1932, 1.7356, 1.0799, 1.7500, 1.6694, 1.1793, 1.1254],\n",
            "        [1.0548, 1.5583, 0.9909, 1.5737, 1.4924, 1.0798, 1.0315]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "197\n",
            "tensor([[1.6126, 2.2605, 1.3365, 2.2756, 2.2053, 1.4623, 1.4060],\n",
            "        [2.3767, 3.1695, 1.7745, 3.1968, 3.1484, 1.9212, 1.8931],\n",
            "        [2.4118, 3.2110, 1.7928, 3.2385, 3.1906, 1.9343, 1.9146],\n",
            "        [2.9268, 3.7848, 2.0702, 3.8258, 3.7926, 2.2224, 2.2348],\n",
            "        [2.6547, 3.4879, 1.9256, 3.5215, 3.4807, 2.0716, 2.0676]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "198\n",
            "tensor([[1.0828, 1.5952, 1.0060, 1.6094, 1.5300, 1.0991, 1.0514],\n",
            "        [2.1168, 2.8706, 1.6265, 2.8935, 2.8363, 1.7682, 1.7336],\n",
            "        [2.1610, 2.9238, 1.6549, 2.9463, 2.8917, 1.7911, 1.7600],\n",
            "        [3.1623, 4.0332, 2.1890, 4.0732, 4.0429, 2.3659, 2.3840],\n",
            "        [2.6067, 3.4322, 1.8976, 3.4691, 3.4256, 2.0509, 2.0411]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "199\n",
            "tensor([[2.9253, 3.7894, 2.0661, 3.8302, 3.8004, 2.2212, 2.2379],\n",
            "        [1.3679, 1.9628, 1.1880, 1.9756, 1.9016, 1.2970, 1.2475],\n",
            "        [3.1809, 4.0566, 2.1963, 4.0994, 4.0683, 2.3767, 2.4002],\n",
            "        [2.8309, 3.6851, 2.0139, 3.7202, 3.6861, 2.1715, 2.1828],\n",
            "        [1.4956, 2.1224, 1.2652, 2.1343, 2.0636, 1.3814, 1.3311]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "200\n",
            "tensor([[1.2302, 1.7893, 1.0989, 1.8021, 1.7258, 1.2036, 1.1557],\n",
            "        [1.2750, 1.8463, 1.1267, 1.8581, 1.7822, 1.2306, 1.1855],\n",
            "        [3.0803, 3.9551, 2.1437, 4.0005, 3.9717, 2.3080, 2.3396],\n",
            "        [3.1810, 4.0622, 2.1965, 4.1062, 4.0731, 2.3802, 2.4052],\n",
            "        [3.1928, 4.0723, 2.2018, 4.1148, 4.0815, 2.3907, 2.4137]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "201\n",
            "tensor([[3.1562, 4.0373, 2.1811, 4.0818, 4.0513, 2.3544, 2.3885],\n",
            "        [2.1708, 2.9441, 1.6541, 2.9664, 2.9129, 1.7927, 1.7729],\n",
            "        [3.1880, 4.0707, 2.1984, 4.1138, 4.0840, 2.3845, 2.4098],\n",
            "        [2.9117, 3.7820, 2.0538, 3.8205, 3.7933, 2.1998, 2.2325],\n",
            "        [1.0947, 1.6188, 1.0127, 1.6299, 1.5531, 1.1022, 1.0627]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "202\n",
            "tensor([[1.0225, 1.5251, 0.9675, 1.5395, 1.4605, 1.0520, 1.0148],\n",
            "        [2.7735, 3.6344, 1.9815, 3.6684, 3.6375, 2.1291, 2.1485],\n",
            "        [1.5700, 2.2184, 1.3064, 2.2307, 2.1622, 1.4238, 1.3851],\n",
            "        [3.1972, 4.0871, 2.1989, 4.1219, 4.0855, 2.3942, 2.4236],\n",
            "        [2.4360, 3.2563, 1.7999, 3.2839, 3.2389, 1.9416, 1.9415]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "203\n",
            "tensor([[3.1861, 4.0774, 2.1958, 4.1183, 4.0866, 2.3779, 2.4159],\n",
            "        [0.9088, 1.3813, 0.8914, 1.3959, 1.3164, 0.9661, 0.9366],\n",
            "        [3.2039, 4.0941, 2.2041, 4.1361, 4.1046, 2.3889, 2.4256],\n",
            "        [1.1221, 1.6573, 1.0306, 1.6705, 1.5930, 1.1277, 1.0856],\n",
            "        [3.0144, 3.8950, 2.1060, 3.9355, 3.9072, 2.2657, 2.3035]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "204\n",
            "tensor([[3.2022, 4.0973, 2.2017, 4.1360, 4.1024, 2.3918, 2.4285],\n",
            "        [1.0697, 1.5907, 0.9955, 1.6031, 1.5263, 1.0861, 1.0482],\n",
            "        [2.9719, 3.8561, 2.0820, 3.8947, 3.8719, 2.2336, 2.2758],\n",
            "        [1.8368, 2.5538, 1.4621, 2.5688, 2.5073, 1.5934, 1.5617],\n",
            "        [2.7832, 3.6582, 1.9845, 3.6911, 3.6618, 2.1261, 2.1595]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "205\n",
            "tensor([[0.8925, 1.3613, 0.8796, 1.3745, 1.2957, 0.9519, 0.9248],\n",
            "        [1.0872, 1.6168, 1.0069, 1.6274, 1.5500, 1.0957, 1.0611],\n",
            "        [1.4281, 2.0524, 1.2200, 2.0643, 1.9927, 1.3366, 1.2952],\n",
            "        [3.1821, 4.0787, 2.1879, 4.1177, 4.0869, 2.3724, 2.4145],\n",
            "        [0.7842, 1.2194, 0.8059, 1.2327, 1.1551, 0.8651, 0.8464]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "206\n",
            "tensor([[1.3138, 1.9088, 1.1486, 1.9192, 1.8456, 1.2556, 1.2180],\n",
            "        [2.9708, 3.8583, 2.0767, 3.8955, 3.8684, 2.2425, 2.2800],\n",
            "        [0.8966, 1.3682, 0.8820, 1.3817, 1.3025, 0.9554, 0.9286],\n",
            "        [2.1398, 2.9215, 1.6296, 2.9395, 2.8890, 1.7682, 1.7581],\n",
            "        [2.4461, 3.2784, 1.7981, 3.3013, 3.2602, 1.9435, 1.9517]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "207\n",
            "tensor([[2.9408, 3.8328, 2.0591, 3.8653, 3.8383, 2.2201, 2.2614],\n",
            "        [0.9101, 1.3889, 0.8897, 1.3997, 1.3214, 0.9654, 0.9378],\n",
            "        [2.6794, 3.5497, 1.9232, 3.5782, 3.5457, 2.0689, 2.0992],\n",
            "        [1.7468, 2.4516, 1.4051, 2.4629, 2.3995, 1.5395, 1.5070],\n",
            "        [2.5360, 3.3847, 1.8423, 3.4092, 3.3689, 1.9856, 2.0076]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "208\n",
            "tensor([[1.3864, 2.0027, 1.1904, 2.0125, 1.9401, 1.3052, 1.2678],\n",
            "        [1.0257, 1.5391, 0.9640, 1.5516, 1.4710, 1.0523, 1.0202],\n",
            "        [1.7947, 2.5125, 1.4298, 2.5236, 2.4621, 1.5661, 1.5378],\n",
            "        [1.8389, 2.5649, 1.4564, 2.5775, 2.5175, 1.5923, 1.5670],\n",
            "        [3.0177, 3.9143, 2.0953, 3.9532, 3.9245, 2.2619, 2.3123]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "209\n",
            "tensor([[3.1771, 4.0836, 2.1750, 4.1223, 4.0932, 2.3616, 2.4142],\n",
            "        [1.2144, 1.7848, 1.0827, 1.7963, 1.7189, 1.1891, 1.1523],\n",
            "        [1.8234, 2.5486, 1.4449, 2.5587, 2.4986, 1.5759, 1.5540],\n",
            "        [2.2111, 3.0117, 1.6622, 3.0297, 2.9784, 1.8117, 1.8044],\n",
            "        [2.3832, 3.2121, 1.7567, 3.2348, 3.1889, 1.9099, 1.9146]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "210\n",
            "tensor([[1.6018, 2.2767, 1.3155, 2.2870, 2.2198, 1.4409, 1.4104],\n",
            "        [3.0692, 3.9704, 2.1179, 4.0098, 3.9858, 2.2852, 2.3419],\n",
            "        [3.1858, 4.0958, 2.1772, 4.1342, 4.1010, 2.3721, 2.4235],\n",
            "        [1.2498, 1.8324, 1.1030, 1.8441, 1.7681, 1.2111, 1.1760],\n",
            "        [2.0144, 2.7808, 1.5543, 2.7979, 2.7407, 1.6921, 1.6808]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "211\n",
            "tensor([[2.0293, 2.7994, 1.5598, 2.8140, 2.7602, 1.6977, 1.6884],\n",
            "        [1.6270, 2.3081, 1.3303, 2.3221, 2.2538, 1.4608, 1.4281],\n",
            "        [2.4767, 3.3270, 1.8063, 3.3517, 3.3103, 1.9574, 1.9751],\n",
            "        [1.8032, 2.5256, 1.4326, 2.5404, 2.4760, 1.5676, 1.5432],\n",
            "        [1.1069, 1.6498, 1.0125, 1.6615, 1.5825, 1.1113, 1.0779]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "212\n",
            "tensor([[2.9921, 3.8943, 2.0734, 3.9323, 3.9085, 2.2355, 2.2945],\n",
            "        [3.0779, 3.9859, 2.1191, 4.0271, 3.9960, 2.2932, 2.3517],\n",
            "        [2.7772, 3.6641, 1.9624, 3.6989, 3.6673, 2.1106, 2.1611],\n",
            "        [3.1253, 4.0342, 2.1442, 4.0749, 4.0491, 2.3332, 2.3806],\n",
            "        [2.6039, 3.4683, 1.8703, 3.4986, 3.4591, 2.0200, 2.0537]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "213\n",
            "tensor([[1.4969, 2.1494, 1.2520, 2.1626, 2.0915, 1.3793, 1.3429],\n",
            "        [1.1734, 1.7357, 1.0526, 1.7480, 1.6709, 1.1562, 1.1224],\n",
            "        [1.5103, 2.1638, 1.2578, 2.1753, 2.1040, 1.3855, 1.3496],\n",
            "        [2.9750, 3.8755, 2.0648, 3.9150, 3.8876, 2.2331, 2.2832],\n",
            "        [3.1599, 4.0705, 2.1593, 4.1136, 4.0830, 2.3476, 2.4020]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "214\n",
            "tensor([[3.1903, 4.1029, 2.1713, 4.1424, 4.1117, 2.3753, 2.4234],\n",
            "        [0.9661, 1.4664, 0.9222, 1.4820, 1.4017, 1.0113, 0.9800],\n",
            "        [0.7476, 1.1779, 0.7755, 1.1927, 1.1141, 0.8378, 0.8220],\n",
            "        [1.2448, 1.8267, 1.0985, 1.8413, 1.7650, 1.2089, 1.1714],\n",
            "        [3.0521, 3.9582, 2.1015, 4.0013, 3.9796, 2.2832, 2.3325]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "215\n",
            "tensor([[1.5657, 2.2368, 1.2921, 2.2520, 2.1832, 1.4272, 1.3892],\n",
            "        [1.8559, 2.5927, 1.4588, 2.6102, 2.5487, 1.6061, 1.5786],\n",
            "        [2.1940, 2.9972, 1.6469, 3.0204, 2.9709, 1.8015, 1.7935],\n",
            "        [1.6826, 2.3817, 1.3587, 2.3978, 2.3307, 1.4953, 1.4659],\n",
            "        [1.0358, 1.5579, 0.9658, 1.5723, 1.4942, 1.0614, 1.0285]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "216\n",
            "tensor([[2.5904, 3.4583, 1.8619, 3.4908, 3.4528, 2.0227, 2.0440],\n",
            "        [2.5537, 3.4196, 1.8439, 3.4516, 3.4170, 1.9968, 2.0208],\n",
            "        [3.1689, 4.0839, 2.1604, 4.1257, 4.0947, 2.3634, 2.4118],\n",
            "        [2.7854, 3.6795, 1.9659, 3.7167, 3.6883, 2.1332, 2.1666],\n",
            "        [3.1617, 4.0748, 2.1534, 4.1123, 4.0776, 2.3675, 2.4120]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "217\n",
            "tensor([[2.1357, 2.9342, 1.6195, 2.9589, 2.9057, 1.7727, 1.7612],\n",
            "        [1.0072, 1.5240, 0.9484, 1.5405, 1.4604, 1.0460, 1.0099],\n",
            "        [0.9944, 1.5058, 0.9365, 1.5211, 1.4440, 1.0339, 1.0001],\n",
            "        [2.6368, 3.5166, 1.8900, 3.5518, 3.5166, 2.0478, 2.0756],\n",
            "        [2.1640, 2.9661, 1.6329, 2.9901, 2.9390, 1.7906, 1.7785]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "218\n",
            "tensor([[2.0589, 2.8403, 1.5765, 2.8631, 2.8104, 1.7302, 1.7106],\n",
            "        [2.5546, 3.4223, 1.8462, 3.4560, 3.4182, 2.0066, 2.0274],\n",
            "        [2.7380, 3.6264, 1.9457, 3.6655, 3.6371, 2.1084, 2.1415],\n",
            "        [2.1838, 2.9891, 1.6470, 3.0161, 2.9655, 1.8054, 1.7928],\n",
            "        [1.0597, 1.5918, 0.9844, 1.6077, 1.5284, 1.0820, 1.0480]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "219\n",
            "tensor([[1.3464, 1.9616, 1.1645, 1.9792, 1.9052, 1.2871, 1.2464],\n",
            "        [1.5073, 2.1646, 1.2610, 2.1826, 2.1122, 1.3944, 1.3540],\n",
            "        [2.7406, 3.6319, 1.9483, 3.6724, 3.6453, 2.1056, 2.1423],\n",
            "        [1.0970, 1.6404, 1.0103, 1.6595, 1.5801, 1.1134, 1.0762],\n",
            "        [2.6101, 3.4820, 1.8773, 3.5210, 3.4839, 2.0472, 2.0646]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "220\n",
            "tensor([[1.6849, 2.3874, 1.3659, 2.4058, 2.3422, 1.5054, 1.4712],\n",
            "        [2.9490, 3.8572, 2.0559, 3.9029, 3.8834, 2.2199, 2.2744],\n",
            "        [2.4295, 3.2753, 1.7821, 3.3081, 3.2675, 1.9455, 1.9500],\n",
            "        [1.5261, 2.1911, 1.2732, 2.2083, 2.1385, 1.4046, 1.3685],\n",
            "        [3.0998, 4.0152, 2.1354, 4.0671, 4.0443, 2.3265, 2.3724]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "221\n",
            "tensor([[1.2313, 1.8158, 1.0956, 1.8328, 1.7586, 1.2105, 1.1698],\n",
            "        [1.0353, 1.5617, 0.9718, 1.5789, 1.5015, 1.0676, 1.0342],\n",
            "        [1.7153, 2.4276, 1.3859, 2.4466, 2.3837, 1.5258, 1.4949],\n",
            "        [0.9926, 1.5061, 0.9451, 1.5253, 1.4454, 1.0395, 1.0057],\n",
            "        [2.9977, 3.9086, 2.0831, 3.9591, 3.9379, 2.2612, 2.3110]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "222\n",
            "tensor([[2.5589, 3.4333, 1.8545, 3.4698, 3.4360, 2.0070, 2.0387],\n",
            "        [1.4086, 2.0443, 1.2045, 2.0630, 1.9917, 1.3326, 1.2943],\n",
            "        [1.8499, 2.5914, 1.4612, 2.6128, 2.5545, 1.6128, 1.5840],\n",
            "        [2.7225, 3.6190, 1.9444, 3.6589, 3.6328, 2.1024, 2.1398],\n",
            "        [3.1116, 4.0326, 2.1429, 4.0812, 4.0562, 2.3364, 2.3891]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "223\n",
            "tensor([[1.0971, 1.6454, 1.0118, 1.6635, 1.5861, 1.1168, 1.0809],\n",
            "        [1.1469, 1.7100, 1.0434, 1.7278, 1.6506, 1.1518, 1.1159],\n",
            "        [2.5733, 3.4488, 1.8641, 3.4861, 3.4518, 2.0257, 2.0491],\n",
            "        [2.7496, 3.6457, 1.9555, 3.6861, 3.6586, 2.1237, 2.1612],\n",
            "        [0.9559, 1.4599, 0.9206, 1.4784, 1.3988, 1.0096, 0.9810]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "224\n",
            "tensor([[1.0157, 1.5390, 0.9607, 1.5573, 1.4787, 1.0571, 1.0250],\n",
            "        [3.1408, 4.0645, 2.1568, 4.1121, 4.0883, 2.3551, 2.4094],\n",
            "        [2.4786, 3.3379, 1.8133, 3.3741, 3.3370, 1.9751, 1.9905],\n",
            "        [2.1736, 2.9865, 1.6464, 3.0148, 2.9665, 1.8018, 1.7995],\n",
            "        [3.0987, 4.0182, 2.1379, 4.0671, 4.0427, 2.3333, 2.3816]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "225\n",
            "tensor([[1.9286, 2.6910, 1.5080, 2.7142, 2.6603, 1.6531, 1.6408],\n",
            "        [2.8396, 3.7491, 2.0020, 3.7936, 3.7734, 2.1649, 2.2193],\n",
            "        [1.1686, 1.7390, 1.0576, 1.7553, 1.6794, 1.1661, 1.1320],\n",
            "        [2.5975, 3.4802, 1.8772, 3.5188, 3.4895, 2.0300, 2.0669],\n",
            "        [3.1770, 4.1012, 2.1757, 4.1491, 4.1253, 2.3808, 2.4376]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "226\n",
            "tensor([[1.5073, 2.1736, 1.2653, 2.1919, 2.1240, 1.3944, 1.3662],\n",
            "        [0.9889, 1.5032, 0.9425, 1.5231, 1.4439, 1.0383, 1.0073],\n",
            "        [2.5422, 3.4152, 1.8454, 3.4533, 3.4224, 2.0054, 2.0343],\n",
            "        [3.1738, 4.0996, 2.1727, 4.1498, 4.1255, 2.3842, 2.4365],\n",
            "        [3.1609, 4.0872, 2.1670, 4.1357, 4.1111, 2.3696, 2.4279]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "227\n",
            "tensor([[0.7485, 1.1856, 0.7818, 1.2060, 1.1266, 0.8519, 0.8343],\n",
            "        [0.8734, 1.3513, 0.8665, 1.3713, 1.2922, 0.9505, 0.9249],\n",
            "        [2.0918, 2.8910, 1.6040, 2.9182, 2.8727, 1.7532, 1.7495],\n",
            "        [2.4447, 3.3029, 1.7938, 3.3387, 3.3015, 1.9578, 1.9754],\n",
            "        [1.8123, 2.5506, 1.4437, 2.5734, 2.5174, 1.5847, 1.5669]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "228\n",
            "tensor([[2.5618, 3.4332, 1.8580, 3.4726, 3.4416, 2.0200, 2.0474],\n",
            "        [0.9134, 1.4032, 0.8858, 1.4213, 1.3454, 0.9742, 0.9499],\n",
            "        [1.1960, 1.7733, 1.0752, 1.7934, 1.7191, 1.1899, 1.1542],\n",
            "        [2.6321, 3.5141, 1.8951, 3.5566, 3.5293, 2.0585, 2.0925],\n",
            "        [2.5127, 3.3809, 1.8322, 3.4190, 3.3878, 1.9904, 2.0170]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "229\n",
            "tensor([[1.5357, 2.2057, 1.2840, 2.2263, 2.1605, 1.4198, 1.3844],\n",
            "        [0.8758, 1.3543, 0.8696, 1.3750, 1.2959, 0.9533, 0.9272],\n",
            "        [3.0569, 3.9738, 2.1196, 4.0279, 4.0109, 2.2987, 2.3589],\n",
            "        [2.1859, 3.0002, 1.6557, 3.0307, 2.9852, 1.8105, 1.8105],\n",
            "        [1.7535, 2.4769, 1.4113, 2.4987, 2.4401, 1.5555, 1.5283]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "230\n",
            "tensor([[1.7263, 2.4410, 1.3963, 2.4631, 2.4029, 1.5363, 1.5085],\n",
            "        [1.2010, 1.7797, 1.0828, 1.7986, 1.7245, 1.1928, 1.1557],\n",
            "        [2.9004, 3.8085, 2.0375, 3.8576, 3.8393, 2.1981, 2.2560],\n",
            "        [2.7593, 3.6498, 1.9635, 3.6971, 3.6711, 2.1345, 2.1707],\n",
            "        [0.8387, 1.3033, 0.8459, 1.3250, 1.2461, 0.9225, 0.8996]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "231\n",
            "tensor([[3.1669, 4.0898, 2.1733, 4.1400, 4.1162, 2.3686, 2.4322],\n",
            "        [0.9701, 1.4773, 0.9349, 1.4988, 1.4197, 1.0231, 0.9948],\n",
            "        [2.6925, 3.5835, 1.9307, 3.6258, 3.6000, 2.0885, 2.1302],\n",
            "        [2.5966, 3.4748, 1.8773, 3.5151, 3.4868, 2.0330, 2.0695],\n",
            "        [2.9962, 3.9118, 2.0874, 3.9631, 3.9481, 2.2585, 2.3181]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "232\n",
            "tensor([[2.8730, 3.7771, 2.0246, 3.8209, 3.8006, 2.1843, 2.2382],\n",
            "        [2.2230, 3.0431, 1.6798, 3.0739, 3.0309, 1.8236, 1.8318],\n",
            "        [3.0973, 4.0104, 2.1397, 4.0631, 4.0474, 2.3117, 2.3790],\n",
            "        [2.6214, 3.5045, 1.8927, 3.5426, 3.5169, 2.0410, 2.0827],\n",
            "        [2.4493, 3.3042, 1.8006, 3.3412, 3.3069, 1.9534, 1.9749]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "233\n",
            "tensor([[1.5237, 2.1895, 1.2775, 2.2074, 2.1430, 1.4016, 1.3723],\n",
            "        [3.0857, 4.0007, 2.1332, 4.0497, 4.0365, 2.3067, 2.3698],\n",
            "        [1.6224, 2.3110, 1.3352, 2.3318, 2.2698, 1.4676, 1.4392],\n",
            "        [0.9906, 1.5010, 0.9461, 1.5215, 1.4455, 1.0361, 1.0057],\n",
            "        [2.9604, 3.8709, 2.0679, 3.9168, 3.9012, 2.2352, 2.2910]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "234\n",
            "tensor([[3.1863, 4.1024, 2.1816, 4.1478, 4.1287, 2.3630, 2.4333],\n",
            "        [0.9299, 1.4223, 0.9048, 1.4392, 1.3634, 0.9854, 0.9610],\n",
            "        [0.8571, 1.3235, 0.8581, 1.3449, 1.2659, 0.9338, 0.9092],\n",
            "        [2.8932, 3.7956, 2.0323, 3.8390, 3.8244, 2.1816, 2.2447],\n",
            "        [3.1937, 4.1113, 2.1859, 4.1583, 4.1365, 2.3787, 2.4410]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "235\n",
            "tensor([[0.8347, 1.2932, 0.8411, 1.3106, 1.2337, 0.9123, 0.8914],\n",
            "        [3.0783, 3.9841, 2.1278, 4.0303, 4.0199, 2.2837, 2.3563],\n",
            "        [0.7739, 1.2135, 0.8010, 1.2316, 1.1541, 0.8638, 0.8469],\n",
            "        [2.2051, 3.0117, 1.6637, 3.0382, 2.9941, 1.8064, 1.8132],\n",
            "        [1.2621, 1.8502, 1.1149, 1.8654, 1.7931, 1.2212, 1.1892]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "236\n",
            "tensor([[2.5376, 3.3946, 1.8486, 3.4298, 3.4000, 1.9845, 2.0209],\n",
            "        [2.0239, 2.7917, 1.5645, 2.8158, 2.7681, 1.6976, 1.6934],\n",
            "        [2.9140, 3.8064, 2.0425, 3.8502, 3.8380, 2.1840, 2.2516],\n",
            "        [2.7177, 3.5913, 1.9409, 3.6296, 3.6081, 2.0815, 2.1306],\n",
            "        [2.0891, 2.8659, 1.6011, 2.8913, 2.8450, 1.7354, 1.7340]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "237\n",
            "tensor([[2.3514, 3.1712, 1.7475, 3.2036, 3.1689, 1.8746, 1.9002],\n",
            "        [1.7730, 2.4822, 1.4233, 2.5032, 2.4458, 1.5466, 1.5291],\n",
            "        [1.5664, 2.2269, 1.3013, 2.2455, 2.1822, 1.4170, 1.3931],\n",
            "        [2.2018, 2.9968, 1.6654, 3.0262, 2.9827, 1.7943, 1.8067],\n",
            "        [3.1668, 4.0682, 2.1768, 4.1169, 4.1039, 2.3345, 2.4115]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "238\n",
            "tensor([[3.2035, 4.1004, 2.1987, 4.1542, 4.1377, 2.3693, 2.4405],\n",
            "        [2.7151, 3.5796, 1.9441, 3.6235, 3.6018, 2.0667, 2.1283],\n",
            "        [1.0361, 1.5516, 0.9763, 1.5721, 1.4972, 1.0618, 1.0349],\n",
            "        [1.2546, 1.8342, 1.1160, 1.8538, 1.7816, 1.2182, 1.1862],\n",
            "        [1.2004, 1.7617, 1.0810, 1.7811, 1.7077, 1.1750, 1.1477]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "239\n",
            "tensor([[3.2183, 4.1111, 2.2060, 4.1646, 4.1425, 2.3768, 2.4505],\n",
            "        [0.8163, 1.2610, 0.8298, 1.2833, 1.2051, 0.8935, 0.8784],\n",
            "        [1.7409, 2.4360, 1.4113, 2.4636, 2.4046, 1.5260, 1.5109],\n",
            "        [0.9637, 1.4530, 0.9315, 1.4766, 1.3980, 1.0082, 0.9842],\n",
            "        [3.2118, 4.1025, 2.2047, 4.1580, 4.1391, 2.3655, 2.4465]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "240\n",
            "tensor([[0.9766, 1.4676, 0.9398, 1.4925, 1.4146, 1.0167, 0.9932],\n",
            "        [1.9757, 2.7164, 1.5435, 2.7477, 2.6974, 1.6606, 1.6625],\n",
            "        [3.0911, 3.9721, 2.1449, 4.0334, 4.0204, 2.2890, 2.3663],\n",
            "        [2.2043, 2.9861, 1.6705, 3.0246, 2.9807, 1.7943, 1.8105],\n",
            "        [3.0856, 3.9679, 2.1429, 4.0280, 4.0139, 2.2844, 2.3638]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "241\n",
            "tensor([[2.6697, 3.5151, 1.9263, 3.5656, 3.5410, 2.0475, 2.1001],\n",
            "        [1.7704, 2.4631, 1.4273, 2.4937, 2.4364, 1.5403, 1.5294],\n",
            "        [2.1160, 2.8793, 1.6264, 2.9161, 2.8713, 1.7430, 1.7528],\n",
            "        [2.8982, 3.7670, 2.0457, 3.8234, 3.8085, 2.1662, 2.2436],\n",
            "        [2.7226, 3.5761, 1.9538, 3.6288, 3.6081, 2.0759, 2.1344]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "242\n",
            "tensor([[0.8843, 1.3450, 0.8800, 1.3715, 1.2917, 0.9484, 0.9272],\n",
            "        [3.2201, 4.0999, 2.2137, 4.1620, 4.1456, 2.3787, 2.4491],\n",
            "        [3.1456, 4.0210, 2.1744, 4.0870, 4.0742, 2.3187, 2.3964],\n",
            "        [1.9408, 2.6686, 1.5265, 2.7025, 2.6491, 1.6481, 1.6396],\n",
            "        [2.7281, 3.5807, 1.9587, 3.6348, 3.6151, 2.0750, 2.1362]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "243\n",
            "tensor([[1.2434, 1.8059, 1.1111, 1.8329, 1.7609, 1.2079, 1.1755],\n",
            "        [1.7977, 2.4951, 1.4476, 2.5290, 2.4721, 1.5620, 1.5474],\n",
            "        [2.8754, 3.7377, 2.0356, 3.7963, 3.7833, 2.1523, 2.2255],\n",
            "        [1.7863, 2.4802, 1.4388, 2.5134, 2.4551, 1.5578, 1.5390],\n",
            "        [0.9123, 1.3801, 0.8994, 1.4066, 1.3290, 0.9713, 0.9464]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "244\n",
            "tensor([[3.2159, 4.0898, 2.2110, 4.1535, 4.1371, 2.3754, 2.4433],\n",
            "        [1.5425, 2.1792, 1.2935, 2.2088, 2.1449, 1.4048, 1.3770],\n",
            "        [2.3160, 3.1018, 1.7361, 3.1472, 3.1083, 1.8641, 1.8753],\n",
            "        [3.2140, 4.0882, 2.2117, 4.1511, 4.1323, 2.3770, 2.4453],\n",
            "        [3.0894, 3.9587, 2.1468, 4.0227, 4.0138, 2.2826, 2.3578]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "245\n",
            "tensor([[0.7328, 1.1424, 0.7781, 1.1695, 1.0915, 0.8324, 0.8157],\n",
            "        [1.3181, 1.8992, 1.1629, 1.9280, 1.8571, 1.2619, 1.2278],\n",
            "        [1.5421, 2.1790, 1.2920, 2.2073, 2.1436, 1.4141, 1.3782],\n",
            "        [2.4580, 3.2653, 1.8162, 3.3145, 3.2815, 1.9446, 1.9642],\n",
            "        [0.7467, 1.1616, 0.7890, 1.1888, 1.1103, 0.8441, 0.8270]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "246\n",
            "tensor([[2.2869, 3.0697, 1.7272, 3.1169, 3.0772, 1.8486, 1.8589],\n",
            "        [1.2995, 1.8740, 1.1512, 1.9035, 1.8322, 1.2526, 1.2157],\n",
            "        [1.0903, 1.6091, 1.0199, 1.6383, 1.5623, 1.1070, 1.0727],\n",
            "        [2.8477, 3.7024, 2.0301, 3.7626, 3.7468, 2.1526, 2.2075],\n",
            "        [1.5538, 2.1915, 1.3048, 2.2227, 2.1587, 1.4163, 1.3856]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "247\n",
            "tensor([[0.9748, 1.4587, 0.9458, 1.4884, 1.4115, 1.0246, 0.9926],\n",
            "        [3.1273, 3.9885, 2.1758, 4.0570, 4.0445, 2.3112, 2.3835],\n",
            "        [0.9441, 1.4207, 0.9259, 1.4491, 1.3721, 1.0004, 0.9703],\n",
            "        [0.8303, 1.2708, 0.8481, 1.2985, 1.2221, 0.9109, 0.8872],\n",
            "        [2.4067, 3.2082, 1.7970, 3.2587, 3.2245, 1.9200, 1.9357]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "248\n",
            "tensor([[2.1071, 2.8560, 1.6310, 2.8970, 2.8530, 1.7548, 1.7440],\n",
            "        [2.7280, 3.5676, 1.9703, 3.6237, 3.6047, 2.0891, 2.1323],\n",
            "        [1.5519, 2.1886, 1.3121, 2.2206, 2.1594, 1.4194, 1.3849],\n",
            "        [2.3782, 3.1732, 1.7828, 3.2214, 3.1902, 1.9045, 1.9156],\n",
            "        [2.9708, 3.8309, 2.1006, 3.8927, 3.8848, 2.2271, 2.2833]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "249\n",
            "tensor([[1.5606, 2.1991, 1.3163, 2.2298, 2.1700, 1.4239, 1.3888],\n",
            "        [2.9149, 3.7670, 2.0715, 3.8303, 3.8201, 2.1969, 2.2481],\n",
            "        [3.2225, 4.0856, 2.2288, 4.1511, 4.1400, 2.3916, 2.4457],\n",
            "        [2.7244, 3.5624, 1.9718, 3.6204, 3.6057, 2.0891, 2.1302],\n",
            "        [2.4022, 3.2001, 1.7965, 3.2475, 3.2193, 1.9110, 1.9291]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "250\n",
            "tensor([[3.0468, 3.9032, 2.1406, 3.9695, 3.9645, 2.2825, 2.3310],\n",
            "        [1.9401, 2.6596, 1.5375, 2.6966, 2.6505, 1.6571, 1.6382],\n",
            "        [1.5093, 2.1323, 1.2831, 2.1619, 2.1012, 1.3910, 1.3540],\n",
            "        [1.4447, 2.0544, 1.2472, 2.0843, 2.0209, 1.3516, 1.3129],\n",
            "        [0.8462, 1.2896, 0.8612, 1.3169, 1.2421, 0.9267, 0.8991]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "251\n",
            "tensor([[2.1032, 2.8516, 1.6328, 2.8919, 2.8562, 1.7501, 1.7421],\n",
            "        [2.5131, 3.3213, 1.8584, 3.3723, 3.3508, 1.9827, 2.0006],\n",
            "        [3.1897, 4.0502, 2.2152, 4.1196, 4.1165, 2.3712, 2.4223],\n",
            "        [3.2289, 4.0902, 2.2337, 4.1555, 4.1500, 2.3988, 2.4485],\n",
            "        [2.9019, 3.7533, 2.0656, 3.8155, 3.8103, 2.1909, 2.2415]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "252\n",
            "tensor([[1.7384, 2.4155, 1.4215, 2.4479, 2.3978, 1.5420, 1.5080],\n",
            "        [3.0344, 3.8898, 2.1326, 3.9556, 3.9557, 2.2659, 2.3241],\n",
            "        [0.8624, 1.3098, 0.8735, 1.3384, 1.2647, 0.9416, 0.9116],\n",
            "        [1.7219, 2.3940, 1.4128, 2.4268, 2.3769, 1.5260, 1.4961],\n",
            "        [3.2247, 4.0888, 2.2301, 4.1513, 4.1479, 2.4004, 2.4486]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "253\n",
            "tensor([[2.3077, 3.0875, 1.7446, 3.1335, 3.1071, 1.8731, 1.8723],\n",
            "        [3.1514, 4.0095, 2.1923, 4.0767, 4.0796, 2.3446, 2.3988],\n",
            "        [2.4027, 3.1966, 1.7983, 3.2447, 3.2252, 1.9235, 1.9303],\n",
            "        [0.9770, 1.4595, 0.9509, 1.4883, 1.4168, 1.0325, 0.9950],\n",
            "        [0.9152, 1.3787, 0.9091, 1.4077, 1.3351, 0.9839, 0.9506]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "254\n",
            "tensor([[3.2269, 4.0865, 2.2314, 4.1549, 4.1549, 2.4046, 2.4488],\n",
            "        [1.0087, 1.5003, 0.9710, 1.5291, 1.4590, 1.0537, 1.0176],\n",
            "        [0.7224, 1.1261, 0.7764, 1.1547, 1.0805, 0.8322, 0.8114],\n",
            "        [1.8237, 2.5168, 1.4717, 2.5535, 2.5079, 1.5928, 1.5648],\n",
            "        [3.1991, 4.0571, 2.2177, 4.1264, 4.1264, 2.3849, 2.4301]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "255\n",
            "tensor([[3.1209, 3.9737, 2.1779, 4.0423, 4.0446, 2.3402, 2.3787],\n",
            "        [1.9960, 2.7214, 1.5716, 2.7645, 2.7247, 1.6966, 1.6774],\n",
            "        [3.1817, 4.0393, 2.2084, 4.1058, 4.1105, 2.3669, 2.4166],\n",
            "        [3.2248, 4.0816, 2.2297, 4.1480, 4.1491, 2.4008, 2.4455],\n",
            "        [1.3113, 1.8851, 1.1656, 1.9165, 1.8526, 1.2709, 1.2268]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "256\n",
            "tensor([[1.7817, 2.4604, 1.4468, 2.4976, 2.4510, 1.5704, 1.5369],\n",
            "        [3.0090, 3.8559, 2.1201, 3.9240, 3.9281, 2.2616, 2.3075],\n",
            "        [2.3549, 3.1355, 1.7717, 3.1867, 3.1642, 1.9028, 1.9025],\n",
            "        [1.2058, 1.7492, 1.0990, 1.7794, 1.7129, 1.1959, 1.1535],\n",
            "        [1.3967, 1.9887, 1.2158, 2.0205, 1.9615, 1.3281, 1.2828]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "257\n",
            "tensor([[1.0884, 1.5980, 1.0241, 1.6295, 1.5597, 1.1166, 1.0735],\n",
            "        [0.7375, 1.1436, 0.7864, 1.1728, 1.1001, 0.8452, 0.8227],\n",
            "        [3.2314, 4.0818, 2.2332, 4.1495, 4.1496, 2.4164, 2.4521],\n",
            "        [2.9565, 3.7979, 2.0934, 3.8663, 3.8708, 2.2334, 2.2756],\n",
            "        [2.5056, 3.3040, 1.8546, 3.3617, 3.3466, 1.9830, 1.9968]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "258\n",
            "tensor([[2.9551, 3.7959, 2.0931, 3.8658, 3.8692, 2.2386, 2.2753],\n",
            "        [2.4640, 3.2570, 1.8327, 3.3125, 3.2944, 1.9699, 1.9702],\n",
            "        [3.2042, 4.0497, 2.2217, 4.1254, 4.1321, 2.3951, 2.4307],\n",
            "        [0.7437, 1.1524, 0.7936, 1.1844, 1.1098, 0.8565, 0.8293],\n",
            "        [1.6353, 2.2801, 1.3611, 2.3207, 2.2668, 1.4885, 1.4445]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "259\n",
            "tensor([[2.2107, 2.9655, 1.6930, 3.0167, 2.9875, 1.8252, 1.8125],\n",
            "        [1.2893, 1.8523, 1.1440, 1.8808, 1.8208, 1.2592, 1.2078],\n",
            "        [3.1530, 3.9963, 2.1954, 4.0742, 4.0820, 2.3597, 2.3988],\n",
            "        [3.2093, 4.0541, 2.2228, 4.1298, 4.1312, 2.4016, 2.4383],\n",
            "        [3.2373, 4.0825, 2.2379, 4.1585, 4.1599, 2.4238, 2.4556]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "260\n",
            "tensor([[3.1075, 3.9437, 2.1697, 4.0210, 4.0239, 2.3490, 2.3714],\n",
            "        [3.1942, 4.0349, 2.2173, 4.1157, 4.1235, 2.3935, 2.4250],\n",
            "        [3.0336, 3.8688, 2.1330, 3.9452, 3.9543, 2.2889, 2.3210],\n",
            "        [1.4113, 2.0045, 1.2277, 2.0411, 1.9827, 1.3456, 1.2950],\n",
            "        [1.7953, 2.4731, 1.4577, 2.5178, 2.4713, 1.5886, 1.5483]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "261\n",
            "tensor([[1.0281, 1.5172, 0.9838, 1.5534, 1.4820, 1.0775, 1.0328],\n",
            "        [1.0002, 1.4834, 0.9672, 1.5188, 1.4470, 1.0596, 1.0147],\n",
            "        [3.2368, 4.0747, 2.2367, 4.1545, 4.1562, 2.4226, 2.4538],\n",
            "        [3.2326, 4.0706, 2.2318, 4.1500, 4.1477, 2.4247, 2.4539],\n",
            "        [2.5900, 3.3889, 1.8985, 3.4552, 3.4422, 2.0440, 2.0472]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "262\n",
            "tensor([[3.1945, 4.0255, 2.2151, 4.1112, 4.1191, 2.3949, 2.4237],\n",
            "        [2.0256, 2.7392, 1.5880, 2.7901, 2.7528, 1.7243, 1.6936],\n",
            "        [1.5793, 2.2062, 1.3271, 2.2464, 2.1926, 1.4567, 1.4058],\n",
            "        [3.2058, 4.0404, 2.2201, 4.1254, 4.1280, 2.3986, 2.4329],\n",
            "        [2.5590, 3.3561, 1.8831, 3.4224, 3.4097, 2.0263, 2.0308]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "263\n",
            "tensor([[3.2339, 4.0666, 2.2382, 4.1492, 4.1521, 2.4293, 2.4504],\n",
            "        [2.1541, 2.8876, 1.6619, 2.9429, 2.9111, 1.8064, 1.7762],\n",
            "        [2.9422, 3.7671, 2.0874, 3.8472, 3.8520, 2.2332, 2.2647],\n",
            "        [0.8562, 1.2952, 0.8707, 1.3309, 1.2571, 0.9485, 0.9123],\n",
            "        [2.5317, 3.3198, 1.8695, 3.3877, 3.3719, 2.0212, 2.0154]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "264\n",
            "tensor([[3.1897, 4.0196, 2.2191, 4.1059, 4.1106, 2.3962, 2.4216],\n",
            "        [1.1495, 1.6706, 1.0653, 1.7088, 1.6400, 1.1704, 1.1185],\n",
            "        [1.1594, 1.6830, 1.0718, 1.7210, 1.6519, 1.1771, 1.1255],\n",
            "        [2.2540, 3.0005, 1.7199, 3.0617, 3.0333, 1.8651, 1.8396],\n",
            "        [3.2376, 4.0675, 2.2396, 4.1507, 4.1477, 2.4338, 2.4563]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "265\n",
            "tensor([[2.0892, 2.8120, 1.6293, 2.8676, 2.8340, 1.7694, 1.7374],\n",
            "        [2.2044, 2.9461, 1.6960, 3.0053, 2.9754, 1.8315, 1.8110],\n",
            "        [1.7441, 2.4044, 1.4304, 2.4524, 2.4032, 1.5603, 1.5166],\n",
            "        [3.2369, 4.0623, 2.2418, 4.1489, 4.1528, 2.4268, 2.4527],\n",
            "        [3.1832, 4.0057, 2.2143, 4.0962, 4.1046, 2.3911, 2.4170]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "266\n",
            "tensor([[1.6396, 2.2769, 1.3714, 2.3230, 2.2688, 1.5002, 1.4507],\n",
            "        [1.0951, 1.5975, 1.0353, 1.6367, 1.5676, 1.1312, 1.0811],\n",
            "        [3.2218, 4.0450, 2.2358, 4.1311, 4.1322, 2.4269, 2.4458],\n",
            "        [2.6028, 3.3924, 1.9132, 3.4657, 3.4551, 2.0556, 2.0591],\n",
            "        [1.4599, 2.0580, 1.2637, 2.1024, 2.0424, 1.3850, 1.3328]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "267\n",
            "tensor([[1.5989, 2.2230, 1.3461, 2.2693, 2.2146, 1.4775, 1.4232],\n",
            "        [3.2315, 4.0498, 2.2450, 4.1396, 4.1393, 2.4256, 2.4516],\n",
            "        [2.3259, 3.0796, 1.7654, 3.1455, 3.1186, 1.9087, 1.8910],\n",
            "        [1.2796, 1.8303, 1.1491, 1.8696, 1.8047, 1.2590, 1.2062],\n",
            "        [1.6862, 2.3310, 1.3999, 2.3790, 2.3280, 1.5356, 1.4811]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "268\n",
            "tensor([[2.9011, 3.7124, 2.0778, 3.7982, 3.7989, 2.2268, 2.2482],\n",
            "        [2.9338, 3.7472, 2.0956, 3.8343, 3.8358, 2.2429, 2.2666],\n",
            "        [2.8776, 3.6873, 2.0655, 3.7716, 3.7730, 2.2035, 2.2307],\n",
            "        [2.0983, 2.8138, 1.6411, 2.8732, 2.8389, 1.7795, 1.7455],\n",
            "        [3.2345, 4.0533, 2.2489, 4.1444, 4.1449, 2.4289, 2.4587]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "269\n",
            "tensor([[2.9398, 3.7541, 2.1013, 3.8403, 3.8359, 2.2503, 2.2798],\n",
            "        [2.5886, 3.3711, 1.9148, 3.4469, 3.4328, 2.0549, 2.0572],\n",
            "        [1.3386, 1.9017, 1.1936, 1.9440, 1.8808, 1.3045, 1.2529],\n",
            "        [1.3933, 1.9714, 1.2274, 2.0138, 1.9524, 1.3430, 1.2893],\n",
            "        [0.9599, 1.4257, 0.9486, 1.4631, 1.3908, 1.0318, 0.9896]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "270\n",
            "tensor([[0.9184, 1.3723, 0.9220, 1.4114, 1.3374, 1.0028, 0.9638],\n",
            "        [3.1899, 4.0051, 2.2320, 4.0997, 4.1022, 2.3988, 2.4339],\n",
            "        [3.2207, 4.0393, 2.2503, 4.1329, 4.1306, 2.4261, 2.4571],\n",
            "        [1.4728, 2.0696, 1.2787, 2.1147, 2.0554, 1.3961, 1.3458],\n",
            "        [2.7668, 3.5680, 2.0131, 3.6488, 3.6417, 2.1608, 2.1733]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "271\n",
            "tensor([[3.1029, 3.9178, 2.1924, 4.0108, 4.0167, 2.3416, 2.3812],\n",
            "        [2.5757, 3.3602, 1.9157, 3.4372, 3.4217, 2.0512, 2.0586],\n",
            "        [1.1748, 1.7005, 1.0937, 1.7424, 1.6722, 1.1963, 1.1465],\n",
            "        [2.6471, 3.4387, 1.9525, 3.5164, 3.5030, 2.0970, 2.1030],\n",
            "        [2.1961, 2.9320, 1.7055, 2.9950, 2.9624, 1.8393, 1.8203]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "272\n",
            "tensor([[1.2592, 1.8064, 1.1495, 1.8493, 1.7828, 1.2590, 1.2070],\n",
            "        [2.3927, 3.1517, 1.8157, 3.2226, 3.1993, 1.9551, 1.9447],\n",
            "        [3.1880, 4.0018, 2.2394, 4.0991, 4.1045, 2.4107, 2.4406],\n",
            "        [0.8062, 1.2292, 0.8477, 1.2667, 1.1930, 0.9179, 0.8854],\n",
            "        [3.2120, 4.0278, 2.2516, 4.1218, 4.1226, 2.4223, 2.4578]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "273\n",
            "tensor([[2.8187, 3.6239, 2.0509, 3.7108, 3.7071, 2.1950, 2.2157],\n",
            "        [1.6815, 2.3252, 1.4122, 2.3752, 2.3223, 1.5369, 1.4929],\n",
            "        [3.0153, 3.8275, 2.1531, 3.9214, 3.9244, 2.3091, 2.3391],\n",
            "        [2.5847, 3.3732, 1.9280, 3.4513, 3.4380, 2.0664, 2.0727],\n",
            "        [3.2354, 4.0495, 2.2663, 4.1468, 4.1464, 2.4467, 2.4797]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "274\n",
            "tensor([[1.5024, 2.1080, 1.3072, 2.1564, 2.0965, 1.4261, 1.3774],\n",
            "        [1.2209, 1.7591, 1.1265, 1.8010, 1.7331, 1.2359, 1.1844],\n",
            "        [2.9204, 3.7300, 2.1060, 3.8211, 3.8184, 2.2524, 2.2830],\n",
            "        [2.9878, 3.7975, 2.1408, 3.8925, 3.8912, 2.2944, 2.3262],\n",
            "        [2.8797, 3.6940, 2.0883, 3.7834, 3.7820, 2.2266, 2.2597]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "275\n",
            "tensor([[1.9916, 2.6908, 1.5962, 2.7500, 2.7087, 1.7294, 1.7006],\n",
            "        [2.9591, 3.7707, 2.1272, 3.8625, 3.8630, 2.2772, 2.3101],\n",
            "        [3.0111, 3.8217, 2.1542, 3.9171, 3.9188, 2.3087, 2.3405],\n",
            "        [3.2152, 4.0282, 2.2600, 4.1263, 4.1259, 2.4358, 2.4710],\n",
            "        [2.7823, 3.5901, 2.0364, 3.6754, 3.6705, 2.1703, 2.2012]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "276\n",
            "tensor([[1.5426, 2.1550, 1.3314, 2.2024, 2.1454, 1.4488, 1.4049],\n",
            "        [1.8198, 2.4871, 1.4964, 2.5427, 2.4942, 1.6269, 1.5891],\n",
            "        [1.0626, 1.5562, 1.0263, 1.5976, 1.5249, 1.1171, 1.0752],\n",
            "        [3.2403, 4.0511, 2.2759, 4.1480, 4.1450, 2.4518, 2.4913],\n",
            "        [1.7960, 2.4596, 1.4822, 2.5130, 2.4628, 1.6128, 1.5738]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "277\n",
            "tensor([[1.0946, 1.5970, 1.0506, 1.6375, 1.5665, 1.1388, 1.0988],\n",
            "        [2.0464, 2.7528, 1.6302, 2.8133, 2.7734, 1.7575, 1.7381],\n",
            "        [1.5810, 2.2022, 1.3561, 2.2493, 2.1928, 1.4743, 1.4322],\n",
            "        [1.4104, 1.9928, 1.2533, 2.0367, 1.9742, 1.3628, 1.3170],\n",
            "        [1.2408, 1.7809, 1.1448, 1.8234, 1.7562, 1.2479, 1.2019]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "278\n",
            "tensor([[2.0616, 2.7686, 1.6443, 2.8282, 2.7888, 1.7698, 1.7488],\n",
            "        [1.8643, 2.5379, 1.5294, 2.5905, 2.5453, 1.6490, 1.6195],\n",
            "        [1.0399, 1.5282, 1.0147, 1.5678, 1.4962, 1.1008, 1.0613],\n",
            "        [2.6954, 3.4846, 1.9972, 3.5667, 3.5577, 2.1194, 2.1503],\n",
            "        [2.9943, 3.7977, 2.1528, 3.8890, 3.8877, 2.2891, 2.3371]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "279\n",
            "tensor([[3.1904, 3.9944, 2.2607, 4.0915, 4.0948, 2.4025, 2.4618],\n",
            "        [0.8661, 1.3067, 0.8971, 1.3416, 1.2696, 0.9627, 0.9355],\n",
            "        [1.2860, 1.8369, 1.1753, 1.8771, 1.8122, 1.2756, 1.2341],\n",
            "        [0.9155, 1.3694, 0.9324, 1.4061, 1.3329, 1.0022, 0.9717],\n",
            "        [1.6679, 2.3027, 1.4152, 2.3547, 2.3002, 1.5296, 1.4936]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "280\n",
            "tensor([[1.3081, 1.8651, 1.1930, 1.9072, 1.8417, 1.2902, 1.2515],\n",
            "        [0.8796, 1.3232, 0.9078, 1.3597, 1.2870, 0.9737, 0.9467],\n",
            "        [2.1446, 2.8645, 1.6975, 2.9243, 2.8905, 1.8069, 1.8041],\n",
            "        [1.2721, 1.8197, 1.1714, 1.8630, 1.7968, 1.2669, 1.2269],\n",
            "        [1.1975, 1.7271, 1.1231, 1.7673, 1.6996, 1.2118, 1.1747]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "281\n",
            "tensor([[2.4485, 3.2129, 1.8706, 3.2816, 3.2651, 1.9794, 2.0001],\n",
            "        [2.0066, 2.7064, 1.6178, 2.7619, 2.7239, 1.7283, 1.7179],\n",
            "        [2.3047, 3.0486, 1.7905, 3.1142, 3.0887, 1.9085, 1.9099],\n",
            "        [2.6622, 3.4483, 1.9885, 3.5260, 3.5182, 2.1011, 2.1361],\n",
            "        [0.9620, 1.4272, 0.9651, 1.4632, 1.3917, 1.0372, 1.0062]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "282\n",
            "tensor([[1.2557, 1.7984, 1.1568, 1.8361, 1.7721, 1.2446, 1.2127],\n",
            "        [3.0346, 3.8364, 2.1870, 3.9284, 3.9339, 2.2987, 2.3684],\n",
            "        [1.1541, 1.6719, 1.0949, 1.7083, 1.6414, 1.1749, 1.1428],\n",
            "        [1.6399, 2.2717, 1.4049, 2.3193, 2.2659, 1.5085, 1.4784],\n",
            "        [1.9574, 2.6502, 1.5936, 2.7050, 2.6637, 1.6970, 1.6891]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "283\n",
            "tensor([[3.0078, 3.8115, 2.1756, 3.8967, 3.9002, 2.2927, 2.3560],\n",
            "        [1.3341, 1.8983, 1.2152, 1.9393, 1.8761, 1.3070, 1.2716],\n",
            "        [1.0205, 1.5048, 1.0097, 1.5417, 1.4699, 1.0826, 1.0510],\n",
            "        [1.4381, 2.0283, 1.2829, 2.0687, 2.0089, 1.3738, 1.3431],\n",
            "        [1.3661, 1.9376, 1.2345, 1.9781, 1.9163, 1.3271, 1.2934]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "Loss at epoch 6: 121.2255\n",
            "Pearson correlation for aspect 1: 0.6190\n",
            "Pearson correlation for aspect 2: 0.6828\n",
            "Pearson correlation for aspect 3: 0.2389\n",
            "Pearson correlation for aspect 4: 0.7010\n",
            "Pearson correlation for aspect 5: 0.7052\n",
            "Pearson correlation for aspect 6: 0.3154\n",
            "Pearson correlation for aspect 7: 0.4072\n",
            "Mean Pearson correlation: 0.5242\n",
            "0\n",
            "tensor([[2.6780, 3.4686, 2.0050, 3.5457, 3.5342, 2.0980, 2.1536],\n",
            "        [3.0525, 3.8589, 2.2061, 3.9510, 3.9556, 2.3043, 2.3842],\n",
            "        [1.0183, 1.5020, 1.0110, 1.5393, 1.4678, 1.0797, 1.0508],\n",
            "        [0.7061, 1.0995, 0.7886, 1.1316, 1.0592, 0.8299, 0.8198],\n",
            "        [1.9062, 2.5890, 1.5669, 2.6407, 2.5979, 1.6637, 1.6554]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "1\n",
            "tensor([[2.1933, 2.9241, 1.7372, 2.9856, 2.9540, 1.8321, 1.8464],\n",
            "        [0.8394, 1.2721, 0.8872, 1.3079, 1.2328, 0.9394, 0.9208],\n",
            "        [1.0504, 1.5432, 1.0334, 1.5813, 1.5091, 1.1022, 1.0749],\n",
            "        [1.2152, 1.7499, 1.1450, 1.7906, 1.7232, 1.2209, 1.1919],\n",
            "        [2.8585, 3.6577, 2.1054, 3.7420, 3.7402, 2.1959, 2.2657]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "2\n",
            "tensor([[3.2558, 4.0617, 2.3142, 4.1500, 4.1480, 2.4404, 2.5192],\n",
            "        [3.2433, 4.0479, 2.3112, 4.1447, 4.1463, 2.4255, 2.5090],\n",
            "        [1.4282, 2.0136, 1.2813, 2.0576, 1.9969, 1.3649, 1.3396],\n",
            "        [1.9988, 2.6947, 1.6270, 2.7508, 2.7119, 1.7146, 1.7167],\n",
            "        [0.8524, 1.2882, 0.8979, 1.3238, 1.2494, 0.9468, 0.9310]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "3\n",
            "tensor([[2.2780, 3.0147, 1.7919, 3.0821, 3.0563, 1.8712, 1.8990],\n",
            "        [1.9147, 2.5960, 1.5771, 2.6481, 2.6033, 1.6653, 1.6632],\n",
            "        [2.5518, 3.3227, 1.9448, 3.3977, 3.3820, 2.0245, 2.0724],\n",
            "        [1.4589, 2.0496, 1.3033, 2.0941, 2.0346, 1.3849, 1.3602],\n",
            "        [1.4364, 2.0214, 1.2898, 2.0678, 2.0059, 1.3692, 1.3450]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "4\n",
            "tensor([[3.2502, 4.0531, 2.3213, 4.1478, 4.1478, 2.4224, 2.5147],\n",
            "        [3.1177, 3.9184, 2.2532, 4.0138, 4.0212, 2.3353, 2.4275],\n",
            "        [1.1744, 1.6955, 1.1211, 1.7378, 1.6697, 1.1867, 1.1627],\n",
            "        [1.0462, 1.5334, 1.0360, 1.5745, 1.5043, 1.0956, 1.0718],\n",
            "        [1.3453, 1.9096, 1.2336, 1.9521, 1.8897, 1.3047, 1.2823]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "5\n",
            "tensor([[2.7432, 3.5255, 2.0532, 3.6087, 3.5987, 2.1364, 2.1934],\n",
            "        [3.0459, 3.8488, 2.2188, 3.9440, 3.9475, 2.2961, 2.3857],\n",
            "        [3.2591, 4.0617, 2.3288, 4.1552, 4.1535, 2.4291, 2.5236],\n",
            "        [2.1333, 2.8466, 1.7130, 2.9093, 2.8765, 1.7905, 1.8051],\n",
            "        [3.1960, 3.9991, 2.2970, 4.0957, 4.1021, 2.3817, 2.4779]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "6\n",
            "tensor([[3.2496, 4.0537, 2.3244, 4.1505, 4.1495, 2.4215, 2.5179],\n",
            "        [0.8829, 1.3282, 0.9242, 1.3658, 1.2925, 0.9728, 0.9560],\n",
            "        [2.9775, 3.7759, 2.1820, 3.8696, 3.8713, 2.2600, 2.3426],\n",
            "        [1.9513, 2.6413, 1.6062, 2.6975, 2.6561, 1.6866, 1.6912],\n",
            "        [1.2198, 1.7546, 1.1541, 1.7979, 1.7312, 1.2211, 1.1972]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "7\n",
            "tensor([[3.2645, 4.0716, 2.3339, 4.1665, 4.1665, 2.4410, 2.5299],\n",
            "        [1.1674, 1.6899, 1.1212, 1.7306, 1.6633, 1.1851, 1.1598],\n",
            "        [3.2706, 4.0762, 2.3397, 4.1715, 4.1688, 2.4483, 2.5339],\n",
            "        [1.6457, 2.2778, 1.4234, 2.3255, 2.2725, 1.5032, 1.4882],\n",
            "        [1.8958, 2.5758, 1.5796, 2.6314, 2.5896, 1.6501, 1.6536]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "8\n",
            "tensor([[2.0164, 2.7185, 1.6515, 2.7774, 2.7411, 1.7268, 1.7336],\n",
            "        [2.5812, 3.3633, 1.9750, 3.4431, 3.4277, 2.0419, 2.0996],\n",
            "        [1.0119, 1.4947, 1.0148, 1.5339, 1.4619, 1.0730, 1.0510],\n",
            "        [1.5698, 2.1886, 1.3817, 2.2348, 2.1804, 1.4577, 1.4372],\n",
            "        [2.5099, 3.2824, 1.9361, 3.3594, 3.3426, 2.0026, 2.0518]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "9\n",
            "tensor([[3.2538, 4.0597, 2.3336, 4.1591, 4.1584, 2.4303, 2.5197],\n",
            "        [2.6074, 3.3941, 1.9903, 3.4728, 3.4595, 2.0628, 2.1147],\n",
            "        [1.4201, 2.0069, 1.2899, 2.0531, 1.9918, 1.3644, 1.3376],\n",
            "        [2.5392, 3.3157, 1.9525, 3.3923, 3.3777, 2.0293, 2.0700],\n",
            "        [2.1860, 2.9178, 1.7515, 2.9822, 2.9501, 1.8272, 1.8449]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "10\n",
            "tensor([[3.2292, 4.0436, 2.3255, 4.1385, 4.1412, 2.4203, 2.5050],\n",
            "        [3.2530, 4.0635, 2.3373, 4.1600, 4.1649, 2.4375, 2.5174],\n",
            "        [3.1514, 3.9636, 2.2860, 4.0601, 4.0638, 2.3845, 2.4570],\n",
            "        [3.1321, 3.9429, 2.2744, 4.0392, 4.0469, 2.3522, 2.4407],\n",
            "        [1.2776, 1.8334, 1.1975, 1.8742, 1.8088, 1.2652, 1.2383]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "11\n",
            "tensor([[3.2531, 4.0664, 2.3383, 4.1636, 4.1650, 2.4458, 2.5195],\n",
            "        [2.3110, 3.0650, 1.8276, 3.1322, 3.1058, 1.9001, 1.9243],\n",
            "        [3.1753, 3.9870, 2.2975, 4.0845, 4.0863, 2.3983, 2.4697],\n",
            "        [2.2524, 2.9996, 1.7939, 3.0654, 3.0351, 1.8674, 1.8881],\n",
            "        [1.8644, 2.5478, 1.5656, 2.6009, 2.5584, 1.6385, 1.6343]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "12\n",
            "tensor([[2.4745, 3.2508, 1.9206, 3.3237, 3.3064, 1.9874, 2.0278],\n",
            "        [1.6763, 2.3221, 1.4522, 2.3722, 2.3202, 1.5290, 1.5090],\n",
            "        [2.2133, 2.9572, 1.7722, 3.0218, 2.9898, 1.8418, 1.8628],\n",
            "        [2.9567, 3.7709, 2.1841, 3.8619, 3.8646, 2.2500, 2.3280],\n",
            "        [3.2582, 4.0725, 2.3393, 4.1638, 4.1596, 2.4532, 2.5243]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "13\n",
            "tensor([[2.7877, 3.5924, 2.0941, 3.6748, 3.6713, 2.1547, 2.2200],\n",
            "        [1.7610, 2.4241, 1.5065, 2.4762, 2.4265, 1.5813, 1.5649],\n",
            "        [1.9476, 2.6458, 1.6161, 2.7008, 2.6582, 1.6943, 1.6861],\n",
            "        [1.2256, 1.7702, 1.1648, 1.8118, 1.7438, 1.2307, 1.2006],\n",
            "        [3.2441, 4.0552, 2.3335, 4.1488, 4.1472, 2.4301, 2.5084]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "14\n",
            "tensor([[1.0081, 1.4979, 1.0199, 1.5354, 1.4618, 1.0741, 1.0459],\n",
            "        [0.9357, 1.4031, 0.9630, 1.4387, 1.3669, 1.0182, 0.9916],\n",
            "        [1.7204, 2.3771, 1.4813, 2.4268, 2.3755, 1.5580, 1.5351],\n",
            "        [3.2685, 4.0837, 2.3511, 4.1775, 4.1749, 2.4540, 2.5224],\n",
            "        [1.4926, 2.1013, 1.3382, 2.1447, 2.0867, 1.4076, 1.3809]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "15\n",
            "tensor([[3.1697, 3.9788, 2.2971, 4.0696, 4.0704, 2.3714, 2.4533],\n",
            "        [3.2610, 4.0738, 2.3495, 4.1692, 4.1654, 2.4499, 2.5147],\n",
            "        [2.3715, 3.1335, 1.8672, 3.2037, 3.1759, 1.9384, 1.9559],\n",
            "        [1.6057, 2.2378, 1.4108, 2.2881, 2.2289, 1.4868, 1.4593],\n",
            "        [1.7341, 2.3921, 1.4920, 2.4434, 2.3895, 1.5652, 1.5426]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "16\n",
            "tensor([[2.6476, 3.4371, 2.0235, 3.5155, 3.4977, 2.0814, 2.1261],\n",
            "        [2.5920, 3.3818, 1.9960, 3.4586, 3.4390, 2.0566, 2.0941],\n",
            "        [3.2104, 4.0233, 2.3288, 4.1189, 4.1183, 2.4148, 2.4786],\n",
            "        [2.5264, 3.3053, 1.9577, 3.3791, 3.3568, 2.0232, 2.0504],\n",
            "        [1.5025, 2.1133, 1.3495, 2.1570, 2.0957, 1.4198, 1.3866]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "17\n",
            "tensor([[3.2655, 4.0818, 2.3609, 4.1749, 4.1673, 2.4525, 2.5153],\n",
            "        [1.8556, 2.5417, 1.5715, 2.5942, 2.5433, 1.6406, 1.6220],\n",
            "        [2.5835, 3.3735, 1.9949, 3.4489, 3.4284, 2.0567, 2.0874],\n",
            "        [3.2661, 4.0798, 2.3605, 4.1736, 4.1687, 2.4483, 2.5145],\n",
            "        [2.0364, 2.7488, 1.6754, 2.8042, 2.7613, 1.7531, 1.7372]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "18\n",
            "tensor([[1.5117, 2.1289, 1.3584, 2.1709, 2.1079, 1.4297, 1.3927],\n",
            "        [1.7640, 2.4353, 1.5181, 2.4835, 2.4292, 1.5881, 1.5620],\n",
            "        [1.0212, 1.5159, 1.0335, 1.5507, 1.4750, 1.0857, 1.0512],\n",
            "        [1.7300, 2.3934, 1.4965, 2.4401, 2.3840, 1.5680, 1.5384],\n",
            "        [1.4082, 2.0020, 1.2930, 2.0435, 1.9772, 1.3590, 1.3229]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "19\n",
            "tensor([[1.4063, 2.0012, 1.2938, 2.0405, 1.9730, 1.3633, 1.3215],\n",
            "        [3.1405, 3.9623, 2.3054, 4.0537, 4.0506, 2.3834, 2.4339],\n",
            "        [2.7675, 3.5795, 2.1040, 3.6588, 3.6439, 2.1711, 2.2049],\n",
            "        [0.8254, 1.2658, 0.8955, 1.2991, 1.2213, 0.9394, 0.9113],\n",
            "        [3.0130, 3.8361, 2.2373, 3.9220, 3.9175, 2.3049, 2.3558]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "20\n",
            "tensor([[1.4588, 2.0681, 1.3312, 2.1068, 2.0423, 1.3998, 1.3590],\n",
            "        [3.2698, 4.0984, 2.3790, 4.1871, 4.1747, 2.4805, 2.5237],\n",
            "        [0.7614, 1.1848, 0.8527, 1.2178, 1.1395, 0.8897, 0.8655],\n",
            "        [3.2410, 4.0666, 2.3637, 4.1587, 4.1500, 2.4553, 2.5047],\n",
            "        [1.0353, 1.5389, 1.0509, 1.5753, 1.4982, 1.1075, 1.0665]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "21\n",
            "tensor([[2.7595, 3.5776, 2.1074, 3.6537, 3.6404, 2.1669, 2.2009],\n",
            "        [2.5696, 3.3719, 2.0039, 3.4425, 3.4208, 2.0635, 2.0834],\n",
            "        [3.2637, 4.0917, 2.3800, 4.1787, 4.1663, 2.4803, 2.5221],\n",
            "        [1.8275, 2.5185, 1.5662, 2.5667, 2.5112, 1.6430, 1.6091],\n",
            "        [2.1973, 2.9504, 1.7879, 3.0069, 2.9665, 1.8592, 1.8464]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "22\n",
            "tensor([[1.2409, 1.8053, 1.1941, 1.8405, 1.7667, 1.2628, 1.2130],\n",
            "        [1.6187, 2.2696, 1.4375, 2.3097, 2.2478, 1.5154, 1.4688],\n",
            "        [2.7699, 3.5919, 2.1195, 3.6681, 3.6521, 2.1824, 2.2107],\n",
            "        [3.2398, 4.0735, 2.3745, 4.1596, 4.1503, 2.4682, 2.5075],\n",
            "        [2.6639, 3.4764, 2.0611, 3.5492, 3.5272, 2.1312, 2.1444]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "23\n",
            "tensor([[1.6991, 2.3693, 1.4929, 2.4131, 2.3535, 1.5709, 1.5257],\n",
            "        [2.6437, 3.4610, 2.0552, 3.5307, 3.5109, 2.1109, 2.1318],\n",
            "        [1.7882, 2.4768, 1.5493, 2.5221, 2.4647, 1.6252, 1.5838],\n",
            "        [0.8038, 1.2457, 0.8887, 1.2757, 1.1969, 0.9290, 0.8989],\n",
            "        [2.3941, 3.1808, 1.9086, 3.2417, 3.2080, 1.9830, 1.9769]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "24\n",
            "tensor([[1.1020, 1.6295, 1.1028, 1.6622, 1.5859, 1.1624, 1.1133],\n",
            "        [1.1886, 1.7427, 1.1639, 1.7739, 1.7009, 1.2251, 1.1757],\n",
            "        [3.1621, 4.0006, 2.3416, 4.0852, 4.0772, 2.4244, 2.4594],\n",
            "        [2.9490, 3.7855, 2.2272, 3.8641, 3.8551, 2.2917, 2.3225],\n",
            "        [1.6221, 2.2810, 1.4491, 2.3199, 2.2587, 1.5211, 1.4741]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "25\n",
            "tensor([[3.2633, 4.1019, 2.3979, 4.1850, 4.1725, 2.4947, 2.5249],\n",
            "        [1.0834, 1.6095, 1.0924, 1.6408, 1.5638, 1.1534, 1.1030],\n",
            "        [1.0350, 1.5466, 1.0592, 1.5787, 1.5002, 1.1167, 1.0686],\n",
            "        [3.2434, 4.0841, 2.3916, 4.1680, 4.1595, 2.4855, 2.5111],\n",
            "        [1.2565, 1.8295, 1.2127, 1.8616, 1.7898, 1.2769, 1.2236]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "26\n",
            "tensor([[3.1786, 4.0203, 2.3599, 4.1029, 4.0932, 2.4412, 2.4707],\n",
            "        [1.7950, 2.4886, 1.5586, 2.5262, 2.4724, 1.6298, 1.5846],\n",
            "        [2.1539, 2.9143, 1.7842, 2.9650, 2.9235, 1.8494, 1.8233],\n",
            "        [1.0349, 1.5487, 1.0639, 1.5808, 1.5030, 1.1206, 1.0701],\n",
            "        [1.7610, 2.4503, 1.5401, 2.4897, 2.4323, 1.6157, 1.5670]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "27\n",
            "tensor([[3.2287, 4.0732, 2.3935, 4.1544, 4.1422, 2.4811, 2.5025],\n",
            "        [2.0544, 2.7999, 1.7255, 2.8469, 2.8026, 1.7963, 1.7591],\n",
            "        [3.2608, 4.1034, 2.4093, 4.1826, 4.1713, 2.5056, 2.5222],\n",
            "        [3.1242, 3.9664, 2.3364, 4.0483, 4.0421, 2.4135, 2.4338],\n",
            "        [1.6611, 2.3275, 1.4808, 2.3663, 2.3058, 1.5539, 1.4994]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "28\n",
            "tensor([[1.0850, 1.6140, 1.1007, 1.6418, 1.5669, 1.1557, 1.1027],\n",
            "        [0.9525, 1.4433, 1.0079, 1.4724, 1.3950, 1.0563, 1.0092],\n",
            "        [1.5560, 2.2019, 1.4163, 2.2362, 2.1745, 1.4893, 1.4282],\n",
            "        [1.8504, 2.5568, 1.6023, 2.5968, 2.5448, 1.6735, 1.6254],\n",
            "        [3.2487, 4.0883, 2.4049, 4.1661, 4.1574, 2.4963, 2.5144]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "29\n",
            "tensor([[3.2503, 4.0917, 2.4090, 4.1654, 4.1617, 2.4969, 2.5123],\n",
            "        [0.9991, 1.5042, 1.0419, 1.5320, 1.4559, 1.0948, 1.0425],\n",
            "        [1.2544, 1.8275, 1.2197, 1.8567, 1.7877, 1.2840, 1.2228],\n",
            "        [1.4938, 2.1263, 1.3801, 2.1602, 2.0957, 1.4500, 1.3881],\n",
            "        [1.5828, 2.2361, 1.4362, 2.2682, 2.2083, 1.5045, 1.4463]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "30\n",
            "tensor([[3.2488, 4.0927, 2.4118, 4.1620, 4.1569, 2.5006, 2.5136],\n",
            "        [2.4305, 3.2195, 1.9491, 3.2698, 3.2443, 2.0258, 1.9949],\n",
            "        [1.4248, 2.0416, 1.3337, 2.0717, 2.0071, 1.4007, 1.3408],\n",
            "        [1.0142, 1.5252, 1.0550, 1.5506, 1.4767, 1.1073, 1.0539],\n",
            "        [3.0110, 3.8521, 2.2824, 3.9198, 3.9185, 2.3329, 2.3581]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "31\n",
            "tensor([[3.0362, 3.8765, 2.2963, 3.9441, 3.9476, 2.3579, 2.3745],\n",
            "        [1.5776, 2.2276, 1.4332, 2.2556, 2.1999, 1.5037, 1.4423],\n",
            "        [3.2137, 4.0552, 2.3943, 4.1273, 4.1267, 2.4836, 2.4910],\n",
            "        [3.2183, 4.0589, 2.3972, 4.1305, 4.1313, 2.4792, 2.4928],\n",
            "        [2.3689, 3.1581, 1.9201, 3.2072, 3.1793, 1.9853, 1.9595]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "32\n",
            "tensor([[3.2642, 4.1013, 2.4198, 4.1693, 4.1647, 2.5138, 2.5260],\n",
            "        [0.9285, 1.4106, 0.9944, 1.4372, 1.3627, 1.0431, 0.9919],\n",
            "        [2.9924, 3.8311, 2.2740, 3.8946, 3.8979, 2.3292, 2.3476],\n",
            "        [0.9831, 1.4810, 1.0326, 1.5067, 1.4330, 1.0842, 1.0309],\n",
            "        [0.9046, 1.3796, 0.9744, 1.4048, 1.3298, 1.0222, 0.9730]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "33\n",
            "tensor([[3.2133, 4.0501, 2.3975, 4.1187, 4.1196, 2.4766, 2.4906],\n",
            "        [2.8061, 3.6361, 2.1756, 3.6954, 3.6897, 2.2306, 2.2341],\n",
            "        [2.7108, 3.5314, 2.1208, 3.5879, 3.5796, 2.1785, 2.1735],\n",
            "        [1.5365, 2.1751, 1.4079, 2.2024, 2.1449, 1.4831, 1.4159],\n",
            "        [3.2663, 4.1033, 2.4263, 4.1714, 4.1708, 2.5190, 2.5250]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "34\n",
            "tensor([[1.0571, 1.5759, 1.0878, 1.6012, 1.5287, 1.1449, 1.0855],\n",
            "        [0.7474, 1.1744, 0.8609, 1.1986, 1.1244, 0.8968, 0.8579],\n",
            "        [1.9764, 2.7033, 1.6912, 2.7372, 2.6963, 1.7541, 1.7062],\n",
            "        [3.1690, 4.0056, 2.3779, 4.0703, 4.0699, 2.4534, 2.4596],\n",
            "        [3.2670, 4.1008, 2.4288, 4.1663, 4.1631, 2.5209, 2.5247]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "35\n",
            "tensor([[2.7298, 3.5462, 2.1374, 3.6010, 3.5934, 2.1934, 2.1839],\n",
            "        [3.2726, 4.1028, 2.4372, 4.1696, 4.1684, 2.5210, 2.5270],\n",
            "        [2.8721, 3.6972, 2.2167, 3.7548, 3.7530, 2.2707, 2.2717],\n",
            "        [1.2770, 1.8519, 1.2421, 1.8781, 1.8121, 1.3051, 1.2381],\n",
            "        [1.0514, 1.5693, 1.0851, 1.5930, 1.5209, 1.1406, 1.0810]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "36\n",
            "tensor([[3.2677, 4.0995, 2.4368, 4.1634, 4.1629, 2.5215, 2.5241],\n",
            "        [2.4982, 3.2940, 2.0088, 3.3404, 3.3232, 2.0626, 2.0376],\n",
            "        [0.9645, 1.4551, 1.0263, 1.4800, 1.4062, 1.0749, 1.0177],\n",
            "        [1.1797, 1.7305, 1.1788, 1.7535, 1.6862, 1.2317, 1.1697],\n",
            "        [2.7131, 3.5327, 2.1311, 3.5835, 3.5773, 2.1721, 2.1727]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "37\n",
            "tensor([[2.7925, 3.6157, 2.1770, 3.6685, 3.6652, 2.2156, 2.2217],\n",
            "        [1.6736, 2.3390, 1.5048, 2.3640, 2.3121, 1.5709, 1.5058],\n",
            "        [1.2978, 1.8784, 1.2594, 1.9008, 1.8365, 1.3171, 1.2517],\n",
            "        [1.7460, 2.4268, 1.5510, 2.4534, 2.4049, 1.6162, 1.5544],\n",
            "        [1.6651, 2.3276, 1.4988, 2.3534, 2.3018, 1.5639, 1.5006]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "38\n",
            "tensor([[0.9165, 1.3925, 0.9906, 1.4162, 1.3424, 1.0343, 0.9832],\n",
            "        [2.8828, 3.7101, 2.2278, 3.7651, 3.7622, 2.2764, 2.2798],\n",
            "        [2.7621, 3.5820, 2.1592, 3.6319, 3.6298, 2.1992, 2.2013],\n",
            "        [1.8377, 2.5348, 1.6101, 2.5634, 2.5182, 1.6723, 1.6148],\n",
            "        [1.5745, 2.2190, 1.4420, 2.2418, 2.1891, 1.5016, 1.4391]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "39\n",
            "tensor([[2.0189, 2.7477, 1.7217, 2.7779, 2.7413, 1.7725, 1.7326],\n",
            "        [1.0692, 1.5892, 1.1016, 1.6103, 1.5406, 1.1511, 1.0927],\n",
            "        [3.1211, 3.9499, 2.3566, 4.0091, 4.0119, 2.4179, 2.4275],\n",
            "        [2.3621, 3.1403, 1.9274, 3.1795, 3.1564, 1.9734, 1.9513],\n",
            "        [2.3287, 3.1010, 1.9080, 3.1406, 3.1139, 1.9591, 1.9320]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "40\n",
            "tensor([[0.8225, 1.2720, 0.9222, 1.2932, 1.2197, 0.9561, 0.9139],\n",
            "        [3.0097, 3.8374, 2.2977, 3.8939, 3.8996, 2.3363, 2.3547],\n",
            "        [3.1589, 3.9860, 2.3781, 4.0460, 4.0539, 2.4172, 2.4439],\n",
            "        [3.1713, 3.9989, 2.3855, 4.0581, 4.0631, 2.4275, 2.4566],\n",
            "        [1.2016, 1.7573, 1.1933, 1.7791, 1.7117, 1.2482, 1.1863]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "41\n",
            "tensor([[3.0411, 3.8741, 2.3131, 3.9261, 3.9360, 2.3497, 2.3752],\n",
            "        [2.4439, 3.2358, 1.9776, 3.2741, 3.2560, 2.0183, 2.0041],\n",
            "        [1.1348, 1.6756, 1.1447, 1.6928, 1.6261, 1.1956, 1.1396],\n",
            "        [1.1803, 1.7323, 1.1774, 1.7510, 1.6844, 1.2281, 1.1707],\n",
            "        [1.6093, 2.2628, 1.4645, 2.2850, 2.2315, 1.5214, 1.4644]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "42\n",
            "tensor([[2.5901, 3.4002, 2.0609, 3.4392, 3.4286, 2.0913, 2.0967],\n",
            "        [2.1239, 2.8672, 1.7834, 2.8987, 2.8653, 1.8360, 1.8008],\n",
            "        [1.1173, 1.6545, 1.1330, 1.6710, 1.6045, 1.1786, 1.1267],\n",
            "        [0.9875, 1.4866, 1.0426, 1.5066, 1.4344, 1.0844, 1.0357],\n",
            "        [3.2778, 4.1038, 2.4381, 4.1580, 4.1593, 2.5017, 2.5291]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "43\n",
            "tensor([[1.8152, 2.5103, 1.5922, 2.5296, 2.4889, 1.6398, 1.5987],\n",
            "        [3.2815, 4.1089, 2.4389, 4.1610, 4.1650, 2.5027, 2.5315],\n",
            "        [2.3342, 3.1122, 1.9090, 3.1442, 3.1218, 1.9491, 1.9354],\n",
            "        [2.1129, 2.8562, 1.7736, 2.8838, 2.8520, 1.8234, 1.7931],\n",
            "        [1.1934, 1.7503, 1.1865, 1.7671, 1.7013, 1.2318, 1.1813]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "44\n",
            "tensor([[2.8574, 3.6840, 2.2093, 3.7295, 3.7295, 2.2329, 2.2625],\n",
            "        [0.9743, 1.4711, 1.0309, 1.4882, 1.4196, 1.0701, 1.0261],\n",
            "        [2.0073, 2.7386, 1.7139, 2.7647, 2.7312, 1.7599, 1.7283],\n",
            "        [2.2658, 3.0351, 1.8675, 3.0651, 3.0414, 1.9069, 1.8926],\n",
            "        [1.1323, 1.6710, 1.1438, 1.6889, 1.6220, 1.1903, 1.1385]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "45\n",
            "tensor([[2.7457, 3.5627, 2.1434, 3.6052, 3.6040, 2.1686, 2.1947],\n",
            "        [1.4211, 2.0314, 1.3373, 2.0485, 1.9923, 1.3875, 1.3374],\n",
            "        [2.7332, 3.5485, 2.1376, 3.5901, 3.5904, 2.1620, 2.1852],\n",
            "        [3.2275, 4.0528, 2.4096, 4.1071, 4.1224, 2.4508, 2.4911],\n",
            "        [2.6394, 3.4517, 2.0843, 3.4916, 3.4855, 2.1112, 2.1303]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "46\n",
            "tensor([[1.8150, 2.5076, 1.5902, 2.5283, 2.4890, 1.6341, 1.6018],\n",
            "        [3.1406, 3.9713, 2.3616, 4.0208, 4.0343, 2.3912, 2.4382],\n",
            "        [0.9661, 1.4588, 1.0252, 1.4765, 1.4084, 1.0629, 1.0208],\n",
            "        [0.8688, 1.3328, 0.9538, 1.3519, 1.2818, 0.9858, 0.9502],\n",
            "        [3.0109, 3.8368, 2.2907, 3.8862, 3.8966, 2.3204, 2.3589]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "47\n",
            "tensor([[2.7557, 3.5687, 2.1467, 3.6093, 3.6131, 2.1650, 2.1971],\n",
            "        [2.4922, 3.2853, 1.9981, 3.3197, 3.3116, 2.0187, 2.0342],\n",
            "        [1.3692, 1.9663, 1.3023, 1.9818, 1.9261, 1.3448, 1.3012],\n",
            "        [2.0182, 2.7448, 1.7137, 2.7682, 2.7366, 1.7514, 1.7328],\n",
            "        [1.4399, 2.0524, 1.3453, 2.0690, 2.0134, 1.3927, 1.3505]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "48\n",
            "tensor([[1.7562, 2.4334, 1.5497, 2.4524, 2.4123, 1.5937, 1.5592],\n",
            "        [2.8212, 3.6399, 2.1802, 3.6814, 3.6884, 2.1937, 2.2362],\n",
            "        [2.0027, 2.7276, 1.7042, 2.7496, 2.7203, 1.7438, 1.7210],\n",
            "        [2.5849, 3.3827, 2.0467, 3.4181, 3.4132, 2.0699, 2.0902],\n",
            "        [0.7403, 1.1640, 0.8568, 1.1835, 1.1118, 0.8809, 0.8545]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "49\n",
            "tensor([[2.9902, 3.8140, 2.2714, 3.8590, 3.8718, 2.2911, 2.3391],\n",
            "        [0.9076, 1.3800, 0.9775, 1.3973, 1.3287, 1.0096, 0.9761],\n",
            "        [3.1472, 3.9659, 2.3575, 4.0165, 4.0317, 2.3827, 2.4368],\n",
            "        [2.8515, 3.6660, 2.1935, 3.7072, 3.7145, 2.2109, 2.2526],\n",
            "        [0.9947, 1.4915, 1.0381, 1.5086, 1.4429, 1.0745, 1.0385]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "50\n",
            "tensor([[1.5464, 2.1795, 1.4092, 2.1949, 2.1459, 1.4548, 1.4173],\n",
            "        [1.5184, 2.1471, 1.3906, 2.1606, 2.1130, 1.4351, 1.4000],\n",
            "        [2.3986, 3.1786, 1.9333, 3.2079, 3.1941, 1.9552, 1.9727],\n",
            "        [1.6219, 2.2727, 1.4605, 2.2900, 2.2445, 1.5037, 1.4712],\n",
            "        [0.8208, 1.2670, 0.9111, 1.2851, 1.2144, 0.9397, 0.9122]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "51\n",
            "tensor([[3.1313, 3.9478, 2.3392, 4.0014, 4.0155, 2.3660, 2.4275],\n",
            "        [1.1512, 1.6905, 1.1454, 1.7058, 1.6434, 1.1878, 1.1487],\n",
            "        [2.8975, 3.7127, 2.2114, 3.7551, 3.7632, 2.2280, 2.2800],\n",
            "        [1.7568, 2.4302, 1.5405, 2.4497, 2.4084, 1.5895, 1.5591],\n",
            "        [3.2458, 4.0615, 2.4015, 4.1167, 4.1317, 2.4330, 2.4979]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "52\n",
            "tensor([[1.5477, 2.1785, 1.4067, 2.1952, 2.1468, 1.4540, 1.4194],\n",
            "        [2.8647, 3.6803, 2.1895, 3.7248, 3.7347, 2.2024, 2.2597],\n",
            "        [2.3220, 3.0885, 1.8803, 3.1174, 3.1017, 1.9072, 1.9229],\n",
            "        [1.4727, 2.0871, 1.3507, 2.1023, 2.0513, 1.4108, 1.3695],\n",
            "        [1.5838, 2.2239, 1.4298, 2.2418, 2.1950, 1.4785, 1.4446]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "53\n",
            "tensor([[2.4599, 3.2396, 1.9574, 3.2744, 3.2656, 1.9872, 2.0081],\n",
            "        [1.1449, 1.6806, 1.1383, 1.6971, 1.6354, 1.1823, 1.1450],\n",
            "        [2.4395, 3.2158, 1.9447, 3.2492, 3.2371, 1.9700, 1.9951],\n",
            "        [2.9248, 3.7409, 2.2176, 3.7859, 3.7998, 2.2315, 2.2962],\n",
            "        [2.7729, 3.5797, 2.1352, 3.6234, 3.6274, 2.1564, 2.2048]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "54\n",
            "tensor([[3.2562, 4.0691, 2.3940, 4.1251, 4.1416, 2.4367, 2.5034],\n",
            "        [1.7757, 2.4542, 1.5489, 2.4748, 2.4360, 1.5913, 1.5712],\n",
            "        [0.8617, 1.3173, 0.9357, 1.3378, 1.2681, 0.9707, 0.9430],\n",
            "        [1.0110, 1.5100, 1.0405, 1.5275, 1.4613, 1.0838, 1.0502],\n",
            "        [2.9024, 3.7217, 2.2042, 3.7680, 3.7818, 2.2152, 2.2827]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "55\n",
            "tensor([[3.2948, 4.1040, 2.4118, 4.1619, 4.1726, 2.4664, 2.5306],\n",
            "        [3.2925, 4.1008, 2.4119, 4.1600, 4.1734, 2.4626, 2.5287],\n",
            "        [2.4156, 3.1863, 1.9253, 3.2224, 3.2098, 1.9576, 1.9803],\n",
            "        [1.4460, 2.0536, 1.3372, 2.0731, 2.0216, 1.3859, 1.3517],\n",
            "        [3.2938, 4.1047, 2.4128, 4.1642, 4.1791, 2.4635, 2.5290]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "56\n",
            "tensor([[1.9881, 2.6998, 1.6734, 2.7295, 2.6974, 1.7211, 1.7113],\n",
            "        [3.2682, 4.0796, 2.3997, 4.1406, 4.1553, 2.4496, 2.5134],\n",
            "        [1.5798, 2.2160, 1.4201, 2.2371, 2.1897, 1.4716, 1.4421],\n",
            "        [3.2597, 4.0709, 2.3936, 4.1324, 4.1479, 2.4414, 2.5067],\n",
            "        [2.3968, 3.1667, 1.9158, 3.2033, 3.1913, 1.9493, 1.9679]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "57\n",
            "tensor([[3.2418, 4.0531, 2.3829, 4.1156, 4.1328, 2.4370, 2.4968],\n",
            "        [3.0104, 3.8221, 2.2582, 3.8804, 3.8940, 2.2906, 2.3515],\n",
            "        [0.7761, 1.2068, 0.8727, 1.2266, 1.1574, 0.9000, 0.8784],\n",
            "        [0.7747, 1.2022, 0.8702, 1.2230, 1.1532, 0.8986, 0.8763],\n",
            "        [1.4885, 2.1073, 1.3628, 2.1275, 2.0780, 1.4136, 1.3810]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "58\n",
            "tensor([[1.7671, 2.4426, 1.5376, 2.4681, 2.4292, 1.5931, 1.5678],\n",
            "        [2.8408, 3.6535, 2.1665, 3.7040, 3.7146, 2.1923, 2.2475],\n",
            "        [2.0810, 2.8100, 1.7292, 2.8393, 2.8172, 1.7735, 1.7688],\n",
            "        [3.2913, 4.1013, 2.4089, 4.1627, 4.1793, 2.4668, 2.5289],\n",
            "        [2.9280, 3.7434, 2.2134, 3.7970, 3.8103, 2.2458, 2.3013]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "59\n",
            "tensor([[0.8701, 1.3287, 0.9407, 1.3485, 1.2815, 0.9794, 0.9485],\n",
            "        [1.0657, 1.5792, 1.0807, 1.6002, 1.5358, 1.1287, 1.0895],\n",
            "        [3.2272, 4.0395, 2.3748, 4.1036, 4.1212, 2.4273, 2.4866],\n",
            "        [1.9011, 2.6017, 1.6204, 2.6298, 2.5966, 1.6784, 1.6553],\n",
            "        [1.8733, 2.5698, 1.6041, 2.5961, 2.5641, 1.6580, 1.6365]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "60\n",
            "tensor([[3.1645, 3.9795, 2.3438, 4.0412, 4.0622, 2.3924, 2.4463],\n",
            "        [0.7788, 1.2124, 0.8726, 1.2330, 1.1646, 0.9079, 0.8821],\n",
            "        [2.5427, 3.3343, 1.9999, 3.3780, 3.3747, 2.0480, 2.0638],\n",
            "        [2.7555, 3.5666, 2.1213, 3.6144, 3.6219, 2.1564, 2.1943],\n",
            "        [3.3056, 4.1187, 2.4177, 4.1790, 4.1920, 2.4972, 2.5424]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "61\n",
            "tensor([[2.7109, 3.5178, 2.0971, 3.5665, 3.5697, 2.1449, 2.1693],\n",
            "        [2.5620, 3.3581, 2.0169, 3.4007, 3.3989, 2.0559, 2.0734],\n",
            "        [1.3464, 1.9358, 1.2723, 1.9579, 1.9039, 1.3341, 1.2867],\n",
            "        [1.5561, 2.1912, 1.4080, 2.2143, 2.1680, 1.4723, 1.4280],\n",
            "        [1.2371, 1.7970, 1.1988, 1.8189, 1.7615, 1.2558, 1.2094]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "62\n",
            "tensor([[3.3004, 4.1189, 2.4216, 4.1822, 4.1979, 2.4961, 2.5360],\n",
            "        [0.8753, 1.3371, 0.9447, 1.3585, 1.2921, 0.9889, 0.9530],\n",
            "        [2.2424, 3.0025, 1.8326, 3.0402, 3.0231, 1.8835, 1.8748],\n",
            "        [1.5861, 2.2304, 1.4282, 2.2523, 2.2094, 1.4877, 1.4457],\n",
            "        [2.7514, 3.5596, 2.1223, 3.6105, 3.6166, 2.1719, 2.1918]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "63\n",
            "tensor([[3.2327, 4.0542, 2.3881, 4.1171, 4.1370, 2.4553, 2.4909],\n",
            "        [2.5736, 3.3700, 2.0214, 3.4136, 3.4141, 2.0607, 2.0798],\n",
            "        [0.8658, 1.3270, 0.9422, 1.3482, 1.2821, 0.9810, 0.9453],\n",
            "        [2.8682, 3.6885, 2.1883, 3.7397, 3.7540, 2.2241, 2.2624],\n",
            "        [0.9696, 1.4590, 1.0140, 1.4791, 1.4159, 1.0586, 1.0196]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "64\n",
            "tensor([[3.1363, 3.9609, 2.3364, 4.0219, 4.0436, 2.3877, 2.4290],\n",
            "        [2.5366, 3.3334, 2.0018, 3.3734, 3.3735, 2.0447, 2.0571],\n",
            "        [2.0339, 2.7620, 1.7079, 2.7911, 2.7694, 1.7628, 1.7372],\n",
            "        [0.8821, 1.3471, 0.9527, 1.3691, 1.3022, 0.9957, 0.9573],\n",
            "        [3.2649, 4.0885, 2.4054, 4.1483, 4.1687, 2.4715, 2.5097]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "65\n",
            "tensor([[2.7145, 3.5290, 2.1042, 3.5740, 3.5805, 2.1463, 2.1687],\n",
            "        [2.2156, 2.9725, 1.8157, 3.0060, 2.9899, 1.8709, 1.8555],\n",
            "        [1.3879, 1.9907, 1.3020, 2.0084, 1.9585, 1.3567, 1.3118],\n",
            "        [2.7665, 3.5831, 2.1331, 3.6297, 3.6418, 2.1705, 2.1970],\n",
            "        [1.0545, 1.5711, 1.0766, 1.5909, 1.5289, 1.1260, 1.0809]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "66\n",
            "tensor([[1.4012, 2.0088, 1.3102, 2.0269, 1.9778, 1.3682, 1.3216],\n",
            "        [1.8370, 2.5335, 1.5862, 2.5572, 2.5248, 1.6427, 1.6099],\n",
            "        [2.2086, 2.9645, 1.8089, 2.9957, 2.9781, 1.8628, 1.8497],\n",
            "        [2.8593, 3.6818, 2.1824, 3.7311, 3.7456, 2.2207, 2.2553],\n",
            "        [0.7365, 1.1591, 0.8454, 1.1794, 1.1124, 0.8762, 0.8492]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "67\n",
            "tensor([[3.0078, 3.8348, 2.2632, 3.8856, 3.9075, 2.3043, 2.3432],\n",
            "        [2.9202, 3.7486, 2.2131, 3.7970, 3.8134, 2.2545, 2.2933],\n",
            "        [0.8356, 1.2895, 0.9193, 1.3091, 1.2423, 0.9564, 0.9220],\n",
            "        [1.0611, 1.5793, 1.0787, 1.5975, 1.5356, 1.1294, 1.0837],\n",
            "        [1.2427, 1.8116, 1.2028, 1.8282, 1.7747, 1.2566, 1.2104]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "68\n",
            "tensor([[1.5662, 2.2124, 1.4130, 2.2272, 2.1852, 1.4736, 1.4301],\n",
            "        [3.2537, 4.0837, 2.3946, 4.1341, 4.1531, 2.4542, 2.5000],\n",
            "        [3.0541, 3.8844, 2.2875, 3.9323, 3.9572, 2.3321, 2.3700],\n",
            "        [2.9053, 3.7349, 2.2057, 3.7780, 3.7984, 2.2406, 2.2781],\n",
            "        [2.7277, 3.5477, 2.1074, 3.5859, 3.5991, 2.1370, 2.1689]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "69\n",
            "tensor([[2.9931, 3.8275, 2.2516, 3.8697, 3.8903, 2.2951, 2.3340],\n",
            "        [3.2554, 4.0858, 2.3948, 4.1339, 4.1589, 2.4491, 2.4956],\n",
            "        [2.5003, 3.3010, 1.9749, 3.3305, 3.3307, 2.0102, 2.0281],\n",
            "        [1.2824, 1.8643, 1.2300, 1.8779, 1.8253, 1.2835, 1.2379],\n",
            "        [0.8810, 1.3496, 0.9497, 1.3666, 1.3012, 0.9902, 0.9537]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "70\n",
            "tensor([[1.3727, 1.9798, 1.2892, 1.9904, 1.9427, 1.3424, 1.2979],\n",
            "        [1.9224, 2.6417, 1.6335, 2.6559, 2.6316, 1.6867, 1.6588],\n",
            "        [2.1125, 2.8643, 1.7485, 2.8845, 2.8665, 1.8011, 1.7838],\n",
            "        [2.2502, 3.0233, 1.8309, 3.0450, 3.0365, 1.8796, 1.8701],\n",
            "        [1.3100, 1.9009, 1.2462, 1.9125, 1.8612, 1.3012, 1.2559]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "71\n",
            "tensor([[2.9697, 3.8098, 2.2359, 3.8416, 3.8688, 2.2699, 2.3109],\n",
            "        [1.3070, 1.8988, 1.2456, 1.9087, 1.8591, 1.2978, 1.2517],\n",
            "        [2.8318, 3.6692, 2.1620, 3.6999, 3.7188, 2.1991, 2.2287],\n",
            "        [1.3040, 1.8960, 1.2432, 1.9055, 1.8559, 1.2968, 1.2507],\n",
            "        [2.4986, 3.3095, 1.9740, 3.3318, 3.3358, 2.0119, 2.0240]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "72\n",
            "tensor([[0.8992, 1.3820, 0.9633, 1.3925, 1.3310, 1.0021, 0.9655],\n",
            "        [2.3594, 3.1536, 1.8921, 3.1701, 3.1695, 1.9355, 1.9334],\n",
            "        [3.2205, 4.0643, 2.3690, 4.1004, 4.1221, 2.4402, 2.4706],\n",
            "        [3.1448, 3.9892, 2.3289, 4.0226, 4.0455, 2.3843, 2.4230],\n",
            "        [3.2316, 4.0756, 2.3780, 4.1132, 4.1437, 2.4327, 2.4732]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "73\n",
            "tensor([[0.7143, 1.1409, 0.8256, 1.1509, 1.0871, 0.8527, 0.8291],\n",
            "        [0.8504, 1.3197, 0.9265, 1.3282, 1.2680, 0.9612, 0.9281],\n",
            "        [1.1462, 1.7009, 1.1334, 1.7089, 1.6558, 1.1819, 1.1396],\n",
            "        [1.7977, 2.5054, 1.5494, 2.5080, 2.4789, 1.6101, 1.5736],\n",
            "        [1.8174, 2.5286, 1.5658, 2.5348, 2.5070, 1.6212, 1.5899]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "74\n",
            "tensor([[3.2651, 4.1123, 2.3856, 4.1426, 4.1634, 2.4486, 2.4951],\n",
            "        [0.8797, 1.3598, 0.9480, 1.3680, 1.3064, 0.9845, 0.9513],\n",
            "        [2.9948, 3.8464, 2.2409, 3.8720, 3.8988, 2.2716, 2.3229],\n",
            "        [2.3587, 3.1620, 1.8882, 3.1742, 3.1735, 1.9311, 1.9323],\n",
            "        [2.4294, 3.2429, 1.9267, 3.2547, 3.2575, 1.9611, 1.9759]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "75\n",
            "tensor([[2.2609, 3.0507, 1.8264, 3.0562, 3.0515, 1.8663, 1.8652],\n",
            "        [1.9007, 2.6312, 1.6140, 2.6345, 2.6122, 1.6641, 1.6397],\n",
            "        [1.1466, 1.7062, 1.1367, 1.7110, 1.6564, 1.1839, 1.1390],\n",
            "        [1.7248, 2.4211, 1.5062, 2.4226, 2.3940, 1.5581, 1.5247],\n",
            "        [1.2462, 1.8293, 1.2003, 1.8343, 1.7836, 1.2498, 1.2069]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "76\n",
            "tensor([[0.8137, 1.2730, 0.8983, 1.2802, 1.2172, 0.9265, 0.9006],\n",
            "        [1.5545, 2.2161, 1.3976, 2.2158, 2.1807, 1.4494, 1.4129],\n",
            "        [1.7945, 2.5082, 1.5484, 2.5073, 2.4831, 1.5934, 1.5683],\n",
            "        [2.1532, 2.9294, 1.7654, 2.9334, 2.9262, 1.8030, 1.7980],\n",
            "        [3.1140, 3.9726, 2.3031, 3.9960, 4.0266, 2.3333, 2.3952]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "77\n",
            "tensor([[2.4449, 3.2634, 1.9340, 3.2705, 3.2780, 1.9546, 1.9794],\n",
            "        [2.9057, 3.7639, 2.1889, 3.7809, 3.8084, 2.2094, 2.2657],\n",
            "        [3.1109, 3.9657, 2.2974, 3.9854, 4.0186, 2.3214, 2.3872],\n",
            "        [0.7457, 1.1845, 0.8481, 1.1918, 1.1297, 0.8693, 0.8497],\n",
            "        [1.0831, 1.6225, 1.0876, 1.6258, 1.5709, 1.1277, 1.0920]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "78\n",
            "tensor([[1.3453, 1.9595, 1.2651, 1.9586, 1.9141, 1.3042, 1.2726],\n",
            "        [1.0447, 1.5750, 1.0613, 1.5797, 1.5231, 1.1001, 1.0667],\n",
            "        [0.8262, 1.2900, 0.9093, 1.2982, 1.2356, 0.9345, 0.9104],\n",
            "        [2.7018, 3.5458, 2.0758, 3.5583, 3.5784, 2.0937, 2.1360],\n",
            "        [2.4889, 3.3136, 1.9589, 3.3212, 3.3320, 1.9788, 2.0052]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "79\n",
            "tensor([[1.9525, 2.7032, 1.6459, 2.7020, 2.6861, 1.6805, 1.6712],\n",
            "        [3.1187, 3.9806, 2.3031, 4.0019, 4.0297, 2.3386, 2.3954],\n",
            "        [1.0328, 1.5608, 1.0547, 1.5656, 1.5092, 1.0901, 1.0570],\n",
            "        [3.1432, 4.0049, 2.3168, 4.0280, 4.0615, 2.3377, 2.4087],\n",
            "        [3.1641, 4.0240, 2.3275, 4.0472, 4.0812, 2.3535, 2.4210]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "80\n",
            "tensor([[0.7918, 1.2476, 0.8812, 1.2545, 1.1932, 0.9035, 0.8830],\n",
            "        [1.5852, 2.2559, 1.4135, 2.2550, 2.2195, 1.4602, 1.4310],\n",
            "        [2.6742, 3.5227, 2.0579, 3.5317, 3.5509, 2.0694, 2.1196],\n",
            "        [3.2262, 4.0885, 2.3583, 4.1119, 4.1442, 2.3925, 2.4590],\n",
            "        [2.1236, 2.9042, 1.7435, 2.9046, 2.8955, 1.7728, 1.7788]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "81\n",
            "tensor([[1.5001, 2.1553, 1.3603, 2.1543, 2.1136, 1.4039, 1.3753],\n",
            "        [1.4697, 2.1166, 1.3424, 2.1157, 2.0748, 1.3846, 1.3530],\n",
            "        [2.4467, 3.2700, 1.9266, 3.2756, 3.2813, 1.9570, 1.9784],\n",
            "        [2.5668, 3.4057, 1.9953, 3.4143, 3.4273, 2.0090, 2.0513],\n",
            "        [0.9302, 1.4296, 0.9803, 1.4349, 1.3759, 1.0119, 0.9843]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "82\n",
            "tensor([[1.9397, 2.6882, 1.6275, 2.6859, 2.6683, 1.6638, 1.6577],\n",
            "        [1.9794, 2.7372, 1.6509, 2.7368, 2.7184, 1.6898, 1.6867],\n",
            "        [2.9928, 3.8586, 2.2256, 3.8762, 3.9031, 2.2557, 2.3128],\n",
            "        [2.3089, 3.1192, 1.8457, 3.1237, 3.1198, 1.8751, 1.8944],\n",
            "        [0.9216, 1.4187, 0.9754, 1.4258, 1.3639, 1.0099, 0.9783]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "83\n",
            "tensor([[3.2663, 4.1317, 2.3655, 4.1526, 4.1791, 2.4105, 2.4819],\n",
            "        [1.3650, 1.9904, 1.2701, 1.9879, 1.9432, 1.3124, 1.2845],\n",
            "        [2.2764, 3.0816, 1.8211, 3.0833, 3.0795, 1.8508, 1.8717],\n",
            "        [1.9435, 2.6938, 1.6278, 2.6942, 2.6733, 1.6681, 1.6627],\n",
            "        [2.8450, 3.7074, 2.1400, 3.7230, 3.7436, 2.1635, 2.2222]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "84\n",
            "tensor([[2.3185, 3.1332, 1.8436, 3.1381, 3.1336, 1.8737, 1.9007],\n",
            "        [1.1655, 1.7373, 1.1359, 1.7389, 1.6859, 1.1847, 1.1500],\n",
            "        [2.6280, 3.4818, 2.0178, 3.4901, 3.5016, 2.0377, 2.0915],\n",
            "        [2.1076, 2.8848, 1.7194, 2.8851, 2.8707, 1.7605, 1.7647],\n",
            "        [1.9870, 2.7485, 1.6511, 2.7491, 2.7297, 1.6917, 1.6908]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "85\n",
            "tensor([[1.4540, 2.1066, 1.3258, 2.1059, 2.0598, 1.3727, 1.3478],\n",
            "        [1.4720, 2.1279, 1.3344, 2.1263, 2.0842, 1.3783, 1.3579],\n",
            "        [3.1040, 3.9791, 2.2723, 3.9998, 4.0281, 2.3067, 2.3846],\n",
            "        [0.8541, 1.3332, 0.9205, 1.3411, 1.2759, 0.9515, 0.9315],\n",
            "        [3.1335, 4.0051, 2.2887, 4.0253, 4.0433, 2.3400, 2.4048]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "86\n",
            "tensor([[1.5110, 2.1777, 1.3569, 2.1756, 2.1315, 1.4053, 1.3843],\n",
            "        [3.2819, 4.1585, 2.3670, 4.1789, 4.1980, 2.4271, 2.5005],\n",
            "        [1.0348, 1.5717, 1.0465, 1.5763, 1.5131, 1.0875, 1.0602],\n",
            "        [2.4642, 3.3054, 1.9210, 3.3110, 3.3099, 1.9531, 1.9953],\n",
            "        [0.9812, 1.5037, 1.0104, 1.5082, 1.4445, 1.0493, 1.0241]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "87\n",
            "tensor([[0.9375, 1.4483, 0.9788, 1.4541, 1.3898, 1.0183, 0.9936],\n",
            "        [2.9543, 3.8360, 2.1902, 3.8546, 3.8731, 2.2229, 2.2985],\n",
            "        [3.0103, 3.8911, 2.2190, 3.9098, 3.9273, 2.2611, 2.3362],\n",
            "        [3.0694, 3.9533, 2.2535, 3.9740, 3.9932, 2.2871, 2.3699],\n",
            "        [2.1950, 2.9999, 1.7670, 3.0024, 2.9875, 1.8062, 1.8277]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "88\n",
            "tensor([[3.2082, 4.0904, 2.3250, 4.1157, 4.1347, 2.3753, 2.4599],\n",
            "        [1.0920, 1.6509, 1.0865, 1.6573, 1.5952, 1.1324, 1.1060],\n",
            "        [2.8313, 3.7105, 2.1220, 3.7274, 3.7412, 2.1534, 2.2270],\n",
            "        [2.6491, 3.5165, 2.0239, 3.5292, 3.5335, 2.0542, 2.1168],\n",
            "        [2.8048, 3.6858, 2.1091, 3.6999, 3.7122, 2.1370, 2.2116]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "89\n",
            "tensor([[2.8596, 3.7420, 2.1365, 3.7591, 3.7746, 2.1665, 2.2455],\n",
            "        [2.3915, 3.2344, 1.8772, 3.2416, 3.2338, 1.9096, 1.9585],\n",
            "        [1.5372, 2.2151, 1.3752, 2.2185, 2.1733, 1.4270, 1.4111],\n",
            "        [1.5135, 2.1872, 1.3602, 2.1886, 2.1440, 1.4112, 1.3920],\n",
            "        [0.9484, 1.4640, 0.9869, 1.4715, 1.4057, 1.0262, 1.0041]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "90\n",
            "tensor([[2.8590, 3.7514, 2.1391, 3.7685, 3.7853, 2.1550, 2.2475],\n",
            "        [2.1096, 2.9041, 1.7177, 2.9102, 2.8886, 1.7643, 1.7812],\n",
            "        [1.2413, 1.8438, 1.1843, 1.8488, 1.7912, 1.2336, 1.2108],\n",
            "        [2.8401, 3.7231, 2.1273, 3.7424, 3.7536, 2.1540, 2.2360],\n",
            "        [3.0742, 3.9626, 2.2515, 3.9872, 4.0072, 2.2874, 2.3799]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "91\n",
            "tensor([[2.6317, 3.5014, 2.0121, 3.5164, 3.5180, 2.0386, 2.1079],\n",
            "        [2.9620, 3.8476, 2.1910, 3.8701, 3.8869, 2.2163, 2.3090],\n",
            "        [1.4625, 2.1229, 1.3254, 2.1249, 2.0771, 1.3757, 1.3587],\n",
            "        [3.2475, 4.1294, 2.3438, 4.1590, 4.1747, 2.3969, 2.4878],\n",
            "        [3.2665, 4.1496, 2.3537, 4.1771, 4.1917, 2.4167, 2.5015]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "92\n",
            "tensor([[3.2518, 4.1331, 2.3437, 4.1614, 4.1751, 2.3957, 2.4908],\n",
            "        [1.0307, 1.5702, 1.0425, 1.5792, 1.5138, 1.0855, 1.0631],\n",
            "        [3.1514, 4.0338, 2.2900, 4.0664, 4.0838, 2.3232, 2.4255],\n",
            "        [3.2764, 4.1583, 2.3559, 4.1877, 4.2007, 2.4211, 2.5070],\n",
            "        [0.9848, 1.5096, 1.0076, 1.5178, 1.4532, 1.0486, 1.0282]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "93\n",
            "tensor([[1.4958, 2.1571, 1.3394, 2.1618, 2.1122, 1.3907, 1.3798],\n",
            "        [2.9763, 3.8590, 2.1972, 3.8855, 3.9001, 2.2256, 2.3173],\n",
            "        [2.1193, 2.9123, 1.7206, 2.9212, 2.9000, 1.7568, 1.7852],\n",
            "        [3.1251, 4.0027, 2.2751, 4.0346, 4.0513, 2.3120, 2.4091],\n",
            "        [1.5913, 2.2776, 1.4036, 2.2826, 2.2371, 1.4584, 1.4450]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "94\n",
            "tensor([[2.4967, 3.3445, 1.9333, 3.3596, 3.3557, 1.9553, 2.0218],\n",
            "        [2.9668, 3.8466, 2.1908, 3.8742, 3.8883, 2.2199, 2.3112],\n",
            "        [1.7819, 2.5091, 1.5206, 2.5163, 2.4781, 1.5727, 1.5688],\n",
            "        [2.6983, 3.5617, 2.0436, 3.5820, 3.5845, 2.0771, 2.1463],\n",
            "        [3.0383, 3.9186, 2.2287, 3.9461, 3.9623, 2.2627, 2.3541]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "95\n",
            "tensor([[2.7552, 3.6256, 2.0733, 3.6483, 3.6524, 2.0977, 2.1808],\n",
            "        [1.2291, 1.8258, 1.1740, 1.8327, 1.7724, 1.2247, 1.2004],\n",
            "        [3.1164, 3.9898, 2.2649, 4.0202, 4.0309, 2.3140, 2.4002],\n",
            "        [1.9946, 2.7624, 1.6454, 2.7704, 2.7421, 1.6858, 1.7038],\n",
            "        [0.9726, 1.4910, 0.9996, 1.5021, 1.4334, 1.0398, 1.0202]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "96\n",
            "tensor([[2.7080, 3.5710, 2.0445, 3.5932, 3.5942, 2.0791, 2.1495],\n",
            "        [1.6672, 2.3703, 1.4485, 2.3775, 2.3325, 1.5002, 1.4923],\n",
            "        [2.5501, 3.4002, 1.9599, 3.4169, 3.4149, 1.9871, 2.0497],\n",
            "        [1.7810, 2.5089, 1.5154, 2.5156, 2.4763, 1.5619, 1.5658],\n",
            "        [3.1025, 3.9804, 2.2563, 4.0135, 4.0259, 2.2947, 2.3924]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "97\n",
            "tensor([[1.3260, 1.9457, 1.2320, 1.9512, 1.8936, 1.2837, 1.2632],\n",
            "        [0.9254, 1.4298, 0.9654, 1.4404, 1.3704, 1.0011, 0.9852],\n",
            "        [2.4125, 3.2462, 1.8794, 3.2604, 3.2493, 1.9168, 1.9664],\n",
            "        [3.2620, 4.1353, 2.3357, 4.1687, 4.1804, 2.3860, 2.4878],\n",
            "        [0.9193, 1.4225, 0.9605, 1.4340, 1.3645, 0.9978, 0.9812]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "98\n",
            "tensor([[2.6137, 3.4704, 1.9879, 3.4888, 3.4862, 2.0173, 2.0892],\n",
            "        [2.3660, 3.1912, 1.8506, 3.2081, 3.1915, 1.8903, 1.9371],\n",
            "        [2.7046, 3.5670, 2.0341, 3.5887, 3.5896, 2.0685, 2.1448],\n",
            "        [1.3743, 2.0064, 1.2603, 2.0118, 1.9570, 1.3093, 1.2942],\n",
            "        [2.7389, 3.6048, 2.0551, 3.6267, 3.6282, 2.0864, 2.1644]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "99\n",
            "tensor([[3.2266, 4.1010, 2.3093, 4.1351, 4.1460, 2.3645, 2.4651],\n",
            "        [3.2589, 4.1317, 2.3272, 4.1675, 4.1783, 2.3884, 2.4882],\n",
            "        [3.1397, 4.0165, 2.2633, 4.0506, 4.0636, 2.3140, 2.4112],\n",
            "        [1.2797, 1.8875, 1.1968, 1.8941, 1.8338, 1.2520, 1.2325],\n",
            "        [2.3695, 3.1949, 1.8465, 3.2114, 3.1945, 1.8964, 1.9403]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "100\n",
            "tensor([[1.5357, 2.2076, 1.3583, 2.2188, 2.1637, 1.4199, 1.4070],\n",
            "        [3.2632, 4.1379, 2.3241, 4.1744, 4.1765, 2.3997, 2.4955],\n",
            "        [2.8048, 3.6817, 2.0819, 3.7065, 3.7101, 2.1136, 2.2090],\n",
            "        [2.8061, 3.6814, 2.0833, 3.7067, 3.7091, 2.1193, 2.2107],\n",
            "        [3.1890, 4.0633, 2.2844, 4.1002, 4.1122, 2.3398, 2.4452]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "101\n",
            "tensor([[2.7935, 3.6734, 2.0721, 3.6996, 3.7015, 2.1103, 2.2064],\n",
            "        [2.8220, 3.6994, 2.0875, 3.7257, 3.7281, 2.1277, 2.2217],\n",
            "        [3.2806, 4.1527, 2.3268, 4.1881, 4.1888, 2.4153, 2.5112],\n",
            "        [2.1149, 2.9020, 1.6953, 2.9162, 2.8857, 1.7550, 1.7818],\n",
            "        [1.4331, 2.0814, 1.2922, 2.0916, 2.0333, 1.3539, 1.3390]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "102\n",
            "tensor([[1.6235, 2.3215, 1.4064, 2.3296, 2.2781, 1.4726, 1.4686],\n",
            "        [0.7059, 1.1403, 0.8010, 1.1552, 1.0811, 0.8319, 0.8260],\n",
            "        [2.9871, 3.8693, 2.1691, 3.9020, 3.9065, 2.2208, 2.3261],\n",
            "        [3.1836, 4.0594, 2.2728, 4.0992, 4.1059, 2.3455, 2.4480],\n",
            "        [1.1203, 1.6845, 1.0895, 1.6951, 1.6265, 1.1457, 1.1257]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "103\n",
            "tensor([[0.7708, 1.2278, 0.8472, 1.2433, 1.1683, 0.8860, 0.8763],\n",
            "        [2.4880, 3.3326, 1.8991, 3.3533, 3.3372, 1.9565, 2.0186],\n",
            "        [2.2090, 3.0173, 1.7439, 3.0313, 3.0025, 1.8033, 1.8446],\n",
            "        [2.6423, 3.5058, 1.9835, 3.5294, 3.5190, 2.0369, 2.1149],\n",
            "        [2.7333, 3.6045, 2.0311, 3.6301, 3.6285, 2.0749, 2.1677]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "104\n",
            "tensor([[2.6319, 3.4948, 1.9743, 3.5172, 3.5119, 2.0242, 2.1061],\n",
            "        [0.8125, 1.2815, 0.8766, 1.2966, 1.2212, 0.9165, 0.9062],\n",
            "        [0.8614, 1.3491, 0.9116, 1.3634, 1.2886, 0.9535, 0.9418],\n",
            "        [3.2468, 4.1226, 2.2992, 4.1590, 4.1612, 2.3961, 2.4891],\n",
            "        [3.2505, 4.1263, 2.3019, 4.1641, 4.1680, 2.3846, 2.4901]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "105\n",
            "tensor([[2.7899, 3.6603, 2.0548, 3.6859, 3.6841, 2.1078, 2.2002],\n",
            "        [1.0601, 1.6072, 1.0434, 1.6191, 1.5496, 1.1021, 1.0832],\n",
            "        [1.7214, 2.4375, 1.4584, 2.4476, 2.3987, 1.5316, 1.5306],\n",
            "        [1.8342, 2.5740, 1.5237, 2.5837, 2.5413, 1.5935, 1.6030],\n",
            "        [1.0309, 1.5685, 1.0228, 1.5779, 1.5083, 1.0736, 1.0594]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "106\n",
            "tensor([[1.7862, 2.5164, 1.4930, 2.5242, 2.4799, 1.5642, 1.5699],\n",
            "        [0.9087, 1.4102, 0.9424, 1.4234, 1.3508, 0.9892, 0.9744],\n",
            "        [1.3932, 2.0313, 1.2549, 2.0392, 1.9799, 1.3215, 1.3102],\n",
            "        [2.1680, 2.9676, 1.7136, 2.9812, 2.9506, 1.7847, 1.8164],\n",
            "        [3.1955, 4.0707, 2.2698, 4.1113, 4.1169, 2.3469, 2.4513]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "107\n",
            "tensor([[0.8945, 1.3906, 0.9323, 1.4034, 1.3313, 0.9763, 0.9637],\n",
            "        [2.3375, 3.1618, 1.8103, 3.1793, 3.1577, 1.8745, 1.9209],\n",
            "        [2.3502, 3.1754, 1.8169, 3.1932, 3.1730, 1.8724, 1.9280],\n",
            "        [0.7449, 1.1909, 0.8251, 1.2056, 1.1318, 0.8584, 0.8531],\n",
            "        [1.2520, 1.8533, 1.1683, 1.8635, 1.7981, 1.2294, 1.2158]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "108\n",
            "tensor([[3.1895, 4.0645, 2.2658, 4.1020, 4.1087, 2.3445, 2.4440],\n",
            "        [1.4682, 2.1285, 1.3053, 2.1357, 2.0782, 1.3686, 1.3603],\n",
            "        [1.4373, 2.0907, 1.2857, 2.1001, 2.0423, 1.3513, 1.3421],\n",
            "        [1.7375, 2.4580, 1.4673, 2.4652, 2.4192, 1.5305, 1.5368],\n",
            "        [2.8116, 3.6862, 2.0669, 3.7111, 3.7146, 2.1114, 2.2094]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "109\n",
            "tensor([[1.6345, 2.3320, 1.4047, 2.3412, 2.2903, 1.4704, 1.4708],\n",
            "        [1.0584, 1.6048, 1.0425, 1.6167, 1.5456, 1.0958, 1.0792],\n",
            "        [1.3216, 1.9428, 1.2126, 1.9517, 1.8891, 1.2741, 1.2622],\n",
            "        [2.4995, 3.3428, 1.8955, 3.3629, 3.3481, 1.9499, 2.0199],\n",
            "        [3.1196, 3.9930, 2.2288, 4.0292, 4.0315, 2.3068, 2.4031]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "110\n",
            "tensor([[2.9568, 3.8345, 2.1418, 3.8661, 3.8694, 2.1915, 2.2985],\n",
            "        [3.1284, 4.0005, 2.2334, 4.0392, 4.0442, 2.3035, 2.4052],\n",
            "        [2.8513, 3.7230, 2.0870, 3.7526, 3.7540, 2.1372, 2.2335],\n",
            "        [2.3185, 3.1371, 1.7980, 3.1552, 3.1308, 1.8547, 1.9060],\n",
            "        [2.7132, 3.5759, 2.0139, 3.6032, 3.5975, 2.0620, 2.1502]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "111\n",
            "tensor([[2.4266, 3.2541, 1.8568, 3.2770, 3.2596, 1.9154, 1.9725],\n",
            "        [0.9894, 1.5133, 0.9951, 1.5282, 1.4562, 1.0451, 1.0319],\n",
            "        [1.4295, 2.0731, 1.2780, 2.0860, 2.0264, 1.3427, 1.3342],\n",
            "        [3.1716, 4.0428, 2.2540, 4.0838, 4.0941, 2.3188, 2.4301],\n",
            "        [3.1934, 4.0654, 2.2632, 4.1051, 4.1112, 2.3338, 2.4451]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "112\n",
            "tensor([[2.5631, 3.4069, 1.9321, 3.4345, 3.4242, 1.9813, 2.0577],\n",
            "        [3.2513, 4.1177, 2.2952, 4.1615, 4.1678, 2.3722, 2.4829],\n",
            "        [3.2385, 4.1078, 2.2891, 4.1534, 4.1595, 2.3659, 2.4756],\n",
            "        [2.7862, 3.6537, 2.0513, 3.6847, 3.6838, 2.0955, 2.1957],\n",
            "        [0.7333, 1.1744, 0.8169, 1.1926, 1.1166, 0.8513, 0.8465]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "113\n",
            "tensor([[2.9591, 3.8257, 2.1412, 3.8656, 3.8690, 2.1975, 2.3011],\n",
            "        [0.6734, 1.0925, 0.7741, 1.1116, 1.0364, 0.8016, 0.8005],\n",
            "        [1.3527, 1.9773, 1.2298, 1.9905, 1.9296, 1.2925, 1.2840],\n",
            "        [0.8947, 1.3860, 0.9296, 1.4037, 1.3314, 0.9727, 0.9650],\n",
            "        [3.1408, 4.0088, 2.2376, 4.0519, 4.0597, 2.3083, 2.4169]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "114\n",
            "tensor([[0.8701, 1.3551, 0.9140, 1.3739, 1.2994, 0.9582, 0.9472],\n",
            "        [0.9187, 1.4182, 0.9499, 1.4373, 1.3635, 0.9943, 0.9829],\n",
            "        [2.9835, 3.8498, 2.1570, 3.8927, 3.8982, 2.2153, 2.3184],\n",
            "        [2.3226, 3.1357, 1.8002, 3.1603, 3.1414, 1.8503, 1.9098],\n",
            "        [3.1466, 4.0143, 2.2406, 4.0613, 4.0697, 2.2994, 2.4187]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "115\n",
            "tensor([[2.4475, 3.2770, 1.8718, 3.3067, 3.2928, 1.9226, 1.9912],\n",
            "        [0.7281, 1.1653, 0.8156, 1.1853, 1.1107, 0.8452, 0.8425],\n",
            "        [1.8205, 2.5492, 1.5183, 2.5712, 2.5281, 1.5793, 1.5957],\n",
            "        [1.9794, 2.7340, 1.6059, 2.7533, 2.7190, 1.6699, 1.6937],\n",
            "        [1.8061, 2.5294, 1.5083, 2.5465, 2.5047, 1.5680, 1.5821]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "116\n",
            "tensor([[0.8238, 1.2923, 0.8838, 1.3123, 1.2391, 0.9195, 0.9128],\n",
            "        [2.5063, 3.3406, 1.9060, 3.3747, 3.3637, 1.9524, 2.0278],\n",
            "        [2.1191, 2.8990, 1.6885, 2.9223, 2.8977, 1.7454, 1.7839],\n",
            "        [1.7457, 2.4599, 1.4777, 2.4799, 2.4359, 1.5352, 1.5471],\n",
            "        [3.2535, 4.1155, 2.3025, 4.1676, 4.1775, 2.3769, 2.4873]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "117\n",
            "tensor([[0.8692, 1.3497, 0.9191, 1.3743, 1.3003, 0.9595, 0.9484],\n",
            "        [3.2655, 4.1226, 2.3100, 4.1767, 4.1880, 2.3875, 2.4960],\n",
            "        [1.4861, 2.1400, 1.3180, 2.1578, 2.1055, 1.3761, 1.3744],\n",
            "        [3.2631, 4.1199, 2.3086, 4.1769, 4.1902, 2.3829, 2.4925],\n",
            "        [2.3250, 3.1299, 1.8037, 3.1603, 3.1422, 1.8596, 1.9110]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "118\n",
            "tensor([[0.9886, 1.5079, 0.9999, 1.5303, 1.4618, 1.0485, 1.0354],\n",
            "        [3.2314, 4.0881, 2.2918, 4.1457, 4.1590, 2.3641, 2.4726],\n",
            "        [1.1526, 1.7177, 1.1079, 1.7384, 1.6740, 1.1603, 1.1482],\n",
            "        [2.1088, 2.8834, 1.6869, 2.9111, 2.8858, 1.7446, 1.7778],\n",
            "        [1.1693, 1.7400, 1.1181, 1.7598, 1.6948, 1.1713, 1.1605]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "119\n",
            "tensor([[2.7524, 3.6017, 2.0413, 3.6490, 3.6505, 2.0893, 2.1796],\n",
            "        [1.0400, 1.5711, 1.0349, 1.5936, 1.5263, 1.0823, 1.0691],\n",
            "        [2.6496, 3.4913, 1.9847, 3.5338, 3.5333, 2.0356, 2.1157],\n",
            "        [2.7756, 3.6236, 2.0541, 3.6715, 3.6751, 2.1049, 2.1932],\n",
            "        [2.7871, 3.6362, 2.0602, 3.6830, 3.6871, 2.1040, 2.1982]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "120\n",
            "tensor([[2.2904, 3.0953, 1.7923, 3.1312, 3.1121, 1.8438, 1.8963],\n",
            "        [2.3379, 3.1436, 1.8169, 3.1805, 3.1643, 1.8735, 1.9241],\n",
            "        [1.1236, 1.6817, 1.0917, 1.7057, 1.6387, 1.1427, 1.1311],\n",
            "        [1.8551, 2.5873, 1.5429, 2.6138, 2.5782, 1.6046, 1.6198],\n",
            "        [2.7607, 3.6068, 2.0452, 3.6565, 3.6606, 2.0921, 2.1842]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "121\n",
            "tensor([[3.2280, 4.0859, 2.2952, 4.1476, 4.1619, 2.3747, 2.4764],\n",
            "        [2.1006, 2.8748, 1.6843, 2.9092, 2.8824, 1.7463, 1.7782],\n",
            "        [0.8157, 1.2818, 0.8842, 1.3073, 1.2350, 0.9217, 0.9127],\n",
            "        [3.2953, 4.1467, 2.3255, 4.2071, 4.2140, 2.4200, 2.5217],\n",
            "        [1.5226, 2.1838, 1.3467, 2.2101, 2.1604, 1.4085, 1.4038]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "122\n",
            "tensor([[3.0638, 3.9263, 2.2089, 3.9877, 4.0012, 2.2727, 2.3781],\n",
            "        [2.1913, 2.9807, 1.7362, 3.0148, 2.9976, 1.7919, 1.8359],\n",
            "        [1.7736, 2.4908, 1.4967, 2.5197, 2.4797, 1.5589, 1.5693],\n",
            "        [0.9207, 1.4213, 0.9571, 1.4449, 1.3755, 1.0020, 0.9887],\n",
            "        [3.2264, 4.0840, 2.2939, 4.1483, 4.1636, 2.3745, 2.4794]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "123\n",
            "tensor([[2.6700, 3.5204, 2.0002, 3.5678, 3.5722, 2.0465, 2.1370],\n",
            "        [0.9780, 1.4968, 0.9958, 1.5227, 1.4534, 1.0468, 1.0327],\n",
            "        [0.8104, 1.2765, 0.8802, 1.3017, 1.2306, 0.9192, 0.9095],\n",
            "        [3.2688, 4.1262, 2.3162, 4.1893, 4.2054, 2.3928, 2.5039],\n",
            "        [2.3641, 3.1838, 1.8331, 3.2238, 3.2123, 1.8878, 1.9492]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "124\n",
            "tensor([[0.8249, 1.2955, 0.8926, 1.3244, 1.2512, 0.9345, 0.9239],\n",
            "        [1.9290, 2.6834, 1.5930, 2.7142, 2.6844, 1.6513, 1.6742],\n",
            "        [0.9251, 1.4284, 0.9626, 1.4559, 1.3841, 1.0086, 0.9966],\n",
            "        [1.3004, 1.9119, 1.2093, 1.9385, 1.8799, 1.2722, 1.2597],\n",
            "        [1.0226, 1.5548, 1.0280, 1.5818, 1.5138, 1.0802, 1.0656]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "125\n",
            "tensor([[1.1101, 1.6691, 1.0864, 1.6962, 1.6307, 1.1447, 1.1282],\n",
            "        [3.2060, 4.0695, 2.2856, 4.1383, 4.1550, 2.3582, 2.4712],\n",
            "        [2.6131, 3.4618, 1.9724, 3.5101, 3.5110, 2.0258, 2.1059],\n",
            "        [3.0527, 3.9198, 2.2062, 3.9806, 3.9939, 2.2783, 2.3772],\n",
            "        [1.1998, 1.7827, 1.1434, 1.8091, 1.7474, 1.2053, 1.1898]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "126\n",
            "tensor([[2.0254, 2.7956, 1.6457, 2.8306, 2.8044, 1.7076, 1.7374],\n",
            "        [2.0235, 2.7898, 1.6428, 2.8251, 2.7971, 1.7121, 1.7363],\n",
            "        [1.1240, 1.6882, 1.0977, 1.7171, 1.6521, 1.1556, 1.1390],\n",
            "        [2.5946, 3.4446, 1.9633, 3.4935, 3.4943, 2.0203, 2.0964],\n",
            "        [0.9033, 1.3999, 0.9466, 1.4279, 1.3573, 0.9950, 0.9808]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "127\n",
            "tensor([[2.2827, 3.0915, 1.7889, 3.1340, 3.1184, 1.8570, 1.9033],\n",
            "        [0.9606, 1.4765, 0.9877, 1.5071, 1.4359, 1.0431, 1.0265],\n",
            "        [3.2585, 4.1208, 2.3119, 4.1906, 4.2056, 2.4032, 2.5098],\n",
            "        [0.8380, 1.3163, 0.9028, 1.3463, 1.2729, 0.9465, 0.9368],\n",
            "        [1.6764, 2.3800, 1.4437, 2.4125, 2.3684, 1.5130, 1.5153]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "128\n",
            "tensor([[3.2107, 4.0767, 2.2862, 4.1473, 4.1627, 2.3854, 2.4834],\n",
            "        [0.9257, 1.4320, 0.9630, 1.4622, 1.3902, 1.0186, 1.0014],\n",
            "        [2.1062, 2.8936, 1.6919, 2.9346, 2.9086, 1.7655, 1.7971],\n",
            "        [2.9989, 3.8707, 2.1751, 3.9360, 3.9486, 2.2454, 2.3519],\n",
            "        [1.2194, 1.8137, 1.1607, 1.8443, 1.7803, 1.2289, 1.2112]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "129\n",
            "tensor([[1.8700, 2.6148, 1.5529, 2.6502, 2.6143, 1.6417, 1.6475],\n",
            "        [3.2635, 4.1244, 2.3103, 4.1964, 4.2034, 2.4266, 2.5233],\n",
            "        [1.5394, 2.2144, 1.3574, 2.2465, 2.1980, 1.4367, 1.4280],\n",
            "        [2.6504, 3.5037, 1.9910, 3.5604, 3.5602, 2.0669, 2.1389],\n",
            "        [2.9293, 3.7997, 2.1392, 3.8657, 3.8768, 2.2177, 2.3117]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "130\n",
            "tensor([[1.9343, 2.6886, 1.5906, 2.7279, 2.6934, 1.6795, 1.6904],\n",
            "        [3.1119, 3.9809, 2.2318, 4.0538, 4.0667, 2.3323, 2.4296],\n",
            "        [1.5156, 2.1857, 1.3468, 2.2202, 2.1687, 1.4257, 1.4158],\n",
            "        [1.4188, 2.0633, 1.2823, 2.0953, 2.0378, 1.3654, 1.3488],\n",
            "        [3.2741, 4.1340, 2.3154, 4.2082, 4.2159, 2.4386, 2.5330]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "131\n",
            "tensor([[3.1120, 3.9733, 2.2258, 4.0467, 4.0426, 2.3630, 2.4400],\n",
            "        [0.8182, 1.2919, 0.8896, 1.3265, 1.2495, 0.9446, 0.9283],\n",
            "        [3.2794, 4.1411, 2.3152, 4.2178, 4.2203, 2.4511, 2.5433],\n",
            "        [3.2201, 4.0866, 2.2887, 4.1637, 4.1727, 2.4093, 2.5032],\n",
            "        [0.9297, 1.4389, 0.9666, 1.4724, 1.3980, 1.0281, 1.0093]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "132\n",
            "tensor([[1.5574, 2.2396, 1.3684, 2.2774, 2.2244, 1.4596, 1.4499],\n",
            "        [2.7564, 3.6271, 2.0436, 3.6920, 3.6952, 2.1307, 2.2181],\n",
            "        [1.0388, 1.5807, 1.0358, 1.6128, 1.5422, 1.1072, 1.0881],\n",
            "        [3.0138, 3.8783, 2.1749, 3.9542, 3.9591, 2.2887, 2.3794],\n",
            "        [3.2316, 4.0974, 2.2898, 4.1789, 4.1843, 2.4158, 2.5140]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "133\n",
            "tensor([[2.7130, 3.5684, 2.0159, 3.6342, 3.6304, 2.1099, 2.1916],\n",
            "        [2.7257, 3.5862, 2.0237, 3.6542, 3.6497, 2.1293, 2.2029],\n",
            "        [2.8303, 3.7037, 2.0805, 3.7748, 3.7766, 2.1762, 2.2688],\n",
            "        [1.1756, 1.7598, 1.1283, 1.7938, 1.7268, 1.2107, 1.1896],\n",
            "        [2.2424, 3.0563, 1.7652, 3.1103, 3.0855, 1.8615, 1.9026]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "134\n",
            "tensor([[2.2937, 3.1113, 1.7900, 3.1689, 3.1434, 1.8982, 1.9360],\n",
            "        [1.5337, 2.2080, 1.3507, 2.2484, 2.1926, 1.4545, 1.4392],\n",
            "        [2.5337, 3.3785, 1.9212, 3.4422, 3.4301, 2.0264, 2.0869],\n",
            "        [2.8002, 3.6714, 2.0634, 3.7432, 3.7415, 2.1677, 2.2541],\n",
            "        [1.1541, 1.7308, 1.1153, 1.7692, 1.6988, 1.1990, 1.1787]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "135\n",
            "tensor([[0.8213, 1.2948, 0.8870, 1.3309, 1.2528, 0.9516, 0.9347],\n",
            "        [1.6525, 2.3522, 1.4204, 2.3955, 2.3424, 1.5251, 1.5200],\n",
            "        [0.9408, 1.4536, 0.9704, 1.4905, 1.4149, 1.0458, 1.0240],\n",
            "        [2.6043, 3.4534, 1.9545, 3.5216, 3.5075, 2.0730, 2.1351],\n",
            "        [1.8320, 2.5702, 1.5242, 2.6168, 2.5709, 1.6348, 1.6394]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "136\n",
            "tensor([[3.2307, 4.0960, 2.2810, 4.1853, 4.1792, 2.4466, 2.5335],\n",
            "        [2.0612, 2.8441, 1.6570, 2.8989, 2.8599, 1.7716, 1.7915],\n",
            "        [0.9689, 1.4907, 0.9899, 1.5308, 1.4526, 1.0712, 1.0474],\n",
            "        [1.4785, 2.1408, 1.3147, 2.1837, 2.1217, 1.4239, 1.4053],\n",
            "        [1.0416, 1.5859, 1.0378, 1.6239, 1.5499, 1.1205, 1.0981]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "137\n",
            "tensor([[2.9850, 3.8508, 2.1496, 3.9375, 3.9266, 2.2930, 2.3775],\n",
            "        [1.8902, 2.6429, 1.5588, 2.6941, 2.6499, 1.6721, 1.6821],\n",
            "        [0.9380, 1.4484, 0.9655, 1.4884, 1.4103, 1.0471, 1.0233],\n",
            "        [1.0967, 1.6577, 1.0745, 1.7006, 1.6231, 1.1673, 1.1415],\n",
            "        [1.6818, 2.3888, 1.4338, 2.4370, 2.3827, 1.5503, 1.5433]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "138\n",
            "tensor([[1.8454, 2.5874, 1.5294, 2.6385, 2.5907, 1.6463, 1.6534],\n",
            "        [2.5050, 3.3481, 1.8965, 3.4207, 3.3964, 2.0150, 2.0791],\n",
            "        [2.5845, 3.4363, 1.9385, 3.5087, 3.4941, 2.0565, 2.1280],\n",
            "        [0.9415, 1.4534, 0.9684, 1.4950, 1.4140, 1.0506, 1.0288],\n",
            "        [2.5146, 3.3527, 1.9006, 3.4251, 3.4016, 2.0274, 2.0838]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "139\n",
            "tensor([[2.3968, 3.2282, 1.8361, 3.2966, 3.2666, 1.9614, 2.0127],\n",
            "        [2.5182, 3.3563, 1.8991, 3.4296, 3.4034, 2.0295, 2.0880],\n",
            "        [3.2753, 4.1334, 2.2956, 4.2278, 4.2206, 2.4733, 2.5625],\n",
            "        [3.1053, 3.9737, 2.2067, 4.0636, 4.0612, 2.3498, 2.4528],\n",
            "        [2.1664, 2.9649, 1.7094, 3.0261, 2.9891, 1.8306, 1.8649]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "140\n",
            "tensor([[2.8258, 3.6888, 2.0606, 3.7704, 3.7579, 2.1948, 2.2789],\n",
            "        [1.8378, 2.5756, 1.5216, 2.6288, 2.5730, 1.6422, 1.6486],\n",
            "        [1.1377, 1.7084, 1.0978, 1.7512, 1.6723, 1.1942, 1.1717],\n",
            "        [0.8368, 1.3169, 0.8952, 1.3582, 1.2747, 0.9706, 0.9522],\n",
            "        [2.2683, 3.0816, 1.7644, 3.1459, 3.1116, 1.8849, 1.9291]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "141\n",
            "tensor([[1.7112, 2.4261, 1.4456, 2.4756, 2.4167, 1.5628, 1.5645],\n",
            "        [1.6481, 2.3469, 1.4087, 2.3969, 2.3337, 1.5288, 1.5226],\n",
            "        [1.0564, 1.6054, 1.0444, 1.6483, 1.5675, 1.1360, 1.1139],\n",
            "        [1.7828, 2.5104, 1.4873, 2.5628, 2.5050, 1.6111, 1.6128],\n",
            "        [0.9107, 1.4125, 0.9451, 1.4555, 1.3719, 1.0271, 1.0064]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "142\n",
            "tensor([[1.6990, 2.4123, 1.4376, 2.4621, 2.4008, 1.5622, 1.5573],\n",
            "        [3.1835, 4.0460, 2.2395, 4.1407, 4.1299, 2.4087, 2.5039],\n",
            "        [0.8750, 1.3663, 0.9215, 1.4078, 1.3240, 0.9966, 0.9793],\n",
            "        [2.2478, 3.0568, 1.7469, 3.1211, 3.0803, 1.8734, 1.9147],\n",
            "        [2.0115, 2.7812, 1.6136, 2.8374, 2.7871, 1.7497, 1.7614]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "143\n",
            "tensor([[2.7643, 3.6309, 2.0210, 3.7080, 3.6910, 2.1488, 2.2398],\n",
            "        [1.7963, 2.5300, 1.4935, 2.5821, 2.5225, 1.6185, 1.6223],\n",
            "        [0.7273, 1.1722, 0.8167, 1.2109, 1.1259, 0.8787, 0.8674],\n",
            "        [2.1298, 2.9202, 1.6802, 2.9788, 2.9340, 1.8141, 1.8372],\n",
            "        [2.2567, 3.0693, 1.7496, 3.1313, 3.0900, 1.8799, 1.9206]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "144\n",
            "tensor([[0.8365, 1.3187, 0.8918, 1.3577, 1.2735, 0.9672, 0.9503],\n",
            "        [0.8038, 1.2741, 0.8721, 1.3153, 1.2290, 0.9427, 0.9264],\n",
            "        [1.0478, 1.5948, 1.0330, 1.6338, 1.5510, 1.1249, 1.1027],\n",
            "        [3.0569, 3.9306, 2.1706, 4.0172, 4.0035, 2.3255, 2.4234],\n",
            "        [1.0473, 1.5947, 1.0341, 1.6365, 1.5533, 1.1329, 1.1061]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "145\n",
            "tensor([[3.2648, 4.1302, 2.2742, 4.2163, 4.2012, 2.4486, 2.5514],\n",
            "        [2.7720, 3.6409, 2.0187, 3.7145, 3.6947, 2.1502, 2.2407],\n",
            "        [1.5495, 2.2321, 1.3464, 2.2767, 2.2086, 1.4659, 1.4559],\n",
            "        [1.6280, 2.3300, 1.3911, 2.3738, 2.3095, 1.5153, 1.5085],\n",
            "        [1.6959, 2.4125, 1.4317, 2.4576, 2.3956, 1.5555, 1.5532]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "146\n",
            "tensor([[1.4927, 2.1630, 1.3080, 2.2042, 2.1344, 1.4290, 1.4149],\n",
            "        [1.9791, 2.7519, 1.5905, 2.8018, 2.7482, 1.7234, 1.7393],\n",
            "        [2.6454, 3.5125, 1.9529, 3.5806, 3.5558, 2.0841, 2.1632],\n",
            "        [0.9928, 1.5268, 0.9958, 1.5656, 1.4812, 1.0868, 1.0652],\n",
            "        [1.9263, 2.6872, 1.5591, 2.7366, 2.6796, 1.6930, 1.7036]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "147\n",
            "tensor([[3.2497, 4.1161, 2.2584, 4.1982, 4.1806, 2.4432, 2.5420],\n",
            "        [2.7806, 3.6470, 2.0186, 3.7179, 3.6944, 2.1693, 2.2458],\n",
            "        [2.2733, 3.0880, 1.7457, 3.1412, 3.1001, 1.8847, 1.9264],\n",
            "        [2.1354, 2.9341, 1.6742, 2.9836, 2.9358, 1.8091, 1.8394],\n",
            "        [3.2045, 4.0766, 2.2373, 4.1607, 4.1503, 2.4042, 2.5086]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "148\n",
            "tensor([[0.8504, 1.3387, 0.8991, 1.3743, 1.2877, 0.9765, 0.9582],\n",
            "        [3.0671, 3.9412, 2.1652, 4.0188, 4.0029, 2.3234, 2.4221],\n",
            "        [2.0778, 2.8680, 1.6411, 2.9156, 2.8665, 1.7728, 1.7975],\n",
            "        [3.2229, 4.0882, 2.2420, 4.1654, 4.1459, 2.4325, 2.5232],\n",
            "        [2.1483, 2.9526, 1.6809, 3.0009, 2.9557, 1.8098, 1.8440]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "149\n",
            "tensor([[2.5144, 3.3682, 1.8782, 3.4261, 3.3942, 2.0090, 2.0757],\n",
            "        [2.8495, 3.7234, 2.0496, 3.7916, 3.7726, 2.1811, 2.2816],\n",
            "        [2.6893, 3.5574, 1.9689, 3.6201, 3.5967, 2.1037, 2.1820],\n",
            "        [1.5192, 2.1991, 1.3219, 2.2368, 2.1660, 1.4436, 1.4295],\n",
            "        [1.2915, 1.9126, 1.1841, 1.9482, 1.8704, 1.2937, 1.2740]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "150\n",
            "tensor([[3.2009, 4.0805, 2.2322, 4.1558, 4.1389, 2.4129, 2.5039],\n",
            "        [2.3744, 3.2189, 1.8031, 3.2687, 3.2340, 1.9240, 1.9828],\n",
            "        [2.2924, 3.1190, 1.7578, 3.1699, 3.1291, 1.8922, 1.9330],\n",
            "        [2.1028, 2.9004, 1.6542, 2.9469, 2.8973, 1.7851, 1.8117],\n",
            "        [3.2398, 4.1163, 2.2516, 4.1917, 4.1735, 2.4256, 2.5248]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "151\n",
            "tensor([[3.2263, 4.1043, 2.2438, 4.1783, 4.1606, 2.4175, 2.5154],\n",
            "        [3.2341, 4.1134, 2.2496, 4.1884, 4.1719, 2.4248, 2.5190],\n",
            "        [1.5322, 2.2226, 1.3296, 2.2538, 2.1847, 1.4478, 1.4353],\n",
            "        [1.0618, 1.6216, 1.0370, 1.6554, 1.5708, 1.1307, 1.1104],\n",
            "        [3.2318, 4.1077, 2.2495, 4.1828, 4.1647, 2.4270, 2.5186]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "152\n",
            "tensor([[2.9892, 3.8709, 2.1195, 3.9363, 3.9180, 2.2679, 2.3632],\n",
            "        [1.3973, 2.0546, 1.2485, 2.0881, 2.0115, 1.3603, 1.3451],\n",
            "        [3.2774, 4.1523, 2.2673, 4.2242, 4.2023, 2.4490, 2.5471],\n",
            "        [0.9151, 1.4301, 0.9404, 1.4625, 1.3754, 1.0197, 1.0025],\n",
            "        [1.3348, 1.9741, 1.2099, 2.0056, 1.9278, 1.3146, 1.2989]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "153\n",
            "tensor([[2.6948, 3.5728, 1.9648, 3.6271, 3.6022, 2.0902, 2.1776],\n",
            "        [1.0624, 1.6243, 1.0348, 1.6549, 1.5706, 1.1293, 1.1087],\n",
            "        [0.8637, 1.3643, 0.9058, 1.3966, 1.3074, 0.9850, 0.9664],\n",
            "        [2.5213, 3.3864, 1.8746, 3.4357, 3.4027, 2.0014, 2.0730],\n",
            "        [2.7514, 3.6339, 1.9950, 3.6915, 3.6668, 2.1237, 2.2149]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "154\n",
            "tensor([[3.0152, 3.8985, 2.1281, 3.9616, 3.9420, 2.2726, 2.3742],\n",
            "        [2.8652, 3.7490, 2.0504, 3.8082, 3.7842, 2.1920, 2.2845],\n",
            "        [1.5057, 2.1926, 1.3101, 2.2218, 2.1493, 1.4214, 1.4136],\n",
            "        [3.2664, 4.1462, 2.2548, 4.2138, 4.1888, 2.4387, 2.5402],\n",
            "        [2.8346, 3.7231, 2.0365, 3.7799, 3.7588, 2.1590, 2.2614]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "155\n",
            "tensor([[1.5481, 2.2423, 1.3344, 2.2728, 2.1993, 1.4491, 1.4415],\n",
            "        [0.7610, 1.2263, 0.8351, 1.2577, 1.1670, 0.8998, 0.8870],\n",
            "        [1.9542, 2.7341, 1.5675, 2.7703, 2.7112, 1.6880, 1.7072],\n",
            "        [3.2269, 4.1022, 2.2315, 4.1679, 4.1413, 2.4064, 2.5107],\n",
            "        [3.2661, 4.1479, 2.2578, 4.2158, 4.1940, 2.4226, 2.5307]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "156\n",
            "tensor([[2.7002, 3.5803, 1.9680, 3.6283, 3.5982, 2.0963, 2.1764],\n",
            "        [3.2264, 4.1095, 2.2388, 4.1686, 4.1458, 2.4129, 2.5061],\n",
            "        [1.9945, 2.7828, 1.5896, 2.8157, 2.7602, 1.7063, 1.7298],\n",
            "        [1.2585, 1.8802, 1.1605, 1.9070, 1.8247, 1.2573, 1.2424],\n",
            "        [2.8472, 3.7463, 2.0481, 3.7976, 3.7791, 2.1611, 2.2664]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "157\n",
            "tensor([[1.1878, 1.7896, 1.1168, 1.8152, 1.7311, 1.2103, 1.1921],\n",
            "        [3.2743, 4.1541, 2.2625, 4.2128, 4.1890, 2.4347, 2.5324],\n",
            "        [1.0424, 1.6026, 1.0274, 1.6292, 1.5413, 1.1107, 1.0901],\n",
            "        [3.0556, 3.9444, 2.1537, 3.9976, 3.9771, 2.2945, 2.3909],\n",
            "        [2.0531, 2.8503, 1.6208, 2.8798, 2.8267, 1.7369, 1.7634]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "158\n",
            "tensor([[2.6223, 3.5027, 1.9309, 3.5414, 3.5136, 2.0376, 2.1210],\n",
            "        [2.4739, 3.3329, 1.8515, 3.3682, 3.3335, 1.9633, 2.0280],\n",
            "        [0.8990, 1.4122, 0.9316, 1.4373, 1.3498, 1.0025, 0.9842],\n",
            "        [1.8261, 2.5878, 1.4986, 2.6103, 2.5519, 1.6056, 1.6170],\n",
            "        [2.1982, 3.0228, 1.7043, 3.0525, 3.0084, 1.8187, 1.8559]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "159\n",
            "tensor([[1.5169, 2.2076, 1.3220, 2.2296, 2.1579, 1.4237, 1.4123],\n",
            "        [1.2361, 1.8535, 1.1493, 1.8759, 1.7951, 1.2449, 1.2231],\n",
            "        [1.2973, 1.9315, 1.1860, 1.9528, 1.8724, 1.2819, 1.2646],\n",
            "        [2.6233, 3.4928, 1.9299, 3.5309, 3.5027, 2.0485, 2.1152],\n",
            "        [0.9695, 1.5059, 0.9795, 1.5307, 1.4423, 1.0541, 1.0356]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "160\n",
            "tensor([[3.2423, 4.1269, 2.2515, 4.1745, 4.1612, 2.4087, 2.4953],\n",
            "        [1.6779, 2.4067, 1.4124, 2.4239, 2.3599, 1.5216, 1.5157],\n",
            "        [0.9646, 1.4976, 0.9742, 1.5212, 1.4344, 1.0513, 1.0295],\n",
            "        [1.9402, 2.7202, 1.5615, 2.7419, 2.6874, 1.6766, 1.6862],\n",
            "        [2.0855, 2.8871, 1.6406, 2.9100, 2.8612, 1.7548, 1.7755]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "161\n",
            "tensor([[0.7996, 1.2810, 0.8634, 1.3051, 1.2177, 0.9264, 0.9086],\n",
            "        [1.4685, 2.1474, 1.2925, 2.1649, 2.0922, 1.3934, 1.3762],\n",
            "        [2.2985, 3.1407, 1.7608, 3.1662, 3.1281, 1.8725, 1.9126],\n",
            "        [3.2856, 4.1665, 2.2731, 4.2110, 4.1983, 2.4303, 2.5220],\n",
            "        [1.2957, 1.9295, 1.1879, 1.9453, 1.8692, 1.2797, 1.2590]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "162\n",
            "tensor([[3.0090, 3.9041, 2.1322, 3.9434, 3.9397, 2.2435, 2.3426],\n",
            "        [0.9995, 1.5473, 0.9984, 1.5659, 1.4823, 1.0731, 1.0509],\n",
            "        [3.1951, 4.0873, 2.2281, 4.1318, 4.1262, 2.3674, 2.4619],\n",
            "        [0.8673, 1.3728, 0.9088, 1.3920, 1.3075, 0.9741, 0.9566],\n",
            "        [1.9831, 2.7723, 1.5855, 2.7909, 2.7398, 1.6963, 1.7094]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "163\n",
            "tensor([[0.8835, 1.3946, 0.9235, 1.4162, 1.3289, 0.9924, 0.9698],\n",
            "        [1.2853, 1.9191, 1.1805, 1.9331, 1.8569, 1.2712, 1.2507],\n",
            "        [0.9121, 1.4300, 0.9393, 1.4510, 1.3657, 1.0124, 0.9890],\n",
            "        [1.2334, 1.8522, 1.1501, 1.8678, 1.7903, 1.2400, 1.2151],\n",
            "        [0.7826, 1.2575, 0.8508, 1.2796, 1.1943, 0.9102, 0.8945]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "164\n",
            "tensor([[2.9737, 3.8644, 2.1142, 3.9000, 3.8931, 2.2446, 2.3208],\n",
            "        [1.6204, 2.3372, 1.3803, 2.3511, 2.2877, 1.4859, 1.4732],\n",
            "        [2.2619, 3.1004, 1.7416, 3.1199, 3.0861, 1.8427, 1.8826],\n",
            "        [0.8206, 1.3094, 0.8794, 1.3316, 1.2450, 0.9438, 0.9225],\n",
            "        [2.4835, 3.3566, 1.8607, 3.3795, 3.3554, 1.9621, 2.0223]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "165\n",
            "tensor([[0.8335, 1.3259, 0.8871, 1.3472, 1.2607, 0.9530, 0.9318],\n",
            "        [1.0421, 1.6059, 1.0257, 1.6226, 1.5415, 1.1059, 1.0813],\n",
            "        [0.9761, 1.5158, 0.9819, 1.5353, 1.4515, 1.0604, 1.0351],\n",
            "        [3.0682, 3.9601, 2.1600, 3.9988, 3.9976, 2.2914, 2.3759],\n",
            "        [2.0698, 2.8769, 1.6347, 2.8928, 2.8496, 1.7450, 1.7620]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "166\n",
            "tensor([[0.7854, 1.2642, 0.8550, 1.2843, 1.1984, 0.9158, 0.8964],\n",
            "        [1.1865, 1.7931, 1.1200, 1.8105, 1.7316, 1.2111, 1.1834],\n",
            "        [2.6882, 3.5768, 1.9676, 3.6015, 3.5879, 2.0737, 2.1431],\n",
            "        [2.7004, 3.5859, 1.9728, 3.6129, 3.5978, 2.0909, 2.1531],\n",
            "        [2.0455, 2.8522, 1.6226, 2.8657, 2.8245, 1.7310, 1.7458]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "167\n",
            "tensor([[1.1615, 1.7641, 1.1034, 1.7774, 1.7001, 1.1925, 1.1661],\n",
            "        [2.6098, 3.4936, 1.9265, 3.5161, 3.4971, 2.0327, 2.0992],\n",
            "        [1.3460, 1.9997, 1.2208, 2.0125, 1.9416, 1.3143, 1.2910],\n",
            "        [2.1694, 3.0028, 1.6959, 3.0167, 2.9817, 1.7991, 1.8257],\n",
            "        [1.0045, 1.5584, 1.0022, 1.5746, 1.4924, 1.0799, 1.0558]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "168\n",
            "tensor([[2.0007, 2.8013, 1.6010, 2.8138, 2.7683, 1.7121, 1.7199],\n",
            "        [2.8416, 3.7403, 2.0472, 3.7675, 3.7617, 2.1623, 2.2403],\n",
            "        [3.2067, 4.0973, 2.2364, 4.1312, 4.1263, 2.4005, 2.4701],\n",
            "        [2.9842, 3.8876, 2.1238, 3.9178, 3.9127, 2.2418, 2.3285],\n",
            "        [2.4642, 3.3432, 1.8520, 3.3603, 3.3394, 1.9591, 2.0123]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "169\n",
            "tensor([[3.2163, 4.1095, 2.2421, 4.1432, 4.1383, 2.4074, 2.4786],\n",
            "        [0.9660, 1.5096, 0.9789, 1.5250, 1.4431, 1.0559, 1.0302],\n",
            "        [2.5561, 3.4395, 1.9016, 3.4601, 3.4421, 2.0137, 2.0682],\n",
            "        [1.6445, 2.3751, 1.3986, 2.3877, 2.3261, 1.5094, 1.4941],\n",
            "        [0.9382, 1.4723, 0.9486, 1.4812, 1.4061, 1.0269, 1.0041]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "170\n",
            "tensor([[1.0650, 1.6404, 1.0438, 1.6575, 1.5743, 1.1319, 1.1031],\n",
            "        [3.1219, 4.0242, 2.1940, 4.0593, 4.0491, 2.3471, 2.4235],\n",
            "        [2.7026, 3.6061, 1.9779, 3.6285, 3.6171, 2.0902, 2.1631],\n",
            "        [2.9476, 3.8574, 2.1045, 3.8874, 3.8859, 2.2231, 2.3088],\n",
            "        [1.7804, 2.5457, 1.4770, 2.5557, 2.5011, 1.5878, 1.5832]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "171\n",
            "tensor([[2.2885, 3.1455, 1.7570, 3.1623, 3.1278, 1.8742, 1.9102],\n",
            "        [1.9920, 2.7988, 1.5947, 2.8112, 2.7634, 1.7131, 1.7215],\n",
            "        [1.0429, 1.6157, 1.0301, 1.6313, 1.5485, 1.1175, 1.0897],\n",
            "        [1.7778, 2.5446, 1.4746, 2.5536, 2.4992, 1.5869, 1.5828],\n",
            "        [1.1601, 1.7678, 1.1046, 1.7808, 1.7010, 1.1977, 1.1700]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "172\n",
            "tensor([[3.0328, 3.9495, 2.1469, 3.9803, 3.9785, 2.2764, 2.3685],\n",
            "        [2.2583, 3.1099, 1.7404, 3.1249, 3.0889, 1.8624, 1.8918],\n",
            "        [1.5073, 2.2122, 1.3185, 2.2227, 2.1542, 1.4291, 1.4095],\n",
            "        [3.2471, 4.1473, 2.2573, 4.1846, 4.1792, 2.4094, 2.4998],\n",
            "        [2.1841, 3.0278, 1.7025, 3.0421, 3.0044, 1.8144, 1.8442]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "173\n",
            "tensor([[1.1978, 1.8206, 1.1276, 1.8337, 1.7533, 1.2274, 1.2006],\n",
            "        [1.4486, 2.1400, 1.2820, 2.1502, 2.0808, 1.3927, 1.3704],\n",
            "        [2.9393, 3.8552, 2.0953, 3.8836, 3.8757, 2.2220, 2.3122],\n",
            "        [1.0809, 1.6687, 1.0571, 1.6805, 1.6000, 1.1469, 1.1166],\n",
            "        [1.4211, 2.1060, 1.2640, 2.1149, 2.0448, 1.3743, 1.3515]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "174\n",
            "tensor([[2.6479, 3.5515, 1.9442, 3.5688, 3.5547, 2.0588, 2.1331],\n",
            "        [1.6206, 2.3557, 1.3817, 2.3626, 2.2990, 1.4988, 1.4844],\n",
            "        [0.9550, 1.5025, 0.9704, 1.5184, 1.4326, 1.0557, 1.0296],\n",
            "        [1.5261, 2.2379, 1.3263, 2.2471, 2.1787, 1.4420, 1.4226],\n",
            "        [3.2411, 4.1488, 2.2512, 4.1827, 4.1762, 2.4202, 2.5026]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "175\n",
            "tensor([[1.5454, 2.2672, 1.3381, 2.2749, 2.2081, 1.4522, 1.4378],\n",
            "        [0.7960, 1.2884, 0.8610, 1.3054, 1.2177, 0.9316, 0.9119],\n",
            "        [3.2374, 4.1401, 2.2390, 4.1619, 4.1501, 2.4246, 2.5034],\n",
            "        [2.9223, 3.8441, 2.0844, 3.8680, 3.8618, 2.2165, 2.3034],\n",
            "        [2.4767, 3.3634, 1.8517, 3.3777, 3.3515, 1.9756, 2.0303]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "176\n",
            "tensor([[2.6394, 3.5404, 1.9327, 3.5554, 3.5352, 2.0695, 2.1331],\n",
            "        [1.2596, 1.9014, 1.1621, 1.9086, 1.8321, 1.2655, 1.2411],\n",
            "        [3.2014, 4.1111, 2.2215, 4.1375, 4.1398, 2.3745, 2.4698],\n",
            "        [1.5242, 2.2396, 1.3226, 2.2451, 2.1778, 1.4380, 1.4226],\n",
            "        [1.6247, 2.3644, 1.3809, 2.3677, 2.3060, 1.4985, 1.4882]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "177\n",
            "tensor([[2.8606, 3.7811, 2.0479, 3.7987, 3.7914, 2.1808, 2.2651],\n",
            "        [2.6781, 3.5963, 1.9556, 3.6090, 3.5996, 2.0682, 2.1525],\n",
            "        [3.1203, 4.0398, 2.1814, 4.0648, 4.0661, 2.3253, 2.4219],\n",
            "        [2.3407, 3.2187, 1.7786, 3.2275, 3.1976, 1.8986, 1.9456],\n",
            "        [2.5993, 3.5051, 1.9153, 3.5184, 3.5007, 2.0442, 2.1070]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "178\n",
            "tensor([[2.1921, 3.0469, 1.6955, 3.0508, 3.0167, 1.8182, 1.8508],\n",
            "        [2.6767, 3.5941, 1.9515, 3.6039, 3.5943, 2.0709, 2.1500],\n",
            "        [3.2631, 4.1713, 2.2494, 4.1922, 4.1824, 2.4334, 2.5175],\n",
            "        [1.3163, 1.9778, 1.1958, 1.9837, 1.9097, 1.3060, 1.2822],\n",
            "        [1.7848, 2.5623, 1.4709, 2.5660, 2.5094, 1.5923, 1.5920]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "179\n",
            "tensor([[3.1036, 4.0257, 2.1691, 4.0450, 4.0457, 2.3210, 2.4109],\n",
            "        [2.3435, 3.2243, 1.7747, 3.2277, 3.1998, 1.8962, 1.9437],\n",
            "        [3.1264, 4.0432, 2.1793, 4.0616, 4.0587, 2.3448, 2.4257],\n",
            "        [1.8946, 2.6914, 1.5277, 2.6932, 2.6437, 1.6557, 1.6579],\n",
            "        [0.8641, 1.3862, 0.9082, 1.3992, 1.3124, 0.9845, 0.9625]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "180\n",
            "tensor([[3.1195, 4.0409, 2.1713, 4.0543, 4.0618, 2.3131, 2.4137],\n",
            "        [1.9231, 2.7363, 1.5443, 2.7337, 2.6892, 1.6630, 1.6757],\n",
            "        [2.9006, 3.8345, 2.0628, 3.8437, 3.8462, 2.1899, 2.2806],\n",
            "        [1.6796, 2.4380, 1.4072, 2.4353, 2.3780, 1.5315, 1.5188],\n",
            "        [1.6484, 2.3979, 1.3881, 2.3943, 2.3392, 1.5066, 1.4953]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "181\n",
            "tensor([[3.1969, 4.1208, 2.2134, 4.1362, 4.1426, 2.3784, 2.4631],\n",
            "        [1.4535, 2.1561, 1.2764, 2.1530, 2.0891, 1.3882, 1.3657],\n",
            "        [3.2481, 4.1687, 2.2378, 4.1800, 4.1856, 2.4074, 2.4938],\n",
            "        [1.1762, 1.8025, 1.1072, 1.8051, 1.7285, 1.2095, 1.1805],\n",
            "        [0.7918, 1.2882, 0.8554, 1.2998, 1.2147, 0.9278, 0.9044]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "182\n",
            "tensor([[2.5744, 3.4814, 1.8897, 3.4782, 3.4681, 2.0226, 2.0759],\n",
            "        [3.2499, 4.1683, 2.2331, 4.1740, 4.1772, 2.4128, 2.4923],\n",
            "        [2.0934, 2.9386, 1.6363, 2.9298, 2.8976, 1.7588, 1.7759],\n",
            "        [1.3342, 2.0070, 1.2021, 2.0044, 1.9358, 1.3131, 1.2846],\n",
            "        [1.9022, 2.7137, 1.5309, 2.7061, 2.6627, 1.6535, 1.6581]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "183\n",
            "tensor([[3.0667, 3.9973, 2.1400, 4.0002, 4.0131, 2.2987, 2.3707],\n",
            "        [1.6126, 2.3583, 1.3645, 2.3476, 2.2942, 1.4804, 1.4641],\n",
            "        [1.4691, 2.1789, 1.2828, 2.1723, 2.1118, 1.3947, 1.3717],\n",
            "        [2.1123, 2.9638, 1.6436, 2.9530, 2.9238, 1.7657, 1.7846],\n",
            "        [2.0090, 2.8440, 1.5864, 2.8312, 2.7968, 1.7048, 1.7200]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "184\n",
            "tensor([[1.0887, 1.6907, 1.0494, 1.6899, 1.6129, 1.1471, 1.1129],\n",
            "        [3.0135, 3.9465, 2.1085, 3.9432, 3.9563, 2.2391, 2.3295],\n",
            "        [1.8520, 2.6542, 1.4985, 2.6389, 2.5986, 1.6150, 1.6165],\n",
            "        [1.0795, 1.6759, 1.0402, 1.6738, 1.5976, 1.1380, 1.1049],\n",
            "        [3.2628, 4.1862, 2.2353, 4.1841, 4.1973, 2.4050, 2.4845]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "185\n",
            "tensor([[0.9338, 1.4826, 0.9475, 1.4848, 1.4066, 1.0310, 1.0017],\n",
            "        [2.8632, 3.7964, 2.0296, 3.7857, 3.7958, 2.1620, 2.2390],\n",
            "        [0.7470, 1.2308, 0.8209, 1.2359, 1.1540, 0.8848, 0.8643],\n",
            "        [3.2425, 4.1616, 2.2175, 4.1522, 4.1613, 2.3998, 2.4729],\n",
            "        [1.9838, 2.8159, 1.5724, 2.7988, 2.7662, 1.6881, 1.7010]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "186\n",
            "tensor([[1.4882, 2.2046, 1.2881, 2.1920, 2.1330, 1.4046, 1.3787],\n",
            "        [1.3478, 2.0249, 1.2043, 2.0135, 1.9501, 1.3125, 1.2846],\n",
            "        [2.9038, 3.8434, 2.0469, 3.8316, 3.8448, 2.1782, 2.2609],\n",
            "        [1.9802, 2.8049, 1.5637, 2.7873, 2.7547, 1.6914, 1.6938],\n",
            "        [1.2501, 1.8992, 1.1467, 1.8911, 1.8240, 1.2493, 1.2188]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "187\n",
            "tensor([[2.1100, 2.9572, 1.6298, 2.9355, 2.9120, 1.7603, 1.7710],\n",
            "        [1.8735, 2.6791, 1.5043, 2.6603, 2.6206, 1.6289, 1.6256],\n",
            "        [1.3447, 2.0233, 1.2024, 2.0092, 1.9463, 1.3073, 1.2807],\n",
            "        [0.9711, 1.5330, 0.9697, 1.5305, 1.4540, 1.0552, 1.0243],\n",
            "        [2.8861, 3.8201, 2.0356, 3.8056, 3.8212, 2.1686, 2.2470]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "188\n",
            "tensor([[3.2603, 4.1826, 2.2191, 4.1684, 4.1851, 2.4013, 2.4768],\n",
            "        [3.2549, 4.1764, 2.2183, 4.1635, 4.1844, 2.3950, 2.4699],\n",
            "        [2.5481, 3.4657, 1.8611, 3.4427, 3.4474, 1.9754, 2.0389],\n",
            "        [2.8498, 3.7843, 2.0140, 3.7662, 3.7831, 2.1443, 2.2228],\n",
            "        [2.3075, 3.1892, 1.7339, 3.1663, 3.1556, 1.8502, 1.8905]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "189\n",
            "tensor([[2.1565, 3.0137, 1.6551, 2.9888, 2.9700, 1.7771, 1.7976],\n",
            "        [1.8635, 2.6675, 1.4956, 2.6449, 2.6108, 1.6159, 1.6157],\n",
            "        [2.6977, 3.6251, 1.9365, 3.6030, 3.6150, 2.0637, 2.1292],\n",
            "        [3.2662, 4.1875, 2.2200, 4.1710, 4.1893, 2.4038, 2.4768],\n",
            "        [1.7068, 2.4762, 1.4061, 2.4514, 2.4137, 1.5252, 1.5136]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "190\n",
            "tensor([[2.8507, 3.7842, 2.0103, 3.7621, 3.7816, 2.1335, 2.2149],\n",
            "        [3.2058, 4.1342, 2.1910, 4.1208, 4.1504, 2.3518, 2.4322],\n",
            "        [2.0476, 2.8871, 1.5963, 2.8634, 2.8405, 1.7178, 1.7277],\n",
            "        [0.9451, 1.4990, 0.9513, 1.4955, 1.4194, 1.0318, 1.0047],\n",
            "        [2.3800, 3.2715, 1.7712, 3.2472, 3.2412, 1.8971, 1.9350]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "191\n",
            "tensor([[1.5353, 2.2614, 1.3083, 2.2409, 2.1923, 1.4224, 1.3998],\n",
            "        [3.1132, 4.0424, 2.1417, 4.0284, 4.0567, 2.2946, 2.3744],\n",
            "        [3.0960, 4.0255, 2.1335, 4.0094, 4.0400, 2.2829, 2.3631],\n",
            "        [3.1616, 4.0848, 2.1657, 4.0704, 4.0978, 2.3336, 2.4044],\n",
            "        [1.9441, 2.7620, 1.5365, 2.7371, 2.7092, 1.6599, 1.6612]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "192\n",
            "tensor([[2.8404, 3.7757, 2.0020, 3.7538, 3.7796, 2.1159, 2.2030],\n",
            "        [3.0425, 3.9743, 2.1035, 3.9590, 3.9873, 2.2499, 2.3284],\n",
            "        [1.8453, 2.6431, 1.4822, 2.6197, 2.5872, 1.6046, 1.5982],\n",
            "        [2.9834, 3.9169, 2.0729, 3.8978, 3.9314, 2.2035, 2.2881],\n",
            "        [3.1417, 4.0688, 2.1551, 4.0557, 4.0870, 2.3159, 2.3898]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "193\n",
            "tensor([[2.4829, 3.3871, 1.8199, 3.3605, 3.3656, 1.9444, 1.9878],\n",
            "        [0.8291, 1.3382, 0.8708, 1.3395, 1.2619, 0.9482, 0.9193],\n",
            "        [1.4326, 2.1331, 1.2489, 2.1140, 2.0609, 1.3609, 1.3305],\n",
            "        [1.0205, 1.5971, 0.9951, 1.5899, 1.5193, 1.0878, 1.0538],\n",
            "        [3.2593, 4.1777, 2.2106, 4.1627, 4.1947, 2.3886, 2.4584]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "194\n",
            "tensor([[0.9080, 1.4437, 0.9210, 1.4410, 1.3668, 1.0059, 0.9731],\n",
            "        [1.3481, 2.0207, 1.1961, 2.0050, 1.9482, 1.3093, 1.2735],\n",
            "        [2.2335, 3.1023, 1.6892, 3.0753, 3.0671, 1.8062, 1.8330],\n",
            "        [1.7530, 2.5283, 1.4273, 2.5041, 2.4681, 1.5438, 1.5341],\n",
            "        [1.4035, 2.0905, 1.2267, 2.0727, 2.0183, 1.3390, 1.3083]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "195\n",
            "tensor([[2.1687, 3.0247, 1.6559, 2.9981, 2.9876, 1.7714, 1.7907],\n",
            "        [2.0449, 2.8680, 1.5830, 2.8427, 2.8230, 1.7123, 1.7131],\n",
            "        [3.0136, 3.9346, 2.0857, 3.9180, 3.9467, 2.2367, 2.3008],\n",
            "        [2.2619, 3.1311, 1.7023, 3.1035, 3.0983, 1.8260, 1.8478],\n",
            "        [0.9109, 1.4489, 0.9251, 1.4456, 1.3727, 1.0090, 0.9749]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "196\n",
            "tensor([[2.4430, 3.3414, 1.7989, 3.3132, 3.3212, 1.9190, 1.9567],\n",
            "        [2.1434, 2.9946, 1.6401, 2.9672, 2.9565, 1.7598, 1.7739],\n",
            "        [1.0531, 1.6366, 1.0166, 1.6290, 1.5607, 1.1093, 1.0712],\n",
            "        [1.6966, 2.4583, 1.3955, 2.4341, 2.3974, 1.5125, 1.4947],\n",
            "        [1.8590, 2.6519, 1.4852, 2.6261, 2.5981, 1.6098, 1.5967]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "197\n",
            "tensor([[3.2397, 4.1463, 2.1971, 4.1271, 4.1548, 2.3784, 2.4391],\n",
            "        [2.9163, 3.8448, 2.0373, 3.8214, 3.8559, 2.1604, 2.2328],\n",
            "        [2.7987, 3.7250, 1.9776, 3.7006, 3.7296, 2.1004, 2.1645],\n",
            "        [3.2078, 4.1223, 2.1827, 4.1070, 4.1422, 2.3532, 2.4122],\n",
            "        [2.4889, 3.3826, 1.8197, 3.3558, 3.3644, 1.9441, 1.9789]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "198\n",
            "tensor([[0.8119, 1.3158, 0.8608, 1.3179, 1.2401, 0.9342, 0.9031],\n",
            "        [2.3390, 3.2225, 1.7429, 3.1946, 3.1941, 1.8628, 1.8913],\n",
            "        [2.6517, 3.5662, 1.9048, 3.5401, 3.5587, 2.0359, 2.0785],\n",
            "        [2.2966, 3.1772, 1.7248, 3.1477, 3.1471, 1.8364, 1.8642],\n",
            "        [1.1544, 1.7738, 1.0797, 1.7618, 1.6958, 1.1790, 1.1397]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "199\n",
            "tensor([[3.2524, 4.1661, 2.2055, 4.1505, 4.1804, 2.3829, 2.4445],\n",
            "        [3.2503, 4.1640, 2.2060, 4.1485, 4.1773, 2.3831, 2.4433],\n",
            "        [2.0406, 2.8768, 1.5887, 2.8472, 2.8274, 1.7004, 1.7073],\n",
            "        [2.0634, 2.9050, 1.5996, 2.8758, 2.8592, 1.7134, 1.7221],\n",
            "        [1.5675, 2.2987, 1.3235, 2.2759, 2.2310, 1.4413, 1.4106]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "200\n",
            "tensor([[3.1903, 4.1091, 2.1766, 4.0949, 4.1232, 2.3349, 2.4067],\n",
            "        [2.5146, 3.4269, 1.8383, 3.3977, 3.4094, 1.9450, 1.9973],\n",
            "        [2.6871, 3.5997, 1.9238, 3.5746, 3.5914, 2.0532, 2.1003],\n",
            "        [1.2585, 1.9110, 1.1489, 1.8980, 1.8340, 1.2505, 1.2126],\n",
            "        [1.8809, 2.6887, 1.5032, 2.6617, 2.6323, 1.6203, 1.6121]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "201\n",
            "tensor([[2.6139, 3.5378, 1.8880, 3.5071, 3.5236, 1.9995, 2.0591],\n",
            "        [1.7412, 2.5209, 1.4275, 2.4957, 2.4593, 1.5391, 1.5250],\n",
            "        [2.3998, 3.2959, 1.7783, 3.2664, 3.2708, 1.8914, 1.9288],\n",
            "        [0.8795, 1.4112, 0.9083, 1.4082, 1.3320, 0.9852, 0.9515],\n",
            "        [2.6770, 3.5977, 1.9199, 3.5684, 3.5855, 2.0400, 2.0946]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "202\n",
            "tensor([[3.1624, 4.0885, 2.1634, 4.0691, 4.1000, 2.3228, 2.3942],\n",
            "        [1.0809, 1.6812, 1.0368, 1.6721, 1.6030, 1.1315, 1.0930],\n",
            "        [1.4397, 2.1497, 1.2550, 2.1281, 2.0773, 1.3621, 1.3333],\n",
            "        [2.2731, 3.1553, 1.7126, 3.1251, 3.1160, 1.8297, 1.8575],\n",
            "        [1.2979, 1.9609, 1.1718, 1.9433, 1.8852, 1.2757, 1.2391]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "203\n",
            "tensor([[0.6888, 1.1539, 0.7748, 1.1555, 1.0754, 0.8310, 0.8141],\n",
            "        [1.3870, 2.0830, 1.2241, 2.0637, 2.0080, 1.3276, 1.3005],\n",
            "        [2.6364, 3.5602, 1.8975, 3.5313, 3.5432, 2.0093, 2.0760],\n",
            "        [2.5002, 3.4170, 1.8303, 3.3876, 3.3944, 1.9480, 1.9975],\n",
            "        [2.2150, 3.0945, 1.6833, 3.0645, 3.0544, 1.7923, 1.8243]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "204\n",
            "tensor([[1.6851, 2.4616, 1.3980, 2.4371, 2.3958, 1.5059, 1.4963],\n",
            "        [3.1881, 4.1170, 2.1777, 4.0963, 4.1218, 2.3538, 2.4194],\n",
            "        [2.1998, 3.0815, 1.6759, 3.0505, 3.0419, 1.7840, 1.8160],\n",
            "        [1.3127, 1.9930, 1.1819, 1.9768, 1.9160, 1.2868, 1.2572],\n",
            "        [0.9252, 1.4815, 0.9395, 1.4757, 1.4010, 1.0162, 0.9887]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "205\n",
            "tensor([[1.2097, 1.8602, 1.1211, 1.8476, 1.7799, 1.2207, 1.1877],\n",
            "        [2.6076, 3.5467, 1.8894, 3.5184, 3.5309, 1.9965, 2.0672],\n",
            "        [3.0676, 4.0090, 2.1166, 3.9888, 4.0130, 2.2636, 2.3494],\n",
            "        [1.3302, 2.0134, 1.1913, 1.9964, 1.9355, 1.2958, 1.2670],\n",
            "        [1.9608, 2.7975, 1.5502, 2.7694, 2.7422, 1.6654, 1.6719]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "206\n",
            "tensor([[0.9674, 1.5385, 0.9686, 1.5340, 1.4564, 1.0477, 1.0210],\n",
            "        [1.4619, 2.1861, 1.2738, 2.1660, 2.1120, 1.3749, 1.3552],\n",
            "        [3.0285, 3.9762, 2.1004, 3.9567, 3.9877, 2.2361, 2.3224],\n",
            "        [3.2177, 4.1579, 2.1970, 4.1413, 4.1680, 2.3593, 2.4406],\n",
            "        [1.3422, 2.0344, 1.1937, 2.0108, 1.9553, 1.2938, 1.2716]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "207\n",
            "tensor([[3.2409, 4.1759, 2.2068, 4.1585, 4.1754, 2.3791, 2.4606],\n",
            "        [2.7869, 3.7302, 1.9806, 3.7082, 3.7233, 2.1096, 2.1792],\n",
            "        [3.0002, 3.9494, 2.0862, 3.9329, 3.9593, 2.2177, 2.3079],\n",
            "        [1.3978, 2.1061, 1.2327, 2.0851, 2.0290, 1.3332, 1.3110],\n",
            "        [1.7309, 2.5262, 1.4240, 2.5003, 2.4600, 1.5334, 1.5297]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "208\n",
            "tensor([[1.9384, 2.7793, 1.5425, 2.7538, 2.7239, 1.6510, 1.6615],\n",
            "        [3.2238, 4.1620, 2.1997, 4.1482, 4.1701, 2.3669, 2.4479],\n",
            "        [3.2468, 4.1855, 2.2122, 4.1696, 4.1895, 2.3859, 2.4626],\n",
            "        [2.4228, 3.3463, 1.7985, 3.3191, 3.3141, 1.9141, 1.9608],\n",
            "        [0.9413, 1.5065, 0.9531, 1.5025, 1.4249, 1.0302, 1.0035]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "209\n",
            "tensor([[2.8526, 3.8110, 2.0167, 3.7917, 3.8106, 2.1372, 2.2210],\n",
            "        [0.8318, 1.3563, 0.8815, 1.3577, 1.2759, 0.9528, 0.9244],\n",
            "        [2.4424, 3.3715, 1.8095, 3.3458, 3.3456, 1.9103, 1.9700],\n",
            "        [2.6801, 3.6343, 1.9291, 3.6128, 3.6222, 2.0410, 2.1174],\n",
            "        [2.3298, 3.2329, 1.7486, 3.2096, 3.1983, 1.8676, 1.9037]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "210\n",
            "tensor([[2.3310, 3.2427, 1.7502, 3.2187, 3.2062, 1.8576, 1.9046],\n",
            "        [3.2504, 4.1887, 2.2140, 4.1758, 4.1909, 2.3894, 2.4671],\n",
            "        [0.9947, 1.5803, 0.9896, 1.5773, 1.4979, 1.0759, 1.0430],\n",
            "        [1.2125, 1.8712, 1.1233, 1.8585, 1.7885, 1.2225, 1.1913],\n",
            "        [0.7992, 1.3141, 0.8606, 1.3176, 1.2333, 0.9290, 0.9025]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "211\n",
            "tensor([[0.8335, 1.3638, 0.8839, 1.3663, 1.2805, 0.9559, 0.9285],\n",
            "        [2.8466, 3.8131, 2.0136, 3.7939, 3.8104, 2.1251, 2.2149],\n",
            "        [2.8895, 3.8525, 2.0339, 3.8354, 3.8525, 2.1585, 2.2420],\n",
            "        [1.6072, 2.3774, 1.3592, 2.3568, 2.3060, 1.4717, 1.4514],\n",
            "        [3.1079, 4.0639, 2.1469, 4.0528, 4.0734, 2.3029, 2.3782]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "212\n",
            "tensor([[3.2304, 4.1773, 2.2057, 4.1678, 4.1826, 2.3778, 2.4523],\n",
            "        [3.2065, 4.1500, 2.1919, 4.1360, 4.1500, 2.3687, 2.4426],\n",
            "        [2.5841, 3.5309, 1.8829, 3.5103, 3.5085, 1.9979, 2.0604],\n",
            "        [0.9020, 1.4565, 0.9306, 1.4559, 1.3724, 1.0065, 0.9768],\n",
            "        [0.9510, 1.5231, 0.9633, 1.5222, 1.4397, 1.0474, 1.0130]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "213\n",
            "tensor([[1.0937, 1.7125, 1.0514, 1.7066, 1.6293, 1.1435, 1.1090],\n",
            "        [2.6569, 3.6133, 1.9203, 3.5922, 3.5959, 2.0328, 2.1013],\n",
            "        [2.0980, 2.9715, 1.6292, 2.9477, 2.9187, 1.7417, 1.7595],\n",
            "        [1.6162, 2.3890, 1.3636, 2.3683, 2.3138, 1.4749, 1.4572],\n",
            "        [1.0490, 1.6536, 1.0251, 1.6511, 1.5700, 1.1154, 1.0799]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "214\n",
            "tensor([[1.0934, 1.7155, 1.0555, 1.7108, 1.6302, 1.1493, 1.1102],\n",
            "        [2.7274, 3.6890, 1.9553, 3.6666, 3.6729, 2.0708, 2.1411],\n",
            "        [1.1338, 1.7679, 1.0797, 1.7602, 1.6830, 1.1757, 1.1391],\n",
            "        [1.3798, 2.0890, 1.2257, 2.0740, 2.0068, 1.3338, 1.3034],\n",
            "        [2.2233, 3.1260, 1.6957, 3.1013, 3.0804, 1.8053, 1.8359]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "215\n",
            "tensor([[3.1204, 4.0796, 2.1497, 4.0659, 4.0779, 2.3046, 2.3812],\n",
            "        [3.1987, 4.1476, 2.1886, 4.1380, 4.1538, 2.3395, 2.4230],\n",
            "        [3.2417, 4.1870, 2.2112, 4.1759, 4.1872, 2.3825, 2.4543],\n",
            "        [1.5735, 2.3355, 1.3389, 2.3161, 2.2580, 1.4536, 1.4266],\n",
            "        [1.8937, 2.7344, 1.5198, 2.7101, 2.6704, 1.6325, 1.6311]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "216\n",
            "tensor([[3.1689, 4.1183, 2.1739, 4.0995, 4.1084, 2.3369, 2.4092],\n",
            "        [1.4432, 2.1750, 1.2673, 2.1568, 2.0920, 1.3697, 1.3423],\n",
            "        [2.0361, 2.9054, 1.5975, 2.8786, 2.8482, 1.7080, 1.7160],\n",
            "        [1.9423, 2.7908, 1.5476, 2.7639, 2.7268, 1.6600, 1.6574],\n",
            "        [1.6722, 2.4607, 1.3962, 2.4364, 2.3847, 1.5104, 1.4875]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "217\n",
            "tensor([[2.1061, 2.9855, 1.6353, 2.9587, 2.9305, 1.7461, 1.7569],\n",
            "        [1.7061, 2.5028, 1.4144, 2.4776, 2.4270, 1.5247, 1.5077],\n",
            "        [3.1436, 4.0961, 2.1605, 4.0804, 4.1006, 2.3009, 2.3809],\n",
            "        [3.2472, 4.1949, 2.2151, 4.1788, 4.1925, 2.3839, 2.4509],\n",
            "        [1.9590, 2.8112, 1.5539, 2.7820, 2.7481, 1.6624, 1.6649]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "218\n",
            "tensor([[1.6707, 2.4619, 1.3954, 2.4369, 2.3845, 1.5033, 1.4839],\n",
            "        [2.9071, 3.8748, 2.0428, 3.8518, 3.8698, 2.1653, 2.2393],\n",
            "        [3.2252, 4.1710, 2.1998, 4.1503, 4.1617, 2.3787, 2.4389],\n",
            "        [0.9130, 1.4729, 0.9360, 1.4703, 1.3873, 1.0144, 0.9796],\n",
            "        [0.8531, 1.3877, 0.8877, 1.3848, 1.3029, 0.9630, 0.9325]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "219\n",
            "tensor([[0.5675, 0.9972, 0.6988, 1.0036, 0.9177, 0.7406, 0.7270],\n",
            "        [1.1437, 1.7851, 1.0839, 1.7736, 1.6968, 1.1798, 1.1413],\n",
            "        [1.1462, 1.7859, 1.0857, 1.7732, 1.6973, 1.1785, 1.1406],\n",
            "        [1.0083, 1.6034, 0.9993, 1.5972, 1.5146, 1.0840, 1.0463],\n",
            "        [2.7447, 3.7157, 1.9609, 3.6846, 3.6958, 2.0676, 2.1410]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "220\n",
            "tensor([[2.4459, 3.3761, 1.8083, 3.3463, 3.3354, 1.9291, 1.9610],\n",
            "        [1.5369, 2.2940, 1.3159, 2.2685, 2.2112, 1.4280, 1.3965],\n",
            "        [3.2110, 4.1625, 2.1938, 4.1422, 4.1562, 2.3579, 2.4241],\n",
            "        [0.9104, 1.4719, 0.9367, 1.4687, 1.3831, 1.0136, 0.9782],\n",
            "        [2.7321, 3.6971, 1.9530, 3.6673, 3.6719, 2.0700, 2.1339]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "221\n",
            "tensor([[2.9864, 3.9486, 2.0790, 3.9232, 3.9276, 2.2216, 2.2900],\n",
            "        [2.4186, 3.3525, 1.7962, 3.3204, 3.3073, 1.9084, 1.9438],\n",
            "        [0.8530, 1.3938, 0.8993, 1.3919, 1.3046, 0.9733, 0.9371],\n",
            "        [1.9841, 2.8486, 1.5682, 2.8162, 2.7801, 1.6768, 1.6773],\n",
            "        [3.2211, 4.1691, 2.1941, 4.1449, 4.1541, 2.3646, 2.4309]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "222\n",
            "tensor([[2.2287, 3.1312, 1.6915, 3.0985, 3.0744, 1.8131, 1.8286],\n",
            "        [3.2337, 4.1813, 2.2018, 4.1569, 4.1694, 2.3719, 2.4354],\n",
            "        [1.4707, 2.2128, 1.2794, 2.1873, 2.1240, 1.3818, 1.3545],\n",
            "        [2.7046, 3.6603, 1.9392, 3.6304, 3.6320, 2.0655, 2.1128],\n",
            "        [1.5049, 2.2534, 1.2993, 2.2278, 2.1685, 1.4051, 1.3742]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "223\n",
            "tensor([[3.2273, 4.1688, 2.1951, 4.1471, 4.1506, 2.3783, 2.4372],\n",
            "        [1.0154, 1.6150, 1.0017, 1.6069, 1.5231, 1.0887, 1.0495],\n",
            "        [0.8267, 1.3563, 0.8784, 1.3550, 1.2674, 0.9531, 0.9166],\n",
            "        [3.1162, 4.0684, 2.1420, 4.0467, 4.0644, 2.2787, 2.3580],\n",
            "        [3.0370, 3.9956, 2.1014, 3.9751, 3.9896, 2.2501, 2.3131]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "224\n",
            "tensor([[0.8344, 1.3677, 0.8850, 1.3663, 1.2785, 0.9611, 0.9227],\n",
            "        [3.1146, 4.0683, 2.1421, 4.0495, 4.0645, 2.3053, 2.3600],\n",
            "        [2.6949, 3.6544, 1.9316, 3.6245, 3.6277, 2.0513, 2.1076],\n",
            "        [1.9170, 2.7612, 1.5278, 2.7325, 2.6901, 1.6506, 1.6364],\n",
            "        [2.0231, 2.8872, 1.5849, 2.8574, 2.8205, 1.7055, 1.7015]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "225\n",
            "tensor([[2.9115, 3.8739, 2.0390, 3.8472, 3.8566, 2.1706, 2.2351],\n",
            "        [2.6490, 3.6056, 1.9060, 3.5746, 3.5755, 2.0219, 2.0797],\n",
            "        [3.2058, 4.1541, 2.1844, 4.1365, 4.1451, 2.3638, 2.4200],\n",
            "        [2.1650, 3.0554, 1.6599, 3.0243, 2.9962, 1.7797, 1.7885],\n",
            "        [2.1222, 3.0047, 1.6365, 2.9747, 2.9442, 1.7584, 1.7629]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "226\n",
            "tensor([[2.3470, 3.2671, 1.7514, 3.2362, 3.2181, 1.8712, 1.8982],\n",
            "        [2.8117, 3.7754, 1.9867, 3.7485, 3.7550, 2.1190, 2.1777],\n",
            "        [2.4467, 3.3706, 1.8024, 3.3426, 3.3276, 1.9326, 1.9591],\n",
            "        [3.1430, 4.0924, 2.1515, 4.0754, 4.0851, 2.3262, 2.3800],\n",
            "        [3.2132, 4.1528, 2.1824, 4.1333, 4.1388, 2.3679, 2.4257]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "227\n",
            "tensor([[2.7227, 3.6726, 1.9393, 3.6482, 3.6454, 2.0770, 2.1274],\n",
            "        [2.3253, 3.2409, 1.7397, 3.2131, 3.1909, 1.8687, 1.8892],\n",
            "        [3.1296, 4.0769, 2.1424, 4.0622, 4.0735, 2.3117, 2.3703],\n",
            "        [2.9630, 3.9170, 2.0584, 3.8984, 3.9045, 2.2154, 2.2729],\n",
            "        [1.1509, 1.7905, 1.0856, 1.7813, 1.6995, 1.1880, 1.1431]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "228\n",
            "tensor([[3.1802, 4.1104, 2.1610, 4.0925, 4.1003, 2.3542, 2.4024],\n",
            "        [2.2269, 3.1266, 1.6892, 3.0982, 3.0714, 1.8127, 1.8273],\n",
            "        [0.6891, 1.1645, 0.7831, 1.1710, 1.0796, 0.8488, 0.8178],\n",
            "        [1.2235, 1.8870, 1.1295, 1.8770, 1.7975, 1.2422, 1.1946],\n",
            "        [2.4078, 3.3273, 1.7798, 3.3007, 3.2811, 1.9198, 1.9395]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "229\n",
            "tensor([[1.4152, 2.1337, 1.2429, 2.1190, 2.0466, 1.3606, 1.3205],\n",
            "        [2.4798, 3.4128, 1.8184, 3.3875, 3.3733, 1.9443, 1.9820],\n",
            "        [2.9759, 3.9325, 2.0616, 3.9164, 3.9237, 2.2092, 2.2780],\n",
            "        [2.6504, 3.5954, 1.9008, 3.5733, 3.5644, 2.0435, 2.0879],\n",
            "        [1.3852, 2.0955, 1.2275, 2.0828, 2.0075, 1.3472, 1.3011]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "230\n",
            "tensor([[2.5339, 3.4695, 1.8422, 3.4479, 3.4333, 1.9762, 2.0162],\n",
            "        [0.8509, 1.3879, 0.8936, 1.3913, 1.2993, 0.9768, 0.9371],\n",
            "        [2.5447, 3.4787, 1.8475, 3.4568, 3.4411, 1.9919, 2.0251],\n",
            "        [1.1372, 1.7714, 1.0738, 1.7644, 1.6804, 1.1843, 1.1352],\n",
            "        [2.7237, 3.6745, 1.9338, 3.6529, 3.6470, 2.0650, 2.1282]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "231\n",
            "tensor([[0.9406, 1.5101, 0.9526, 1.5108, 1.4197, 1.0444, 1.0017],\n",
            "        [2.0029, 2.8595, 1.5662, 2.8380, 2.7928, 1.7000, 1.6941],\n",
            "        [1.7194, 2.5164, 1.4137, 2.4986, 2.4375, 1.5437, 1.5178],\n",
            "        [1.2605, 1.9349, 1.1520, 1.9275, 1.8452, 1.2668, 1.2210],\n",
            "        [2.4533, 3.3798, 1.7985, 3.3583, 3.3362, 1.9347, 1.9699]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "232\n",
            "tensor([[0.8827, 1.4307, 0.9150, 1.4351, 1.3396, 1.0034, 0.9616],\n",
            "        [3.2077, 4.1364, 2.1694, 4.1279, 4.1220, 2.3659, 2.4295],\n",
            "        [1.3410, 2.0378, 1.1967, 2.0273, 1.9483, 1.3178, 1.2740],\n",
            "        [2.0345, 2.8933, 1.5810, 2.8732, 2.8270, 1.7196, 1.7147],\n",
            "        [2.0359, 2.8965, 1.5828, 2.8776, 2.8323, 1.7219, 1.7175]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "233\n",
            "tensor([[2.7484, 3.7039, 1.9458, 3.6874, 3.6808, 2.0782, 2.1468],\n",
            "        [1.9797, 2.8259, 1.5517, 2.8076, 2.7582, 1.6927, 1.6808],\n",
            "        [1.1776, 1.8251, 1.0991, 1.8171, 1.7327, 1.2084, 1.1641],\n",
            "        [1.7981, 2.6102, 1.4557, 2.5916, 2.5338, 1.5870, 1.5667],\n",
            "        [2.9732, 3.9182, 2.0545, 3.9098, 3.9076, 2.2104, 2.2817]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "234\n",
            "tensor([[1.0599, 1.6690, 1.0272, 1.6676, 1.5765, 1.1295, 1.0863],\n",
            "        [1.3292, 2.0174, 1.1866, 2.0093, 1.9280, 1.3089, 1.2658],\n",
            "        [1.7187, 2.5098, 1.4070, 2.4931, 2.4304, 1.5417, 1.5170],\n",
            "        [1.1252, 1.7503, 1.0577, 1.7412, 1.6577, 1.1714, 1.1243],\n",
            "        [1.6252, 2.3936, 1.3546, 2.3771, 2.3102, 1.4908, 1.4579]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "235\n",
            "tensor([[2.8765, 3.8250, 2.0043, 3.8140, 3.8078, 2.1566, 2.2249],\n",
            "        [3.0875, 4.0288, 2.1081, 4.0240, 4.0191, 2.2908, 2.3562],\n",
            "        [1.6316, 2.4011, 1.3618, 2.3858, 2.3179, 1.4940, 1.4610],\n",
            "        [1.9530, 2.7984, 1.5376, 2.7811, 2.7297, 1.6720, 1.6656],\n",
            "        [2.9043, 3.8624, 2.0185, 3.8496, 3.8509, 2.1600, 2.2400]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "236\n",
            "tensor([[3.2189, 4.1446, 2.1730, 4.1449, 4.1367, 2.3736, 2.4374],\n",
            "        [2.1661, 3.0473, 1.6496, 3.0315, 2.9902, 1.7883, 1.7979],\n",
            "        [0.9591, 1.5312, 0.9616, 1.5348, 1.4400, 1.0597, 1.0158],\n",
            "        [2.7158, 3.6500, 1.9248, 3.6384, 3.6249, 2.0769, 2.1314],\n",
            "        [2.5472, 3.4825, 1.8440, 3.4682, 3.4482, 1.9850, 2.0294]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "237\n",
            "tensor([[2.7744, 3.7265, 1.9549, 3.7133, 3.7049, 2.0926, 2.1613],\n",
            "        [2.7013, 3.6449, 1.9166, 3.6322, 3.6198, 2.0485, 2.1183],\n",
            "        [1.0512, 1.6542, 1.0213, 1.6549, 1.5630, 1.1229, 1.0785],\n",
            "        [2.9421, 3.8897, 2.0340, 3.8828, 3.8808, 2.1805, 2.2617],\n",
            "        [3.2022, 4.1286, 2.1621, 4.1302, 4.1249, 2.3558, 2.4256]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "238\n",
            "tensor([[3.1896, 4.1164, 2.1526, 4.1174, 4.1157, 2.3408, 2.4143],\n",
            "        [0.6998, 1.1771, 0.7909, 1.1885, 1.0904, 0.8586, 0.8293],\n",
            "        [1.8104, 2.6232, 1.4550, 2.6065, 2.5477, 1.5847, 1.5749],\n",
            "        [1.7265, 2.5173, 1.4109, 2.5047, 2.4391, 1.5438, 1.5233],\n",
            "        [2.5054, 3.4291, 1.8164, 3.4160, 3.3888, 1.9596, 2.0036]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "239\n",
            "tensor([[0.8961, 1.4459, 0.9194, 1.4524, 1.3550, 1.0106, 0.9712],\n",
            "        [2.3260, 3.2241, 1.7238, 3.2105, 3.1719, 1.8632, 1.8936],\n",
            "        [2.4597, 3.3781, 1.7899, 3.3643, 3.3370, 1.9209, 1.9746],\n",
            "        [1.1854, 1.8282, 1.0974, 1.8264, 1.7372, 1.2090, 1.1682],\n",
            "        [1.1514, 1.7869, 1.0792, 1.7847, 1.6953, 1.1874, 1.1469]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "240\n",
            "tensor([[3.2185, 4.1331, 2.1581, 4.1359, 4.1203, 2.3609, 2.4380],\n",
            "        [3.1608, 4.0883, 2.1315, 4.0887, 4.0818, 2.3147, 2.3972],\n",
            "        [1.1861, 1.8303, 1.0980, 1.8282, 1.7377, 1.2072, 1.1696],\n",
            "        [3.2190, 4.1328, 2.1572, 4.1308, 4.1145, 2.3651, 2.4396],\n",
            "        [2.4899, 3.4109, 1.8033, 3.3989, 3.3699, 1.9335, 1.9930]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "241\n",
            "tensor([[0.9479, 1.5134, 0.9502, 1.5195, 1.4223, 1.0447, 1.0066],\n",
            "        [0.9443, 1.5085, 0.9475, 1.5131, 1.4167, 1.0370, 1.0031],\n",
            "        [2.9793, 3.9172, 2.0375, 3.9163, 3.9052, 2.1828, 2.2845],\n",
            "        [2.8750, 3.8124, 1.9882, 3.8096, 3.7962, 2.1372, 2.2234],\n",
            "        [1.6467, 2.4170, 1.3620, 2.4076, 2.3349, 1.4927, 1.4743]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "242\n",
            "tensor([[3.1916, 4.1093, 2.1403, 4.1155, 4.1105, 2.3256, 2.4122],\n",
            "        [2.5726, 3.5034, 1.8390, 3.4919, 3.4697, 1.9678, 2.0394],\n",
            "        [0.9665, 1.5364, 0.9616, 1.5433, 1.4455, 1.0570, 1.0197],\n",
            "        [1.1567, 1.7869, 1.0724, 1.7856, 1.6935, 1.1769, 1.1463],\n",
            "        [2.9178, 3.8585, 2.0063, 3.8552, 3.8485, 2.1456, 2.2448]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "243\n",
            "tensor([[0.7512, 1.2426, 0.8198, 1.2555, 1.1562, 0.8927, 0.8647],\n",
            "        [0.8154, 1.3300, 0.8611, 1.3420, 1.2420, 0.9423, 0.9121],\n",
            "        [1.5691, 2.3166, 1.3141, 2.3089, 2.2343, 1.4395, 1.4194],\n",
            "        [2.1434, 3.0069, 1.6182, 2.9972, 2.9483, 1.7511, 1.7805],\n",
            "        [2.6774, 3.6027, 1.8861, 3.5954, 3.5748, 2.0263, 2.1025]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "244\n",
            "tensor([[2.7678, 3.7011, 1.9296, 3.6959, 3.6815, 2.0603, 2.1522],\n",
            "        [3.2432, 4.1482, 2.1591, 4.1540, 4.1356, 2.3590, 2.4489],\n",
            "        [0.7201, 1.2005, 0.7957, 1.2122, 1.1143, 0.8630, 0.8408],\n",
            "        [1.7351, 2.5191, 1.4035, 2.5102, 2.4422, 1.5277, 1.5231],\n",
            "        [1.6190, 2.3734, 1.3401, 2.3668, 2.2922, 1.4626, 1.4493]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "245\n",
            "tensor([[0.7619, 1.2569, 0.8254, 1.2675, 1.1691, 0.8947, 0.8716],\n",
            "        [2.1335, 2.9881, 1.6121, 2.9789, 2.9299, 1.7388, 1.7680],\n",
            "        [2.7010, 3.6287, 1.8965, 3.6249, 3.6051, 2.0241, 2.1147],\n",
            "        [2.9176, 3.8380, 2.0005, 3.8408, 3.8254, 2.1494, 2.2436],\n",
            "        [2.3721, 3.2607, 1.7346, 3.2549, 3.2190, 1.8652, 1.9150]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "246\n",
            "tensor([[2.5599, 3.4577, 1.8231, 3.4557, 3.4220, 1.9470, 2.0281],\n",
            "        [2.6789, 3.5923, 1.8851, 3.5917, 3.5694, 2.0201, 2.0999],\n",
            "        [1.5431, 2.2743, 1.2963, 2.2702, 2.1936, 1.4122, 1.4001],\n",
            "        [2.6759, 3.5923, 1.8844, 3.5899, 3.5713, 2.0116, 2.0973],\n",
            "        [1.7240, 2.4983, 1.3967, 2.4919, 2.4231, 1.5205, 1.5159]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "247\n",
            "tensor([[2.1918, 3.0486, 1.6424, 3.0441, 2.9985, 1.7637, 1.8043],\n",
            "        [1.1354, 1.7494, 1.0622, 1.7555, 1.6624, 1.1580, 1.1308],\n",
            "        [1.4422, 2.1454, 1.2420, 2.1435, 2.0631, 1.3495, 1.3339],\n",
            "        [1.2368, 1.8803, 1.1236, 1.8861, 1.7945, 1.2279, 1.2011],\n",
            "        [3.1798, 4.0770, 2.1255, 4.0891, 4.0773, 2.2995, 2.4022]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "248\n",
            "tensor([[0.7881, 1.2841, 0.8459, 1.2997, 1.1996, 0.9118, 0.8894],\n",
            "        [0.8770, 1.4048, 0.9042, 1.4207, 1.3197, 0.9811, 0.9541],\n",
            "        [1.1537, 1.7713, 1.0756, 1.7803, 1.6857, 1.1730, 1.1451],\n",
            "        [1.0835, 1.6785, 1.0287, 1.6864, 1.5932, 1.1254, 1.0955],\n",
            "        [2.7918, 3.7091, 1.9404, 3.7121, 3.6964, 2.0583, 2.1652]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "249\n",
            "tensor([[0.7085, 1.1733, 0.7882, 1.1903, 1.0918, 0.8487, 0.8304],\n",
            "        [2.6200, 3.5149, 1.8549, 3.5191, 3.4912, 1.9774, 2.0638],\n",
            "        [2.7831, 3.6940, 1.9358, 3.6983, 3.6833, 2.0533, 2.1590],\n",
            "        [2.7056, 3.6150, 1.8972, 3.6170, 3.5953, 2.0079, 2.1140],\n",
            "        [2.9727, 3.8846, 2.0255, 3.8940, 3.8892, 2.1382, 2.2687]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "250\n",
            "tensor([[1.2542, 1.8950, 1.1319, 1.9009, 1.8120, 1.2332, 1.2096],\n",
            "        [0.8327, 1.3404, 0.8715, 1.3560, 1.2566, 0.9416, 0.9201],\n",
            "        [2.3085, 3.1690, 1.6996, 3.1696, 3.1267, 1.8144, 1.8756],\n",
            "        [1.3842, 2.0626, 1.2080, 2.0645, 1.9824, 1.3101, 1.2946],\n",
            "        [3.2025, 4.0903, 2.1379, 4.1065, 4.0990, 2.2965, 2.4110]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "251\n",
            "tensor([[2.3334, 3.1986, 1.7158, 3.2001, 3.1605, 1.8198, 1.8876],\n",
            "        [1.6230, 2.3560, 1.3413, 2.3565, 2.2833, 1.4453, 1.4465],\n",
            "        [1.6271, 2.3610, 1.3442, 2.3619, 2.2885, 1.4504, 1.4510],\n",
            "        [2.4750, 3.3483, 1.7810, 3.3529, 3.3172, 1.8941, 1.9739],\n",
            "        [0.7675, 1.2487, 0.8297, 1.2673, 1.1671, 0.8936, 0.8724]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "252\n",
            "tensor([[3.2620, 4.1324, 2.1624, 4.1515, 4.1337, 2.3367, 2.4504],\n",
            "        [3.0903, 3.9723, 2.0770, 3.9952, 3.9818, 2.2102, 2.3404],\n",
            "        [1.4044, 2.0794, 1.2177, 2.0858, 2.0012, 1.3213, 1.3069],\n",
            "        [3.2093, 4.0820, 2.1349, 4.1058, 4.0944, 2.2778, 2.4112],\n",
            "        [1.0637, 1.6432, 1.0178, 1.6565, 1.5600, 1.1054, 1.0822]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "253\n",
            "tensor([[2.3387, 3.1810, 1.7066, 3.1854, 3.1412, 1.8277, 1.8903],\n",
            "        [2.4709, 3.3379, 1.7775, 3.3462, 3.3108, 1.8869, 1.9692],\n",
            "        [2.8785, 3.7682, 1.9737, 3.7838, 3.7678, 2.0883, 2.2110],\n",
            "        [3.2529, 4.1194, 2.1562, 4.1437, 4.1295, 2.3181, 2.4405],\n",
            "        [1.8704, 2.6487, 1.4748, 2.6536, 2.5883, 1.5804, 1.6026]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "254\n",
            "tensor([[3.0635, 3.9364, 2.0594, 3.9597, 3.9442, 2.1956, 2.3214],\n",
            "        [2.9252, 3.8077, 1.9933, 3.8251, 3.8092, 2.1124, 2.2369],\n",
            "        [3.1211, 3.9965, 2.0885, 4.0178, 4.0096, 2.2256, 2.3533],\n",
            "        [2.2021, 3.0355, 1.6406, 3.0389, 2.9924, 1.7448, 1.8032],\n",
            "        [3.2721, 4.1298, 2.1598, 4.1517, 4.1331, 2.3386, 2.4555]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "255\n",
            "tensor([[2.6348, 3.5065, 1.8523, 3.5180, 3.4895, 1.9681, 2.0659],\n",
            "        [2.4225, 3.2761, 1.7488, 3.2838, 3.2477, 1.8575, 1.9364],\n",
            "        [1.8328, 2.5914, 1.4467, 2.5960, 2.5293, 1.5635, 1.5756],\n",
            "        [2.1445, 2.9641, 1.6120, 2.9701, 2.9188, 1.7206, 1.7698],\n",
            "        [1.6175, 2.3345, 1.3309, 2.3398, 2.2638, 1.4399, 1.4411]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "256\n",
            "tensor([[0.8364, 1.3318, 0.8715, 1.3528, 1.2520, 0.9431, 0.9207],\n",
            "        [2.9894, 3.8675, 2.0205, 3.8869, 3.8738, 2.1360, 2.2747],\n",
            "        [2.3231, 3.1624, 1.6991, 3.1702, 3.1279, 1.8100, 1.8777],\n",
            "        [3.2236, 4.0797, 2.1354, 4.1074, 4.0934, 2.3035, 2.4205],\n",
            "        [3.2746, 4.1236, 2.1570, 4.1494, 4.1346, 2.3366, 2.4543]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "257\n",
            "tensor([[2.5104, 3.3624, 1.7936, 3.3750, 3.3432, 1.9063, 1.9890],\n",
            "        [0.9081, 1.4264, 0.9183, 1.4472, 1.3461, 0.9983, 0.9725],\n",
            "        [2.5101, 3.3686, 1.7935, 3.3783, 3.3440, 1.9078, 1.9914],\n",
            "        [2.8512, 3.7241, 1.9562, 3.7405, 3.7232, 2.0852, 2.1941],\n",
            "        [2.4543, 3.3039, 1.7646, 3.3140, 3.2763, 1.8827, 1.9582]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "258\n",
            "tensor([[1.2779, 1.9067, 1.1426, 1.9183, 1.8277, 1.2450, 1.2234],\n",
            "        [2.8846, 3.7636, 1.9721, 3.7812, 3.7693, 2.0804, 2.2106],\n",
            "        [0.9758, 1.5149, 0.9616, 1.5342, 1.4344, 1.0471, 1.0189],\n",
            "        [1.3126, 1.9493, 1.1607, 1.9603, 1.8719, 1.2645, 1.2447],\n",
            "        [2.8879, 3.7637, 1.9736, 3.7815, 3.7677, 2.0911, 2.2144]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "259\n",
            "tensor([[0.8243, 1.3126, 0.8654, 1.3351, 1.2330, 0.9386, 0.9123],\n",
            "        [1.3419, 1.9862, 1.1805, 1.9975, 1.9103, 1.2836, 1.2646],\n",
            "        [0.7924, 1.2706, 0.8430, 1.2914, 1.1909, 0.9125, 0.8884],\n",
            "        [2.0080, 2.7952, 1.5435, 2.8024, 2.7432, 1.6542, 1.6863],\n",
            "        [1.4100, 2.0707, 1.2186, 2.0820, 1.9954, 1.3271, 1.3093]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "260\n",
            "tensor([[1.4819, 2.1596, 1.2609, 2.1716, 2.0878, 1.3739, 1.3569],\n",
            "        [1.3311, 1.9671, 1.1725, 1.9784, 1.8886, 1.2780, 1.2547],\n",
            "        [1.2318, 1.8440, 1.1185, 1.8589, 1.7651, 1.2180, 1.1929],\n",
            "        [2.9834, 3.8514, 2.0217, 3.8745, 3.8588, 2.1491, 2.2727],\n",
            "        [2.9281, 3.7970, 1.9959, 3.8195, 3.8032, 2.1254, 2.2391]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "261\n",
            "tensor([[3.2615, 4.0950, 2.1516, 4.1211, 4.1005, 2.3464, 2.4495],\n",
            "        [0.8850, 1.3912, 0.9024, 1.4113, 1.3113, 0.9836, 0.9543],\n",
            "        [2.6306, 3.4881, 1.8529, 3.5067, 3.4758, 1.9727, 2.0641],\n",
            "        [3.0518, 3.9128, 2.0551, 3.9403, 3.9293, 2.1787, 2.3087],\n",
            "        [3.2653, 4.0972, 2.1531, 4.1248, 4.1025, 2.3517, 2.4514]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "262\n",
            "tensor([[2.4722, 3.3093, 1.7750, 3.3242, 3.2873, 1.8965, 1.9661],\n",
            "        [1.9260, 2.6910, 1.5018, 2.7026, 2.6372, 1.6202, 1.6356],\n",
            "        [0.7865, 1.2577, 0.8414, 1.2809, 1.1797, 0.9117, 0.8836],\n",
            "        [3.1943, 4.0408, 2.1245, 4.0739, 4.0628, 2.2795, 2.3962],\n",
            "        [1.0258, 1.5747, 0.9964, 1.5953, 1.4939, 1.0860, 1.0533]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "263\n",
            "tensor([[2.4813, 3.3229, 1.7829, 3.3398, 3.2996, 1.8985, 1.9716],\n",
            "        [3.0097, 3.8698, 2.0354, 3.8963, 3.8832, 2.1692, 2.2833],\n",
            "        [1.5464, 2.2317, 1.2953, 2.2448, 2.1623, 1.4139, 1.3974],\n",
            "        [3.2685, 4.1035, 2.1605, 4.1388, 4.1258, 2.3348, 2.4443],\n",
            "        [2.9024, 3.7566, 1.9850, 3.7811, 3.7614, 2.1225, 2.2210]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "264\n",
            "tensor([[2.8321, 3.6896, 1.9524, 3.7134, 3.6914, 2.0782, 2.1780],\n",
            "        [0.7412, 1.1959, 0.8113, 1.2202, 1.1188, 0.8783, 0.8504],\n",
            "        [0.9922, 1.5274, 0.9724, 1.5483, 1.4492, 1.0638, 1.0293],\n",
            "        [2.8719, 3.7302, 1.9728, 3.7539, 3.7345, 2.1036, 2.2046],\n",
            "        [1.7592, 2.4891, 1.4149, 2.5026, 2.4279, 1.5356, 1.5312]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "265\n",
            "tensor([[2.1929, 2.9958, 1.6430, 3.0103, 2.9576, 1.7598, 1.7974],\n",
            "        [1.1666, 1.7535, 1.0796, 1.7709, 1.6776, 1.1811, 1.1465],\n",
            "        [2.3660, 3.1823, 1.7238, 3.1983, 3.1536, 1.8610, 1.9020],\n",
            "        [2.9375, 3.7951, 2.0043, 3.8211, 3.8039, 2.1311, 2.2405],\n",
            "        [3.2610, 4.0920, 2.1584, 4.1284, 4.1122, 2.3357, 2.4385]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "266\n",
            "tensor([[1.4148, 2.0664, 1.2284, 2.0828, 1.9940, 1.3406, 1.3125],\n",
            "        [1.5654, 2.2463, 1.3097, 2.2626, 2.1787, 1.4321, 1.4073],\n",
            "        [0.7267, 1.1756, 0.8025, 1.2019, 1.0998, 0.8732, 0.8424],\n",
            "        [2.8990, 3.7603, 1.9854, 3.7856, 3.7689, 2.1089, 2.2170],\n",
            "        [1.6744, 2.3830, 1.3688, 2.3977, 2.3191, 1.4898, 1.4763]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "267\n",
            "tensor([[1.4447, 2.0998, 1.2431, 2.1169, 2.0284, 1.3632, 1.3295],\n",
            "        [1.6189, 2.3163, 1.3427, 2.3331, 2.2516, 1.4629, 1.4429],\n",
            "        [2.1896, 2.9831, 1.6384, 3.0000, 2.9446, 1.7700, 1.7936],\n",
            "        [3.1728, 4.0014, 2.1150, 4.0379, 4.0166, 2.2825, 2.3820],\n",
            "        [1.0701, 1.6275, 1.0236, 1.6492, 1.5493, 1.1236, 1.0832]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "268\n",
            "tensor([[2.4006, 3.2241, 1.7487, 3.2449, 3.1999, 1.8845, 1.9221],\n",
            "        [3.2307, 4.0585, 2.1465, 4.0996, 4.0817, 2.3279, 2.4172],\n",
            "        [1.6541, 2.3567, 1.3593, 2.3718, 2.2919, 1.4832, 1.4627],\n",
            "        [2.2982, 3.1037, 1.6945, 3.1241, 3.0739, 1.8275, 1.8597],\n",
            "        [1.2581, 1.8689, 1.1374, 1.8877, 1.7931, 1.2488, 1.2085]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "269\n",
            "tensor([[2.7520, 3.5989, 1.9166, 3.6267, 3.5959, 2.0547, 2.1319],\n",
            "        [1.4675, 2.1314, 1.2605, 2.1492, 2.0599, 1.3818, 1.3477],\n",
            "        [2.8073, 3.6605, 1.9455, 3.6882, 3.6634, 2.0846, 2.1627],\n",
            "        [2.0040, 2.7749, 1.5474, 2.7935, 2.7269, 1.6801, 1.6832],\n",
            "        [0.8221, 1.3016, 0.8681, 1.3294, 1.2252, 0.9496, 0.9116]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "270\n",
            "tensor([[2.3173, 3.1260, 1.7064, 3.1495, 3.0945, 1.8489, 1.8740],\n",
            "        [2.3579, 3.1674, 1.7270, 3.1954, 3.1425, 1.8723, 1.8987],\n",
            "        [1.8446, 2.5871, 1.4658, 2.6069, 2.5320, 1.6006, 1.5852],\n",
            "        [1.3374, 1.9655, 1.1840, 1.9865, 1.8923, 1.3049, 1.2621],\n",
            "        [1.0558, 1.6065, 1.0130, 1.6290, 1.5280, 1.1144, 1.0704]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "271\n",
            "tensor([[0.7468, 1.2023, 0.8189, 1.2321, 1.1271, 0.8934, 0.8590],\n",
            "        [1.0593, 1.6106, 1.0186, 1.6358, 1.5334, 1.1254, 1.0768],\n",
            "        [2.6733, 3.5126, 1.8816, 3.5432, 3.5060, 2.0266, 2.0869],\n",
            "        [0.9640, 1.4895, 0.9613, 1.5179, 1.4121, 1.0585, 1.0136],\n",
            "        [0.6182, 1.0294, 0.7320, 1.0591, 0.9558, 0.7909, 0.7646]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "272\n",
            "tensor([[2.7355, 3.5804, 1.9120, 3.6117, 3.5791, 2.0558, 2.1231],\n",
            "        [2.8001, 3.6520, 1.9445, 3.6840, 3.6546, 2.0904, 2.1645],\n",
            "        [0.8900, 1.3915, 0.9144, 1.4216, 1.3151, 1.0054, 0.9622],\n",
            "        [1.6053, 2.2993, 1.3380, 2.3196, 2.2347, 1.4653, 1.4370],\n",
            "        [3.1402, 3.9686, 2.1032, 4.0119, 3.9894, 2.2710, 2.3650]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "273\n",
            "tensor([[3.0109, 3.8608, 2.0436, 3.8979, 3.8787, 2.1994, 2.2849],\n",
            "        [1.5951, 2.2850, 1.3305, 2.3067, 2.2190, 1.4674, 1.4314],\n",
            "        [1.1073, 1.6754, 1.0511, 1.7025, 1.5982, 1.1599, 1.1127],\n",
            "        [3.2725, 4.0975, 2.1708, 4.1413, 4.1191, 2.3724, 2.4473],\n",
            "        [2.1177, 2.9080, 1.6090, 2.9293, 2.8676, 1.7410, 1.7563]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "274\n",
            "tensor([[2.8305, 3.6872, 1.9594, 3.7182, 3.6947, 2.0954, 2.1774],\n",
            "        [3.2915, 4.1099, 2.1774, 4.1524, 4.1247, 2.3975, 2.4635],\n",
            "        [3.2699, 4.0922, 2.1684, 4.1384, 4.1136, 2.3672, 2.4467],\n",
            "        [1.2927, 1.9128, 1.1614, 1.9353, 1.8374, 1.2823, 1.2357],\n",
            "        [1.3711, 2.0084, 1.2001, 2.0273, 1.9341, 1.3226, 1.2829]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "275\n",
            "tensor([[2.6215, 3.4533, 1.8565, 3.4817, 3.4412, 2.0114, 2.0570],\n",
            "        [2.9265, 3.7764, 2.0045, 3.8114, 3.7896, 2.1594, 2.2349],\n",
            "        [1.3569, 1.9924, 1.1994, 2.0152, 1.9185, 1.3276, 1.2792],\n",
            "        [0.9017, 1.4105, 0.9212, 1.4354, 1.3307, 1.0133, 0.9690],\n",
            "        [3.2605, 4.0862, 2.1627, 4.1286, 4.1087, 2.3604, 2.4366]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "276\n",
            "tensor([[2.7927, 3.6533, 1.9426, 3.6829, 3.6526, 2.0754, 2.1562],\n",
            "        [3.2516, 4.0821, 2.1613, 4.1251, 4.1029, 2.3581, 2.4347],\n",
            "        [2.5687, 3.4019, 1.8319, 3.4314, 3.3894, 1.9852, 2.0267],\n",
            "        [3.2894, 4.1121, 2.1801, 4.1532, 4.1302, 2.3956, 2.4580],\n",
            "        [1.9300, 2.6898, 1.5134, 2.7099, 2.6366, 1.6568, 1.6416]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "277\n",
            "tensor([[2.4020, 3.2269, 1.7534, 3.2517, 3.2013, 1.8944, 1.9259],\n",
            "        [3.1421, 3.9848, 2.1086, 4.0232, 4.0041, 2.2740, 2.3617],\n",
            "        [2.2517, 3.0585, 1.6782, 3.0806, 3.0217, 1.8242, 1.8383],\n",
            "        [1.0460, 1.5988, 1.0160, 1.6239, 1.5188, 1.1185, 1.0710],\n",
            "        [2.5944, 3.4344, 1.8478, 3.4615, 3.4224, 1.9937, 2.0396]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "278\n",
            "tensor([[0.7104, 1.1563, 0.7993, 1.1856, 1.0790, 0.8726, 0.8346],\n",
            "        [2.5465, 3.3898, 1.8263, 3.4143, 3.3714, 1.9661, 2.0119],\n",
            "        [2.0161, 2.7880, 1.5587, 2.8062, 2.7366, 1.6977, 1.6920],\n",
            "        [3.2883, 4.1100, 2.1783, 4.1486, 4.1246, 2.3985, 2.4590],\n",
            "        [2.9980, 3.8486, 2.0401, 3.8837, 3.8632, 2.1995, 2.2759]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "279\n",
            "tensor([[2.3336, 3.1564, 1.7215, 3.1773, 3.1236, 1.8621, 1.8856],\n",
            "        [3.0740, 3.9215, 2.0746, 3.9549, 3.9394, 2.2238, 2.3190],\n",
            "        [2.6091, 3.4612, 1.8554, 3.4853, 3.4477, 1.9947, 2.0490],\n",
            "        [2.9213, 3.7762, 2.0053, 3.8065, 3.7814, 2.1603, 2.2321],\n",
            "        [1.4740, 2.1416, 1.2661, 2.1589, 2.0681, 1.3961, 1.3538]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "280\n",
            "tensor([[1.0486, 1.6023, 1.0155, 1.6264, 1.5202, 1.1253, 1.0740],\n",
            "        [1.3267, 1.9603, 1.1852, 1.9799, 1.8832, 1.3057, 1.2600],\n",
            "        [3.2868, 4.1130, 2.1788, 4.1515, 4.1260, 2.3913, 2.4596],\n",
            "        [0.8013, 1.2776, 0.8590, 1.3045, 1.1974, 0.9415, 0.9001],\n",
            "        [0.8460, 1.3382, 0.8891, 1.3657, 1.2580, 0.9783, 0.9343]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "281\n",
            "tensor([[0.8403, 1.3311, 0.8869, 1.3590, 1.2512, 0.9759, 0.9306],\n",
            "        [1.0883, 1.6541, 1.0389, 1.6766, 1.5722, 1.1540, 1.1018],\n",
            "        [0.8648, 1.3625, 0.9000, 1.3891, 1.2813, 0.9920, 0.9469],\n",
            "        [2.8293, 3.6927, 1.9610, 3.7208, 3.6915, 2.0984, 2.1784],\n",
            "        [3.2582, 4.0858, 2.1614, 4.1271, 4.0951, 2.3756, 2.4482]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "282\n",
            "tensor([[1.9859, 2.7595, 1.5436, 2.7785, 2.7057, 1.6899, 1.6806],\n",
            "        [0.8264, 1.3106, 0.8756, 1.3390, 1.2293, 0.9656, 0.9207],\n",
            "        [2.8951, 3.7538, 1.9904, 3.7834, 3.7585, 2.1331, 2.2170],\n",
            "        [1.0458, 1.5987, 1.0147, 1.6239, 1.5172, 1.1223, 1.0723],\n",
            "        [2.6262, 3.4729, 1.8623, 3.4987, 3.4571, 2.0144, 2.0626]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "283\n",
            "tensor([[2.9608, 3.8200, 2.0205, 3.8526, 3.8267, 2.1890, 2.2626],\n",
            "        [0.8050, 1.2839, 0.8605, 1.3127, 1.2035, 0.9500, 0.9071],\n",
            "        [0.8794, 1.3823, 0.9085, 1.4102, 1.3019, 1.0068, 0.9598],\n",
            "        [3.2247, 4.0601, 2.1459, 4.1025, 4.0789, 2.3431, 2.4214],\n",
            "        [2.2387, 3.0541, 1.6716, 3.0726, 3.0117, 1.8149, 1.8326]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "Loss at epoch 7: 117.9212\n",
            "Pearson correlation for aspect 1: 0.6126\n",
            "Pearson correlation for aspect 2: 0.6884\n",
            "Pearson correlation for aspect 3: 0.2438\n",
            "Pearson correlation for aspect 4: 0.7153\n",
            "Pearson correlation for aspect 5: 0.7087\n",
            "Pearson correlation for aspect 6: 0.3193\n",
            "Pearson correlation for aspect 7: 0.3948\n",
            "Mean Pearson correlation: 0.5261\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
        "train(model, model_path, train_data_loader, eval_data_loader, optimizer, loss_weights, num_epochs)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the loss curves\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, marker='o', label='Training Loss')\n",
        "\n",
        "plt.plot(range(1, num_epochs + 1), val_losses, marker='o', label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Avg Loss per batch')\n",
        "plt.title('Training and Validation Loss over Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "s3ZsBaQWHpd1",
        "outputId": "1defbea8-e421-4091-b67a-36ff0b99e7f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the loss curves\n",
        "plt.plot(range(1, num_epochs + 1), pearson_scores, marker='o', label='Training Loss')\n",
        "\n",
        "# plt.plot(range(1, num_epochs + 1), val_losses, marker='o', label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Pearson Scores per batch')\n",
        "plt.title('Pearson Scores over Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "qjvG4jTmNZZl",
        "outputId": "94498594-d6fe-43a5-d2f6-f8c8982eca23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTEe9rwjTP-e"
      },
      "source": [
        "## 4. Evaluation on test data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining function to predit the model\n",
        "def predict(model, data_loader):\n",
        "  model.eval()\n",
        "  overall_pred, overall_true = [], []\n",
        "  with torch.no_grad():\n",
        "    val_loss_sum=0\n",
        "    for idx, (ids, att_msks, y) in enumerate(data_loader):\n",
        "      ids, att_msks, y = ids.to(device), att_msks.to(device), y.to(device)\n",
        "      y_pred = model(ids, att_msks)\n",
        "\n",
        "\n",
        "      y_pred, y = torch.squeeze(y_pred).cpu().numpy().tolist(), torch.squeeze(y).cpu().numpy().tolist()\n",
        "      overall_pred.append(y_pred)\n",
        "      overall_true.append(y)\n",
        "\n",
        "  return overall_pred, overall_true\n"
      ],
      "metadata": {
        "id": "oRoOJqC7FFX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('testing_set.csv')\n",
        "test_data = test_data[test_data['lang1']==test_data['lang2']]\n",
        "test_data = test_data.rename(columns={'text_1': 'merge1', 'text_2': 'merge2'})\n",
        "test_data_loader = get_data_loader(test_data,False)\n",
        "\n",
        "model.load_state_dict(torch.load(\"BERT_Multilingual_0.25_overall_loss.pth\"), strict=False)\n",
        "model.to(device)\n",
        "test_pred_overall, test_true_overall = predict(model, test_data_loader)\n",
        "print(test_pred_overall)\n"
      ],
      "metadata": {
        "id": "e_T1OBBtkIRG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d21b0ece-0b7a-4e2b-fb18-89d7829d9ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-3df337dbeff9>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"BERT_Multilingual_0.25_overall_loss.pth\"), strict=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.361519694328308, 1.9247442483901978, 1.1100759506225586, 1.9309498071670532, 1.8876211643218994, 1.2195284366607666, 1.2453298568725586], [1.2718610763549805, 1.8117040395736694, 1.0497748851776123, 1.8169597387313843, 1.7744255065917969, 1.1505122184753418, 1.1824922561645508], [1.7983062267303467, 2.471595048904419, 1.3867868185043335, 2.490954875946045, 2.450662136077881, 1.526197075843811, 1.5605626106262207], [1.3124758005142212, 1.8632841110229492, 1.0769702196121216, 1.8688058853149414, 1.8244779109954834, 1.1788688898086548, 1.2112394571304321], [1.4598785638809204, 2.050065517425537, 1.1719162464141846, 2.057950258255005, 2.0160953998565674, 1.2876262664794922, 1.3176733255386353], [1.6732217073440552, 2.3167724609375, 1.3083795309066772, 2.331407308578491, 2.290336847305298, 1.436367392539978, 1.4714337587356567], [2.166170120239258, 2.9190115928649902, 1.614565134048462, 2.951693058013916, 2.9148216247558594, 1.7684720754623413, 1.8173811435699463], [2.6977972984313965, 3.5538241863250732, 1.937654972076416, 3.6061315536499023, 3.572042942047119, 2.109065294265747, 2.188833713531494], [2.9950058460235596, 3.9054832458496094, 2.1148781776428223, 3.964632034301758, 3.9236559867858887, 2.3119802474975586, 2.399148941040039], [1.8502262830734253, 2.535348653793335, 1.4191431999206543, 2.5550355911254883, 2.518632173538208, 1.5599453449249268, 1.5963897705078125], [1.009879469871521, 1.4750111103057861, 0.8792593479156494, 1.4783804416656494, 1.4308046102523804, 0.9532284736633301, 0.9900567531585693], [1.9603086709976196, 2.671872854232788, 1.4886400699615479, 2.697680950164795, 2.6593408584594727, 1.638362169265747, 1.675828456878662], [2.899719476699829, 3.782150983810425, 2.0569827556610107, 3.846644401550293, 3.8171308040618896, 2.235558271408081, 2.324709892272949], [1.4164118766784668, 1.9957462549209595, 1.1442418098449707, 2.0031163692474365, 1.9592909812927246, 1.2571548223495483, 1.2860912084579468], [2.5932984352111816, 3.4313690662384033, 1.8747045993804932, 3.48258376121521, 3.445699691772461, 2.0461132526397705, 2.1174211502075195], [2.7627158164978027, 3.6277499198913574, 1.9758527278900146, 3.686891555786133, 3.653644561767578, 2.1498522758483887, 2.232736110687256], [1.9527283906936646, 2.660719871520996, 1.4837983846664429, 2.6869521141052246, 2.6466028690338135, 1.6317651271820068, 1.6706467866897583], [1.4910979270935059, 2.089665174484253, 1.1905505657196045, 2.098345994949341, 2.056591749191284, 1.310307264328003, 1.340366005897522], [2.470320463180542, 3.2833404541015625, 1.80077064037323, 3.329761028289795, 3.2937614917755127, 1.9670250415802002, 2.030458450317383], [2.9725470542907715, 3.8750219345092773, 2.1021885871887207, 3.9360878467559814, 3.8989803791046143, 2.292600631713867, 2.379824161529541], [1.5061267614364624, 2.1069185733795166, 1.200941562652588, 2.1171796321868896, 2.0754611492156982, 1.3223447799682617, 1.351758599281311], [2.7536330223083496, 3.6175496578216553, 1.9717141389846802, 3.6762261390686035, 3.646191358566284, 2.1416921615600586, 2.2260890007019043], [1.1056945323944092, 1.5971399545669556, 0.9421499371528625, 1.6009424924850464, 1.554724097251892, 1.0249968767166138, 1.0598785877227783], [1.7572884559631348, 2.4213383197784424, 1.3597806692123413, 2.4380698204040527, 2.3966803550720215, 1.4935333728790283, 1.529803991317749], [1.357290506362915, 1.9194447994232178, 1.1054812669754028, 1.9269111156463623, 1.8826168775558472, 1.2108641862869263, 1.2437376976013184], [2.532862901687622, 3.359074592590332, 1.8384867906570435, 3.4092841148376465, 3.376244068145752, 2.004526376724243, 2.074650287628174], [2.816192626953125, 3.6915202140808105, 2.009157419204712, 3.7488362789154053, 3.7146174907684326, 2.1795568466186523, 2.268948554992676], [2.9154622554779053, 3.806396484375, 2.066678047180176, 3.86936092376709, 3.832709789276123, 2.254274845123291, 2.340268135070801], [2.764833450317383, 3.6326797008514404, 1.9787189960479736, 3.689291477203369, 3.6571366786956787, 2.1530861854553223, 2.2347159385681152], [2.5489931106567383, 3.377150774002075, 1.8483006954193115, 3.426539182662964, 3.3943095207214355, 2.0145580768585205, 2.0830883979797363], [1.6926848888397217, 2.3408308029174805, 1.3194810152053833, 2.3546009063720703, 2.312380790710449, 1.4497745037078857, 1.4848157167434692], [2.0284159183502197, 2.7543303966522217, 1.5292127132415771, 2.7809054851531982, 2.74194073677063, 1.6806913614273071, 1.7211520671844482], [1.0612057447433472, 1.5413399934768677, 0.9134318232536316, 1.5445733070373535, 1.4976928234100342, 0.99257493019104, 1.0277323722839355], [1.7839128971099854, 2.453256607055664, 1.3774827718734741, 2.470722198486328, 2.430309295654297, 1.5128326416015625, 1.5485873222351074], [2.8030223846435547, 3.6763737201690674, 2.0006353855133057, 3.7353649139404297, 3.7054343223571777, 2.179070472717285, 2.262246608734131], [1.9467815160751343, 2.6525561809539795, 1.4794940948486328, 2.6775002479553223, 2.6381258964538574, 1.6260020732879639, 1.664300799369812], [1.5306813716888428, 2.139420509338379, 1.2169469594955444, 2.1496636867523193, 2.1080164909362793, 1.3368806838989258, 1.3680903911590576], [2.3860361576080322, 3.183107376098633, 1.7496585845947266, 3.2257752418518066, 3.1926422119140625, 1.9139766693115234, 1.970219373703003], [1.5547009706497192, 2.1700599193573, 1.232778549194336, 2.1798174381256104, 2.1407227516174316, 1.3537123203277588, 1.385972023010254], [1.486040472984314, 2.0835835933685303, 1.1888989210128784, 2.0922129154205322, 2.050196647644043, 1.3051378726959229, 1.336419939994812], [2.7593841552734375, 3.622596025466919, 1.973799705505371, 3.6809067726135254, 3.6508469581604004, 2.1467337608337402, 2.2292346954345703], [2.2041802406311035, 2.9669249057769775, 1.6393771171569824, 3.002990245819092, 2.965100049972534, 1.7974088191986084, 1.847517728805542], [2.136842727661133, 2.8851263523101807, 1.5983150005340576, 2.916088581085205, 2.8813211917877197, 1.7499197721481323, 1.7981404066085815], [2.375016212463379, 3.169917583465576, 1.7425882816314697, 3.2123165130615234, 3.1766271591186523, 1.907145380973816, 1.9626126289367676], [1.455407738685608, 2.0446970462799072, 1.1677438020706177, 2.0524959564208984, 2.009906768798828, 1.2832047939300537, 1.3132685422897339], [2.7001378536224365, 3.5535340309143066, 1.938763976097107, 3.609701156616211, 3.573068141937256, 2.105731725692749, 2.1899213790893555], [2.8518218994140625, 3.728877544403076, 2.0293996334075928, 3.7916815280914307, 3.7608821392059326, 2.207576036453247, 2.2929325103759766], [1.6493819952011108, 2.288353681564331, 1.2918144464492798, 2.3004634380340576, 2.2583060264587402, 1.4211430549621582, 1.4540725946426392], [2.8337886333465576, 3.7108020782470703, 2.017909049987793, 3.7716126441955566, 3.7415757179260254, 2.1928484439849854, 2.282092571258545], [1.5063425302505493, 2.1073243618011475, 1.2015818357467651, 2.116511344909668, 2.074357271194458, 1.3216761350631714, 1.3506327867507935], [2.671605348587036, 3.5214598178863525, 1.9223456382751465, 3.57436203956604, 3.5432586669921875, 2.0958831310272217, 2.167479991912842], [2.6512646675109863, 3.499274969100952, 1.9105645418167114, 3.5535902976989746, 3.5214104652404785, 2.0801470279693604, 2.1562533378601074], [1.3555376529693604, 1.9189872741699219, 1.1047865152359009, 1.9248723983764648, 1.8805772066116333, 1.2118089199066162, 1.2413463592529297], [2.0612781047821045, 2.792454242706299, 1.5485690832138062, 2.820683002471924, 2.78255558013916, 1.7020072937011719, 1.744014024734497], [2.6178505420684814, 3.460188865661621, 1.8905372619628906, 3.5123817920684814, 3.4806554317474365, 2.0599117279052734, 2.1331610679626465], [2.6741158962249756, 3.5266544818878174, 1.9237143993377686, 3.580533027648926, 3.5478858947753906, 2.0966877937316895, 2.1735944747924805], [2.8642468452453613, 3.74462890625, 2.03791880607605, 3.8037922382354736, 3.7740302085876465, 2.2129809856414795, 2.2996954917907715], [1.1617037057876587, 1.6716766357421875, 0.9798180460929871, 1.6746736764907837, 1.6299530267715454, 1.0708842277526855, 1.1025445461273193], [0.9745666980743408, 1.4295734167099, 0.8551466464996338, 1.4309289455413818, 1.3853330612182617, 0.9253233671188354, 0.9628220796585083], [2.4372615814208984, 3.24772047996521, 1.7816904783248901, 3.2926700115203857, 3.2585582733154297, 1.9432120323181152, 2.009594440460205], [1.4785246849060059, 2.075265884399414, 1.1840990781784058, 2.0840437412261963, 2.041649580001831, 1.3032639026641846, 1.3321613073349], [2.713055372238159, 3.5703542232513428, 1.9489558935165405, 3.6271774768829346, 3.5958962440490723, 2.1175763607025146, 2.1984353065490723], [2.8156886100769043, 3.688060760498047, 2.0079152584075928, 3.747471570968628, 3.716496229171753, 2.185786247253418, 2.267329216003418], [1.754311203956604, 2.418782949447632, 1.3590729236602783, 2.433657646179199, 2.394625186920166, 1.494002342224121, 1.528161644935608], [2.2673239707946777, 3.04195499420166, 1.6771252155303955, 3.0798537731170654, 3.045215368270874, 1.8352822065353394, 1.8895028829574585], [1.9340218305587769, 2.6403696537017822, 1.4714463949203491, 2.661668300628662, 2.6229794025421143, 1.6177780628204346, 1.655591368675232], [2.6391141414642334, 3.482586145401001, 1.9034428596496582, 3.5360488891601562, 3.502690315246582, 2.068774461746216, 2.147111415863037], [2.1699330806732178, 2.9269723892211914, 1.6185333728790283, 2.9603195190429688, 2.92318058013916, 1.7753915786743164, 1.8229641914367676], [2.905508518218994, 3.7981698513031006, 2.061495304107666, 3.8574042320251465, 3.8165042400360107, 2.245573043823242, 2.3332767486572266], [1.5215907096862793, 2.1271297931671143, 1.2118208408355713, 2.1362743377685547, 2.093121290206909, 1.3292644023895264, 1.3621875047683716], [1.5443202257156372, 2.155198097229004, 1.2278131246566772, 2.167036294937134, 2.1258435249328613, 1.3487205505371094, 1.379433512687683], [1.6013351678848267, 2.226494312286377, 1.2625882625579834, 2.239520311355591, 2.19620943069458, 1.3892107009887695, 1.4197957515716553], [2.458178758621216, 3.2699170112609863, 1.7939380407333374, 3.316640853881836, 3.282602310180664, 1.9581429958343506, 2.022031307220459], [2.6053645610809326, 3.444617986679077, 1.883062720298767, 3.4965310096740723, 3.462163209915161, 2.0561091899871826, 2.1236934661865234], [1.8571463823318481, 2.5443413257598877, 1.4234172105789185, 2.564812660217285, 2.525383710861206, 1.5638530254364014, 1.6026451587677002], [3.003206253051758, 3.913543939590454, 2.1196868419647217, 3.9728713035583496, 3.931811809539795, 2.3167219161987305, 2.4034605026245117], [2.8107476234436035, 3.6821274757385254, 2.005772590637207, 3.7432191371917725, 3.7137231826782227, 2.180922031402588, 2.2638463973999023], [1.801522135734558, 2.4767634868621826, 1.3875494003295898, 2.49430251121521, 2.4531683921813965, 1.5268710851669312, 1.5636838674545288], [1.2018709182739258, 1.7214093208312988, 1.0046931505203247, 1.726421594619751, 1.6807435750961304, 1.097424864768982, 1.130089282989502], [2.683000326156616, 3.536806583404541, 1.929659128189087, 3.592418670654297, 3.5591394901275635, 2.1024012565612793, 2.177859306335449], [1.5311015844345093, 2.139893054962158, 1.216579556465149, 2.1493637561798096, 2.1075186729431152, 1.3361332416534424, 1.3676029443740845], [1.1931047439575195, 1.7092921733856201, 1.0001473426818848, 1.7139520645141602, 1.6692278385162354, 1.0931475162506104, 1.123932123184204], [2.912468433380127, 3.8054211139678955, 2.06593656539917, 3.8639028072357178, 3.8283355236053467, 2.2513415813446045, 2.338688850402832], [1.2175079584121704, 1.7416386604309082, 1.0164564847946167, 1.7465482950210571, 1.7028864622116089, 1.110859751701355, 1.1422035694122314], [1.278056025505066, 1.821017861366272, 1.054569959640503, 1.8252381086349487, 1.7812578678131104, 1.156090497970581, 1.185794711112976], [2.455497980117798, 3.2680933475494385, 1.792650580406189, 3.3132495880126953, 3.281838893890381, 1.958141803741455, 2.0204906463623047], [1.7070508003234863, 2.3583688735961914, 1.328844428062439, 2.372964859008789, 2.333104133605957, 1.4607025384902954, 1.4945651292800903], [1.035560131072998, 1.507084846496582, 0.8965265154838562, 1.5098533630371094, 1.4645745754241943, 0.9718775749206543, 1.0086779594421387], [1.7639600038528442, 2.4306936264038086, 1.363724708557129, 2.4459009170532227, 2.4057538509368896, 1.5000553131103516, 1.532881259918213], [2.6653456687927246, 3.514474391937256, 1.918441891670227, 3.5677835941314697, 3.537383794784546, 2.0862948894500732, 2.164215564727783], [1.1299084424972534, 1.6310606002807617, 0.9574834704399109, 1.632711410522461, 1.5884881019592285, 1.0460822582244873, 1.0771594047546387], [2.955010175704956, 3.8541479110717773, 2.0909595489501953, 3.9148290157318115, 3.879849672317505, 2.2761566638946533, 2.368246555328369], [1.5770689249038696, 2.195974111557007, 1.24644935131073, 2.20792818069458, 2.165334939956665, 1.369984745979309, 1.4022278785705566], [1.5735641717910767, 2.193026304244995, 1.2448197603225708, 2.205655336380005, 2.1632697582244873, 1.3706685304641724, 1.4004764556884766], [2.2545254230499268, 3.02770733833313, 1.6696592569351196, 3.0647804737091064, 3.0304291248321533, 1.8267117738723755, 1.8817178010940552], [1.4033745527267456, 1.9779413938522339, 1.134826898574829, 1.9844439029693604, 1.9425841569900513, 1.2459778785705566, 1.2749131917953491], [1.4928044080734253, 2.0927085876464844, 1.193547248840332, 2.101637840270996, 2.0584940910339355, 1.3125449419021606, 1.3426772356033325], [1.6371498107910156, 2.271862030029297, 1.284729242324829, 2.2859554290771484, 2.2434566020965576, 1.4123135805130005, 1.445152997970581], [2.1223082542419434, 2.8672280311584473, 1.5874724388122559, 2.8973751068115234, 2.8613719940185547, 1.7412601709365845, 1.7867637872695923], [1.2989143133163452, 1.8455133438110352, 1.0678751468658447, 1.850222110748291, 1.8060870170593262, 1.1714519262313843, 1.1999483108520508], [1.034471869468689, 1.5070030689239502, 0.8953542113304138, 1.5100914239883423, 1.4637961387634277, 0.972442626953125, 1.0084500312805176], [2.629425048828125, 3.472609758377075, 1.8980300426483154, 3.5261411666870117, 3.4926185607910156, 2.064983606338501, 2.140592575073242], [2.941105365753174, 3.835509777069092, 2.0819239616394043, 3.897941827774048, 3.8631346225738525, 2.2677814960479736, 2.3571038246154785], [1.3382130861282349, 1.8951371908187866, 1.0935540199279785, 1.9023005962371826, 1.859269142150879, 1.1983462572097778, 1.229103684425354], [2.684455394744873, 3.5358004570007324, 1.9295518398284912, 3.5922608375549316, 3.562512159347534, 2.0953564643859863, 2.1783647537231445], [2.4819908142089844, 3.2981226444244385, 1.8094253540039062, 3.3463480472564697, 3.313185214996338, 1.9706988334655762, 2.0382871627807617], [1.3371707201004028, 1.894879698753357, 1.094045877456665, 1.9006438255310059, 1.8561499118804932, 1.1996690034866333, 1.229667067527771], [2.935171604156494, 3.829317569732666, 2.078460693359375, 3.8899636268615723, 3.8558757305145264, 2.259094476699829, 2.3510684967041016], [2.5156850814819336, 3.336859941482544, 1.8291661739349365, 3.385319232940674, 3.3540191650390625, 1.9960403442382812, 2.0612430572509766], [1.721722960472107, 2.3770952224731445, 1.3381284475326538, 2.3924529552459717, 2.3522403240203857, 1.471627950668335, 1.5052565336227417], [1.605515956878662, 2.2308969497680664, 1.2656770944595337, 2.244002103805542, 2.2023913860321045, 1.390263319015503, 1.4225828647613525], [2.2931978702545166, 3.0729055404663086, 1.6922564506530762, 3.1108591556549072, 3.0752508640289307, 1.8541483879089355, 1.90533447265625], [2.5888288021087646, 3.4228832721710205, 1.8723028898239136, 3.473641872406006, 3.4411797523498535, 2.0368640422821045, 2.1113481521606445], [2.506355047225952, 3.328362226486206, 1.823533535003662, 3.3763699531555176, 3.341416835784912, 1.9888169765472412, 2.056612014770508], [1.4305505752563477, 2.012118339538574, 1.1536827087402344, 2.0200960636138916, 1.9772961139678955, 1.2655267715454102, 1.2959952354431152], [2.0994210243225098, 2.8423290252685547, 1.5728991031646729, 2.8707704544067383, 2.8333659172058105, 1.726896047592163, 1.7724109888076782], [1.4373732805252075, 2.0206055641174316, 1.1591631174087524, 2.0273830890655518, 1.9865432977676392, 1.2711150646209717, 1.3014270067214966], [1.732054352760315, 2.3898141384124756, 1.344567894935608, 2.4060440063476562, 2.3669989109039307, 1.4763579368591309, 1.5122793912887573], [2.3484463691711426, 3.1404731273651123, 1.726890206336975, 3.180854320526123, 3.1473701000213623, 1.8885436058044434, 1.9470961093902588], [2.9466288089752197, 3.8431663513183594, 2.085747241973877, 3.9062793254852295, 3.8698434829711914, 2.271301746368408, 2.3614907264709473], [2.3376381397247314, 3.125955820083618, 1.7196930646896362, 3.165966272354126, 3.132246255874634, 1.8813084363937378, 1.9383893013000488], [1.6894214153289795, 2.3369252681732178, 1.319746971130371, 2.352463722229004, 2.3115170001983643, 1.451696753501892, 1.4832099676132202], [2.821200132369995, 3.697571277618408, 2.012305498123169, 3.754727602005005, 3.7225098609924316, 2.1890335083007812, 2.2735629081726074], [2.1697745323181152, 2.9256534576416016, 1.6167371273040771, 2.9573769569396973, 2.921618938446045, 1.770961046218872, 1.8193575143814087], [2.724196434020996, 3.582061767578125, 1.9540642499923706, 3.6387109756469727, 3.608989953994751, 2.1258859634399414, 2.204385280609131], [1.3229271173477173, 1.8759076595306396, 1.0844571590423584, 1.882554292678833, 1.8365281820297241, 1.1899003982543945, 1.2189809083938599], [2.6514153480529785, 3.499162197113037, 1.9107940196990967, 3.551119565963745, 3.5178675651550293, 2.080573081970215, 2.155600070953369], [1.5415525436401367, 2.151245594024658, 1.224326729774475, 2.1625399589538574, 2.1185641288757324, 1.3471096754074097, 1.3767963647842407], [2.921799421310425, 3.8127541542053223, 2.070939302444458, 3.8750743865966797, 3.842137098312378, 2.2523837089538574, 2.3425064086914062], [1.1050838232040405, 1.59823477268219, 0.9418708682060242, 1.6015052795410156, 1.5550576448440552, 1.0266646146774292, 1.0600732564926147], [1.4977245330810547, 2.0957765579223633, 1.197192668914795, 2.106750249862671, 2.0646891593933105, 1.3162387609481812, 1.3458223342895508], [2.738227605819702, 3.599944829940796, 1.9623552560806274, 3.657344102859497, 3.62882399559021, 2.138428211212158, 2.21622896194458], [2.8362693786621094, 3.7125837802886963, 2.0199198722839355, 3.773252487182617, 3.7433557510375977, 2.2013497352600098, 2.2826271057128906], [2.488801956176758, 3.3078198432922363, 1.8125046491622925, 3.3546864986419678, 3.3190152645111084, 1.9775936603546143, 2.0446724891662598], [1.3832221031188965, 1.9529366493225098, 1.1224740743637085, 1.959774136543274, 1.915217638015747, 1.2320175170898438, 1.2627129554748535], [2.3322436809539795, 3.12003231048584, 1.7176859378814697, 3.1600582599639893, 3.1268839836120605, 1.8791028261184692, 1.934700608253479], [1.6904670000076294, 2.338275194168091, 1.3181655406951904, 2.3521604537963867, 2.312016010284424, 1.449298620223999, 1.4831407070159912], [2.9877736568450928, 3.8932242393493652, 2.110283136367798, 3.955490827560425, 3.917705535888672, 2.304126739501953, 2.392451763153076], [1.6950187683105469, 2.3438737392425537, 1.3201419115066528, 2.359025001525879, 2.3175292015075684, 1.4520033597946167, 1.4850075244903564], [2.182217597961426, 2.9407060146331787, 1.6243534088134766, 2.9732871055603027, 2.939718723297119, 1.7788176536560059, 1.8288027048110962], [2.0502359867095947, 2.7815539836883545, 1.5451513528823853, 2.810451030731201, 2.7725963592529297, 1.6970534324645996, 1.7392274141311646], [1.6859016418457031, 2.332556962966919, 1.3163180351257324, 2.347402572631836, 2.305185556411743, 1.4495606422424316, 1.4813300371170044], [1.916002869606018, 2.615912914276123, 1.4588334560394287, 2.638080596923828, 2.597705125808716, 1.6050045490264893, 1.643398642539978], [2.715047597885132, 3.5727713108062744, 1.9484516382217407, 3.627932071685791, 3.596406936645508, 2.121122121810913, 2.1991233825683594], [2.936595916748047, 3.8288681507110596, 2.078315258026123, 3.8886327743530273, 3.855377435684204, 2.2581381797790527, 2.352109432220459], [2.9012789726257324, 3.7907397747039795, 2.0577268600463867, 3.8515965938568115, 3.817478895187378, 2.2380852699279785, 2.3278889656066895], [2.704585313796997, 3.5624895095825195, 1.9413902759552002, 3.6163535118103027, 3.5798702239990234, 2.1222846508026123, 2.193286895751953], [1.9390112161636353, 2.644300937652588, 1.4757907390594482, 2.667909622192383, 2.6296470165252686, 1.6189459562301636, 1.6590629816055298], [1.918716549873352, 2.6192057132720947, 1.4618185758590698, 2.642240524291992, 2.6030781269073486, 1.6037890911102295, 1.6448578834533691], [2.894007921218872, 3.778804302215576, 2.0546205043792725, 3.839583396911621, 3.808356523513794, 2.2367427349090576, 2.3216090202331543], [2.4886512756347656, 3.3058199882507324, 1.8121788501739502, 3.351517915725708, 3.3184475898742676, 1.9741017818450928, 2.042712688446045], [1.1759545803070068, 1.6900577545166016, 0.9870246052742004, 1.6932271718978882, 1.6489179134368896, 1.0791943073272705, 1.1113555431365967], [2.9717390537261963, 3.8752100467681885, 2.1009700298309326, 3.9362683296203613, 3.895590305328369, 2.283524990081787, 2.3818483352661133], [1.6896878480911255, 2.3380415439605713, 1.3187650442123413, 2.353595733642578, 2.3121390342712402, 1.45140540599823, 1.4838508367538452], [2.716878890991211, 3.5729153156280518, 1.9487370252609253, 3.6298389434814453, 3.601893663406372, 2.1175713539123535, 2.198655605316162], [1.43325674533844, 2.0157053470611572, 1.1562556028366089, 2.02514386177063, 1.9818267822265625, 1.2701334953308105, 1.2997145652770996], [1.3360728025436401, 1.8947405815124512, 1.0920215845108032, 1.9003572463989258, 1.8559162616729736, 1.1976128816604614, 1.2275177240371704], [2.6307718753814697, 3.4733262062072754, 1.8983224630355835, 3.526895761489868, 3.4970321655273438, 2.066800117492676, 2.139942169189453], [2.6234567165374756, 3.466737985610962, 1.8940353393554688, 3.5190494060516357, 3.488142251968384, 2.068082332611084, 2.137091636657715], [2.707566738128662, 3.5621273517608643, 1.9435913562774658, 3.618594169616699, 3.590794563293457, 2.1173665523529053, 2.192871570587158], [2.7367119789123535, 3.5965917110443115, 1.961221694946289, 3.654517412185669, 3.625007390975952, 2.1352920532226562, 2.212618350982666], [2.9518837928771973, 3.8534915447235107, 2.089792013168335, 3.9140326976776123, 3.8737943172454834, 2.2814180850982666, 2.3674583435058594], [1.0477509498596191, 1.5258326530456543, 0.903434693813324, 1.5281404256820679, 1.4821381568908691, 0.9833114147186279, 1.0180842876434326], [2.222975730895996, 2.9890825748443604, 1.6502379179000854, 3.0238242149353027, 2.98630952835083, 1.8046663999557495, 1.8586764335632324], [1.8038004636764526, 2.478257656097412, 1.3908404111862183, 2.4966886043548584, 2.458038091659546, 1.5281500816345215, 1.5633213520050049], [1.7532289028167725, 2.414806365966797, 1.3582273721694946, 2.430812120437622, 2.391530990600586, 1.4922459125518799, 1.5262751579284668], [1.8795559406280518, 2.5715956687927246, 1.437300443649292, 2.593374729156494, 2.5543553829193115, 1.5823149681091309, 1.61681067943573], [2.4394781589508057, 3.2498362064361572, 1.7822257280349731, 3.2935056686401367, 3.261317729949951, 1.9481792449951172, 2.00958251953125], [2.489755868911743, 3.3080193996429443, 1.8117241859436035, 3.3550922870635986, 3.3194687366485596, 1.9748599529266357, 2.043177604675293], [1.625916838645935, 2.2576944828033447, 1.2785403728485107, 2.271141529083252, 2.230297803878784, 1.4052915573120117, 1.437334656715393], [1.2759677171707153, 1.8178058862686157, 1.0532498359680176, 1.8224546909332275, 1.7781063318252563, 1.1548155546188354, 1.1849128007888794], [1.2607536315917969, 1.7976542711257935, 1.0430585145950317, 1.8023557662963867, 1.7578409910202026, 1.1409294605255127, 1.1737173795700073], [2.120197296142578, 2.866168975830078, 1.5860830545425415, 2.895738363265991, 2.8569204807281494, 1.7383992671966553, 1.7876759767532349], [2.941819667816162, 3.8378512859344482, 2.083568811416626, 3.9014647006988525, 3.8652307987213135, 2.2712671756744385, 2.358924388885498], [2.716947078704834, 3.576390027999878, 1.9491386413574219, 3.633012294769287, 3.596924304962158, 2.125187635421753, 2.204254150390625], [2.1685173511505127, 2.9243810176849365, 1.616551160812378, 2.9572911262512207, 2.9197354316711426, 1.7718775272369385, 1.8224633932113647], [2.740943193435669, 3.6021792888641357, 1.964593529701233, 3.660162925720215, 3.630368232727051, 2.1386125087738037, 2.2163596153259277], [2.3024470806121826, 3.0858359336853027, 1.6993123292922974, 3.1254167556762695, 3.089690685272217, 1.857430338859558, 1.9159338474273682], [2.588953971862793, 3.425128936767578, 1.8719213008880615, 3.477585792541504, 3.4427247047424316, 2.0396931171417236, 2.113126754760742], [1.124009132385254, 1.6228688955307007, 0.9543270468711853, 1.6253238916397095, 1.5795761346817017, 1.0399317741394043, 1.0736875534057617], [1.1579926013946533, 1.6668695211410522, 0.9767774343490601, 1.6707158088684082, 1.6247202157974243, 1.0674551725387573, 1.0988515615463257], [2.3860361576080322, 3.183107376098633, 1.7496585845947266, 3.2257752418518066, 3.1926422119140625, 1.9139766693115234, 1.970219373703003], [1.9815312623977661, 2.6959962844848633, 1.5014382600784302, 2.721505641937256, 2.6838550567626953, 1.6493918895721436, 1.688513159751892], [1.4134348630905151, 1.9930555820465088, 1.1410597562789917, 1.9981722831726074, 1.9558228254318237, 1.2539421319961548, 1.2835720777511597], [1.1530029773712158, 1.659541368484497, 0.9733073115348816, 1.6633069515228271, 1.6176809072494507, 1.0640060901641846, 1.095569133758545], [2.021559953689575, 2.7449138164520264, 1.5253527164459229, 2.770723819732666, 2.7335758209228516, 1.6758167743682861, 1.7159866094589233], [1.3397020101547241, 1.8982043266296387, 1.0935730934143066, 1.9048182964324951, 1.860819697380066, 1.2008894681930542, 1.2308651208877563], [0.9316680431365967, 1.3739638328552246, 0.8264774680137634, 1.375079870223999, 1.3285973072052002, 0.8905282616615295, 0.9311692714691162], [1.0979375839233398, 1.5894520282745361, 0.9381055235862732, 1.5926254987716675, 1.5469911098480225, 1.0222632884979248, 1.0556634664535522], [2.351449728012085, 3.142070770263672, 1.728299856185913, 3.183568239212036, 3.147517204284668, 1.891167402267456, 1.9474328756332397], [1.0158090591430664, 1.4815418720245361, 0.8829323649406433, 1.4849328994750977, 1.4390685558319092, 0.9571559429168701, 0.9934254288673401], [2.138455629348755, 2.8870863914489746, 1.5985995531082153, 2.9175281524658203, 2.8823695182800293, 1.7515255212783813, 1.7993654012680054], [2.878720998764038, 3.761274814605713, 2.0456552505493164, 3.8226327896118164, 3.7917213439941406, 2.2266058921813965, 2.3108091354370117], [2.7074825763702393, 3.565916061401367, 1.9453315734863281, 3.619601011276245, 3.5895113945007324, 2.1140544414520264, 2.1949820518493652], [1.846001148223877, 2.5348947048187256, 1.412091851234436, 2.551204204559326, 2.510329008102417, 1.5530593395233154, 1.5925434827804565], [1.8504493236541748, 2.5378096103668213, 1.4188196659088135, 2.556607961654663, 2.5163516998291016, 1.5594457387924194, 1.5954676866531372], [2.508769989013672, 3.3314967155456543, 1.8243902921676636, 3.379439115524292, 3.3454809188842773, 1.9870827198028564, 2.057429790496826], [1.314955472946167, 1.8680707216262817, 1.080025315284729, 1.8716120719909668, 1.82906174659729, 1.1825549602508545, 1.2125474214553833], [1.3467159271240234, 1.906418800354004, 1.1004106998443604, 1.9120643138885498, 1.867762565612793, 1.20535147190094, 1.235480785369873], [2.218027114868164, 2.9843108654022217, 1.6461882591247559, 3.017446517944336, 2.9821386337280273, 1.8012242317199707, 1.854775071144104], [1.0587425231933594, 1.539067029953003, 0.9110262989997864, 1.541425347328186, 1.4951586723327637, 0.9896537065505981, 1.025282382965088], [2.9808435440063477, 3.8878376483917236, 2.106539249420166, 3.947526216506958, 3.9059245586395264, 2.2954752445220947, 2.387981414794922], [1.1759244203567505, 1.6893293857574463, 0.9893857836723328, 1.6925541162490845, 1.6487303972244263, 1.0801132917404175, 1.1115505695343018], [2.9820196628570557, 3.885258197784424, 2.1064491271972656, 3.946791410446167, 3.906752347946167, 2.297452211380005, 2.387235641479492], [2.0301594734191895, 2.7542927265167236, 1.530495524406433, 2.7798523902893066, 2.742213487625122, 1.6823327541351318, 1.7210334539413452], [2.0769946575164795, 2.81219220161438, 1.5600590705871582, 2.841433525085449, 2.8017725944519043, 1.7136728763580322, 1.7559823989868164], [2.7081797122955322, 3.5628693103790283, 1.945343255996704, 3.6193692684173584, 3.5889370441436768, 2.1107070446014404, 2.193718910217285], [2.5112197399139404, 3.335869312286377, 1.8254671096801758, 3.3800692558288574, 3.344027519226074, 1.9949464797973633, 2.057670831680298], [2.0265402793884277, 2.750377893447876, 1.529824137687683, 2.7779979705810547, 2.7407355308532715, 1.678657054901123, 1.7210352420806885], [2.632688283920288, 3.4763123989105225, 1.8995853662490845, 3.528925657272339, 3.497346878051758, 2.0669095516204834, 2.1423425674438477], [2.309645652770996, 3.0958967208862305, 1.7033390998840332, 3.1356358528137207, 3.099339246749878, 1.8645631074905396, 1.921195387840271], [1.9181922674179077, 2.6201179027557373, 1.461668610572815, 2.6420722007751465, 2.6026883125305176, 1.6046298742294312, 1.643340826034546], [2.8369405269622803, 3.7132325172424316, 2.021066904067993, 3.7741963863372803, 3.743239641189575, 2.1989197731018066, 2.2819361686706543], [2.852984666824341, 3.731287717819214, 2.029979705810547, 3.791691541671753, 3.761157989501953, 2.2095754146575928, 2.29213285446167], [1.8047670125961304, 2.4813904762268066, 1.3884565830230713, 2.4988012313842773, 2.457702875137329, 1.5288150310516357, 1.5634899139404297], [1.324996829032898, 1.8787767887115479, 1.0855008363723755, 1.8853936195373535, 1.8401416540145874, 1.191300392150879, 1.2213377952575684], [1.2659331560134888, 1.8038114309310913, 1.0474789142608643, 1.8103381395339966, 1.7654703855514526, 1.1474244594573975, 1.1780041456222534], [2.9124879837036133, 3.800734519958496, 2.0657520294189453, 3.8623974323272705, 3.8304169178009033, 2.2503230571746826, 2.335822582244873], [2.942634344100952, 3.836296319961548, 2.0833218097686768, 3.8994929790496826, 3.8663339614868164, 2.270521640777588, 2.357405185699463], [1.9222174882888794, 2.6222875118255615, 1.4630720615386963, 2.6462066173553467, 2.6063458919525146, 1.6083652973175049, 1.6452257633209229], [2.818218231201172, 3.69169282913208, 2.01001238822937, 3.7516963481903076, 3.720411539077759, 2.1874334812164307, 2.2700066566467285], [2.5479252338409424, 3.3762264251708984, 1.8472505807876587, 3.4257876873016357, 3.392538070678711, 2.013526678085327, 2.082258939743042], [2.902129888534546, 3.790534257888794, 2.059915065765381, 3.8519704341888428, 3.819472074508667, 2.24788761138916, 2.3291282653808594], [2.9989013671875, 3.9071643352508545, 2.1171398162841797, 3.967365026473999, 3.925116777420044, 2.3120508193969727, 2.3998866081237793], [2.795522451400757, 3.6637542247772217, 1.9956544637680054, 3.7235686779022217, 3.694347381591797, 2.163891553878784, 2.251335620880127], [1.2777031660079956, 1.8184078931808472, 1.054945707321167, 1.8240876197814941, 1.7795076370239258, 1.155652642250061, 1.1869553327560425], [1.4197325706481934, 1.9986995458602905, 1.1459999084472656, 2.0053012371063232, 1.961738109588623, 1.2585248947143555, 1.2880587577819824], [2.9405157566070557, 3.8368752002716064, 2.0825130939483643, 3.896378517150879, 3.8597025871276855, 2.263638973236084, 2.35958194732666], [2.82460355758667, 3.700162410736084, 2.0137698650360107, 3.7599668502807617, 3.729701519012451, 2.192350387573242, 2.2753615379333496], [1.891735315322876, 2.5885844230651855, 1.4455201625823975, 2.6088778972625732, 2.570223331451416, 1.5861209630966187, 1.6262811422348022], [2.8121261596679688, 3.687959909439087, 2.0062146186828613, 3.747933864593506, 3.715052604675293, 2.181863784790039, 2.269461154937744], [1.1668288707733154, 1.6754928827285767, 0.9823241829872131, 1.6797983646392822, 1.6341410875320435, 1.0725085735321045, 1.1045297384262085], [2.900526762008667, 3.7855679988861084, 2.0597965717315674, 3.847139358520508, 3.815430164337158, 2.2395899295806885, 2.3279170989990234], [2.1860196590423584, 2.9442999362945557, 1.6281249523162842, 2.9779140949249268, 2.9416730403900146, 1.7850570678710938, 1.8325235843658447], [1.0887794494628906, 1.5777478218078613, 0.9312607049942017, 1.5793795585632324, 1.5351207256317139, 1.0121573209762573, 1.0474905967712402], [1.9874523878097534, 2.704956293106079, 1.5043758153915405, 2.7308101654052734, 2.6915225982666016, 1.6506781578063965, 1.6941633224487305], [1.4316800832748413, 2.0133252143859863, 1.1536051034927368, 2.0208497047424316, 1.9773635864257812, 1.267875075340271, 1.296331763267517], [1.5805529356002808, 2.199925661087036, 1.2502371072769165, 2.214015483856201, 2.1708779335021973, 1.374786138534546, 1.4063363075256348], [1.527072548866272, 2.135869264602661, 1.214453101158142, 2.1456103324890137, 2.1018142700195312, 1.3393124341964722, 1.3672562837600708], [1.3889800310134888, 1.9613159894943237, 1.1267955303192139, 1.968018889427185, 1.9241676330566406, 1.2374699115753174, 1.2679214477539062], [1.9700604677200317, 2.6844799518585205, 1.4932959079742432, 2.707749843597412, 2.6705374717712402, 1.6408867835998535, 1.6810921430587769], [1.5562516450881958, 2.1701040267944336, 1.233460545539856, 2.1806089878082275, 2.1401779651641846, 1.3585326671600342, 1.3862911462783813], [2.056199073791504, 2.7875254154205322, 1.547637701034546, 2.815800428390503, 2.7783985137939453, 1.6971782445907593, 1.7411867380142212], [1.6409308910369873, 2.275944471359253, 1.2872909307479858, 2.2895448207855225, 2.2477126121520996, 1.4148837327957153, 1.4460670948028564], [2.926009178161621, 3.817948818206787, 2.0746960639953613, 3.8793983459472656, 3.845229148864746, 2.2626254558563232, 2.3452858924865723], [1.7622649669647217, 2.4263901710510254, 1.363410472869873, 2.4441537857055664, 2.403737783432007, 1.5000468492507935, 1.533478021621704], [2.676577568054199, 3.529519557952881, 1.9254350662231445, 3.583944320678711, 3.553377151489258, 2.094634771347046, 2.1737093925476074], [2.9592559337615967, 3.857111692428589, 2.0921454429626465, 3.9200456142425537, 3.882675886154175, 2.279468536376953, 2.3703646659851074], [1.9490448236465454, 2.655996799468994, 1.4796494245529175, 2.6799545288085938, 2.6413865089416504, 1.6266142129898071, 1.6657989025115967], [1.4493619203567505, 2.0357723236083984, 1.165753960609436, 2.0439722537994385, 2.0008320808410645, 1.2790446281433105, 1.3096412420272827], [2.7797231674194336, 3.6487529277801514, 1.9871783256530762, 3.7055275440216064, 3.6746177673339844, 2.1644134521484375, 2.245126724243164], [2.9118025302886963, 3.802992343902588, 2.065687894821167, 3.864933729171753, 3.8291542530059814, 2.249676465988159, 2.338163375854492], [1.9074100255966187, 2.604999303817749, 1.454802393913269, 2.628361225128174, 2.58998441696167, 1.5987392663955688, 1.6370428800582886], [2.2299890518188477, 2.9995882511138916, 1.656195044517517, 3.034489631652832, 2.9987759590148926, 1.8132710456848145, 1.8644758462905884], [2.2064223289489746, 2.968350887298584, 1.6395962238311768, 3.0023818016052246, 2.967528820037842, 1.7951533794403076, 1.8450491428375244], [1.825587272644043, 2.504408597946167, 1.40525221824646, 2.524179697036743, 2.4838945865631104, 1.5439587831497192, 1.5795185565948486], [2.3835668563842773, 3.18274188041687, 1.7487746477127075, 3.2250773906707764, 3.1927390098571777, 1.9120702743530273, 1.970400094985962], [2.5847907066345215, 3.4183030128479004, 1.8696506023406982, 3.4700281620025635, 3.43791127204895, 2.040125608444214, 2.1086325645446777], [1.9922746419906616, 2.710876703262329, 1.5074763298034668, 2.737647533416748, 2.6981780529022217, 1.6565555334091187, 1.6993708610534668], [2.912576198577881, 3.808840274810791, 2.0656676292419434, 3.868124485015869, 3.8262178897857666, 2.252346992492676, 2.339547634124756], [1.2069857120513916, 1.7295104265213013, 1.0091356039047241, 1.7335723638534546, 1.6872029304504395, 1.1032593250274658, 1.1338146924972534], [1.2228983640670776, 1.7484767436981201, 1.0188957452774048, 1.7535372972488403, 1.7088837623596191, 1.1136094331741333, 1.1456693410873413], [2.3998355865478516, 3.2024002075195312, 1.7594904899597168, 3.2467551231384277, 3.212388515472412, 1.9214451313018799, 1.9836432933807373], [2.207329750061035, 2.9701294898986816, 1.6396937370300293, 3.0036568641662598, 2.96848726272583, 1.794787049293518, 1.8465476036071777], [2.835420608520508, 3.7106058597564697, 2.0199127197265625, 3.7699408531188965, 3.739480972290039, 2.2020423412323, 2.281355857849121], [2.803772211074829, 3.674506902694702, 2.0017154216766357, 3.7341816425323486, 3.7054173946380615, 2.173844337463379, 2.2587485313415527], [1.3339155912399292, 1.8903695344924927, 1.090512990951538, 1.8967556953430176, 1.8516343832015991, 1.1965422630310059, 1.2288278341293335], [2.9372780323028564, 3.8324718475341797, 2.079810857772827, 3.8918824195861816, 3.855220317840576, 2.2592177391052246, 2.3543362617492676], [1.9599531888961792, 2.6702983379364014, 1.4865081310272217, 2.693800449371338, 2.657582998275757, 1.6311814785003662, 1.672644853591919], [2.8525733947753906, 3.728825330734253, 2.0297484397888184, 3.791062355041504, 3.760688543319702, 2.206099033355713, 2.292922019958496], [2.939279317855835, 3.8389203548431396, 2.082540512084961, 3.897667646408081, 3.859407901763916, 2.263193130493164, 2.357849597930908], [2.911191940307617, 3.802417516708374, 2.0633671283721924, 3.862738847732544, 3.829395055770874, 2.248026132583618, 2.3356003761291504], [2.768455743789673, 3.6352996826171875, 1.9800552129745483, 3.6937460899353027, 3.663114309310913, 2.154388904571533, 2.2369794845581055], [2.364257574081421, 3.1600282192230225, 1.736278772354126, 3.200725793838501, 3.164210557937622, 1.896067500114441, 1.9577884674072266], [1.15373957157135, 1.6607953310012817, 0.9743911027908325, 1.6652592420578003, 1.6193104982376099, 1.064851999282837, 1.0957425832748413], [2.109168529510498, 2.8505451679229736, 1.579884648323059, 2.8808741569519043, 2.843608856201172, 1.732295036315918, 1.7774125337600708], [1.8808189630508423, 2.57243013381958, 1.4374017715454102, 2.5940325260162354, 2.5539710521698, 1.580944299697876, 1.617960810661316], [2.5622777938842773, 3.398297071456909, 1.8570587635040283, 3.445237159729004, 3.4082539081573486, 2.0311198234558105, 2.0963830947875977], [1.4351227283477783, 2.0181593894958496, 1.1567227840423584, 2.0267245769500732, 1.9838497638702393, 1.270472764968872, 1.3006213903427124], [2.051011800765991, 2.781076192855835, 1.5448362827301025, 2.808486223220825, 2.7699527740478516, 1.6952736377716064, 1.7374862432479858], [2.3223254680633545, 3.1103127002716064, 1.709763526916504, 3.150050163269043, 3.112584114074707, 1.874220609664917, 1.9276354312896729], [2.9338741302490234, 3.832643508911133, 2.078972816467285, 3.8909618854522705, 3.8541719913482666, 2.265212297439575, 2.3547072410583496], [2.2784805297851562, 3.0554165840148926, 1.6845605373382568, 3.0934736728668213, 3.0585622787475586, 1.8455216884613037, 1.8968766927719116], [1.421189785003662, 2.000809669494629, 1.1476125717163086, 2.0085058212280273, 1.9643759727478027, 1.2590796947479248, 1.2895525693893433], [2.566288709640503, 3.401456117630005, 1.8602571487426758, 3.4504001140594482, 3.4195363521575928, 2.029677152633667, 2.098137378692627], [1.674268126487732, 2.317563772201538, 1.3079400062561035, 2.331644058227539, 2.290431499481201, 1.4384405612945557, 1.470580816268921], [2.937999963760376, 3.83201265335083, 2.081810235977173, 3.893263101577759, 3.8588976860046387, 2.2687456607818604, 2.3550472259521484], [2.0902867317199707, 2.8287787437438965, 1.5672900676727295, 2.8579585552215576, 2.8195393085479736, 1.7193306684494019, 1.7640936374664307], [1.7441668510437012, 2.4060959815979004, 1.3522393703460693, 2.4221861362457275, 2.380526065826416, 1.4873322248458862, 1.5228196382522583], [2.392320156097412, 3.1912455558776855, 1.7537562847137451, 3.233858108520508, 3.1992340087890625, 1.9176599979400635, 1.9743058681488037], [2.286902666091919, 3.0684735774993896, 1.6890770196914673, 3.1067051887512207, 3.0685572624206543, 1.8512682914733887, 1.9045966863632202], [1.7728320360183716, 2.4410390853881836, 1.372409701347351, 2.458120107650757, 2.419196605682373, 1.5076971054077148, 1.542114496231079], [2.861710548400879, 3.7425343990325928, 2.0360264778137207, 3.8045966625213623, 3.7718241214752197, 2.213466167449951, 2.302609443664551], [1.535822868347168, 2.146798849105835, 1.2198878526687622, 2.155801773071289, 2.1149423122406006, 1.3417656421661377, 1.3713302612304688], [1.6907154321670532, 2.337186813354492, 1.3175982236862183, 2.3527214527130127, 2.3103792667388916, 1.4516007900238037, 1.4834026098251343], [2.921140670776367, 3.813918113708496, 2.071690797805786, 3.873594284057617, 3.8381667137145996, 2.2556700706481934, 2.343081474304199], [2.657081365585327, 3.5061848163604736, 1.9141020774841309, 3.558821439743042, 3.5255117416381836, 2.088376522064209, 2.160046100616455], [2.9325060844421387, 3.8249263763427734, 2.0765254497528076, 3.8853530883789062, 3.853066921234131, 2.25545072555542, 2.3494553565979004], [2.7708938121795654, 3.637763023376465, 1.981046199798584, 3.697476863861084, 3.6656711101531982, 2.1592185497283936, 2.2378993034362793], [2.7596499919891357, 3.6245133876800537, 1.9754796028137207, 3.6836559772491455, 3.6533141136169434, 2.151825189590454, 2.2300362586975098], [2.7995550632476807, 3.6693811416625977, 1.9982225894927979, 3.728717803955078, 3.700284004211426, 2.1734724044799805, 2.256575584411621], [2.7276508808135986, 3.5933234691619873, 1.9565858840942383, 3.6452412605285645, 3.60200572013855, 2.133322238922119, 2.213470935821533], [2.4483511447906494, 3.259962558746338, 1.7888706922531128, 3.3043863773345947, 3.270691156387329, 1.9500327110290527, 2.016172170639038], [1.5743013620376587, 2.1950509548187256, 1.2457040548324585, 2.206294536590576, 2.1643218994140625, 1.3710606098175049, 1.4004892110824585], [2.4378864765167236, 3.248582363128662, 1.7819563150405884, 3.2910044193267822, 3.2573606967926025, 1.9486615657806396, 2.0067901611328125], [1.5049365758895874, 2.1053316593170166, 1.2002782821655273, 2.11542010307312, 2.07283091545105, 1.320238709449768, 1.3506428003311157], [2.6726980209350586, 3.522876262664795, 1.9237749576568604, 3.577653408050537, 3.5482676029205322, 2.0938124656677246, 2.169489860534668], [1.7500879764556885, 2.4138593673706055, 1.35418701171875, 2.4289095401763916, 2.3889448642730713, 1.4906251430511475, 1.5233651399612427], [1.8544235229492188, 2.540219306945801, 1.420997977256775, 2.5619890689849854, 2.5217199325561523, 1.5637116432189941, 1.598962664604187], [2.7245001792907715, 3.5854172706604004, 1.9536808729171753, 3.642143726348877, 3.6056106090545654, 2.1300430297851562, 2.2097277641296387], [2.8824193477630615, 3.7661502361297607, 2.0477023124694824, 3.8277523517608643, 3.797320604324341, 2.2256479263305664, 2.3147101402282715], [2.515104055404663, 3.3383662700653076, 1.8273680210113525, 3.384986639022827, 3.35237455368042, 1.9979400634765625, 2.061875820159912], [2.4014241695404053, 3.203390121459961, 1.7590482234954834, 3.2456891536712646, 3.211592674255371, 1.9234249591827393, 1.982850432395935], [2.931417942047119, 3.8233790397644043, 2.0758421421051025, 3.8848254680633545, 3.8498945236206055, 2.2540602684020996, 2.3486881256103516], [2.1886773109436035, 2.9501194953918457, 1.6309325695037842, 2.9845147132873535, 2.9487624168395996, 1.789535641670227, 1.835501790046692], [2.859079599380493, 3.737330675125122, 2.0341579914093018, 3.797417402267456, 3.765876054763794, 2.202037811279297, 2.2954936027526855], [2.421254873275757, 3.227083206176758, 1.77165687084198, 3.2705166339874268, 3.2377164363861084, 1.932464599609375, 1.9970169067382812], [2.9567630290985107, 3.8561229705810547, 2.0914106369018555, 3.9154961109161377, 3.8814053535461426, 2.2770164012908936, 2.3663101196289062], [1.1078128814697266, 1.6011536121368408, 0.9442254900932312, 1.6051381826400757, 1.558465600013733, 1.0280519723892212, 1.063209891319275], [2.9509215354919434, 3.8463947772979736, 2.0895416736602783, 3.9095654487609863, 3.8746113777160645, 2.279047966003418, 2.362914562225342], [1.9757500886917114, 2.689408779144287, 1.4982264041900635, 2.715026617050171, 2.6761932373046875, 1.6463727951049805, 1.6866282224655151], [1.5001450777053833, 2.099708080291748, 1.19725501537323, 2.1098296642303467, 2.06851863861084, 1.3172600269317627, 1.346353530883789], [2.4306561946868896, 3.237406015396118, 1.776606798171997, 3.28108549118042, 3.2469558715820312, 1.9391508102416992, 2.0024237632751465], [2.1151790618896484, 2.8590140342712402, 1.582628846168518, 2.888472557067871, 2.850511074066162, 1.736576795578003, 1.7815124988555908], [1.3076262474060059, 1.8587981462478638, 1.0728346109390259, 1.8638174533843994, 1.8197821378707886, 1.1767261028289795, 1.2075984477996826], [2.208178997039795, 2.970270872116089, 1.6405662298202515, 3.005645990371704, 2.9712893962860107, 1.798846960067749, 1.8476293087005615], [1.2611619234085083, 1.7974295616149902, 1.043894648551941, 1.802842378616333, 1.7573777437210083, 1.1435050964355469, 1.174320101737976], [1.3321888446807861, 1.887282371520996, 1.0908108949661255, 1.895150065422058, 1.849959135055542, 1.1972278356552124, 1.2264854907989502], [1.2670128345489502, 1.8050358295440674, 1.0492820739746094, 1.8096420764923096, 1.7654995918273926, 1.148337721824646, 1.1778783798217773], [2.394456624984741, 3.194110155105591, 1.7548115253448486, 3.2371666431427, 3.203737735748291, 1.9170823097229004, 1.9769572019577026], [2.134812116622925, 2.882152795791626, 1.5970664024353027, 2.914001226425171, 2.8772289752960205, 1.7486540079116821, 1.7971090078353882], [2.9729015827178955, 3.8749587535858154, 2.102494239807129, 3.936958074569702, 3.89863920211792, 2.294248342514038, 2.38067626953125], [1.2877898216247559, 1.8323843479156494, 1.0605254173278809, 1.8369767665863037, 1.793184518814087, 1.1629945039749146, 1.192321538925171], [2.6980152130126953, 3.552412509918213, 1.9382163286209106, 3.6089835166931152, 3.5776522159576416, 2.110116481781006, 2.1881446838378906], [1.941386342048645, 2.647033214569092, 1.4750244617462158, 2.671555757522583, 2.6318447589874268, 1.6207737922668457, 1.6609487533569336], [1.0056068897247314, 1.469449520111084, 0.8765043020248413, 1.471851110458374, 1.4251476526260376, 0.9504753351211548, 0.9862104654312134], [2.761486053466797, 3.625430107116699, 1.9758950471878052, 3.6841654777526855, 3.6552491188049316, 2.147524356842041, 2.2305002212524414], [2.0275940895080566, 2.7530195713043213, 1.5297797918319702, 2.7791311740875244, 2.7400529384613037, 1.6770130395889282, 1.7196409702301025], [0.9995208978652954, 1.4613112211227417, 0.8727272748947144, 1.4632422924041748, 1.4176735877990723, 0.944938063621521, 0.981608510017395], [1.4725334644317627, 2.067430257797241, 1.1809415817260742, 2.077378273010254, 2.0338313579559326, 1.2984791994094849, 1.3287111520767212], [2.022155523300171, 2.74676251411438, 1.5271427631378174, 2.7714853286743164, 2.7369186878204346, 1.6732887029647827, 1.7171043157577515], [2.9439544677734375, 3.837109327316284, 2.0840253829956055, 3.8979976177215576, 3.8654706478118896, 2.263148546218872, 2.355839252471924], [2.882458448410034, 3.7637939453125, 2.0477755069732666, 3.8275842666625977, 3.796276092529297, 2.23075008392334, 2.3152737617492676], [2.823906183242798, 3.698965072631836, 2.0137970447540283, 3.7603819370269775, 3.729418992996216, 2.1928870677948, 2.275935649871826], [1.2847583293914795, 1.8272606134414673, 1.058384656906128, 1.832773208618164, 1.789196252822876, 1.1590919494628906, 1.1902862787246704], [2.0352885723114014, 2.761240243911743, 1.5329340696334839, 2.788224697113037, 2.750058174133301, 1.6833323240280151, 1.7256044149398804], [2.9983596801757812, 3.9080917835235596, 2.117467164993286, 3.968064785003662, 3.9273791313171387, 2.313077926635742, 2.3995089530944824], [2.802241563796997, 3.6753933429718018, 2.000483274459839, 3.7352395057678223, 3.7032036781311035, 2.175903797149658, 2.2614693641662598], [2.4434974193573, 3.255045175552368, 1.7845189571380615, 3.2992851734161377, 3.2622272968292236, 1.9507031440734863, 2.01243257522583], [2.6750431060791016, 3.526198625564575, 1.925202488899231, 3.581580400466919, 3.5522961616516113, 2.09649658203125, 2.171436309814453], [1.7912369966506958, 2.464301109313965, 1.382529377937317, 2.48372745513916, 2.4425158500671387, 1.5212565660476685, 1.556681513786316], [1.0902762413024902, 1.5791782140731812, 0.9328814744949341, 1.582261323928833, 1.5356340408325195, 1.0171228647232056, 1.0489307641983032], [1.8168203830718994, 2.4939498901367188, 1.3977055549621582, 2.512550115585327, 2.4729275703430176, 1.5363235473632812, 1.57171630859375], [1.5233094692230225, 2.1292707920074463, 1.213261365890503, 2.1391663551330566, 2.0970308780670166, 1.3337467908859253, 1.3632662296295166], [1.8255529403686523, 2.504828929901123, 1.4040356874465942, 2.524362087249756, 2.484928846359253, 1.5431348085403442, 1.578794002532959], [2.9941720962524414, 3.9030425548553467, 2.114152431488037, 3.9604365825653076, 3.9197230339050293, 2.3032546043395996, 2.3971152305603027], [2.8691885471343994, 3.749490976333618, 2.0399134159088135, 3.811284303665161, 3.779404640197754, 2.218993663787842, 2.3049373626708984], [1.2606629133224487, 1.796372890472412, 1.044433832168579, 1.8016265630722046, 1.7581807374954224, 1.1437900066375732, 1.1729185581207275], [1.1778936386108398, 1.6909105777740479, 0.9897863864898682, 1.6946070194244385, 1.6499884128570557, 1.0816361904144287, 1.1119312047958374], [2.9879558086395264, 3.8992230892181396, 2.1108195781707764, 3.9557628631591797, 3.9090511798858643, 2.3017821311950684, 2.3962721824645996], [1.6892294883728027, 2.338433265686035, 1.3177947998046875, 2.352309226989746, 2.3111095428466797, 1.450060486793518, 1.4827767610549927], [1.2837014198303223, 1.825432538986206, 1.0600745677947998, 1.8319751024246216, 1.786794662475586, 1.1609036922454834, 1.1907035112380981], [2.8808469772338867, 3.7608861923217773, 2.0462563037872314, 3.824449062347412, 3.792022466659546, 2.2183878421783447, 2.3134474754333496], [2.98821759223938, 3.8972909450531006, 2.1112561225891113, 3.956660032272339, 3.916560411453247, 2.3024497032165527, 2.396069049835205], [1.2452024221420288, 1.7773641347885132, 1.033522129058838, 1.7814377546310425, 1.7364383935928345, 1.1295548677444458, 1.161411166191101], [1.9529045820236206, 2.661835193634033, 1.4843679666519165, 2.6855249404907227, 2.6493587493896484, 1.6277837753295898, 1.6693085432052612], [2.376075267791748, 3.172569513320923, 1.744120717048645, 3.2144646644592285, 3.1773269176483154, 1.9082282781600952, 1.9637516736984253], [1.8275277614593506, 2.507737874984741, 1.4044660329818726, 2.52665114402771, 2.487020969390869, 1.5429000854492188, 1.5794585943222046], [1.0210802555084229, 1.489610195159912, 0.886741042137146, 1.4916496276855469, 1.4455225467681885, 0.960077166557312, 0.9986072778701782], [2.367830753326416, 3.163449764251709, 1.7383595705032349, 3.2051761150360107, 3.169649362564087, 1.902221441268921, 1.9597221612930298], [1.2416211366653442, 1.772873044013977, 1.0318882465362549, 1.7777117490768433, 1.7325941324234009, 1.1281027793884277, 1.1586970090866089], [1.3767879009246826, 1.945326328277588, 1.1178056001663208, 1.951554775238037, 1.908004641532898, 1.2283644676208496, 1.2566810846328735], [1.6222623586654663, 2.253295421600342, 1.2770776748657227, 2.2668325901031494, 2.2249670028686523, 1.4056458473205566, 1.4342578649520874], [2.542529821395874, 3.3686745166778564, 1.8457739353179932, 3.4171810150146484, 3.384822368621826, 2.0111544132232666, 2.078941822052002], [2.9461796283721924, 3.844496965408325, 2.086442470550537, 3.9033915996551514, 3.866328239440918, 2.268606185913086, 2.3585238456726074], [2.416482448577881, 3.223104238510132, 1.769473671913147, 3.2668795585632324, 3.233699083328247, 1.9311110973358154, 1.9945262670516968], [1.100879430770874, 1.5920506715774536, 0.9397255778312683, 1.5962159633636475, 1.5503627061843872, 1.0236698389053345, 1.0570666790008545], [2.159050226211548, 2.9125592708587646, 1.6094496250152588, 2.9432566165924072, 2.9051616191864014, 1.7637741565704346, 1.812111496925354], [2.93196964263916, 3.8252804279327393, 2.078916311264038, 3.886894941329956, 3.85068416595459, 2.265308380126953, 2.3510985374450684], [2.9442145824432373, 3.8389406204223633, 2.083643913269043, 3.9007558822631836, 3.8667664527893066, 2.268012285232544, 2.359241008758545], [1.9964138269424438, 2.7149529457092285, 1.5104079246520996, 2.740841865539551, 2.703260660171509, 1.6584365367889404, 1.6984939575195312], [2.632301092147827, 3.4761693477630615, 1.8996119499206543, 3.5296084880828857, 3.497680902481079, 2.0669639110565186, 2.1425180435180664], [2.2817041873931885, 3.0606517791748047, 1.684138298034668, 3.098464012145996, 3.0616939067840576, 1.8446495532989502, 1.8997541666030884], [1.5112063884735107, 2.1142385005950928, 1.2036643028259277, 2.1235785484313965, 2.081019639968872, 1.324039101600647, 1.353716254234314], [2.200986385345459, 2.963468313217163, 1.636757731437683, 2.9975945949554443, 2.962705612182617, 1.7934083938598633, 1.8434299230575562], [1.145134687423706, 1.6496840715408325, 0.9669980406761169, 1.6525578498840332, 1.607529640197754, 1.0568642616271973, 1.087398648262024], [1.262727975845337, 1.8005775213241577, 1.0453816652297974, 1.8055006265640259, 1.7611851692199707, 1.1457934379577637, 1.1757701635360718], [2.779775857925415, 3.6479320526123047, 1.985619068145752, 3.7054896354675293, 3.677906036376953, 2.161051034927368, 2.2441139221191406], [2.1413583755493164, 2.890986442565918, 1.6004501581192017, 2.9225571155548096, 2.8857688903808594, 1.75390625, 1.8016612529754639], [2.7682738304138184, 3.6330394744873047, 1.9795551300048828, 3.6924543380737305, 3.660630464553833, 2.1573054790496826, 2.23599910736084], [1.2724859714508057, 1.8122422695159912, 1.0520260334014893, 1.8170216083526611, 1.7724543809890747, 1.1509953737258911, 1.1816614866256714], [2.8657987117767334, 3.7474067211151123, 2.0389721393585205, 3.808521032333374, 3.7749533653259277, 2.2101075649261475, 2.303534507751465], [2.813524007797241, 3.685544967651367, 2.006087064743042, 3.7470543384552, 3.7165720462799072, 2.1817173957824707, 2.2672290802001953], [2.721616268157959, 3.579185724258423, 1.951454520225525, 3.636610984802246, 3.6055126190185547, 2.1206893920898438, 2.203418731689453], [2.3447165489196777, 3.135232448577881, 1.7235054969787598, 3.1742584705352783, 3.138021469116211, 1.8830069303512573, 1.9421725273132324], [2.5348896980285645, 3.3609564304351807, 1.840712070465088, 3.4094090461730957, 3.377110242843628, 2.0063490867614746, 2.0736141204833984], [2.330260753631592, 3.1162006855010986, 1.7157455682754517, 3.1563236713409424, 3.1198227405548096, 1.8760374784469604, 1.931961178779602], [2.6227214336395264, 3.464571475982666, 1.894209861755371, 3.5181589126586914, 3.4881770610809326, 2.0621073246002197, 2.135220527648926], [1.7121977806091309, 2.3661675453186035, 1.3312270641326904, 2.3800623416900635, 2.3403477668762207, 1.466099739074707, 1.4988913536071777], [1.3739972114562988, 1.941150426864624, 1.117214560508728, 1.9498683214187622, 1.9053900241851807, 1.2270015478134155, 1.256606101989746], [2.907731533050537, 3.7973074913024902, 2.0625617504119873, 3.8599469661712646, 3.8245112895965576, 2.247537136077881, 2.333284854888916], [1.08758544921875, 1.5750207901000977, 0.9301000833511353, 1.5783793926239014, 1.5328431129455566, 1.011347770690918, 1.0467262268066406], [2.485001564025879, 3.3042657375335693, 1.8096368312835693, 3.3503212928771973, 3.312318801879883, 1.9772148132324219, 2.040281295776367], [2.6780447959899902, 3.5286130905151367, 1.9250679016113281, 3.583233118057251, 3.550567626953125, 2.099571704864502, 2.172478675842285], [2.762594699859619, 3.6262123584747314, 1.975624680519104, 3.6844491958618164, 3.656137704849243, 2.1505160331726074, 2.230654716491699], [1.9287906885147095, 2.632533311843872, 1.4695055484771729, 2.6565542221069336, 2.616572856903076, 1.6132330894470215, 1.6521331071853638], [1.9978209733963013, 2.716972827911377, 1.5108658075332642, 2.7424917221069336, 2.7062692642211914, 1.659255862236023, 1.7008774280548096], [2.939755439758301, 3.8374440670013428, 2.0826313495635986, 3.895251512527466, 3.8593802452087402, 2.260406732559204, 2.3582496643066406], [2.58048677444458, 3.4154508113861084, 1.8667945861816406, 3.4660394191741943, 3.432494640350342, 2.0420613288879395, 2.107384204864502], [2.625612258911133, 3.466356039047241, 1.8942841291427612, 3.5189261436462402, 3.486356019973755, 2.069180488586426, 2.135835647583008], [2.942260980606079, 3.838460922241211, 2.083448648452759, 3.8994240760803223, 3.862706422805786, 2.2694478034973145, 2.358372211456299], [2.6954052448272705, 3.5507447719573975, 1.9372398853302002, 3.6071488857269287, 3.576848030090332, 2.1050021648406982, 2.1857824325561523], [2.5313615798950195, 3.3553078174591064, 1.8377665281295776, 3.4047398567199707, 3.3699488639831543, 2.0092451572418213, 2.071599006652832], [2.7243611812591553, 3.585092067718506, 1.9549713134765625, 3.641799211502075, 3.609494924545288, 2.1227712631225586, 2.206538200378418], [1.2388006448745728, 1.7702239751815796, 1.0296391248703003, 1.7751078605651855, 1.72948157787323, 1.1270318031311035, 1.157281517982483], [2.6227307319641113, 3.465837240219116, 1.8927431106567383, 3.5183963775634766, 3.485093355178833, 2.0681354999542236, 2.136808395385742], [1.8973369598388672, 2.5927553176879883, 1.4471924304962158, 2.614483594894409, 2.5750601291656494, 1.5948126316070557, 1.6276211738586426], [2.9709270000457764, 3.8715672492980957, 2.1001698970794678, 3.9336044788360596, 3.8970093727111816, 2.2906436920166016, 2.377410411834717], [1.1117466688156128, 1.6057854890823364, 0.9476673007011414, 1.6083272695541382, 1.5634006261825562, 1.0323160886764526, 1.0644488334655762], [2.9683995246887207, 3.8709914684295654, 2.0994741916656494, 3.9322474002838135, 3.89389705657959, 2.287642478942871, 2.378018856048584], [2.261798858642578, 3.0365395545959473, 1.6735820770263672, 3.073758125305176, 3.035674571990967, 1.830122947692871, 1.885684847831726], [2.7115797996520996, 3.5700905323028564, 1.946905255317688, 3.6271259784698486, 3.5942223072052, 2.1221773624420166, 2.2002053260803223], [2.0332372188568115, 2.758307695388794, 1.5312551259994507, 2.785773992538452, 2.7470858097076416, 1.6827644109725952, 1.72404944896698], [2.772780418395996, 3.638760805130005, 1.983119010925293, 3.699638605117798, 3.668295383453369, 2.1580538749694824, 2.2396154403686523], [1.588955044746399, 2.210845708847046, 1.254828691482544, 2.2235021591186523, 2.1819636821746826, 1.3792719841003418, 1.4097599983215332], [1.532886028289795, 2.14163875579834, 1.2191798686981201, 2.152627944946289, 2.109618663787842, 1.3406354188919067, 1.3701997995376587], [3.0009803771972656, 3.911851406097412, 2.118739128112793, 3.9726643562316895, 3.9304022789001465, 2.3163766860961914, 2.404602527618408], [0.9926220178604126, 1.4537301063537598, 0.8674460053443909, 1.454635500907898, 1.4094345569610596, 0.9381895065307617, 0.9764808416366577], [2.8134522438049316, 3.6880502700805664, 2.0067124366760254, 3.7459909915924072, 3.711665153503418, 2.1859097480773926, 2.267005443572998], [2.9181759357452393, 3.8080151081085205, 2.068418264389038, 3.871504783630371, 3.8368592262268066, 2.2524712085723877, 2.339876651763916], [2.936410427093506, 3.8314616680145264, 2.080753803253174, 3.892487049102783, 3.8599133491516113, 2.265645742416382, 2.3534059524536133], [2.9074857234954834, 3.795226573944092, 2.062412977218628, 3.855881690979004, 3.8211264610290527, 2.240978717803955, 2.3298850059509277], [2.709554433822632, 3.5650393962860107, 1.9444465637207031, 3.6221048831939697, 3.588984966278076, 2.1213157176971436, 2.195988178253174], [1.6624302864074707, 2.3033969402313232, 1.300877332687378, 2.3178961277008057, 2.2757647037506104, 1.4288136959075928, 1.4633105993270874], [1.3755007982254028, 1.9434436559677124, 1.11860191822052, 1.9508835077285767, 1.9079926013946533, 1.2287367582321167, 1.2567245960235596], [2.4238224029541016, 3.2286832332611084, 1.772043228149414, 3.2736971378326416, 3.2366843223571777, 1.9380621910095215, 1.9969598054885864], [1.3407031297683716, 1.898850679397583, 1.0935766696929932, 1.9043338298797607, 1.8614745140075684, 1.199873685836792, 1.2307612895965576], [1.2482088804244995, 1.78229558467865, 1.0357609987258911, 1.7859829664230347, 1.742120385169983, 1.1322447061538696, 1.1647688150405884], [1.1307272911071777, 1.631426215171814, 0.9585174322128296, 1.634352684020996, 1.5880521535873413, 1.045969843864441, 1.0792927742004395], [2.941688060760498, 3.8376550674438477, 2.084688186645508, 3.898585319519043, 3.863750457763672, 2.2733092308044434, 2.357574462890625], [1.4786288738250732, 2.0741989612579346, 1.1836283206939697, 2.083914279937744, 2.04086971282959, 1.3021475076675415, 1.331507682800293], [2.10383939743042, 2.8484156131744385, 1.5760688781738281, 2.878880262374878, 2.84051775932312, 1.732378363609314, 1.7771565914154053], [1.3124985694885254, 1.8630365133285522, 1.077467441558838, 1.8692069053649902, 1.8260631561279297, 1.1814963817596436, 1.2110884189605713], [2.7140893936157227, 3.5705010890960693, 1.9474424123764038, 3.6264326572418213, 3.5942728519439697, 2.1262333393096924, 2.1974687576293945], [1.3827780485153198, 1.9542454481124878, 1.1222612857818604, 1.961108684539795, 1.9171911478042603, 1.2343862056732178, 1.2644190788269043], [1.025596022605896, 1.4953868389129639, 0.8899506330490112, 1.497302532196045, 1.4512550830841064, 0.9642133712768555, 1.0000951290130615], [1.3080174922943115, 1.8572580814361572, 1.0748673677444458, 1.8631850481033325, 1.8185805082321167, 1.1774659156799316, 1.2093532085418701], [1.124776840209961, 1.6240043640136719, 0.9546554684638977, 1.6268826723098755, 1.58122718334198, 1.0414812564849854, 1.0734766721725464], [1.1085565090179443, 1.602975845336914, 0.9446545839309692, 1.605467438697815, 1.5604667663574219, 1.0278340578079224, 1.0624970197677612], [2.8526718616485596, 3.731455087661743, 2.030123233795166, 3.7915401458740234, 3.760354518890381, 2.203853130340576, 2.293539047241211], [1.6953331232070923, 2.345350980758667, 1.3213860988616943, 2.3593997955322266, 2.319406032562256, 1.4538938999176025, 1.4874423742294312], [2.89123797416687, 3.776498317718506, 2.0537357330322266, 3.8399014472961426, 3.80717134475708, 2.2390897274017334, 2.3221435546875], [2.909543514251709, 3.7991132736206055, 2.064279794692993, 3.8600339889526367, 3.8272037506103516, 2.2490081787109375, 2.3326773643493652], [2.206169366836548, 2.9683563709259033, 1.6402766704559326, 3.0025925636291504, 2.9668922424316406, 1.796189546585083, 1.845334529876709], [2.1842007637023926, 2.9421324729919434, 1.6264023780822754, 2.9765632152557373, 2.9414710998535156, 1.7837518453598022, 1.8309434652328491], [2.1842596530914307, 2.942303419113159, 1.626326322555542, 2.9756019115448, 2.939307689666748, 1.7829114198684692, 1.8307634592056274], [2.062241315841675, 2.795830011367798, 1.5510485172271729, 2.8239665031433105, 2.7865331172943115, 1.7039121389389038, 1.745221734046936], [1.9116958379745483, 2.6117045879364014, 1.4582512378692627, 2.634157419204712, 2.595885753631592, 1.602837324142456, 1.640425205230713], [1.0571473836898804, 1.5356844663619995, 0.9101495146751404, 1.5394840240478516, 1.4925317764282227, 0.9878697395324707, 1.0244985818862915], [1.1464935541152954, 1.649291753768921, 0.9687584042549133, 1.6538619995117188, 1.6080374717712402, 1.0567303895950317, 1.0891337394714355], [1.6975566148757935, 2.347787380218506, 1.322153091430664, 2.3638811111450195, 2.322354555130005, 1.4546213150024414, 1.488100290298462], [1.98053777217865, 2.6962780952453613, 1.5010323524475098, 2.7234156131744385, 2.6845858097076416, 1.6498072147369385, 1.6902340650558472], [1.5909879207611084, 2.2137718200683594, 1.2562627792358398, 2.2264339923858643, 2.1848716735839844, 1.3822702169418335, 1.4125491380691528], [2.912071943283081, 3.801809787750244, 2.0650064945220947, 3.863602638244629, 3.832760810852051, 2.2507107257843018, 2.3358187675476074], [1.223248839378357, 1.7488240003585815, 1.0195369720458984, 1.7535979747772217, 1.7082560062408447, 1.114936113357544, 1.146360158920288], [1.0630160570144653, 1.5435643196105957, 0.9140039682388306, 1.546177625656128, 1.4994252920150757, 0.992497444152832, 1.0288543701171875], [2.476156234741211, 3.2928314208984375, 1.8039828538894653, 3.3378353118896484, 3.305697441101074, 1.9720146656036377, 2.0351474285125732], [2.41318416595459, 3.2166857719421387, 1.7661470174789429, 3.259880542755127, 3.2259421348571777, 1.933361530303955, 1.9895334243774414], [1.3933558464050293, 1.9663387537002563, 1.1286722421646118, 1.9728007316589355, 1.929274082183838, 1.237497091293335, 1.269250512123108], [2.9186861515045166, 3.8107352256774902, 2.070652961730957, 3.8730061054229736, 3.8380448818206787, 2.2550599575042725, 2.341909408569336], [2.7004952430725098, 3.5564825534820557, 1.9400428533554077, 3.6128363609313965, 3.5825393199920654, 2.1064505577087402, 2.1903443336486816], [2.95928955078125, 3.86419939994812, 2.0942349433898926, 3.921027898788452, 3.878390073776245, 2.279910087585449, 2.3744163513183594], [1.869372010231018, 2.55997371673584, 1.4316203594207764, 2.58182430267334, 2.5428285598754883, 1.5757732391357422, 1.6114201545715332], [2.7836573123931885, 3.65362286567688, 1.9891902208328247, 3.7128803730010986, 3.679882287979126, 2.162999153137207, 2.2478132247924805], [2.607530355453491, 3.4473886489868164, 1.8845865726470947, 3.4995367527008057, 3.4680917263031006, 2.0547544956207275, 2.125678062438965], [2.5672788619995117, 3.4010274410247803, 1.859262228012085, 3.4516265392303467, 3.416931629180908, 2.0276007652282715, 2.099771499633789], [2.744246244430542, 3.607537031173706, 1.9661312103271484, 3.6659045219421387, 3.6329429149627686, 2.1393861770629883, 2.2211761474609375], [2.6372931003570557, 3.4823801517486572, 1.9004950523376465, 3.534238338470459, 3.499729871749878, 2.066009998321533, 2.145735740661621], [1.5348924398422241, 2.143336772918701, 1.2206110954284668, 2.1538541316986084, 2.1114308834075928, 1.3393244743347168, 1.3717396259307861], [2.8022689819335938, 3.6740942001342773, 2.00140380859375, 3.732539176940918, 3.7032220363616943, 2.1779589653015137, 2.2588963508605957], [2.2411949634552, 3.011641263961792, 1.6608437299728394, 3.0477638244628906, 3.011448621749878, 1.8140923976898193, 1.8714121580123901], [3.000735282897949, 3.9121227264404297, 2.120011329650879, 3.9719972610473633, 3.929798126220703, 2.3150289058685303, 2.403611183166504], [2.836902618408203, 3.7177915573120117, 2.021883964538574, 3.776061773300171, 3.740602970123291, 2.2042770385742188, 2.286990165710449], [2.8330154418945312, 3.7094578742980957, 2.0185956954956055, 3.769953727722168, 3.7384908199310303, 2.197061538696289, 2.2819266319274902], [2.002249240875244, 2.721930980682373, 1.513979434967041, 2.7477314472198486, 2.7087996006011963, 1.6629295349121094, 1.7027987241744995], [2.972066879272461, 3.8726727962493896, 2.101626396179199, 3.935068130493164, 3.8966317176818848, 2.2897069454193115, 2.3801870346069336], [2.599456787109375, 3.4387905597686768, 1.8789204359054565, 3.489528179168701, 3.455127477645874, 2.0487914085388184, 2.1197896003723145], [1.1177922487258911, 1.6142773628234863, 0.9512768387794495, 1.6170669794082642, 1.5708109140396118, 1.0361119508743286, 1.0694680213928223], [1.8596551418304443, 2.5499889850616455, 1.425862193107605, 2.5701658725738525, 2.5299530029296875, 1.570347547531128, 1.6055740118026733], [1.8031284809112549, 2.478630781173706, 1.3895188570022583, 2.4972617626190186, 2.4566266536712646, 1.527777910232544, 1.5636903047561646], [2.867492437362671, 3.750286817550659, 2.0393121242523193, 3.8101887702941895, 3.780484437942505, 2.217062473297119, 2.3043832778930664], [2.965488910675049, 3.8700101375579834, 2.096585273742676, 3.930213212966919, 3.8920674324035645, 2.286911964416504, 2.3776822090148926], [1.8622033596038818, 2.5509684085845947, 1.4256576299667358, 2.5720977783203125, 2.5308563709259033, 1.5717308521270752, 1.6059374809265137], [2.9212698936462402, 3.815704584121704, 2.0701355934143066, 3.8751115798950195, 3.8382880687713623, 2.2507035732269287, 2.3424715995788574], [2.4344420433044434, 3.2447330951690674, 1.7800636291503906, 3.289935350418091, 3.254354238510132, 1.9457135200500488, 2.0088021755218506], [2.85593318939209, 3.736591339111328, 2.032670021057129, 3.7963547706604004, 3.765439987182617, 2.2105746269226074, 2.295621871948242], [1.3847445249557495, 1.9545522928237915, 1.1233952045440674, 1.9613919258117676, 1.917838454246521, 1.2345187664031982, 1.2624410390853882], [2.972175359725952, 3.874150514602661, 2.1019744873046875, 3.9361536502838135, 3.899949073791504, 2.293527603149414, 2.380992889404297], [1.5756781101226807, 2.19574236869812, 1.2471261024475098, 2.206914186477661, 2.1654789447784424, 1.368729591369629, 1.4013919830322266], [2.243255853652954, 3.0128087997436523, 1.6635209321975708, 3.0500831604003906, 3.0135550498962402, 1.820960521697998, 1.872918963432312], [2.958982229232788, 3.859816789627075, 2.094078779220581, 3.9200074672698975, 3.880152463912964, 2.2841989994049072, 2.3703713417053223], [3.003727436065674, 3.9134700298309326, 2.120896816253662, 3.974553108215332, 3.9330270290374756, 2.317220687866211, 2.4046249389648438], [1.7186425924301147, 2.3735387325286865, 1.3350144624710083, 2.3886983394622803, 2.3486835956573486, 1.4693981409072876, 1.5007392168045044], [2.047124147415161, 2.7760016918182373, 1.542884111404419, 2.803194999694824, 2.76737380027771, 1.691487193107605, 1.7342971563339233], [2.4234535694122314, 3.230903148651123, 1.77423894405365, 3.2753422260284424, 3.24120831489563, 1.9360244274139404, 1.9989453554153442], [1.283311367034912, 1.825490951538086, 1.0578566789627075, 1.8312819004058838, 1.7867794036865234, 1.1576637029647827, 1.1891521215438843], [2.847980499267578, 3.724499464035034, 2.026214838027954, 3.785935878753662, 3.756593942642212, 2.202528476715088, 2.289322853088379], [2.678140878677368, 3.5295920372009277, 1.9265069961547852, 3.5855162143707275, 3.5537166595458984, 2.0924839973449707, 2.174976348876953], [1.5430940389633179, 2.1543967723846436, 1.2263157367706299, 2.1658883094787598, 2.1241729259490967, 1.34803307056427, 1.3783949613571167], [2.6487579345703125, 3.4958810806274414, 1.9090975522994995, 3.550008773803711, 3.5190746784210205, 2.07705020904541, 2.1536264419555664], [2.7596933841705322, 3.6232593059539795, 1.974806547164917, 3.6815757751464844, 3.649966239929199, 2.144386053085327, 2.2281765937805176], [1.2210770845413208, 1.7474726438522339, 1.017557978630066, 1.751546859741211, 1.706426739692688, 1.1135540008544922, 1.144491195678711], [1.5858793258666992, 2.207141637802124, 1.2515950202941895, 2.2197892665863037, 2.178497076034546, 1.3751884698867798, 1.4076176881790161], [2.90875244140625, 3.799253225326538, 2.064387321472168, 3.8596317768096924, 3.8256895542144775, 2.2431869506835938, 2.33404541015625], [1.659302830696106, 2.299041509628296, 1.3000342845916748, 2.314657688140869, 2.2730069160461426, 1.4295423030853271, 1.461108922958374], [1.8326514959335327, 2.513568639755249, 1.4084287881851196, 2.5337038040161133, 2.493608236312866, 1.5491516590118408, 1.5840367078781128], [2.8857524394989014, 3.7692341804504395, 2.050093173980713, 3.83182954788208, 3.799478054046631, 2.2336947917938232, 2.3170928955078125], [2.9342668056488037, 3.8292133808135986, 2.07844877243042, 3.890181303024292, 3.8553452491760254, 2.258852958679199, 2.3536319732666016], [2.631885051727295, 3.474250555038452, 1.898984670639038, 3.527433395385742, 3.4984076023101807, 2.06886625289917, 2.1400680541992188], [1.6633448600769043, 2.3044583797454834, 1.3021222352981567, 2.31864333152771, 2.276606798171997, 1.431503415107727, 1.463655710220337], [2.113792896270752, 2.8566274642944336, 1.5830775499343872, 2.8875224590301514, 2.8500866889953613, 1.7360124588012695, 1.781741976737976], [2.790370464324951, 3.660214424133301, 1.9939863681793213, 3.719069004058838, 3.689342975616455, 2.1721763610839844, 2.2515087127685547], [2.656125068664551, 3.5027735233306885, 1.9128179550170898, 3.5564959049224854, 3.525580644607544, 2.083927869796753, 2.1575875282287598], [2.257192611694336, 3.03007435798645, 1.6717877388000488, 3.067610502243042, 3.0329782962799072, 1.8274047374725342, 1.8836246728897095], [2.6770472526550293, 3.528162956237793, 1.9255940914154053, 3.5836715698242188, 3.5543699264526367, 2.097024917602539, 2.1728105545043945], [3.0019707679748535, 3.913311004638672, 2.119232654571533, 3.9732861518859863, 3.931082010269165, 2.3180508613586426, 2.4045896530151367], [2.381868839263916, 3.1810765266418457, 1.7458044290542603, 3.2212436199188232, 3.1849305629730225, 1.9065672159194946, 1.9678598642349243], [2.548246383666992, 3.377202272415161, 1.847427487373352, 3.4264421463012695, 3.393399238586426, 2.0136239528656006, 2.0846426486968994], [2.826367139816284, 3.70320725440979, 2.0148422718048096, 3.7636897563934326, 3.73097562789917, 2.1917762756347656, 2.2781944274902344], [1.8119773864746094, 2.487370491027832, 1.3944876194000244, 2.506382465362549, 2.4672019481658936, 1.5358517169952393, 1.5690019130706787], [1.5769634246826172, 2.197445869445801, 1.2459392547607422, 2.2081828117370605, 2.1662235260009766, 1.370467185974121, 1.4008162021636963], [1.4551026821136475, 2.0435550212860107, 1.1678296327590942, 2.052194356918335, 2.008760690689087, 1.2833740711212158, 1.312886118888855], [2.8344624042510986, 3.7129948139190674, 2.018958568572998, 3.773982048034668, 3.7412467002868652, 2.1989316940307617, 2.284555435180664], [1.9256490468978882, 2.6297712326049805, 1.466822624206543, 2.653108835220337, 2.614441394805908, 1.6110459566116333, 1.650199055671692], [1.650477647781372, 2.288663148880005, 1.291724443435669, 2.30177640914917, 2.2597367763519287, 1.422835111618042, 1.4526209831237793], [1.1512072086334229, 1.657267451286316, 0.9734254479408264, 1.6597068309783936, 1.613232135772705, 1.0602837800979614, 1.0929539203643799], [2.692887306213379, 3.5504162311553955, 1.936414361000061, 3.602982759475708, 3.5665979385375977, 2.106151819229126, 2.1853251457214355], [2.8020706176757812, 3.6710760593414307, 2.0004003047943115, 3.7315049171447754, 3.7013399600982666, 2.1758270263671875, 2.257984161376953], [1.3993861675262451, 1.9735208749771118, 1.1335434913635254, 1.980760931968689, 1.9358855485916138, 1.243261456489563, 1.2745474576950073], [2.912163019180298, 3.80025315284729, 2.06457257270813, 3.8600213527679443, 3.829096555709839, 2.2424323558807373, 2.332313060760498], [1.1951812505722046, 1.7134464979171753, 1.0020378828048706, 1.7172231674194336, 1.6710093021392822, 1.0937068462371826, 1.1253044605255127], [1.4489721059799194, 2.0357346534729004, 1.1659735441207886, 2.0455286502838135, 2.0024704933166504, 1.2816954851150513, 1.311076045036316], [1.271383285522461, 1.810488224029541, 1.0518115758895874, 1.8159323930740356, 1.771183729171753, 1.151092529296875, 1.1813074350357056], [2.5777502059936523, 3.411979913711548, 1.8660039901733398, 3.462287664413452, 3.42869234085083, 2.0290966033935547, 2.1040759086608887], [2.347107172012329, 3.1369407176971436, 1.7265875339508057, 3.177807331085205, 3.144231081008911, 1.8874077796936035, 1.9437379837036133], [2.8074464797973633, 3.678619146347046, 2.003755807876587, 3.7376747131347656, 3.70703125, 2.180953025817871, 2.2624154090881348], [2.8266985416412354, 3.705352783203125, 2.015108823776245, 3.765458106994629, 3.730685234069824, 2.195957660675049, 2.279573917388916], [2.412365674972534, 3.2158472537994385, 1.765730381011963, 3.258319139480591, 3.224912166595459, 1.9298322200775146, 1.9894590377807617], [2.573478937149048, 3.4056894779205322, 1.8625422716140747, 3.4546549320220947, 3.425764560699463, 2.0318312644958496, 2.101449489593506], [1.921897530555725, 2.624922513961792, 1.4642834663391113, 2.6480162143707275, 2.608760356903076, 1.6106971502304077, 1.6483234167099], [2.7393972873687744, 3.600749969482422, 1.9622482061386108, 3.6570210456848145, 3.6252737045288086, 2.138424873352051, 2.2163496017456055], [2.5711700916290283, 3.4052090644836426, 1.8611257076263428, 3.4547908306121826, 3.421692132949829, 2.029266834259033, 2.1017327308654785], [2.912992000579834, 3.8058485984802246, 2.0667526721954346, 3.8658721446990967, 3.828554153442383, 2.2550010681152344, 2.3371787071228027], [2.465513229370117, 3.2790005207061768, 1.798216700553894, 3.3241562843322754, 3.2897181510925293, 1.963564395904541, 2.0260133743286133], [1.3746551275253296, 1.9415725469589233, 1.1174956560134888, 1.9489415884017944, 1.905478835105896, 1.2268611192703247, 1.256080150604248], [2.346451759338379, 3.1368765830993652, 1.7254537343978882, 3.177339792251587, 3.143649101257324, 1.8897396326065063, 1.9435808658599854], [1.4047857522964478, 1.9803130626678467, 1.1370444297790527, 1.9875611066818237, 1.9459245204925537, 1.2465832233428955, 1.2779579162597656], [1.5315489768981934, 2.138944149017334, 1.2170056104660034, 2.150223731994629, 2.1069891452789307, 1.339456558227539, 1.3683815002441406], [2.1234383583068848, 2.8680148124694824, 1.590006947517395, 2.899477958679199, 2.863440752029419, 1.743604063987732, 1.7885932922363281], [1.9773160219192505, 2.690448760986328, 1.4976835250854492, 2.7155823707580566, 2.6775035858154297, 1.6444547176361084, 1.6849279403686523], [2.395051956176758, 3.1955432891845703, 1.756054162979126, 3.2382309436798096, 3.2069907188415527, 1.9160387516021729, 1.9787191152572632], [1.5659960508346558, 2.182170867919922, 1.2403658628463745, 2.1951866149902344, 2.1524546146392822, 1.3632384538650513, 1.3953156471252441], [1.922711730003357, 2.6257450580596924, 1.4640073776245117, 2.6499054431915283, 2.609874725341797, 1.6126682758331299, 1.6499603986740112], [2.6124014854431152, 3.4528393745422363, 1.8870962858200073, 3.5044052600860596, 3.473865032196045, 2.0560719966888428, 2.1284170150756836], [2.6939892768859863, 3.5467307567596436, 1.9363576173782349, 3.601686477661133, 3.5714685916900635, 2.1113457679748535, 2.182384967803955], [1.5246225595474243, 2.1324079036712646, 1.2135523557662964, 2.1412200927734375, 2.100113868713379, 1.3359370231628418, 1.3631207942962646], [1.2733116149902344, 1.813510537147522, 1.0515438318252563, 1.8197640180587769, 1.77443528175354, 1.1538382768630981, 1.1835495233535767], [1.957229733467102, 2.664187431335449, 1.4862416982650757, 2.6893293857574463, 2.6519503593444824, 1.6322864294052124, 1.6711235046386719], [2.218510150909424, 2.9837992191314697, 1.647932767868042, 3.016613721847534, 2.9832098484039307, 1.803454875946045, 1.8545376062393188], [2.0039994716644287, 2.7244176864624023, 1.5115410089492798, 2.7473506927490234, 2.7078959941864014, 1.6625492572784424, 1.703389286994934], [2.8151352405548096, 3.6879336833953857, 2.007751226425171, 3.745523691177368, 3.7175374031066895, 2.1838009357452393, 2.265761375427246], [1.691904067993164, 2.3405001163482666, 1.3199571371078491, 2.354830026626587, 2.31592059135437, 1.4531930685043335, 1.483797311782837], [2.250602960586548, 3.024313449859619, 1.6658823490142822, 3.059476137161255, 3.0202724933624268, 1.82841157913208, 1.8779736757278442], [2.1881585121154785, 2.945589542388916, 1.6276354789733887, 2.9792191982269287, 2.9419875144958496, 1.784619927406311, 1.8314822912216187], [1.6895544528961182, 2.337358236312866, 1.3172049522399902, 2.351931095123291, 2.3116369247436523, 1.450189232826233, 1.4819270372390747], [2.3769028186798096, 3.172128915786743, 1.7437450885772705, 3.213989734649658, 3.18015456199646, 1.909398078918457, 1.9634350538253784], [2.253661870956421, 3.0271265506744385, 1.6696621179580688, 3.062283754348755, 3.0284948348999023, 1.8321267366409302, 1.878423810005188], [1.6762077808380127, 2.319418430328369, 1.309994101524353, 2.3348002433776855, 2.293473958969116, 1.4401808977127075, 1.4729015827178955], [1.102885127067566, 1.5952507257461548, 0.941979169845581, 1.5984562635421753, 1.5531647205352783, 1.0252352952957153, 1.0573878288269043], [2.843823194503784, 3.7202608585357666, 2.0243172645568848, 3.779721975326538, 3.75154447555542, 2.202606678009033, 2.2845849990844727], [1.2617636919021606, 1.7991783618927002, 1.0437153577804565, 1.804760456085205, 1.7591371536254883, 1.1423733234405518, 1.1736996173858643], [1.2803161144256592, 1.8230315446853638, 1.0568292140960693, 1.8279391527175903, 1.7830902338027954, 1.157329797744751, 1.1888911724090576], [2.2279367446899414, 2.997288703918457, 1.6528875827789307, 3.0319724082946777, 2.994248390197754, 1.8119584321975708, 1.8635002374649048], [2.8303959369659424, 3.7076728343963623, 2.0168190002441406, 3.7680246829986572, 3.7356927394866943, 2.1994736194610596, 2.2795629501342773], [1.1455618143081665, 1.65221107006073, 0.9687154293060303, 1.655022144317627, 1.60921049118042, 1.0572642087936401, 1.0908843278884888], [2.899756669998169, 3.784104824066162, 2.056375026702881, 3.846956729888916, 3.815859317779541, 2.2328639030456543, 2.3260068893432617], [1.3579946756362915, 1.9204109907150269, 1.107202410697937, 1.9284117221832275, 1.8845239877700806, 1.2158102989196777, 1.2448818683624268], [2.306187629699707, 3.088655710220337, 1.701799988746643, 3.1272666454315186, 3.0932271480560303, 1.8595616817474365, 1.9153170585632324], [2.934969902038574, 3.8277885913848877, 2.0783283710479736, 3.8903679847717285, 3.8567144870758057, 2.2600812911987305, 2.3504409790039062], [1.8371756076812744, 2.520143985748291, 1.4105428457260132, 2.5390431880950928, 2.498819589614868, 1.5493948459625244, 1.586450457572937], [1.3498252630233765, 1.9090893268585205, 1.100992202758789, 1.916353702545166, 1.871836543083191, 1.2095623016357422, 1.2378616333007812], [2.883747100830078, 3.767383098602295, 2.0494697093963623, 3.829610586166382, 3.7972657680511475, 2.2288284301757812, 2.3172507286071777], [2.1976351737976074, 2.957371473312378, 1.6335170269012451, 2.991379976272583, 2.954758405685425, 1.793269395828247, 1.8385493755340576], [2.800114631652832, 3.6742441654205322, 1.998997449874878, 3.7303802967071533, 3.696363687515259, 2.1796627044677734, 2.2586865425109863], [1.1691662073135376, 1.6806503534317017, 0.9840558171272278, 1.6841899156570435, 1.6390728950500488, 1.0743399858474731, 1.106986165046692], [2.6090188026428223, 3.4509458541870117, 1.8853826522827148, 3.500077962875366, 3.463671922683716, 2.053661823272705, 2.1259875297546387], [1.2943006753921509, 1.840522289276123, 1.063966155052185, 1.846099615097046, 1.8014202117919922, 1.1671772003173828, 1.1990619897842407], [2.100038528442383, 2.8416225910186768, 1.572211503982544, 2.8708033561706543, 2.8310539722442627, 1.7266221046447754, 1.7712275981903076], [2.920283794403076, 3.8103315830230713, 2.071265935897827, 3.8731298446655273, 3.840407133102417, 2.2567362785339355, 2.3415846824645996], [2.058908700942993, 2.78948974609375, 1.5495436191558838, 2.8179306983947754, 2.7795450687408447, 1.699122428894043, 1.7422889471054077], [1.6626906394958496, 2.305448055267334, 1.3000832796096802, 2.3191463947296143, 2.276670455932617, 1.4298595190048218, 1.4618147611618042], [1.9195038080215454, 2.620690107345581, 1.461436152458191, 2.643782377243042, 2.604306936264038, 1.6073471307754517, 1.6463148593902588], [2.264284372329712, 3.038337469100952, 1.674014925956726, 3.075208902359009, 3.040090322494507, 1.8358330726623535, 1.885428547859192], [1.9720250368118286, 2.6865923404693604, 1.493039846420288, 2.710465431213379, 2.6684155464172363, 1.643953561782837, 1.6829503774642944], [2.6100804805755615, 3.447611093521118, 1.885041356086731, 3.4992868900299072, 3.4703845977783203, 2.0473477840423584, 2.1255335807800293], [2.8258068561553955, 3.7008731365203857, 2.0142316818237305, 3.7607481479644775, 3.732089042663574, 2.1901602745056152, 2.2755980491638184], [2.3096582889556885, 3.0938773155212402, 1.7026115655899048, 3.132101535797119, 3.098118782043457, 1.8605817556381226, 1.9175556898117065], [2.945863723754883, 3.843200445175171, 2.085109233856201, 3.9037091732025146, 3.868817090988159, 2.269017219543457, 2.358933925628662], [1.2369368076324463, 1.7672244310379028, 1.0284463167190552, 1.7718629837036133, 1.7255847454071045, 1.1248434782028198, 1.1575169563293457], [1.1119381189346313, 1.605837345123291, 0.9466396570205688, 1.6087323427200317, 1.5630491971969604, 1.029948353767395, 1.0623284578323364], [2.057715892791748, 2.788390874862671, 1.5477120876312256, 2.817150115966797, 2.7775590419769287, 1.698392629623413, 1.741127371788025], [1.2653870582580566, 1.8027533292770386, 1.0468865633010864, 1.8086254596710205, 1.7642911672592163, 1.1464588642120361, 1.1771783828735352], [2.4478299617767334, 3.2620790004730225, 1.7883491516113281, 3.3052268028259277, 3.27336049079895, 1.9562697410583496, 2.0164754390716553], [1.552870750427246, 2.1672658920288086, 1.2316093444824219, 2.177753448486328, 2.134880304336548, 1.3542290925979614, 1.3853846788406372], [2.241157293319702, 3.008754253387451, 1.6601742506027222, 3.045130968093872, 3.009453535079956, 1.8191165924072266, 1.8688490390777588], [2.6675314903259277, 3.5179600715637207, 1.920423150062561, 3.573007583618164, 3.540950298309326, 2.089000940322876, 2.166806221008301], [1.6501379013061523, 2.288635492324829, 1.2941219806671143, 2.3025872707366943, 2.260690927505493, 1.4233416318893433, 1.455058217048645], [2.0045416355133057, 2.7244701385498047, 1.5152870416641235, 2.750776529312134, 2.712815523147583, 1.66611647605896, 1.7058682441711426], [2.339120864868164, 3.127934694290161, 1.722044825553894, 3.169191360473633, 3.1354238986968994, 1.8819059133529663, 1.9393181800842285], [2.63533091545105, 3.480752944946289, 1.9014884233474731, 3.53305721282959, 3.500981330871582, 2.0688393115997314, 2.1449098587036133], [2.97666597366333, 3.8802237510681152, 2.1045734882354736, 3.9416885375976562, 3.904581069946289, 2.2981133460998535, 2.3847298622131348], [1.1010385751724243, 1.593677282333374, 0.9390284419059753, 1.595826268196106, 1.5507235527038574, 1.0234031677246094, 1.0565128326416016], [1.6299904584884644, 2.2627644538879395, 1.2806051969528198, 2.275801658630371, 2.234375476837158, 1.408532738685608, 1.44057035446167], [2.0949630737304688, 2.836731195449829, 1.5716636180877686, 2.866626024246216, 2.829317092895508, 1.7241638898849487, 1.7707264423370361], [1.7312506437301636, 2.388437032699585, 1.3448972702026367, 2.405393600463867, 2.3654165267944336, 1.4797130823135376, 1.5124881267547607], [2.3773412704467773, 3.17425799369812, 1.7426941394805908, 3.214752674102783, 3.181914806365967, 1.9058154821395874, 1.9635422229766846], [1.043494462966919, 1.5176392793655396, 0.9019094109535217, 1.521664023399353, 1.4754490852355957, 0.9798257350921631, 1.015139102935791], [2.1783947944641113, 2.935997724533081, 1.6222633123397827, 2.968646287918091, 2.9328975677490234, 1.7774817943572998, 1.825286865234375], [1.0632820129394531, 1.543658971786499, 0.9142017364501953, 1.5457463264465332, 1.4998589754104614, 0.9942054748535156, 1.0276824235916138], [2.528559446334839, 3.3540382385253906, 1.8364497423171997, 3.403085947036743, 3.3689730167388916, 2.0064072608947754, 2.071389675140381], [1.6778831481933594, 2.323777198791504, 1.309158444404602, 2.336944818496704, 2.2960610389709473, 1.4428876638412476, 1.4739655256271362], [2.786456823348999, 3.6585490703582764, 1.990678310394287, 3.71608567237854, 3.6829159259796143, 2.170123815536499, 2.2507524490356445], [2.218055248260498, 2.984680652618408, 1.6481205224990845, 3.0193090438842773, 2.9846279621124268, 1.8033957481384277, 1.8552638292312622], [1.3876630067825317, 1.9590028524398804, 1.1257609128952026, 1.9658538103103638, 1.9209840297698975, 1.234682321548462, 1.2678228616714478], [2.3703696727752686, 3.165095090866089, 1.739301085472107, 3.206342935562134, 3.170146942138672, 1.903664469718933, 1.9602634906768799], [2.7404377460479736, 3.6051948070526123, 1.961162805557251, 3.6607282161712646, 3.6235718727111816, 2.1335136890411377, 2.2203760147094727], [2.8603124618530273, 3.7405385971069336, 2.035094738006592, 3.8008697032928467, 3.7685086727142334, 2.207710027694702, 2.299149513244629], [2.2896621227264404, 3.0693674087524414, 1.6900333166122437, 3.1065971851348877, 3.0709707736968994, 1.8517811298370361, 1.9040064811706543], [2.9869186878204346, 3.8935348987579346, 2.1107828617095947, 3.9545822143554688, 3.9136810302734375, 2.304389476776123, 2.3918027877807617], [1.342491865158081, 1.9013500213623047, 1.0969674587249756, 1.9066492319107056, 1.8630427122116089, 1.2020108699798584, 1.2324376106262207], [2.839634656906128, 3.7143983840942383, 2.021895408630371, 3.77593994140625, 3.7442264556884766, 2.200047016143799, 2.2834396362304688], [1.405381679534912, 1.9812419414520264, 1.1369140148162842, 1.9888815879821777, 1.9451408386230469, 1.2495605945587158, 1.2785272598266602], [2.4433910846710205, 3.2533063888549805, 1.783947467803955, 3.298079490661621, 3.263225793838501, 1.947204828262329, 2.0124168395996094], [2.4356706142425537, 3.2430660724639893, 1.7808955907821655, 3.2879292964935303, 3.2552568912506104, 1.9457073211669922, 2.006870746612549], [1.7787048816680908, 2.4492764472961426, 1.3735864162445068, 2.4671573638916016, 2.4260921478271484, 1.5098986625671387, 1.5464965105056763], [2.9893407821655273, 3.8963217735290527, 2.1122915744781494, 3.9569034576416016, 3.916895866394043, 2.30779767036438, 2.3940181732177734], [2.9056639671325684, 3.796950578689575, 2.061967611312866, 3.857945680618286, 3.82258939743042, 2.248988389968872, 2.333707809448242], [1.4521576166152954, 2.041037082672119, 1.1674591302871704, 2.048696756362915, 2.00565505027771, 1.2837104797363281, 1.3117702007293701], [1.7905930280685425, 2.466017723083496, 1.3796756267547607, 2.4822964668273926, 2.4416120052337646, 1.5167924165725708, 1.5536125898361206], [1.2219393253326416, 1.746645450592041, 1.020363450050354, 1.7504990100860596, 1.705195665359497, 1.1130690574645996, 1.1445667743682861], [2.8974061012268066, 3.785125732421875, 2.05645489692688, 3.846573829650879, 3.812267541885376, 2.2431325912475586, 2.325817584991455], [2.6359024047851562, 3.480030059814453, 1.900482177734375, 3.5335118770599365, 3.5021743774414062, 2.0719738006591797, 2.145566940307617], [1.3758248090744019, 1.9441754817962646, 1.1180557012557983, 1.9505095481872559, 1.9066364765167236, 1.2267547845840454, 1.2560789585113525], [2.484232187271118, 3.3022754192352295, 1.8084235191345215, 3.34883713722229, 3.3143668174743652, 1.9727981090545654, 2.0396318435668945], [1.6088389158248901, 2.2359817028045654, 1.2667299509048462, 2.2480878829956055, 2.2063746452331543, 1.3937386274337769, 1.4238954782485962], [2.61248779296875, 3.455070734024048, 1.8869174718856812, 3.505896806716919, 3.4688796997070312, 2.058373212814331, 2.1321096420288086], [1.126052975654602, 1.6248477697372437, 0.9563746452331543, 1.6270747184753418, 1.5818853378295898, 1.0408661365509033, 1.0741931200027466], [1.922974705696106, 2.625807285308838, 1.464167594909668, 2.648893117904663, 2.609790802001953, 1.6106114387512207, 1.6483319997787476], [2.465869665145874, 3.2798097133636475, 1.7973473072052002, 3.32555890083313, 3.289661169052124, 1.9663448333740234, 2.027164936065674], [1.336483359336853, 1.8955882787704468, 1.0936698913574219, 1.9006454944610596, 1.8572208881378174, 1.1993741989135742, 1.2287815809249878], [1.9430228471755981, 2.651125431060791, 1.4782187938690186, 2.676351547241211, 2.6355438232421875, 1.6233644485473633, 1.664156436920166], [2.2663872241973877, 3.0416650772094727, 1.6764817237854004, 3.0803372859954834, 3.04349684715271, 1.835597276687622, 1.8904805183410645], [2.9265034198760986, 3.821624279022217, 2.0740625858306885, 3.8817484378814697, 3.8471217155456543, 2.2552993297576904, 2.3473100662231445], [2.1932666301727295, 2.9545795917510986, 1.6331369876861572, 2.989602565765381, 2.9531021118164062, 1.7900402545928955, 1.8394086360931396], [2.4017577171325684, 3.2042088508605957, 1.7603179216384888, 3.246941328048706, 3.212850332260132, 1.9226694107055664, 1.9833731651306152], [2.8398356437683105, 3.7162814140319824, 2.0223021507263184, 3.7764382362365723, 3.7416481971740723, 2.1908111572265625, 2.2851338386535645], [1.5479553937911987, 2.1608030796051025, 1.228244662284851, 2.170837640762329, 2.129505157470703, 1.3503128290176392, 1.381808876991272], [1.8741685152053833, 2.569272994995117, 1.4324768781661987, 2.588533401489258, 2.5476157665252686, 1.5760632753372192, 1.613774061203003], [2.4688720703125, 3.2857706546783447, 1.8016116619110107, 3.3310625553131104, 3.2962982654571533, 1.9660494327545166, 2.0304460525512695], [2.966526985168457, 3.8688812255859375, 2.098987579345703, 3.9320831298828125, 3.8915607929229736, 2.2903339862823486, 2.3779916763305664], [1.8295423984527588, 2.5096967220306396, 1.4064538478851318, 2.530334711074829, 2.491270065307617, 1.547493577003479, 1.5821917057037354], [1.3213047981262207, 1.8737279176712036, 1.083204984664917, 1.8799045085906982, 1.8358733654022217, 1.1870694160461426, 1.2174875736236572], [1.3868210315704346, 1.9576021432876587, 1.1253606081008911, 1.9638513326644897, 1.9210983514785767, 1.2355846166610718, 1.2646270990371704], [1.6963372230529785, 2.346012830734253, 1.3216934204101562, 2.3608973026275635, 2.3200368881225586, 1.4556678533554077, 1.4878488779067993], [2.369367837905884, 3.164250373840332, 1.740126371383667, 3.2064454555511475, 3.171461820602417, 1.8993748426437378, 1.9593278169631958], [1.1874053478240967, 1.7023138999938965, 0.9956540465354919, 1.7054483890533447, 1.6617058515548706, 1.08600914478302, 1.1185029745101929], [1.0186032056808472, 1.4869438409805298, 0.8840458393096924, 1.4889156818389893, 1.442239761352539, 0.9579211473464966, 0.9956278204917908], [0.9364372491836548, 1.3804688453674316, 0.8288511633872986, 1.3806973695755005, 1.3360978364944458, 0.8935874700546265, 0.9345901012420654], [2.4084391593933105, 3.2104945182800293, 1.7638169527053833, 3.2544639110565186, 3.2212142944335938, 1.9231104850769043, 1.9876750707626343], [1.986129641532898, 2.7023425102233887, 1.503962516784668, 2.726853609085083, 2.6899678707122803, 1.6504426002502441, 1.6905494928359985], [1.907762050628662, 2.60559344291687, 1.4543412923812866, 2.6276886463165283, 2.587761402130127, 1.6002923250198364, 1.636215090751648], [2.9563536643981934, 3.8566765785217285, 2.092118263244629, 3.9166462421417236, 3.880873680114746, 2.2817909717559814, 2.369333267211914], [1.6896519660949707, 2.338930130004883, 1.3175485134124756, 2.3545453548431396, 2.3130998611450195, 1.4517873525619507, 1.4842948913574219], [2.4642467498779297, 3.2788643836975098, 1.7981681823730469, 3.3247194290161133, 3.2915520668029785, 1.9639382362365723, 2.02730655670166], [2.1295273303985596, 2.875431776046753, 1.5934988260269165, 2.9083030223846436, 2.87221622467041, 1.7459888458251953, 1.7933332920074463], [1.658992886543274, 2.299064874649048, 1.2989329099655151, 2.3122565746307373, 2.273137092590332, 1.429284691810608, 1.459769368171692], [1.957396388053894, 2.6679279804229736, 1.486818552017212, 2.690554141998291, 2.653169631958008, 1.6319106817245483, 1.6708519458770752], [2.8710179328918457, 3.752028703689575, 2.038814067840576, 3.8131299018859863, 3.780268430709839, 2.2109627723693848, 2.3055739402770996], [1.6312123537063599, 2.263766050338745, 1.2809019088745117, 2.276898145675659, 2.2362685203552246, 1.408134937286377, 1.4405760765075684], [2.582629442214966, 3.4165749549865723, 1.8697651624679565, 3.467620372772217, 3.4362285137176514, 2.0370874404907227, 2.107257843017578], [1.0445809364318848, 1.5201383829116821, 0.9013271927833557, 1.5211678743362427, 1.4763182401657104, 0.9773207902908325, 1.0143402814865112], [1.986864447593689, 2.7029573917388916, 1.5038959980010986, 2.728231906890869, 2.68865704536438, 1.651440143585205, 1.6921371221542358], [2.895728588104248, 3.7815654277801514, 2.0542407035827637, 3.8418595790863037, 3.8092639446258545, 2.2342450618743896, 2.32204008102417], [2.904025077819824, 3.7910268306732178, 2.0599842071533203, 3.853328227996826, 3.821580410003662, 2.241910219192505, 2.3313980102539062], [2.294919967651367, 3.0763680934906006, 1.6944279670715332, 3.1140053272247314, 3.0797157287597656, 1.853208065032959, 1.909454107284546], [2.6496479511260986, 3.4961745738983154, 1.909688949584961, 3.549772262573242, 3.5180418491363525, 2.081403970718384, 2.155938148498535], [1.530289888381958, 2.138448715209961, 1.2183510065078735, 2.148693561553955, 2.1064114570617676, 1.3396610021591187, 1.3688527345657349], [1.3318723440170288, 1.8878382444381714, 1.0899957418441772, 1.8936967849731445, 1.849187970161438, 1.195390224456787, 1.225372076034546], [1.762208342552185, 2.4271812438964844, 1.3637974262237549, 2.445885181427002, 2.4055514335632324, 1.5034562349319458, 1.535548210144043], [2.9194447994232178, 3.809304714202881, 2.068971633911133, 3.8693175315856934, 3.8330461978912354, 2.2424278259277344, 2.3398890495300293], [2.1356561183929443, 2.8853185176849365, 1.5958938598632812, 2.9168856143951416, 2.8766443729400635, 1.7499043941497803, 1.7972087860107422], [2.4765608310699463, 3.293884754180908, 1.8045423030853271, 3.339768648147583, 3.3085408210754395, 1.9678516387939453, 2.0357158184051514], [1.3376717567443848, 1.8957170248031616, 1.093722939491272, 1.9018487930297852, 1.8581697940826416, 1.1991418600082397, 1.230002760887146], [1.7549546957015991, 2.4197754859924316, 1.3586732149124146, 2.43558931350708, 2.394808053970337, 1.4965088367462158, 1.528185486793518], [2.933399200439453, 3.8273470401763916, 2.079449415206909, 3.8895671367645264, 3.854297399520874, 2.265380382537842, 2.352297782897949], [1.586459994316101, 2.2071027755737305, 1.2528282403945923, 2.2190229892730713, 2.177537679672241, 1.377217411994934, 1.4073362350463867], [2.2936646938323975, 3.0751266479492188, 1.6925010681152344, 3.113023519515991, 3.077110528945923, 1.8524736166000366, 1.9077733755111694], [2.8066468238830566, 3.6821844577789307, 2.002326726913452, 3.738426446914673, 3.7038071155548096, 2.178999662399292, 2.2637224197387695], [2.098951578140259, 2.840545415878296, 1.5730206966400146, 2.8701205253601074, 2.832798480987549, 1.7253073453903198, 1.7713420391082764], [2.9009437561035156, 3.7863705158233643, 2.056748390197754, 3.8470356464385986, 3.8163580894470215, 2.234635353088379, 2.324042797088623], [2.3292932510375977, 3.1154627799987793, 1.713710069656372, 3.1559982299804688, 3.122617721557617, 1.8768820762634277, 1.9316775798797607], [2.915987014770508, 3.806334972381592, 2.066908597946167, 3.8686206340789795, 3.8340890407562256, 2.253999948501587, 2.339909076690674], [2.8170533180236816, 3.690692186355591, 2.007655143737793, 3.750369071960449, 3.719783067703247, 2.181432008743286, 2.269303798675537], [2.2737414836883545, 3.0493528842926025, 1.6802911758422852, 3.0868728160858154, 3.0507030487060547, 1.842279076576233, 1.8927412033081055], [1.5459709167480469, 2.1584441661834717, 1.2277123928070068, 2.1691744327545166, 2.127690315246582, 1.3488612174987793, 1.3801144361495972], [2.959587574005127, 3.8599772453308105, 2.0930681228637695, 3.920426845550537, 3.8832414150238037, 2.278898000717163, 2.3725500106811523], [1.553689956665039, 2.1677486896514893, 1.231994390487671, 2.1778171062469482, 2.1375222206115723, 1.3543795347213745, 1.3848628997802734], [1.3432101011276245, 1.9016972780227661, 1.0979946851730347, 1.9095396995544434, 1.8643946647644043, 1.2030977010726929, 1.2345938682556152], [1.7745884656906128, 2.442028760910034, 1.370501160621643, 2.4611384868621826, 2.419987201690674, 1.5093697309494019, 1.5438662767410278], [2.402179718017578, 3.203714370727539, 1.7606323957443237, 3.246840476989746, 3.214238166809082, 1.922231912612915, 1.9826308488845825], [1.6515029668807983, 2.2898216247558594, 1.2934179306030273, 2.3035037517547607, 2.262259006500244, 1.4215946197509766, 1.4548439979553223], [1.4287770986557007, 2.0099546909332275, 1.1526844501495361, 2.0194661617279053, 1.9758927822113037, 1.2666646242141724, 1.2957704067230225], [1.1500377655029297, 1.65542733669281, 0.9710054397583008, 1.6595228910446167, 1.6137604713439941, 1.0577164888381958, 1.0935111045837402], [1.4320454597473145, 2.0156285762786865, 1.1546522378921509, 2.022624969482422, 1.978703260421753, 1.2662171125411987, 1.298417091369629], [1.7791191339492798, 2.447526454925537, 1.3752135038375854, 2.4654085636138916, 2.4267849922180176, 1.5113681554794312, 1.5461091995239258], [1.2486592531204224, 1.7824327945709229, 1.0367000102996826, 1.787384033203125, 1.7408162355422974, 1.1363129615783691, 1.1653187274932861], [1.2797956466674805, 1.822288990020752, 1.055396556854248, 1.8270193338394165, 1.7818089723587036, 1.1591664552688599, 1.1870797872543335], [2.328639507293701, 3.114795684814453, 1.7139239311218262, 3.153831720352173, 3.1180479526519775, 1.8769491910934448, 1.930478811264038], [2.5876529216766357, 3.423888921737671, 1.8714439868927002, 3.475342273712158, 3.4389488697052, 2.0388500690460205, 2.1126327514648438], [2.88265061378479, 3.7666475772857666, 2.0480613708496094, 3.8292622566223145, 3.7962422370910645, 2.2259421348571777, 2.3175315856933594], [1.54746675491333, 2.1591298580169678, 1.2281831502914429, 2.170919895172119, 2.128572463989258, 1.3510057926177979, 1.380948543548584], [2.081658124923706, 2.816879987716675, 1.5635221004486084, 2.8471264839172363, 2.8091392517089844, 1.713832974433899, 1.759405493736267], [2.9951632022857666, 3.9055123329162598, 2.114501476287842, 3.962581157684326, 3.9196722507476807, 2.304896116256714, 2.395962715148926], [2.9620652198791504, 3.8618037700653076, 2.0931942462921143, 3.920915365219116, 3.887991428375244, 2.280329704284668, 2.371067523956299], [2.672865629196167, 3.5235276222229004, 1.9232758283615112, 3.57840633392334, 3.5492265224456787, 2.092007637023926, 2.171929359436035], [1.5618054866790771, 2.177495241165161, 1.2371712923049927, 2.189171314239502, 2.1473469734191895, 1.362181305885315, 1.3916133642196655], [2.318685293197632, 3.1024155616760254, 1.7094159126281738, 3.143205404281616, 3.1056315898895264, 1.8682548999786377, 1.9241899251937866], [2.8362507820129395, 3.7116332054138184, 2.020113468170166, 3.772406816482544, 3.741508960723877, 2.1915197372436523, 2.2812857627868652], [2.1536741256713867, 2.9056944847106934, 1.6068062782287598, 2.9375550746917725, 2.900747299194336, 1.7636367082595825, 1.8084617853164673], [2.3091001510620117, 3.093327283859253, 1.7030442953109741, 3.1303534507751465, 3.095564603805542, 1.8612834215164185, 1.9162977933883667], [1.771605372428894, 2.4387378692626953, 1.368843913078308, 2.455303192138672, 2.4149508476257324, 1.5064027309417725, 1.5398008823394775], [2.7271509170532227, 3.587075710296631, 1.955936074256897, 3.642333984375, 3.6114540100097656, 2.130014657974243, 2.2064719200134277], [2.499037742614746, 3.31852388381958, 1.8193879127502441, 3.366037607192993, 3.3348381519317627, 1.9868569374084473, 2.05002498626709], [1.735999345779419, 2.3947646617889404, 1.3473637104034424, 2.4106273651123047, 2.3701558113098145, 1.4825661182403564, 1.5141032934188843], [1.3547192811965942, 1.9180688858032227, 1.1059224605560303, 1.9248181581497192, 1.8808554410934448, 1.2133896350860596, 1.2429189682006836], [2.694175958633423, 3.5475733280181885, 1.9367659091949463, 3.6028542518615723, 3.5719988346099854, 2.1078455448150635, 2.184152126312256], [2.5173375606536865, 3.340864658355713, 1.8302195072174072, 3.3894917964935303, 3.3572192192077637, 1.9960863590240479, 2.063859462738037], [1.8913452625274658, 2.586639404296875, 1.4442548751831055, 2.608423948287964, 2.5697340965270996, 1.5885151624679565, 1.625939130783081], [2.64798641204834, 3.4958205223083496, 1.908674716949463, 3.548633337020874, 3.5168585777282715, 2.0807509422302246, 2.1538033485412598], [1.8651288747787476, 2.554563045501709, 1.4296486377716064, 2.575788974761963, 2.5374011993408203, 1.568739414215088, 1.608747124671936], [2.8710994720458984, 3.752690076828003, 2.0412607192993164, 3.8127143383026123, 3.7824785709381104, 2.2207419872283936, 2.3066110610961914], [2.768734931945801, 3.636836051940918, 1.9813134670257568, 3.695612907409668, 3.66412091255188, 2.152576446533203, 2.2382450103759766], [1.9255422353744507, 2.6284282207489014, 1.4645764827728271, 2.649646282196045, 2.612175226211548, 1.6086891889572144, 1.6487613916397095], [1.5217701196670532, 2.128079414367676, 1.210762858390808, 2.1371612548828125, 2.0949547290802, 1.3296571969985962, 1.362015962600708], [1.1993927955627441, 1.718932867050171, 1.003859281539917, 1.7246977090835571, 1.6787487268447876, 1.0990517139434814, 1.1294738054275513], [2.739612340927124, 3.5980584621429443, 1.9627028703689575, 3.6562869548797607, 3.6263623237609863, 2.1348092555999756, 2.215261936187744], [1.2406892776489258, 1.7710883617401123, 1.0305653810501099, 1.7759639024734497, 1.7321587800979614, 1.1274043321609497, 1.1582742929458618], [2.148836374282837, 2.898930311203003, 1.6044987440109253, 2.930311918258667, 2.896092176437378, 1.7592524290084839, 1.8057059049606323], [2.727240800857544, 3.58821702003479, 1.9549355506896973, 3.6459779739379883, 3.617013931274414, 2.128957748413086, 2.210381031036377], [1.8769868612289429, 2.567505121231079, 1.4359194040298462, 2.589519739151001, 2.551229953765869, 1.5799858570098877, 1.614881992340088], [2.9091029167175293, 3.797806978225708, 2.0647964477539062, 3.8604888916015625, 3.828007221221924, 2.2467195987701416, 2.334066390991211], [1.9418648481369019, 2.6479592323303223, 1.4762401580810547, 2.6730563640594482, 2.6342737674713135, 1.6241952180862427, 1.6623170375823975], [1.9128762483596802, 2.6121294498443604, 1.4593316316604614, 2.6347496509552, 2.598158836364746, 1.6047227382659912, 1.641305685043335], [2.8965768814086914, 3.781059980392456, 2.054631233215332, 3.8412294387817383, 3.809966802597046, 2.2339437007904053, 2.32004976272583], [1.1988693475723267, 1.7190150022506714, 1.0036370754241943, 1.7224993705749512, 1.6772081851959229, 1.0967631340026855, 1.1281970739364624], [2.8675477504730225, 3.7472455501556396, 2.0386593341827393, 3.8084559440612793, 3.778815269470215, 2.218212127685547, 2.302380084991455], [1.776495337486267, 2.444683074951172, 1.372299313545227, 2.462672233581543, 2.421579122543335, 1.510996699333191, 1.543172836303711], [2.8951332569122314, 3.781702756881714, 2.0551834106445312, 3.842132091522217, 3.8108444213867188, 2.232578754425049, 2.323390007019043], [2.8910181522369385, 3.777113676071167, 2.0522279739379883, 3.837650775909424, 3.8060431480407715, 2.235682249069214, 2.3192076683044434], [1.7277671098709106, 2.384575605392456, 1.3420253992080688, 2.401481866836548, 2.3607330322265625, 1.4775711297988892, 1.5102146863937378], [2.0712814331054688, 2.8056273460388184, 1.5584676265716553, 2.83432936668396, 2.797495126724243, 1.7073283195495605, 1.7527129650115967], [1.3343108892440796, 1.8905787467956543, 1.090908169746399, 1.8966552019119263, 1.8522604703903198, 1.1970046758651733, 1.2267884016036987], [2.0630722045898438, 2.796116352081299, 1.5515568256378174, 2.824495553970337, 2.786181688308716, 1.702909231185913, 1.7447775602340698], [2.648477792739868, 3.4941980838775635, 1.9096561670303345, 3.5489046573638916, 3.5163142681121826, 2.0787041187286377, 2.153459072113037], [2.221529245376587, 2.985363245010376, 1.6483947038650513, 3.021188497543335, 2.9856810569763184, 1.8086614608764648, 1.8554526567459106], [1.1762059926986694, 1.6889047622680664, 0.9879418611526489, 1.6915407180786133, 1.647600531578064, 1.0797615051269531, 1.1111528873443604], [2.0487051010131836, 2.778005838394165, 1.5436654090881348, 2.80698561668396, 2.7688331604003906, 1.6939396858215332, 1.7369565963745117], [2.960036516189575, 3.860311508178711, 2.09427809715271, 3.921236515045166, 3.884221315383911, 2.2807605266571045, 2.3710951805114746], [1.809838056564331, 2.486717700958252, 1.39402437210083, 2.5054173469543457, 2.4666061401367188, 1.5341659784317017, 1.567914605140686], [1.3835859298706055, 1.9542732238769531, 1.1228834390640259, 1.9611090421676636, 1.9174810647964478, 1.2313785552978516, 1.2630947828292847], [2.6000208854675293, 3.438429832458496, 1.8798688650131226, 3.488818407058716, 3.4571077823638916, 2.048325300216675, 2.119555950164795], [1.4886772632598877, 2.086082696914673, 1.1905534267425537, 2.0953409671783447, 2.050812005996704, 1.308316707611084, 1.3390381336212158], [2.875159502029419, 3.7572648525238037, 2.0442988872528076, 3.818864107131958, 3.7876832485198975, 2.2227940559387207, 2.3101282119750977], [1.3358505964279175, 1.8931509256362915, 1.091562271118164, 1.899473786354065, 1.8550894260406494, 1.1988251209259033, 1.2274824380874634], [2.891315460205078, 3.7769405841827393, 2.0533955097198486, 3.8372702598571777, 3.8031985759735107, 2.232243776321411, 2.319492816925049], [2.769364833831787, 3.6324944496154785, 1.978461742401123, 3.692798137664795, 3.66273832321167, 2.1475300788879395, 2.2342567443847656], [2.208548069000244, 2.97163724899292, 1.6402779817581177, 3.006499767303467, 2.9690895080566406, 1.796476125717163, 1.8472394943237305], [1.6055068969726562, 2.230776071548462, 1.265684723854065, 2.2440199851989746, 2.202834129333496, 1.3922796249389648, 1.4224193096160889], [1.3011853694915771, 1.8478604555130005, 1.0707728862762451, 1.853297233581543, 1.81063711643219, 1.1732972860336304, 1.201880693435669], [1.5497575998306274, 2.1626157760620117, 1.2307064533233643, 2.1738672256469727, 2.13214111328125, 1.3519457578659058, 1.3826788663864136], [2.987276315689087, 3.8928370475769043, 2.109689712524414, 3.9524013996124268, 3.9144320487976074, 2.302304744720459, 2.3899760246276855], [2.5563199520111084, 3.3862664699554443, 1.853654384613037, 3.4359829425811768, 3.4029183387756348, 2.021364450454712, 2.088942050933838], [2.9642693996429443, 3.863651752471924, 2.0972936153411865, 3.925328254699707, 3.888845443725586, 2.2845563888549805, 2.3726840019226074], [1.9590238332748413, 2.6680264472961426, 1.4856867790222168, 2.6913139820098877, 2.6537508964538574, 1.6341813802719116, 1.670707106590271], [2.9082043170928955, 3.7971243858337402, 2.0622177124023438, 3.8587417602539062, 3.826482057571411, 2.2446682453155518, 2.3336315155029297], [2.9030940532684326, 3.7908082008361816, 2.0597126483917236, 3.85139799118042, 3.8214731216430664, 2.2396674156188965, 2.3292617797851562], [1.304408311843872, 1.8527418375015259, 1.0714929103851318, 1.8575270175933838, 1.8135510683059692, 1.1735559701919556, 1.2039378881454468], [1.381025791168213, 1.9506094455718994, 1.1220307350158691, 1.9581620693206787, 1.9152432680130005, 1.2340128421783447, 1.260949969291687], [1.3514503240585327, 1.9126368761062622, 1.1028660535812378, 1.9200475215911865, 1.8750932216644287, 1.2097561359405518, 1.2402161359786987], [2.333956480026245, 3.1242661476135254, 1.71869695186615, 3.1641476154327393, 3.1300177574157715, 1.876240611076355, 1.9362760782241821], [1.4307255744934082, 2.0125348567962646, 1.1538264751434326, 2.0224239826202393, 1.9793986082077026, 1.2679111957550049, 1.2982407808303833], [2.4856464862823486, 3.3048667907714844, 1.8103890419006348, 3.3507120609283447, 3.3185391426086426, 1.97833251953125, 2.0427145957946777], [2.9225144386291504, 3.8126635551452637, 2.071805477142334, 3.8756086826324463, 3.841848611831665, 2.259675979614258, 2.3432836532592773], [1.323706030845642, 1.8769786357879639, 1.0852068662643433, 1.8830801248550415, 1.8389540910720825, 1.1896719932556152, 1.2200566530227661], [1.6496177911758423, 2.2877376079559326, 1.2924679517745972, 2.299976348876953, 2.2586233615875244, 1.4218966960906982, 1.4525548219680786], [1.4235388040542603, 2.00483775138855, 1.1495156288146973, 2.0116729736328125, 1.9704294204711914, 1.2626612186431885, 1.2921217679977417], [2.9563381671905518, 3.853609800338745, 2.0905725955963135, 3.9146668910980225, 3.8781898021698, 2.273061990737915, 2.3663430213928223], [1.3902758359909058, 1.9619860649108887, 1.1270755529403687, 1.969417691230774, 1.9239226579666138, 1.238356351852417, 1.269166111946106], [2.4880645275115967, 3.302971124649048, 1.8112291097640991, 3.351011037826538, 3.3163344860076904, 1.976940393447876, 2.041661262512207], [2.9533884525299072, 3.851811647415161, 2.0915110111236572, 3.9137516021728516, 3.8750641345977783, 2.2777390480041504, 2.3687314987182617], [1.3218868970870972, 1.8743133544921875, 1.0842148065567017, 1.8809168338775635, 1.8365200757980347, 1.1887396574020386, 1.2178046703338623], [1.279085397720337, 1.8211023807525635, 1.0558390617370605, 1.8266669511795044, 1.782536506652832, 1.1571226119995117, 1.1871992349624634], [2.9620521068573, 3.864008903503418, 2.0951290130615234, 3.923435926437378, 3.8839073181152344, 2.28214693069458, 2.374570369720459], [2.581252336502075, 3.4191696643829346, 1.868410348892212, 3.4682939052581787, 3.4296035766601562, 2.0398595333099365, 2.1077842712402344], [2.3318028450012207, 3.1181395053863525, 1.7164109945297241, 3.158212661743164, 3.1235814094543457, 1.8789759874343872, 1.9335683584213257], [2.897726535797119, 3.782822847366333, 2.0578606128692627, 3.8460676670074463, 3.813349962234497, 2.24139142036438, 2.3264899253845215], [1.2449570894241333, 1.778550624847412, 1.0345011949539185, 1.7820788621902466, 1.7374275922775269, 1.131544828414917, 1.1625829935073853], [2.8245904445648193, 3.7005579471588135, 2.0135209560394287, 3.758416175842285, 3.7256288528442383, 2.1849451065063477, 2.2742972373962402], [2.2508463859558105, 3.0225448608398438, 1.6683719158172607, 3.0595719814300537, 3.0241572856903076, 1.8272401094436646, 1.877063274383545], [2.2406375408172607, 3.0140395164489746, 1.6607197523117065, 3.0481631755828857, 3.009634494781494, 1.8124134540557861, 1.8721224069595337], [1.7949414253234863, 2.466508626937866, 1.3842427730560303, 2.4850969314575195, 2.4453866481781006, 1.5223884582519531, 1.557665228843689], [2.289299488067627, 3.068613052368164, 1.690995454788208, 3.1065642833709717, 3.0731472969055176, 1.8501248359680176, 1.9042110443115234], [2.785057544708252, 3.6520938873291016, 1.9905009269714355, 3.7110025882720947, 3.68229079246521, 2.161207675933838, 2.24509859085083], [1.3699419498443604, 1.9374409914016724, 1.1153429746627808, 1.9427648782730103, 1.9004639387130737, 1.2234079837799072, 1.2527046203613281], [2.978776454925537, 3.883622884750366, 2.104642152786255, 3.945646047592163, 3.9049792289733887, 2.2953929901123047, 2.3880362510681152], [2.6848952770233154, 3.538809061050415, 1.9298328161239624, 3.593705177307129, 3.5593202114105225, 2.1016101837158203, 2.17897891998291], [2.246964693069458, 3.020718812942505, 1.6639662981033325, 3.0548768043518066, 3.0160186290740967, 1.8242263793945312, 1.8752038478851318], [2.3193771839141846, 3.1051652431488037, 1.708287000656128, 3.143498659133911, 3.1053783893585205, 1.8715828657150269, 1.9243383407592773], [2.824669122695923, 3.6995973587036133, 2.012995719909668, 3.7598628997802734, 3.7285828590393066, 2.195361852645874, 2.27506160736084], [2.655332326889038, 3.502199411392212, 1.913588047027588, 3.5557310581207275, 3.5231027603149414, 2.0819907188415527, 2.157029628753662], [1.7323282957077026, 2.3904502391815186, 1.3452398777008057, 2.40598201751709, 2.3653576374053955, 1.4809705018997192, 1.5127754211425781], [2.0972061157226562, 2.8396573066711426, 1.5721603631973267, 2.867766857147217, 2.8314177989959717, 1.7278170585632324, 1.771096110343933], [1.4655784368515015, 2.0564913749694824, 1.1757794618606567, 2.0653271675109863, 2.022188901901245, 1.2912490367889404, 1.3216142654418945], [2.3862597942352295, 3.1862449645996094, 1.7501888275146484, 3.228196144104004, 3.1938705444335938, 1.914395809173584, 1.9719115495681763], [1.2281707525253296, 1.75519859790802, 1.0228909254074097, 1.760695457458496, 1.7148659229278564, 1.11758291721344, 1.1498302221298218], [2.552155017852783, 3.3834354877471924, 1.8519307374954224, 3.432586193084717, 3.3982136249542236, 2.019801139831543, 2.088407278060913], [2.99467134475708, 3.9050486087799072, 2.1166257858276367, 3.960569143295288, 3.919807195663452, 2.3063206672668457, 2.398125171661377], [2.0538532733917236, 2.784466028213501, 1.5463005304336548, 2.8129422664642334, 2.77571964263916, 1.6968234777450562, 1.740407109260559], [1.571933388710022, 2.1905860900878906, 1.2442545890808105, 2.2016451358795166, 2.159874200820923, 1.367441177368164, 1.398813247680664], [2.5070362091064453, 3.3306665420532227, 1.824477195739746, 3.3783135414123535, 3.3463306427001953, 1.9907774925231934, 2.057079792022705], [2.6536507606506348, 3.502046823501587, 1.9116008281707764, 3.5552337169647217, 3.52364444732666, 2.0827627182006836, 2.158141613006592], [2.7433695793151855, 3.6080384254455566, 1.9652701616287231, 3.665018320083618, 3.632351875305176, 2.1398708820343018, 2.220653533935547], [2.263648509979248, 3.0383572578430176, 1.6748958826065063, 3.07564640045166, 3.039464235305786, 1.8329687118530273, 1.8862367868423462], [2.5510082244873047, 3.381479263305664, 1.8500146865844727, 3.4327211380004883, 3.3989856243133545, 2.020822763442993, 2.088298797607422], [1.8454378843307495, 2.529369592666626, 1.4162135124206543, 2.548771619796753, 2.5102827548980713, 1.5535893440246582, 1.5916788578033447], [2.8320062160491943, 3.713395357131958, 2.0187556743621826, 3.770082712173462, 3.7340643405914307, 2.200974702835083, 2.2833786010742188], [2.9340949058532715, 3.828200101852417, 2.0781893730163574, 3.890364408493042, 3.8567910194396973, 2.2675769329071045, 2.3518519401550293], [2.4121153354644775, 3.215869665145874, 1.7671688795089722, 3.2608413696289062, 3.2256205081939697, 1.9316153526306152, 1.9904460906982422], [2.407670259475708, 3.2088699340820312, 1.7617326974868774, 3.252182722091675, 3.2173941135406494, 1.9302983283996582, 1.9851356744766235], [1.1341769695281982, 1.635253667831421, 0.961287260055542, 1.6393764019012451, 1.5938397645950317, 1.048109531402588, 1.0817333459854126], [1.178259253501892, 1.6920907497406006, 0.9904229044914246, 1.6957001686096191, 1.650895595550537, 1.082184076309204, 1.1129565238952637], [2.8423938751220703, 3.7182836532592773, 2.0242204666137695, 3.778958559036255, 3.745575428009033, 2.1940860748291016, 2.285633087158203], [2.7196266651153564, 3.581716537475586, 1.9506502151489258, 3.6368677616119385, 3.5992021560668945, 2.1278023719787598, 2.2071218490600586], [2.763838529586792, 3.628110647201538, 1.9781190156936646, 3.686898946762085, 3.6572165489196777, 2.1491527557373047, 2.232438087463379], [1.8917330503463745, 2.587303400039673, 1.44587242603302, 2.6097240447998047, 2.569981336593628, 1.589398741722107, 1.6266342401504517], [1.0096787214279175, 1.4748940467834473, 0.8794603943824768, 1.4777159690856934, 1.4314203262329102, 0.9545813798904419, 0.9893187284469604], [2.917736053466797, 3.8088595867156982, 2.069685220718384, 3.870624303817749, 3.8377766609191895, 2.253045082092285, 2.3400325775146484], [1.742541790008545, 2.4016687870025635, 1.3511848449707031, 2.41813588142395, 2.3775763511657715, 1.4875648021697998, 1.5198297500610352], [2.4976303577423096, 3.318885087966919, 1.8181209564208984, 3.3651061058044434, 3.330613374710083, 1.9856207370758057, 2.049185276031494], [2.3547146320343018, 3.147430896759033, 1.7307498455047607, 3.188168525695801, 3.153243064880371, 1.8932127952575684, 1.9501503705978394], [1.409614086151123, 1.9864295721054077, 1.1402032375335693, 1.9954042434692383, 1.9520291090011597, 1.2541121244430542, 1.2828375101089478], [2.9013495445251465, 3.7886624336242676, 2.0599119663238525, 3.8508150577545166, 3.8170862197875977, 2.243155002593994, 2.327277660369873], [2.0535316467285156, 2.7836225032806396, 1.545355200767517, 2.8116743564605713, 2.774301052093506, 1.6978033781051636, 1.7394449710845947], [2.82315731048584, 3.6946322917938232, 2.01237154006958, 3.755153179168701, 3.724822998046875, 2.1865434646606445, 2.2724947929382324], [2.4391703605651855, 3.249976396560669, 1.781790018081665, 3.2938718795776367, 3.2586045265197754, 1.9503600597381592, 2.0088348388671875], [2.440237045288086, 3.247568368911743, 1.7837580442428589, 3.2942464351654053, 3.261021852493286, 1.9457981586456299, 2.0100526809692383], [1.7173906564712524, 2.3704581260681152, 1.3355218172073364, 2.3863253593444824, 2.3462491035461426, 1.4678001403808594, 1.5023891925811768], [2.480962038040161, 3.2972497940063477, 1.8071041107177734, 3.343679189682007, 3.310009002685547, 1.972482681274414, 2.037688732147217], [2.1528260707855225, 2.907332181930542, 1.6055331230163574, 2.9358034133911133, 2.8951683044433594, 1.7567793130874634, 1.8090336322784424], [1.624843716621399, 2.256588935852051, 1.2770087718963623, 2.269181251525879, 2.2271900177001953, 1.4041557312011719, 1.4351627826690674], [2.950152635574341, 3.847907066345215, 2.0890302658081055, 3.910370349884033, 3.8752026557922363, 2.2768187522888184, 2.3651318550109863], [2.9964871406555176, 3.904981851577759, 2.116318702697754, 3.9647793769836426, 3.9253990650177, 2.3093068599700928, 2.399311065673828], [2.1666791439056396, 2.9222161769866943, 1.6154435873031616, 2.955127239227295, 2.917248010635376, 1.7736984491348267, 1.819619059562683], [2.496199607849121, 3.3145346641540527, 1.818122386932373, 3.362111806869507, 3.331099510192871, 1.9825379848480225, 2.048074722290039], [1.124343752861023, 1.6223344802856445, 0.954269528388977, 1.6256327629089355, 1.5792232751846313, 1.040323257446289, 1.0739754438400269], [1.4490805864334106, 2.0357139110565186, 1.1646207571029663, 2.044736623764038, 2.0008199214935303, 1.2785215377807617, 1.3103742599487305], [1.2732348442077637, 1.8118401765823364, 1.051637053489685, 1.8174183368682861, 1.772334337234497, 1.150842547416687, 1.1815000772476196], [2.690335750579834, 3.542179584503174, 1.9342775344848633, 3.5967628955841064, 3.5682473182678223, 2.1004703044891357, 2.179577350616455], [2.6391665935516357, 3.4847869873046875, 1.9024747610092163, 3.5377633571624756, 3.5053746700286865, 2.077666997909546, 2.1472978591918945], [1.2362732887268066, 1.7662241458892822, 1.0275517702102661, 1.771174669265747, 1.7253214120864868, 1.1243047714233398, 1.1564267873764038], [2.567193031311035, 3.398597002029419, 1.8597644567489624, 3.4487574100494385, 3.41668701171875, 2.0279269218444824, 2.097334861755371], [1.3064262866973877, 1.855634093284607, 1.0737643241882324, 1.8599793910980225, 1.8175638914108276, 1.1779123544692993, 1.2060869932174683], [2.5158188343048096, 3.339855670928955, 1.8287017345428467, 3.3876454830169678, 3.3561348915100098, 1.9975786209106445, 2.0611743927001953], [1.674250602722168, 2.319856643676758, 1.3077056407928467, 2.333240032196045, 2.2927494049072266, 1.4393360614776611, 1.471526026725769], [2.872377872467041, 3.754756450653076, 2.0414347648620605, 3.814384937286377, 3.7853400707244873, 2.222551107406616, 2.3068580627441406], [2.3132119178771973, 3.098317861557007, 1.7056703567504883, 3.136002540588379, 3.102365493774414, 1.8642629384994507, 1.9214328527450562], [1.5382623672485352, 2.1477766036987305, 1.2210997343063354, 2.1582419872283936, 2.116785764694214, 1.3436367511749268, 1.3734767436981201], [2.323977470397949, 3.109675884246826, 1.7109453678131104, 3.148653268814087, 3.1147661209106445, 1.8676635026931763, 1.9288692474365234], [2.8278286457061768, 3.7049524784088135, 2.015728712081909, 3.7637252807617188, 3.733059883117676, 2.1884329319000244, 2.276604175567627], [2.897341251373291, 3.784695863723755, 2.0569605827331543, 3.847632884979248, 3.812654495239258, 2.2359371185302734, 2.3261260986328125], [2.2405927181243896, 3.0096304416656494, 1.6620560884475708, 3.0457022190093994, 3.013568878173828, 1.8156532049179077, 1.8709330558776855], [1.5858134031295776, 2.209641218185425, 1.2511205673217773, 2.220386028289795, 2.1792612075805664, 1.3773349523544312, 1.407615065574646], [2.8561816215515137, 3.738581418991089, 2.030919313430786, 3.7977752685546875, 3.7637417316436768, 2.207016706466675, 2.29838228225708], [1.8658193349838257, 2.5552732944488525, 1.4283479452133179, 2.575490951538086, 2.5363869667053223, 1.572776436805725, 1.6066538095474243], [1.4023693799972534, 1.9776320457458496, 1.1360424757003784, 1.9837661981582642, 1.9414461851119995, 1.2447935342788696, 1.2765494585037231], [2.6051242351531982, 3.4444034099578857, 1.8824260234832764, 3.4971835613250732, 3.46286678314209, 2.050482749938965, 2.124382972717285], [1.6766047477722168, 2.3200249671936035, 1.3098907470703125, 2.334796667098999, 2.29354190826416, 1.4405426979064941, 1.473227620124817], [1.422269582748413, 2.001955509185791, 1.148878574371338, 2.010611057281494, 1.9653600454330444, 1.262794017791748, 1.2926301956176758], [2.399538278579712, 3.2015058994293213, 1.7576744556427002, 3.2456095218658447, 3.211671829223633, 1.9223427772521973, 1.9823163747787476], [2.8051772117614746, 3.6778197288513184, 2.003019094467163, 3.735436201095581, 3.7060208320617676, 2.1759278774261475, 2.2612547874450684], [2.7006046772003174, 3.554462432861328, 1.9398432970046997, 3.6118059158325195, 3.5817692279815674, 2.1081700325012207, 2.189757823944092], [1.617537260055542, 2.246544122695923, 1.2730907201766968, 2.259578227996826, 2.218126058578491, 1.3989861011505127, 1.4308439493179321], [2.542630910873413, 3.374572515487671, 1.8472398519515991, 3.422661066055298, 3.386301040649414, 2.0172817707061768, 2.0836052894592285], [2.4678118228912354, 3.2814886569976807, 1.7990992069244385, 3.3273508548736572, 3.293600082397461, 1.9672789573669434, 2.029088020324707], [2.887188673019409, 3.7760555744171143, 2.0517191886901855, 3.8342623710632324, 3.7988452911376953, 2.231450080871582, 2.320246696472168], [1.7624831199645996, 2.4282007217407227, 1.363075852394104, 2.443962574005127, 2.4032015800476074, 1.499129056930542, 1.531973123550415], [2.658428192138672, 3.5052201747894287, 1.9138466119766235, 3.559826135635376, 3.528545379638672, 2.088818311691284, 2.1583805084228516], [2.119107961654663, 2.8642446994781494, 1.5874909162521362, 2.8961169719696045, 2.8570563793182373, 1.7429404258728027, 1.7869670391082764], [2.3045690059661865, 3.088123321533203, 1.7001140117645264, 3.1273369789123535, 3.09236478805542, 1.8571501970291138, 1.9156711101531982], [1.4355995655059814, 2.0195538997650146, 1.1559230089187622, 2.027833938598633, 1.984811782836914, 1.2698254585266113, 1.3003913164138794], [1.3827060461044312, 1.9531266689300537, 1.1231226921081543, 1.9597370624542236, 1.9152642488479614, 1.2325379848480225, 1.262486457824707], [1.4483273029327393, 2.033585786819458, 1.1644047498703003, 2.0428261756896973, 2.000589370727539, 1.280559778213501, 1.308879017829895], [2.983816623687744, 3.8907411098480225, 2.1082663536071777, 3.9523472785949707, 3.911372661590576, 2.303250312805176, 2.39093017578125], [2.2473437786102295, 3.0190622806549072, 1.6636641025543213, 3.054905652999878, 3.017056465148926, 1.8213449716567993, 1.8762894868850708], [2.00850248336792, 2.7294418811798096, 1.5171318054199219, 2.755720853805542, 2.717128276824951, 1.6676421165466309, 1.7064998149871826], [2.4309725761413574, 3.2366695404052734, 1.777228832244873, 3.2815351486206055, 3.247466802597046, 1.940185546875, 2.0029499530792236], [1.995399832725525, 2.7158455848693848, 1.5103330612182617, 2.740072011947632, 2.7022130489349365, 1.6597355604171753, 1.6980845928192139], [1.159233808517456, 1.6680140495300293, 0.976841151714325, 1.671262264251709, 1.626929521560669, 1.0674471855163574, 1.0991538763046265], [1.543988585472107, 2.1542115211486816, 1.2254326343536377, 2.1657633781433105, 2.124359130859375, 1.3473701477050781, 1.3779629468917847], [2.50537371635437, 3.327944040298462, 1.8216915130615234, 3.3747780323028564, 3.336174488067627, 1.9890727996826172, 2.056027889251709], [1.0270017385482788, 1.49736750125885, 0.8898088932037354, 1.4985394477844238, 1.453830599784851, 0.9661002159118652, 1.0014249086380005], [2.4442827701568604, 3.2515931129455566, 1.7845869064331055, 3.2961246967315674, 3.263124942779541, 1.9487509727478027, 2.0096826553344727], [1.7293274402618408, 2.3867883682250977, 1.3430486917495728, 2.40289044380188, 2.3619868755340576, 1.478690505027771, 1.5109676122665405], [2.4611592292785645, 3.275024652481079, 1.7969642877578735, 3.3213858604431152, 3.286008834838867, 1.9605255126953125, 2.0249290466308594], [1.1420143842697144, 1.6443517208099365, 0.9665892720222473, 1.648836612701416, 1.6021039485931396, 1.0519864559173584, 1.0879602432250977], [2.492323160171509, 3.3125970363616943, 1.8160653114318848, 3.3593671321868896, 3.3264007568359375, 1.9793720245361328, 2.045530319213867], [2.991361379623413, 3.9008095264434814, 2.113687753677368, 3.9613380432128906, 3.918154239654541, 2.305729866027832, 2.398176670074463], [1.6887465715408325, 2.3362159729003906, 1.3174448013305664, 2.3506593704223633, 2.3078629970550537, 1.4487378597259521, 1.480660319328308]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pearson_correlations = calculate_pearson_per_aspect(test_pred_overall, test_true_overall)\n",
        "for i, r in enumerate(pearson_correlations):\n",
        "        print(f\"Pearson correlation for aspect {i+1}: {r:.4f}\")\n",
        "\n",
        "curr_pearson = np.mean(pearson_correlations)\n",
        "print(f\"Mean Pearson correlation for test dataset: {curr_pearson:.4f}\")"
      ],
      "metadata": {
        "id": "9FoW_1ySDZ8H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fef73d8-cb6d-4e54-d9a6-52d15545cbdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson correlation for aspect 1: 0.5494\n",
            "Pearson correlation for aspect 2: 0.7449\n",
            "Pearson correlation for aspect 3: 0.2245\n",
            "Pearson correlation for aspect 4: 0.7181\n",
            "Pearson correlation for aspect 5: 0.7489\n",
            "Pearson correlation for aspect 6: 0.3203\n",
            "Pearson correlation for aspect 7: 0.3828\n",
            "Mean Pearson correlation for test dataset: 0.5270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred_overall"
      ],
      "metadata": {
        "id": "fh3hMbu3rkht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aff6734e-9cbe-4375-8789-7283502169bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1.361519694328308,\n",
              "  1.9247442483901978,\n",
              "  1.1100759506225586,\n",
              "  1.9309498071670532,\n",
              "  1.8876211643218994,\n",
              "  1.2195284366607666,\n",
              "  1.2453298568725586],\n",
              " [1.2718610763549805,\n",
              "  1.8117040395736694,\n",
              "  1.0497748851776123,\n",
              "  1.8169597387313843,\n",
              "  1.7744255065917969,\n",
              "  1.1505122184753418,\n",
              "  1.1824922561645508],\n",
              " [1.7983062267303467,\n",
              "  2.471595048904419,\n",
              "  1.3867868185043335,\n",
              "  2.490954875946045,\n",
              "  2.450662136077881,\n",
              "  1.526197075843811,\n",
              "  1.5605626106262207],\n",
              " [1.3124758005142212,\n",
              "  1.8632841110229492,\n",
              "  1.0769702196121216,\n",
              "  1.8688058853149414,\n",
              "  1.8244779109954834,\n",
              "  1.1788688898086548,\n",
              "  1.2112394571304321],\n",
              " [1.4598785638809204,\n",
              "  2.050065517425537,\n",
              "  1.1719162464141846,\n",
              "  2.057950258255005,\n",
              "  2.0160953998565674,\n",
              "  1.2876262664794922,\n",
              "  1.3176733255386353],\n",
              " [1.6732217073440552,\n",
              "  2.3167724609375,\n",
              "  1.3083795309066772,\n",
              "  2.331407308578491,\n",
              "  2.290336847305298,\n",
              "  1.436367392539978,\n",
              "  1.4714337587356567],\n",
              " [2.166170120239258,\n",
              "  2.9190115928649902,\n",
              "  1.614565134048462,\n",
              "  2.951693058013916,\n",
              "  2.9148216247558594,\n",
              "  1.7684720754623413,\n",
              "  1.8173811435699463],\n",
              " [2.6977972984313965,\n",
              "  3.5538241863250732,\n",
              "  1.937654972076416,\n",
              "  3.6061315536499023,\n",
              "  3.572042942047119,\n",
              "  2.109065294265747,\n",
              "  2.188833713531494],\n",
              " [2.9950058460235596,\n",
              "  3.9054832458496094,\n",
              "  2.1148781776428223,\n",
              "  3.964632034301758,\n",
              "  3.9236559867858887,\n",
              "  2.3119802474975586,\n",
              "  2.399148941040039],\n",
              " [1.8502262830734253,\n",
              "  2.535348653793335,\n",
              "  1.4191431999206543,\n",
              "  2.5550355911254883,\n",
              "  2.518632173538208,\n",
              "  1.5599453449249268,\n",
              "  1.5963897705078125],\n",
              " [1.009879469871521,\n",
              "  1.4750111103057861,\n",
              "  0.8792593479156494,\n",
              "  1.4783804416656494,\n",
              "  1.4308046102523804,\n",
              "  0.9532284736633301,\n",
              "  0.9900567531585693],\n",
              " [1.9603086709976196,\n",
              "  2.671872854232788,\n",
              "  1.4886400699615479,\n",
              "  2.697680950164795,\n",
              "  2.6593408584594727,\n",
              "  1.638362169265747,\n",
              "  1.675828456878662],\n",
              " [2.899719476699829,\n",
              "  3.782150983810425,\n",
              "  2.0569827556610107,\n",
              "  3.846644401550293,\n",
              "  3.8171308040618896,\n",
              "  2.235558271408081,\n",
              "  2.324709892272949],\n",
              " [1.4164118766784668,\n",
              "  1.9957462549209595,\n",
              "  1.1442418098449707,\n",
              "  2.0031163692474365,\n",
              "  1.9592909812927246,\n",
              "  1.2571548223495483,\n",
              "  1.2860912084579468],\n",
              " [2.5932984352111816,\n",
              "  3.4313690662384033,\n",
              "  1.8747045993804932,\n",
              "  3.48258376121521,\n",
              "  3.445699691772461,\n",
              "  2.0461132526397705,\n",
              "  2.1174211502075195],\n",
              " [2.7627158164978027,\n",
              "  3.6277499198913574,\n",
              "  1.9758527278900146,\n",
              "  3.686891555786133,\n",
              "  3.653644561767578,\n",
              "  2.1498522758483887,\n",
              "  2.232736110687256],\n",
              " [1.9527283906936646,\n",
              "  2.660719871520996,\n",
              "  1.4837983846664429,\n",
              "  2.6869521141052246,\n",
              "  2.6466028690338135,\n",
              "  1.6317651271820068,\n",
              "  1.6706467866897583],\n",
              " [1.4910979270935059,\n",
              "  2.089665174484253,\n",
              "  1.1905505657196045,\n",
              "  2.098345994949341,\n",
              "  2.056591749191284,\n",
              "  1.310307264328003,\n",
              "  1.340366005897522],\n",
              " [2.470320463180542,\n",
              "  3.2833404541015625,\n",
              "  1.80077064037323,\n",
              "  3.329761028289795,\n",
              "  3.2937614917755127,\n",
              "  1.9670250415802002,\n",
              "  2.030458450317383],\n",
              " [2.9725470542907715,\n",
              "  3.8750219345092773,\n",
              "  2.1021885871887207,\n",
              "  3.9360878467559814,\n",
              "  3.8989803791046143,\n",
              "  2.292600631713867,\n",
              "  2.379824161529541],\n",
              " [1.5061267614364624,\n",
              "  2.1069185733795166,\n",
              "  1.200941562652588,\n",
              "  2.1171796321868896,\n",
              "  2.0754611492156982,\n",
              "  1.3223447799682617,\n",
              "  1.351758599281311],\n",
              " [2.7536330223083496,\n",
              "  3.6175496578216553,\n",
              "  1.9717141389846802,\n",
              "  3.6762261390686035,\n",
              "  3.646191358566284,\n",
              "  2.1416921615600586,\n",
              "  2.2260890007019043],\n",
              " [1.1056945323944092,\n",
              "  1.5971399545669556,\n",
              "  0.9421499371528625,\n",
              "  1.6009424924850464,\n",
              "  1.554724097251892,\n",
              "  1.0249968767166138,\n",
              "  1.0598785877227783],\n",
              " [1.7572884559631348,\n",
              "  2.4213383197784424,\n",
              "  1.3597806692123413,\n",
              "  2.4380698204040527,\n",
              "  2.3966803550720215,\n",
              "  1.4935333728790283,\n",
              "  1.529803991317749],\n",
              " [1.357290506362915,\n",
              "  1.9194447994232178,\n",
              "  1.1054812669754028,\n",
              "  1.9269111156463623,\n",
              "  1.8826168775558472,\n",
              "  1.2108641862869263,\n",
              "  1.2437376976013184],\n",
              " [2.532862901687622,\n",
              "  3.359074592590332,\n",
              "  1.8384867906570435,\n",
              "  3.4092841148376465,\n",
              "  3.376244068145752,\n",
              "  2.004526376724243,\n",
              "  2.074650287628174],\n",
              " [2.816192626953125,\n",
              "  3.6915202140808105,\n",
              "  2.009157419204712,\n",
              "  3.7488362789154053,\n",
              "  3.7146174907684326,\n",
              "  2.1795568466186523,\n",
              "  2.268948554992676],\n",
              " [2.9154622554779053,\n",
              "  3.806396484375,\n",
              "  2.066678047180176,\n",
              "  3.86936092376709,\n",
              "  3.832709789276123,\n",
              "  2.254274845123291,\n",
              "  2.340268135070801],\n",
              " [2.764833450317383,\n",
              "  3.6326797008514404,\n",
              "  1.9787189960479736,\n",
              "  3.689291477203369,\n",
              "  3.6571366786956787,\n",
              "  2.1530861854553223,\n",
              "  2.2347159385681152],\n",
              " [2.5489931106567383,\n",
              "  3.377150774002075,\n",
              "  1.8483006954193115,\n",
              "  3.426539182662964,\n",
              "  3.3943095207214355,\n",
              "  2.0145580768585205,\n",
              "  2.0830883979797363],\n",
              " [1.6926848888397217,\n",
              "  2.3408308029174805,\n",
              "  1.3194810152053833,\n",
              "  2.3546009063720703,\n",
              "  2.312380790710449,\n",
              "  1.4497745037078857,\n",
              "  1.4848157167434692],\n",
              " [2.0284159183502197,\n",
              "  2.7543303966522217,\n",
              "  1.5292127132415771,\n",
              "  2.7809054851531982,\n",
              "  2.74194073677063,\n",
              "  1.6806913614273071,\n",
              "  1.7211520671844482],\n",
              " [1.0612057447433472,\n",
              "  1.5413399934768677,\n",
              "  0.9134318232536316,\n",
              "  1.5445733070373535,\n",
              "  1.4976928234100342,\n",
              "  0.99257493019104,\n",
              "  1.0277323722839355],\n",
              " [1.7839128971099854,\n",
              "  2.453256607055664,\n",
              "  1.3774827718734741,\n",
              "  2.470722198486328,\n",
              "  2.430309295654297,\n",
              "  1.5128326416015625,\n",
              "  1.5485873222351074],\n",
              " [2.8030223846435547,\n",
              "  3.6763737201690674,\n",
              "  2.0006353855133057,\n",
              "  3.7353649139404297,\n",
              "  3.7054343223571777,\n",
              "  2.179070472717285,\n",
              "  2.262246608734131],\n",
              " [1.9467815160751343,\n",
              "  2.6525561809539795,\n",
              "  1.4794940948486328,\n",
              "  2.6775002479553223,\n",
              "  2.6381258964538574,\n",
              "  1.6260020732879639,\n",
              "  1.664300799369812],\n",
              " [1.5306813716888428,\n",
              "  2.139420509338379,\n",
              "  1.2169469594955444,\n",
              "  2.1496636867523193,\n",
              "  2.1080164909362793,\n",
              "  1.3368806838989258,\n",
              "  1.3680903911590576],\n",
              " [2.3860361576080322,\n",
              "  3.183107376098633,\n",
              "  1.7496585845947266,\n",
              "  3.2257752418518066,\n",
              "  3.1926422119140625,\n",
              "  1.9139766693115234,\n",
              "  1.970219373703003],\n",
              " [1.5547009706497192,\n",
              "  2.1700599193573,\n",
              "  1.232778549194336,\n",
              "  2.1798174381256104,\n",
              "  2.1407227516174316,\n",
              "  1.3537123203277588,\n",
              "  1.385972023010254],\n",
              " [1.486040472984314,\n",
              "  2.0835835933685303,\n",
              "  1.1888989210128784,\n",
              "  2.0922129154205322,\n",
              "  2.050196647644043,\n",
              "  1.3051378726959229,\n",
              "  1.336419939994812],\n",
              " [2.7593841552734375,\n",
              "  3.622596025466919,\n",
              "  1.973799705505371,\n",
              "  3.6809067726135254,\n",
              "  3.6508469581604004,\n",
              "  2.1467337608337402,\n",
              "  2.2292346954345703],\n",
              " [2.2041802406311035,\n",
              "  2.9669249057769775,\n",
              "  1.6393771171569824,\n",
              "  3.002990245819092,\n",
              "  2.965100049972534,\n",
              "  1.7974088191986084,\n",
              "  1.847517728805542],\n",
              " [2.136842727661133,\n",
              "  2.8851263523101807,\n",
              "  1.5983150005340576,\n",
              "  2.916088581085205,\n",
              "  2.8813211917877197,\n",
              "  1.7499197721481323,\n",
              "  1.7981404066085815],\n",
              " [2.375016212463379,\n",
              "  3.169917583465576,\n",
              "  1.7425882816314697,\n",
              "  3.2123165130615234,\n",
              "  3.1766271591186523,\n",
              "  1.907145380973816,\n",
              "  1.9626126289367676],\n",
              " [1.455407738685608,\n",
              "  2.0446970462799072,\n",
              "  1.1677438020706177,\n",
              "  2.0524959564208984,\n",
              "  2.009906768798828,\n",
              "  1.2832047939300537,\n",
              "  1.3132685422897339],\n",
              " [2.7001378536224365,\n",
              "  3.5535340309143066,\n",
              "  1.938763976097107,\n",
              "  3.609701156616211,\n",
              "  3.573068141937256,\n",
              "  2.105731725692749,\n",
              "  2.1899213790893555],\n",
              " [2.8518218994140625,\n",
              "  3.728877544403076,\n",
              "  2.0293996334075928,\n",
              "  3.7916815280914307,\n",
              "  3.7608821392059326,\n",
              "  2.207576036453247,\n",
              "  2.2929325103759766],\n",
              " [1.6493819952011108,\n",
              "  2.288353681564331,\n",
              "  1.2918144464492798,\n",
              "  2.3004634380340576,\n",
              "  2.2583060264587402,\n",
              "  1.4211430549621582,\n",
              "  1.4540725946426392],\n",
              " [2.8337886333465576,\n",
              "  3.7108020782470703,\n",
              "  2.017909049987793,\n",
              "  3.7716126441955566,\n",
              "  3.7415757179260254,\n",
              "  2.1928484439849854,\n",
              "  2.282092571258545],\n",
              " [1.5063425302505493,\n",
              "  2.1073243618011475,\n",
              "  1.2015818357467651,\n",
              "  2.116511344909668,\n",
              "  2.074357271194458,\n",
              "  1.3216761350631714,\n",
              "  1.3506327867507935],\n",
              " [2.671605348587036,\n",
              "  3.5214598178863525,\n",
              "  1.9223456382751465,\n",
              "  3.57436203956604,\n",
              "  3.5432586669921875,\n",
              "  2.0958831310272217,\n",
              "  2.167479991912842],\n",
              " [2.6512646675109863,\n",
              "  3.499274969100952,\n",
              "  1.9105645418167114,\n",
              "  3.5535902976989746,\n",
              "  3.5214104652404785,\n",
              "  2.0801470279693604,\n",
              "  2.1562533378601074],\n",
              " [1.3555376529693604,\n",
              "  1.9189872741699219,\n",
              "  1.1047865152359009,\n",
              "  1.9248723983764648,\n",
              "  1.8805772066116333,\n",
              "  1.2118089199066162,\n",
              "  1.2413463592529297],\n",
              " [2.0612781047821045,\n",
              "  2.792454242706299,\n",
              "  1.5485690832138062,\n",
              "  2.820683002471924,\n",
              "  2.78255558013916,\n",
              "  1.7020072937011719,\n",
              "  1.744014024734497],\n",
              " [2.6178505420684814,\n",
              "  3.460188865661621,\n",
              "  1.8905372619628906,\n",
              "  3.5123817920684814,\n",
              "  3.4806554317474365,\n",
              "  2.0599117279052734,\n",
              "  2.1331610679626465],\n",
              " [2.6741158962249756,\n",
              "  3.5266544818878174,\n",
              "  1.9237143993377686,\n",
              "  3.580533027648926,\n",
              "  3.5478858947753906,\n",
              "  2.0966877937316895,\n",
              "  2.1735944747924805],\n",
              " [2.8642468452453613,\n",
              "  3.74462890625,\n",
              "  2.03791880607605,\n",
              "  3.8037922382354736,\n",
              "  3.7740302085876465,\n",
              "  2.2129809856414795,\n",
              "  2.2996954917907715],\n",
              " [1.1617037057876587,\n",
              "  1.6716766357421875,\n",
              "  0.9798180460929871,\n",
              "  1.6746736764907837,\n",
              "  1.6299530267715454,\n",
              "  1.0708842277526855,\n",
              "  1.1025445461273193],\n",
              " [0.9745666980743408,\n",
              "  1.4295734167099,\n",
              "  0.8551466464996338,\n",
              "  1.4309289455413818,\n",
              "  1.3853330612182617,\n",
              "  0.9253233671188354,\n",
              "  0.9628220796585083],\n",
              " [2.4372615814208984,\n",
              "  3.24772047996521,\n",
              "  1.7816904783248901,\n",
              "  3.2926700115203857,\n",
              "  3.2585582733154297,\n",
              "  1.9432120323181152,\n",
              "  2.009594440460205],\n",
              " [1.4785246849060059,\n",
              "  2.075265884399414,\n",
              "  1.1840990781784058,\n",
              "  2.0840437412261963,\n",
              "  2.041649580001831,\n",
              "  1.3032639026641846,\n",
              "  1.3321613073349],\n",
              " [2.713055372238159,\n",
              "  3.5703542232513428,\n",
              "  1.9489558935165405,\n",
              "  3.6271774768829346,\n",
              "  3.5958962440490723,\n",
              "  2.1175763607025146,\n",
              "  2.1984353065490723],\n",
              " [2.8156886100769043,\n",
              "  3.688060760498047,\n",
              "  2.0079152584075928,\n",
              "  3.747471570968628,\n",
              "  3.716496229171753,\n",
              "  2.185786247253418,\n",
              "  2.267329216003418],\n",
              " [1.754311203956604,\n",
              "  2.418782949447632,\n",
              "  1.3590729236602783,\n",
              "  2.433657646179199,\n",
              "  2.394625186920166,\n",
              "  1.494002342224121,\n",
              "  1.528161644935608],\n",
              " [2.2673239707946777,\n",
              "  3.04195499420166,\n",
              "  1.6771252155303955,\n",
              "  3.0798537731170654,\n",
              "  3.045215368270874,\n",
              "  1.8352822065353394,\n",
              "  1.8895028829574585],\n",
              " [1.9340218305587769,\n",
              "  2.6403696537017822,\n",
              "  1.4714463949203491,\n",
              "  2.661668300628662,\n",
              "  2.6229794025421143,\n",
              "  1.6177780628204346,\n",
              "  1.655591368675232],\n",
              " [2.6391141414642334,\n",
              "  3.482586145401001,\n",
              "  1.9034428596496582,\n",
              "  3.5360488891601562,\n",
              "  3.502690315246582,\n",
              "  2.068774461746216,\n",
              "  2.147111415863037],\n",
              " [2.1699330806732178,\n",
              "  2.9269723892211914,\n",
              "  1.6185333728790283,\n",
              "  2.9603195190429688,\n",
              "  2.92318058013916,\n",
              "  1.7753915786743164,\n",
              "  1.8229641914367676],\n",
              " [2.905508518218994,\n",
              "  3.7981698513031006,\n",
              "  2.061495304107666,\n",
              "  3.8574042320251465,\n",
              "  3.8165042400360107,\n",
              "  2.245573043823242,\n",
              "  2.3332767486572266],\n",
              " [1.5215907096862793,\n",
              "  2.1271297931671143,\n",
              "  1.2118208408355713,\n",
              "  2.1362743377685547,\n",
              "  2.093121290206909,\n",
              "  1.3292644023895264,\n",
              "  1.3621875047683716],\n",
              " [1.5443202257156372,\n",
              "  2.155198097229004,\n",
              "  1.2278131246566772,\n",
              "  2.167036294937134,\n",
              "  2.1258435249328613,\n",
              "  1.3487205505371094,\n",
              "  1.379433512687683],\n",
              " [1.6013351678848267,\n",
              "  2.226494312286377,\n",
              "  1.2625882625579834,\n",
              "  2.239520311355591,\n",
              "  2.19620943069458,\n",
              "  1.3892107009887695,\n",
              "  1.4197957515716553],\n",
              " [2.458178758621216,\n",
              "  3.2699170112609863,\n",
              "  1.7939380407333374,\n",
              "  3.316640853881836,\n",
              "  3.282602310180664,\n",
              "  1.9581429958343506,\n",
              "  2.022031307220459],\n",
              " [2.6053645610809326,\n",
              "  3.444617986679077,\n",
              "  1.883062720298767,\n",
              "  3.4965310096740723,\n",
              "  3.462163209915161,\n",
              "  2.0561091899871826,\n",
              "  2.1236934661865234],\n",
              " [1.8571463823318481,\n",
              "  2.5443413257598877,\n",
              "  1.4234172105789185,\n",
              "  2.564812660217285,\n",
              "  2.525383710861206,\n",
              "  1.5638530254364014,\n",
              "  1.6026451587677002],\n",
              " [3.003206253051758,\n",
              "  3.913543939590454,\n",
              "  2.1196868419647217,\n",
              "  3.9728713035583496,\n",
              "  3.931811809539795,\n",
              "  2.3167219161987305,\n",
              "  2.4034605026245117],\n",
              " [2.8107476234436035,\n",
              "  3.6821274757385254,\n",
              "  2.005772590637207,\n",
              "  3.7432191371917725,\n",
              "  3.7137231826782227,\n",
              "  2.180922031402588,\n",
              "  2.2638463973999023],\n",
              " [1.801522135734558,\n",
              "  2.4767634868621826,\n",
              "  1.3875494003295898,\n",
              "  2.49430251121521,\n",
              "  2.4531683921813965,\n",
              "  1.5268710851669312,\n",
              "  1.5636838674545288],\n",
              " [1.2018709182739258,\n",
              "  1.7214093208312988,\n",
              "  1.0046931505203247,\n",
              "  1.726421594619751,\n",
              "  1.6807435750961304,\n",
              "  1.097424864768982,\n",
              "  1.130089282989502],\n",
              " [2.683000326156616,\n",
              "  3.536806583404541,\n",
              "  1.929659128189087,\n",
              "  3.592418670654297,\n",
              "  3.5591394901275635,\n",
              "  2.1024012565612793,\n",
              "  2.177859306335449],\n",
              " [1.5311015844345093,\n",
              "  2.139893054962158,\n",
              "  1.216579556465149,\n",
              "  2.1493637561798096,\n",
              "  2.1075186729431152,\n",
              "  1.3361332416534424,\n",
              "  1.3676029443740845],\n",
              " [1.1931047439575195,\n",
              "  1.7092921733856201,\n",
              "  1.0001473426818848,\n",
              "  1.7139520645141602,\n",
              "  1.6692278385162354,\n",
              "  1.0931475162506104,\n",
              "  1.123932123184204],\n",
              " [2.912468433380127,\n",
              "  3.8054211139678955,\n",
              "  2.06593656539917,\n",
              "  3.8639028072357178,\n",
              "  3.8283355236053467,\n",
              "  2.2513415813446045,\n",
              "  2.338688850402832],\n",
              " [1.2175079584121704,\n",
              "  1.7416386604309082,\n",
              "  1.0164564847946167,\n",
              "  1.7465482950210571,\n",
              "  1.7028864622116089,\n",
              "  1.110859751701355,\n",
              "  1.1422035694122314],\n",
              " [1.278056025505066,\n",
              "  1.821017861366272,\n",
              "  1.054569959640503,\n",
              "  1.8252381086349487,\n",
              "  1.7812578678131104,\n",
              "  1.156090497970581,\n",
              "  1.185794711112976],\n",
              " [2.455497980117798,\n",
              "  3.2680933475494385,\n",
              "  1.792650580406189,\n",
              "  3.3132495880126953,\n",
              "  3.281838893890381,\n",
              "  1.958141803741455,\n",
              "  2.0204906463623047],\n",
              " [1.7070508003234863,\n",
              "  2.3583688735961914,\n",
              "  1.328844428062439,\n",
              "  2.372964859008789,\n",
              "  2.333104133605957,\n",
              "  1.4607025384902954,\n",
              "  1.4945651292800903],\n",
              " [1.035560131072998,\n",
              "  1.507084846496582,\n",
              "  0.8965265154838562,\n",
              "  1.5098533630371094,\n",
              "  1.4645745754241943,\n",
              "  0.9718775749206543,\n",
              "  1.0086779594421387],\n",
              " [1.7639600038528442,\n",
              "  2.4306936264038086,\n",
              "  1.363724708557129,\n",
              "  2.4459009170532227,\n",
              "  2.4057538509368896,\n",
              "  1.5000553131103516,\n",
              "  1.532881259918213],\n",
              " [2.6653456687927246,\n",
              "  3.514474391937256,\n",
              "  1.918441891670227,\n",
              "  3.5677835941314697,\n",
              "  3.537383794784546,\n",
              "  2.0862948894500732,\n",
              "  2.164215564727783],\n",
              " [1.1299084424972534,\n",
              "  1.6310606002807617,\n",
              "  0.9574834704399109,\n",
              "  1.632711410522461,\n",
              "  1.5884881019592285,\n",
              "  1.0460822582244873,\n",
              "  1.0771594047546387],\n",
              " [2.955010175704956,\n",
              "  3.8541479110717773,\n",
              "  2.0909595489501953,\n",
              "  3.9148290157318115,\n",
              "  3.879849672317505,\n",
              "  2.2761566638946533,\n",
              "  2.368246555328369],\n",
              " [1.5770689249038696,\n",
              "  2.195974111557007,\n",
              "  1.24644935131073,\n",
              "  2.20792818069458,\n",
              "  2.165334939956665,\n",
              "  1.369984745979309,\n",
              "  1.4022278785705566],\n",
              " [1.5735641717910767,\n",
              "  2.193026304244995,\n",
              "  1.2448197603225708,\n",
              "  2.205655336380005,\n",
              "  2.1632697582244873,\n",
              "  1.3706685304641724,\n",
              "  1.4004764556884766],\n",
              " [2.2545254230499268,\n",
              "  3.02770733833313,\n",
              "  1.6696592569351196,\n",
              "  3.0647804737091064,\n",
              "  3.0304291248321533,\n",
              "  1.8267117738723755,\n",
              "  1.8817178010940552],\n",
              " [1.4033745527267456,\n",
              "  1.9779413938522339,\n",
              "  1.134826898574829,\n",
              "  1.9844439029693604,\n",
              "  1.9425841569900513,\n",
              "  1.2459778785705566,\n",
              "  1.2749131917953491],\n",
              " [1.4928044080734253,\n",
              "  2.0927085876464844,\n",
              "  1.193547248840332,\n",
              "  2.101637840270996,\n",
              "  2.0584940910339355,\n",
              "  1.3125449419021606,\n",
              "  1.3426772356033325],\n",
              " [1.6371498107910156,\n",
              "  2.271862030029297,\n",
              "  1.284729242324829,\n",
              "  2.2859554290771484,\n",
              "  2.2434566020965576,\n",
              "  1.4123135805130005,\n",
              "  1.445152997970581],\n",
              " [2.1223082542419434,\n",
              "  2.8672280311584473,\n",
              "  1.5874724388122559,\n",
              "  2.8973751068115234,\n",
              "  2.8613719940185547,\n",
              "  1.7412601709365845,\n",
              "  1.7867637872695923],\n",
              " [1.2989143133163452,\n",
              "  1.8455133438110352,\n",
              "  1.0678751468658447,\n",
              "  1.850222110748291,\n",
              "  1.8060870170593262,\n",
              "  1.1714519262313843,\n",
              "  1.1999483108520508],\n",
              " [1.034471869468689,\n",
              "  1.5070030689239502,\n",
              "  0.8953542113304138,\n",
              "  1.5100914239883423,\n",
              "  1.4637961387634277,\n",
              "  0.972442626953125,\n",
              "  1.0084500312805176],\n",
              " [2.629425048828125,\n",
              "  3.472609758377075,\n",
              "  1.8980300426483154,\n",
              "  3.5261411666870117,\n",
              "  3.4926185607910156,\n",
              "  2.064983606338501,\n",
              "  2.140592575073242],\n",
              " [2.941105365753174,\n",
              "  3.835509777069092,\n",
              "  2.0819239616394043,\n",
              "  3.897941827774048,\n",
              "  3.8631346225738525,\n",
              "  2.2677814960479736,\n",
              "  2.3571038246154785],\n",
              " [1.3382130861282349,\n",
              "  1.8951371908187866,\n",
              "  1.0935540199279785,\n",
              "  1.9023005962371826,\n",
              "  1.859269142150879,\n",
              "  1.1983462572097778,\n",
              "  1.229103684425354],\n",
              " [2.684455394744873,\n",
              "  3.5358004570007324,\n",
              "  1.9295518398284912,\n",
              "  3.5922608375549316,\n",
              "  3.562512159347534,\n",
              "  2.0953564643859863,\n",
              "  2.1783647537231445],\n",
              " [2.4819908142089844,\n",
              "  3.2981226444244385,\n",
              "  1.8094253540039062,\n",
              "  3.3463480472564697,\n",
              "  3.313185214996338,\n",
              "  1.9706988334655762,\n",
              "  2.0382871627807617],\n",
              " [1.3371707201004028,\n",
              "  1.894879698753357,\n",
              "  1.094045877456665,\n",
              "  1.9006438255310059,\n",
              "  1.8561499118804932,\n",
              "  1.1996690034866333,\n",
              "  1.229667067527771],\n",
              " [2.935171604156494,\n",
              "  3.829317569732666,\n",
              "  2.078460693359375,\n",
              "  3.8899636268615723,\n",
              "  3.8558757305145264,\n",
              "  2.259094476699829,\n",
              "  2.3510684967041016],\n",
              " [2.5156850814819336,\n",
              "  3.336859941482544,\n",
              "  1.8291661739349365,\n",
              "  3.385319232940674,\n",
              "  3.3540191650390625,\n",
              "  1.9960403442382812,\n",
              "  2.0612430572509766],\n",
              " [1.721722960472107,\n",
              "  2.3770952224731445,\n",
              "  1.3381284475326538,\n",
              "  2.3924529552459717,\n",
              "  2.3522403240203857,\n",
              "  1.471627950668335,\n",
              "  1.5052565336227417],\n",
              " [1.605515956878662,\n",
              "  2.2308969497680664,\n",
              "  1.2656770944595337,\n",
              "  2.244002103805542,\n",
              "  2.2023913860321045,\n",
              "  1.390263319015503,\n",
              "  1.4225828647613525],\n",
              " [2.2931978702545166,\n",
              "  3.0729055404663086,\n",
              "  1.6922564506530762,\n",
              "  3.1108591556549072,\n",
              "  3.0752508640289307,\n",
              "  1.8541483879089355,\n",
              "  1.90533447265625],\n",
              " [2.5888288021087646,\n",
              "  3.4228832721710205,\n",
              "  1.8723028898239136,\n",
              "  3.473641872406006,\n",
              "  3.4411797523498535,\n",
              "  2.0368640422821045,\n",
              "  2.1113481521606445],\n",
              " [2.506355047225952,\n",
              "  3.328362226486206,\n",
              "  1.823533535003662,\n",
              "  3.3763699531555176,\n",
              "  3.341416835784912,\n",
              "  1.9888169765472412,\n",
              "  2.056612014770508],\n",
              " [1.4305505752563477,\n",
              "  2.012118339538574,\n",
              "  1.1536827087402344,\n",
              "  2.0200960636138916,\n",
              "  1.9772961139678955,\n",
              "  1.2655267715454102,\n",
              "  1.2959952354431152],\n",
              " [2.0994210243225098,\n",
              "  2.8423290252685547,\n",
              "  1.5728991031646729,\n",
              "  2.8707704544067383,\n",
              "  2.8333659172058105,\n",
              "  1.726896047592163,\n",
              "  1.7724109888076782],\n",
              " [1.4373732805252075,\n",
              "  2.0206055641174316,\n",
              "  1.1591631174087524,\n",
              "  2.0273830890655518,\n",
              "  1.9865432977676392,\n",
              "  1.2711150646209717,\n",
              "  1.3014270067214966],\n",
              " [1.732054352760315,\n",
              "  2.3898141384124756,\n",
              "  1.344567894935608,\n",
              "  2.4060440063476562,\n",
              "  2.3669989109039307,\n",
              "  1.4763579368591309,\n",
              "  1.5122793912887573],\n",
              " [2.3484463691711426,\n",
              "  3.1404731273651123,\n",
              "  1.726890206336975,\n",
              "  3.180854320526123,\n",
              "  3.1473701000213623,\n",
              "  1.8885436058044434,\n",
              "  1.9470961093902588],\n",
              " [2.9466288089752197,\n",
              "  3.8431663513183594,\n",
              "  2.085747241973877,\n",
              "  3.9062793254852295,\n",
              "  3.8698434829711914,\n",
              "  2.271301746368408,\n",
              "  2.3614907264709473],\n",
              " [2.3376381397247314,\n",
              "  3.125955820083618,\n",
              "  1.7196930646896362,\n",
              "  3.165966272354126,\n",
              "  3.132246255874634,\n",
              "  1.8813084363937378,\n",
              "  1.9383893013000488],\n",
              " [1.6894214153289795,\n",
              "  2.3369252681732178,\n",
              "  1.319746971130371,\n",
              "  2.352463722229004,\n",
              "  2.3115170001983643,\n",
              "  1.451696753501892,\n",
              "  1.4832099676132202],\n",
              " [2.821200132369995,\n",
              "  3.697571277618408,\n",
              "  2.012305498123169,\n",
              "  3.754727602005005,\n",
              "  3.7225098609924316,\n",
              "  2.1890335083007812,\n",
              "  2.2735629081726074],\n",
              " [2.1697745323181152,\n",
              "  2.9256534576416016,\n",
              "  1.6167371273040771,\n",
              "  2.9573769569396973,\n",
              "  2.921618938446045,\n",
              "  1.770961046218872,\n",
              "  1.8193575143814087],\n",
              " [2.724196434020996,\n",
              "  3.582061767578125,\n",
              "  1.9540642499923706,\n",
              "  3.6387109756469727,\n",
              "  3.608989953994751,\n",
              "  2.1258859634399414,\n",
              "  2.204385280609131],\n",
              " [1.3229271173477173,\n",
              "  1.8759076595306396,\n",
              "  1.0844571590423584,\n",
              "  1.882554292678833,\n",
              "  1.8365281820297241,\n",
              "  1.1899003982543945,\n",
              "  1.2189809083938599],\n",
              " [2.6514153480529785,\n",
              "  3.499162197113037,\n",
              "  1.9107940196990967,\n",
              "  3.551119565963745,\n",
              "  3.5178675651550293,\n",
              "  2.080573081970215,\n",
              "  2.155600070953369],\n",
              " [1.5415525436401367,\n",
              "  2.151245594024658,\n",
              "  1.224326729774475,\n",
              "  2.1625399589538574,\n",
              "  2.1185641288757324,\n",
              "  1.3471096754074097,\n",
              "  1.3767963647842407],\n",
              " [2.921799421310425,\n",
              "  3.8127541542053223,\n",
              "  2.070939302444458,\n",
              "  3.8750743865966797,\n",
              "  3.842137098312378,\n",
              "  2.2523837089538574,\n",
              "  2.3425064086914062],\n",
              " [1.1050838232040405,\n",
              "  1.59823477268219,\n",
              "  0.9418708682060242,\n",
              "  1.6015052795410156,\n",
              "  1.5550576448440552,\n",
              "  1.0266646146774292,\n",
              "  1.0600732564926147],\n",
              " [1.4977245330810547,\n",
              "  2.0957765579223633,\n",
              "  1.197192668914795,\n",
              "  2.106750249862671,\n",
              "  2.0646891593933105,\n",
              "  1.3162387609481812,\n",
              "  1.3458223342895508],\n",
              " [2.738227605819702,\n",
              "  3.599944829940796,\n",
              "  1.9623552560806274,\n",
              "  3.657344102859497,\n",
              "  3.62882399559021,\n",
              "  2.138428211212158,\n",
              "  2.21622896194458],\n",
              " [2.8362693786621094,\n",
              "  3.7125837802886963,\n",
              "  2.0199198722839355,\n",
              "  3.773252487182617,\n",
              "  3.7433557510375977,\n",
              "  2.2013497352600098,\n",
              "  2.2826271057128906],\n",
              " [2.488801956176758,\n",
              "  3.3078198432922363,\n",
              "  1.8125046491622925,\n",
              "  3.3546864986419678,\n",
              "  3.3190152645111084,\n",
              "  1.9775936603546143,\n",
              "  2.0446724891662598],\n",
              " [1.3832221031188965,\n",
              "  1.9529366493225098,\n",
              "  1.1224740743637085,\n",
              "  1.959774136543274,\n",
              "  1.915217638015747,\n",
              "  1.2320175170898438,\n",
              "  1.2627129554748535],\n",
              " [2.3322436809539795,\n",
              "  3.12003231048584,\n",
              "  1.7176859378814697,\n",
              "  3.1600582599639893,\n",
              "  3.1268839836120605,\n",
              "  1.8791028261184692,\n",
              "  1.934700608253479],\n",
              " [1.6904670000076294,\n",
              "  2.338275194168091,\n",
              "  1.3181655406951904,\n",
              "  2.3521604537963867,\n",
              "  2.312016010284424,\n",
              "  1.449298620223999,\n",
              "  1.4831407070159912],\n",
              " [2.9877736568450928,\n",
              "  3.8932242393493652,\n",
              "  2.110283136367798,\n",
              "  3.955490827560425,\n",
              "  3.917705535888672,\n",
              "  2.304126739501953,\n",
              "  2.392451763153076],\n",
              " [1.6950187683105469,\n",
              "  2.3438737392425537,\n",
              "  1.3201419115066528,\n",
              "  2.359025001525879,\n",
              "  2.3175292015075684,\n",
              "  1.4520033597946167,\n",
              "  1.4850075244903564],\n",
              " [2.182217597961426,\n",
              "  2.9407060146331787,\n",
              "  1.6243534088134766,\n",
              "  2.9732871055603027,\n",
              "  2.939718723297119,\n",
              "  1.7788176536560059,\n",
              "  1.8288027048110962],\n",
              " [2.0502359867095947,\n",
              "  2.7815539836883545,\n",
              "  1.5451513528823853,\n",
              "  2.810451030731201,\n",
              "  2.7725963592529297,\n",
              "  1.6970534324645996,\n",
              "  1.7392274141311646],\n",
              " [1.6859016418457031,\n",
              "  2.332556962966919,\n",
              "  1.3163180351257324,\n",
              "  2.347402572631836,\n",
              "  2.305185556411743,\n",
              "  1.4495606422424316,\n",
              "  1.4813300371170044],\n",
              " [1.916002869606018,\n",
              "  2.615912914276123,\n",
              "  1.4588334560394287,\n",
              "  2.638080596923828,\n",
              "  2.597705125808716,\n",
              "  1.6050045490264893,\n",
              "  1.643398642539978],\n",
              " [2.715047597885132,\n",
              "  3.5727713108062744,\n",
              "  1.9484516382217407,\n",
              "  3.627932071685791,\n",
              "  3.596406936645508,\n",
              "  2.121122121810913,\n",
              "  2.1991233825683594],\n",
              " [2.936595916748047,\n",
              "  3.8288681507110596,\n",
              "  2.078315258026123,\n",
              "  3.8886327743530273,\n",
              "  3.855377435684204,\n",
              "  2.2581381797790527,\n",
              "  2.352109432220459],\n",
              " [2.9012789726257324,\n",
              "  3.7907397747039795,\n",
              "  2.0577268600463867,\n",
              "  3.8515965938568115,\n",
              "  3.817478895187378,\n",
              "  2.2380852699279785,\n",
              "  2.3278889656066895],\n",
              " [2.704585313796997,\n",
              "  3.5624895095825195,\n",
              "  1.9413902759552002,\n",
              "  3.6163535118103027,\n",
              "  3.5798702239990234,\n",
              "  2.1222846508026123,\n",
              "  2.193286895751953],\n",
              " [1.9390112161636353,\n",
              "  2.644300937652588,\n",
              "  1.4757907390594482,\n",
              "  2.667909622192383,\n",
              "  2.6296470165252686,\n",
              "  1.6189459562301636,\n",
              "  1.6590629816055298],\n",
              " [1.918716549873352,\n",
              "  2.6192057132720947,\n",
              "  1.4618185758590698,\n",
              "  2.642240524291992,\n",
              "  2.6030781269073486,\n",
              "  1.6037890911102295,\n",
              "  1.6448578834533691],\n",
              " [2.894007921218872,\n",
              "  3.778804302215576,\n",
              "  2.0546205043792725,\n",
              "  3.839583396911621,\n",
              "  3.808356523513794,\n",
              "  2.2367427349090576,\n",
              "  2.3216090202331543],\n",
              " [2.4886512756347656,\n",
              "  3.3058199882507324,\n",
              "  1.8121788501739502,\n",
              "  3.351517915725708,\n",
              "  3.3184475898742676,\n",
              "  1.9741017818450928,\n",
              "  2.042712688446045],\n",
              " [1.1759545803070068,\n",
              "  1.6900577545166016,\n",
              "  0.9870246052742004,\n",
              "  1.6932271718978882,\n",
              "  1.6489179134368896,\n",
              "  1.0791943073272705,\n",
              "  1.1113555431365967],\n",
              " [2.9717390537261963,\n",
              "  3.8752100467681885,\n",
              "  2.1009700298309326,\n",
              "  3.9362683296203613,\n",
              "  3.895590305328369,\n",
              "  2.283524990081787,\n",
              "  2.3818483352661133],\n",
              " [1.6896878480911255,\n",
              "  2.3380415439605713,\n",
              "  1.3187650442123413,\n",
              "  2.353595733642578,\n",
              "  2.3121390342712402,\n",
              "  1.45140540599823,\n",
              "  1.4838508367538452],\n",
              " [2.716878890991211,\n",
              "  3.5729153156280518,\n",
              "  1.9487370252609253,\n",
              "  3.6298389434814453,\n",
              "  3.601893663406372,\n",
              "  2.1175713539123535,\n",
              "  2.198655605316162],\n",
              " [1.43325674533844,\n",
              "  2.0157053470611572,\n",
              "  1.1562556028366089,\n",
              "  2.02514386177063,\n",
              "  1.9818267822265625,\n",
              "  1.2701334953308105,\n",
              "  1.2997145652770996],\n",
              " [1.3360728025436401,\n",
              "  1.8947405815124512,\n",
              "  1.0920215845108032,\n",
              "  1.9003572463989258,\n",
              "  1.8559162616729736,\n",
              "  1.1976128816604614,\n",
              "  1.2275177240371704],\n",
              " [2.6307718753814697,\n",
              "  3.4733262062072754,\n",
              "  1.8983224630355835,\n",
              "  3.526895761489868,\n",
              "  3.4970321655273438,\n",
              "  2.066800117492676,\n",
              "  2.139942169189453],\n",
              " [2.6234567165374756,\n",
              "  3.466737985610962,\n",
              "  1.8940353393554688,\n",
              "  3.5190494060516357,\n",
              "  3.488142251968384,\n",
              "  2.068082332611084,\n",
              "  2.137091636657715],\n",
              " [2.707566738128662,\n",
              "  3.5621273517608643,\n",
              "  1.9435913562774658,\n",
              "  3.618594169616699,\n",
              "  3.590794563293457,\n",
              "  2.1173665523529053,\n",
              "  2.192871570587158],\n",
              " [2.7367119789123535,\n",
              "  3.5965917110443115,\n",
              "  1.961221694946289,\n",
              "  3.654517412185669,\n",
              "  3.625007390975952,\n",
              "  2.1352920532226562,\n",
              "  2.212618350982666],\n",
              " [2.9518837928771973,\n",
              "  3.8534915447235107,\n",
              "  2.089792013168335,\n",
              "  3.9140326976776123,\n",
              "  3.8737943172454834,\n",
              "  2.2814180850982666,\n",
              "  2.3674583435058594],\n",
              " [1.0477509498596191,\n",
              "  1.5258326530456543,\n",
              "  0.903434693813324,\n",
              "  1.5281404256820679,\n",
              "  1.4821381568908691,\n",
              "  0.9833114147186279,\n",
              "  1.0180842876434326],\n",
              " [2.222975730895996,\n",
              "  2.9890825748443604,\n",
              "  1.6502379179000854,\n",
              "  3.0238242149353027,\n",
              "  2.98630952835083,\n",
              "  1.8046663999557495,\n",
              "  1.8586764335632324],\n",
              " [1.8038004636764526,\n",
              "  2.478257656097412,\n",
              "  1.3908404111862183,\n",
              "  2.4966886043548584,\n",
              "  2.458038091659546,\n",
              "  1.5281500816345215,\n",
              "  1.5633213520050049],\n",
              " [1.7532289028167725,\n",
              "  2.414806365966797,\n",
              "  1.3582273721694946,\n",
              "  2.430812120437622,\n",
              "  2.391530990600586,\n",
              "  1.4922459125518799,\n",
              "  1.5262751579284668],\n",
              " [1.8795559406280518,\n",
              "  2.5715956687927246,\n",
              "  1.437300443649292,\n",
              "  2.593374729156494,\n",
              "  2.5543553829193115,\n",
              "  1.5823149681091309,\n",
              "  1.61681067943573],\n",
              " [2.4394781589508057,\n",
              "  3.2498362064361572,\n",
              "  1.7822257280349731,\n",
              "  3.2935056686401367,\n",
              "  3.261317729949951,\n",
              "  1.9481792449951172,\n",
              "  2.00958251953125],\n",
              " [2.489755868911743,\n",
              "  3.3080193996429443,\n",
              "  1.8117241859436035,\n",
              "  3.3550922870635986,\n",
              "  3.3194687366485596,\n",
              "  1.9748599529266357,\n",
              "  2.043177604675293],\n",
              " [1.625916838645935,\n",
              "  2.2576944828033447,\n",
              "  1.2785403728485107,\n",
              "  2.271141529083252,\n",
              "  2.230297803878784,\n",
              "  1.4052915573120117,\n",
              "  1.437334656715393],\n",
              " [1.2759677171707153,\n",
              "  1.8178058862686157,\n",
              "  1.0532498359680176,\n",
              "  1.8224546909332275,\n",
              "  1.7781063318252563,\n",
              "  1.1548155546188354,\n",
              "  1.1849128007888794],\n",
              " [1.2607536315917969,\n",
              "  1.7976542711257935,\n",
              "  1.0430585145950317,\n",
              "  1.8023557662963867,\n",
              "  1.7578409910202026,\n",
              "  1.1409294605255127,\n",
              "  1.1737173795700073],\n",
              " [2.120197296142578,\n",
              "  2.866168975830078,\n",
              "  1.5860830545425415,\n",
              "  2.895738363265991,\n",
              "  2.8569204807281494,\n",
              "  1.7383992671966553,\n",
              "  1.7876759767532349],\n",
              " [2.941819667816162,\n",
              "  3.8378512859344482,\n",
              "  2.083568811416626,\n",
              "  3.9014647006988525,\n",
              "  3.8652307987213135,\n",
              "  2.2712671756744385,\n",
              "  2.358924388885498],\n",
              " [2.716947078704834,\n",
              "  3.576390027999878,\n",
              "  1.9491386413574219,\n",
              "  3.633012294769287,\n",
              "  3.596924304962158,\n",
              "  2.125187635421753,\n",
              "  2.204254150390625],\n",
              " [2.1685173511505127,\n",
              "  2.9243810176849365,\n",
              "  1.616551160812378,\n",
              "  2.9572911262512207,\n",
              "  2.9197354316711426,\n",
              "  1.7718775272369385,\n",
              "  1.8224633932113647],\n",
              " [2.740943193435669,\n",
              "  3.6021792888641357,\n",
              "  1.964593529701233,\n",
              "  3.660162925720215,\n",
              "  3.630368232727051,\n",
              "  2.1386125087738037,\n",
              "  2.2163596153259277],\n",
              " [2.3024470806121826,\n",
              "  3.0858359336853027,\n",
              "  1.6993123292922974,\n",
              "  3.1254167556762695,\n",
              "  3.089690685272217,\n",
              "  1.857430338859558,\n",
              "  1.9159338474273682],\n",
              " [2.588953971862793,\n",
              "  3.425128936767578,\n",
              "  1.8719213008880615,\n",
              "  3.477585792541504,\n",
              "  3.4427247047424316,\n",
              "  2.0396931171417236,\n",
              "  2.113126754760742],\n",
              " [1.124009132385254,\n",
              "  1.6228688955307007,\n",
              "  0.9543270468711853,\n",
              "  1.6253238916397095,\n",
              "  1.5795761346817017,\n",
              "  1.0399317741394043,\n",
              "  1.0736875534057617],\n",
              " [1.1579926013946533,\n",
              "  1.6668695211410522,\n",
              "  0.9767774343490601,\n",
              "  1.6707158088684082,\n",
              "  1.6247202157974243,\n",
              "  1.0674551725387573,\n",
              "  1.0988515615463257],\n",
              " [2.3860361576080322,\n",
              "  3.183107376098633,\n",
              "  1.7496585845947266,\n",
              "  3.2257752418518066,\n",
              "  3.1926422119140625,\n",
              "  1.9139766693115234,\n",
              "  1.970219373703003],\n",
              " [1.9815312623977661,\n",
              "  2.6959962844848633,\n",
              "  1.5014382600784302,\n",
              "  2.721505641937256,\n",
              "  2.6838550567626953,\n",
              "  1.6493918895721436,\n",
              "  1.688513159751892],\n",
              " [1.4134348630905151,\n",
              "  1.9930555820465088,\n",
              "  1.1410597562789917,\n",
              "  1.9981722831726074,\n",
              "  1.9558228254318237,\n",
              "  1.2539421319961548,\n",
              "  1.2835720777511597],\n",
              " [1.1530029773712158,\n",
              "  1.659541368484497,\n",
              "  0.9733073115348816,\n",
              "  1.6633069515228271,\n",
              "  1.6176809072494507,\n",
              "  1.0640060901641846,\n",
              "  1.095569133758545],\n",
              " [2.021559953689575,\n",
              "  2.7449138164520264,\n",
              "  1.5253527164459229,\n",
              "  2.770723819732666,\n",
              "  2.7335758209228516,\n",
              "  1.6758167743682861,\n",
              "  1.7159866094589233],\n",
              " [1.3397020101547241,\n",
              "  1.8982043266296387,\n",
              "  1.0935730934143066,\n",
              "  1.9048182964324951,\n",
              "  1.860819697380066,\n",
              "  1.2008894681930542,\n",
              "  1.2308651208877563],\n",
              " [0.9316680431365967,\n",
              "  1.3739638328552246,\n",
              "  0.8264774680137634,\n",
              "  1.375079870223999,\n",
              "  1.3285973072052002,\n",
              "  0.8905282616615295,\n",
              "  0.9311692714691162],\n",
              " [1.0979375839233398,\n",
              "  1.5894520282745361,\n",
              "  0.9381055235862732,\n",
              "  1.5926254987716675,\n",
              "  1.5469911098480225,\n",
              "  1.0222632884979248,\n",
              "  1.0556634664535522],\n",
              " [2.351449728012085,\n",
              "  3.142070770263672,\n",
              "  1.728299856185913,\n",
              "  3.183568239212036,\n",
              "  3.147517204284668,\n",
              "  1.891167402267456,\n",
              "  1.9474328756332397],\n",
              " [1.0158090591430664,\n",
              "  1.4815418720245361,\n",
              "  0.8829323649406433,\n",
              "  1.4849328994750977,\n",
              "  1.4390685558319092,\n",
              "  0.9571559429168701,\n",
              "  0.9934254288673401],\n",
              " [2.138455629348755,\n",
              "  2.8870863914489746,\n",
              "  1.5985995531082153,\n",
              "  2.9175281524658203,\n",
              "  2.8823695182800293,\n",
              "  1.7515255212783813,\n",
              "  1.7993654012680054],\n",
              " [2.878720998764038,\n",
              "  3.761274814605713,\n",
              "  2.0456552505493164,\n",
              "  3.8226327896118164,\n",
              "  3.7917213439941406,\n",
              "  2.2266058921813965,\n",
              "  2.3108091354370117],\n",
              " [2.7074825763702393,\n",
              "  3.565916061401367,\n",
              "  1.9453315734863281,\n",
              "  3.619601011276245,\n",
              "  3.5895113945007324,\n",
              "  2.1140544414520264,\n",
              "  2.1949820518493652],\n",
              " [1.846001148223877,\n",
              "  2.5348947048187256,\n",
              "  1.412091851234436,\n",
              "  2.551204204559326,\n",
              "  2.510329008102417,\n",
              "  1.5530593395233154,\n",
              "  1.5925434827804565],\n",
              " [1.8504493236541748,\n",
              "  2.5378096103668213,\n",
              "  1.4188196659088135,\n",
              "  2.556607961654663,\n",
              "  2.5163516998291016,\n",
              "  1.5594457387924194,\n",
              "  1.5954676866531372],\n",
              " [2.508769989013672,\n",
              "  3.3314967155456543,\n",
              "  1.8243902921676636,\n",
              "  3.379439115524292,\n",
              "  3.3454809188842773,\n",
              "  1.9870827198028564,\n",
              "  2.057429790496826],\n",
              " [1.314955472946167,\n",
              "  1.8680707216262817,\n",
              "  1.080025315284729,\n",
              "  1.8716120719909668,\n",
              "  1.82906174659729,\n",
              "  1.1825549602508545,\n",
              "  1.2125474214553833],\n",
              " [1.3467159271240234,\n",
              "  1.906418800354004,\n",
              "  1.1004106998443604,\n",
              "  1.9120643138885498,\n",
              "  1.867762565612793,\n",
              "  1.20535147190094,\n",
              "  1.235480785369873],\n",
              " [2.218027114868164,\n",
              "  2.9843108654022217,\n",
              "  1.6461882591247559,\n",
              "  3.017446517944336,\n",
              "  2.9821386337280273,\n",
              "  1.8012242317199707,\n",
              "  1.854775071144104],\n",
              " [1.0587425231933594,\n",
              "  1.539067029953003,\n",
              "  0.9110262989997864,\n",
              "  1.541425347328186,\n",
              "  1.4951586723327637,\n",
              "  0.9896537065505981,\n",
              "  1.025282382965088],\n",
              " [2.9808435440063477,\n",
              "  3.8878376483917236,\n",
              "  2.106539249420166,\n",
              "  3.947526216506958,\n",
              "  3.9059245586395264,\n",
              "  2.2954752445220947,\n",
              "  2.387981414794922],\n",
              " [1.1759244203567505,\n",
              "  1.6893293857574463,\n",
              "  0.9893857836723328,\n",
              "  1.6925541162490845,\n",
              "  1.6487303972244263,\n",
              "  1.0801132917404175,\n",
              "  1.1115505695343018],\n",
              " [2.9820196628570557,\n",
              "  3.885258197784424,\n",
              "  2.1064491271972656,\n",
              "  3.946791410446167,\n",
              "  3.906752347946167,\n",
              "  2.297452211380005,\n",
              "  2.387235641479492],\n",
              " [2.0301594734191895,\n",
              "  2.7542927265167236,\n",
              "  1.530495524406433,\n",
              "  2.7798523902893066,\n",
              "  2.742213487625122,\n",
              "  1.6823327541351318,\n",
              "  1.7210334539413452],\n",
              " [2.0769946575164795,\n",
              "  2.81219220161438,\n",
              "  1.5600590705871582,\n",
              "  2.841433525085449,\n",
              "  2.8017725944519043,\n",
              "  1.7136728763580322,\n",
              "  1.7559823989868164],\n",
              " [2.7081797122955322,\n",
              "  3.5628693103790283,\n",
              "  1.945343255996704,\n",
              "  3.6193692684173584,\n",
              "  3.5889370441436768,\n",
              "  2.1107070446014404,\n",
              "  2.193718910217285],\n",
              " [2.5112197399139404,\n",
              "  3.335869312286377,\n",
              "  1.8254671096801758,\n",
              "  3.3800692558288574,\n",
              "  3.344027519226074,\n",
              "  1.9949464797973633,\n",
              "  2.057670831680298],\n",
              " [2.0265402793884277,\n",
              "  2.750377893447876,\n",
              "  1.529824137687683,\n",
              "  2.7779979705810547,\n",
              "  2.7407355308532715,\n",
              "  1.678657054901123,\n",
              "  1.7210352420806885],\n",
              " [2.632688283920288,\n",
              "  3.4763123989105225,\n",
              "  1.8995853662490845,\n",
              "  3.528925657272339,\n",
              "  3.497346878051758,\n",
              "  2.0669095516204834,\n",
              "  2.1423425674438477],\n",
              " [2.309645652770996,\n",
              "  3.0958967208862305,\n",
              "  1.7033390998840332,\n",
              "  3.1356358528137207,\n",
              "  3.099339246749878,\n",
              "  1.8645631074905396,\n",
              "  1.921195387840271],\n",
              " [1.9181922674179077,\n",
              "  2.6201179027557373,\n",
              "  1.461668610572815,\n",
              "  2.6420722007751465,\n",
              "  2.6026883125305176,\n",
              "  1.6046298742294312,\n",
              "  1.643340826034546],\n",
              " [2.8369405269622803,\n",
              "  3.7132325172424316,\n",
              "  2.021066904067993,\n",
              "  3.7741963863372803,\n",
              "  3.743239641189575,\n",
              "  2.1989197731018066,\n",
              "  2.2819361686706543],\n",
              " [2.852984666824341,\n",
              "  3.731287717819214,\n",
              "  2.029979705810547,\n",
              "  3.791691541671753,\n",
              "  3.761157989501953,\n",
              "  2.2095754146575928,\n",
              "  2.29213285446167],\n",
              " [1.8047670125961304,\n",
              "  2.4813904762268066,\n",
              "  1.3884565830230713,\n",
              "  2.4988012313842773,\n",
              "  2.457702875137329,\n",
              "  1.5288150310516357,\n",
              "  1.5634899139404297],\n",
              " [1.324996829032898,\n",
              "  1.8787767887115479,\n",
              "  1.0855008363723755,\n",
              "  1.8853936195373535,\n",
              "  1.8401416540145874,\n",
              "  1.191300392150879,\n",
              "  1.2213377952575684],\n",
              " [1.2659331560134888,\n",
              "  1.8038114309310913,\n",
              "  1.0474789142608643,\n",
              "  1.8103381395339966,\n",
              "  1.7654703855514526,\n",
              "  1.1474244594573975,\n",
              "  1.1780041456222534],\n",
              " [2.9124879837036133,\n",
              "  3.800734519958496,\n",
              "  2.0657520294189453,\n",
              "  3.8623974323272705,\n",
              "  3.8304169178009033,\n",
              "  2.2503230571746826,\n",
              "  2.335822582244873],\n",
              " [2.942634344100952,\n",
              "  3.836296319961548,\n",
              "  2.0833218097686768,\n",
              "  3.8994929790496826,\n",
              "  3.8663339614868164,\n",
              "  2.270521640777588,\n",
              "  2.357405185699463],\n",
              " [1.9222174882888794,\n",
              "  2.6222875118255615,\n",
              "  1.4630720615386963,\n",
              "  2.6462066173553467,\n",
              "  2.6063458919525146,\n",
              "  1.6083652973175049,\n",
              "  1.6452257633209229],\n",
              " [2.818218231201172,\n",
              "  3.69169282913208,\n",
              "  2.01001238822937,\n",
              "  3.7516963481903076,\n",
              "  3.720411539077759,\n",
              "  2.1874334812164307,\n",
              "  2.2700066566467285],\n",
              " [2.5479252338409424,\n",
              "  3.3762264251708984,\n",
              "  1.8472505807876587,\n",
              "  3.4257876873016357,\n",
              "  3.392538070678711,\n",
              "  2.013526678085327,\n",
              "  2.082258939743042],\n",
              " [2.902129888534546,\n",
              "  3.790534257888794,\n",
              "  2.059915065765381,\n",
              "  3.8519704341888428,\n",
              "  3.819472074508667,\n",
              "  2.24788761138916,\n",
              "  2.3291282653808594],\n",
              " [2.9989013671875,\n",
              "  3.9071643352508545,\n",
              "  2.1171398162841797,\n",
              "  3.967365026473999,\n",
              "  3.925116777420044,\n",
              "  2.3120508193969727,\n",
              "  2.3998866081237793],\n",
              " [2.795522451400757,\n",
              "  3.6637542247772217,\n",
              "  1.9956544637680054,\n",
              "  3.7235686779022217,\n",
              "  3.694347381591797,\n",
              "  2.163891553878784,\n",
              "  2.251335620880127],\n",
              " [1.2777031660079956,\n",
              "  1.8184078931808472,\n",
              "  1.054945707321167,\n",
              "  1.8240876197814941,\n",
              "  1.7795076370239258,\n",
              "  1.155652642250061,\n",
              "  1.1869553327560425],\n",
              " [1.4197325706481934,\n",
              "  1.9986995458602905,\n",
              "  1.1459999084472656,\n",
              "  2.0053012371063232,\n",
              "  1.961738109588623,\n",
              "  1.2585248947143555,\n",
              "  1.2880587577819824],\n",
              " [2.9405157566070557,\n",
              "  3.8368752002716064,\n",
              "  2.0825130939483643,\n",
              "  3.896378517150879,\n",
              "  3.8597025871276855,\n",
              "  2.263638973236084,\n",
              "  2.35958194732666],\n",
              " [2.82460355758667,\n",
              "  3.700162410736084,\n",
              "  2.0137698650360107,\n",
              "  3.7599668502807617,\n",
              "  3.729701519012451,\n",
              "  2.192350387573242,\n",
              "  2.2753615379333496],\n",
              " [1.891735315322876,\n",
              "  2.5885844230651855,\n",
              "  1.4455201625823975,\n",
              "  2.6088778972625732,\n",
              "  2.570223331451416,\n",
              "  1.5861209630966187,\n",
              "  1.6262811422348022],\n",
              " [2.8121261596679688,\n",
              "  3.687959909439087,\n",
              "  2.0062146186828613,\n",
              "  3.747933864593506,\n",
              "  3.715052604675293,\n",
              "  2.181863784790039,\n",
              "  2.269461154937744],\n",
              " [1.1668288707733154,\n",
              "  1.6754928827285767,\n",
              "  0.9823241829872131,\n",
              "  1.6797983646392822,\n",
              "  1.6341410875320435,\n",
              "  1.0725085735321045,\n",
              "  1.1045297384262085],\n",
              " [2.900526762008667,\n",
              "  3.7855679988861084,\n",
              "  2.0597965717315674,\n",
              "  3.847139358520508,\n",
              "  3.815430164337158,\n",
              "  2.2395899295806885,\n",
              "  2.3279170989990234],\n",
              " [2.1860196590423584,\n",
              "  2.9442999362945557,\n",
              "  1.6281249523162842,\n",
              "  2.9779140949249268,\n",
              "  2.9416730403900146,\n",
              "  1.7850570678710938,\n",
              "  1.8325235843658447],\n",
              " [1.0887794494628906,\n",
              "  1.5777478218078613,\n",
              "  0.9312607049942017,\n",
              "  1.5793795585632324,\n",
              "  1.5351207256317139,\n",
              "  1.0121573209762573,\n",
              "  1.0474905967712402],\n",
              " [1.9874523878097534,\n",
              "  2.704956293106079,\n",
              "  1.5043758153915405,\n",
              "  2.7308101654052734,\n",
              "  2.6915225982666016,\n",
              "  1.6506781578063965,\n",
              "  1.6941633224487305],\n",
              " [1.4316800832748413,\n",
              "  2.0133252143859863,\n",
              "  1.1536051034927368,\n",
              "  2.0208497047424316,\n",
              "  1.9773635864257812,\n",
              "  1.267875075340271,\n",
              "  1.296331763267517],\n",
              " [1.5805529356002808,\n",
              "  2.199925661087036,\n",
              "  1.2502371072769165,\n",
              "  2.214015483856201,\n",
              "  2.1708779335021973,\n",
              "  1.374786138534546,\n",
              "  1.4063363075256348],\n",
              " [1.527072548866272,\n",
              "  2.135869264602661,\n",
              "  1.214453101158142,\n",
              "  2.1456103324890137,\n",
              "  2.1018142700195312,\n",
              "  1.3393124341964722,\n",
              "  1.3672562837600708],\n",
              " [1.3889800310134888,\n",
              "  1.9613159894943237,\n",
              "  1.1267955303192139,\n",
              "  1.968018889427185,\n",
              "  1.9241676330566406,\n",
              "  1.2374699115753174,\n",
              "  1.2679214477539062],\n",
              " [1.9700604677200317,\n",
              "  2.6844799518585205,\n",
              "  1.4932959079742432,\n",
              "  2.707749843597412,\n",
              "  2.6705374717712402,\n",
              "  1.6408867835998535,\n",
              "  1.6810921430587769],\n",
              " [1.5562516450881958,\n",
              "  2.1701040267944336,\n",
              "  1.233460545539856,\n",
              "  2.1806089878082275,\n",
              "  2.1401779651641846,\n",
              "  1.3585326671600342,\n",
              "  1.3862911462783813],\n",
              " [2.056199073791504,\n",
              "  2.7875254154205322,\n",
              "  1.547637701034546,\n",
              "  2.815800428390503,\n",
              "  2.7783985137939453,\n",
              "  1.6971782445907593,\n",
              "  1.7411867380142212],\n",
              " [1.6409308910369873,\n",
              "  2.275944471359253,\n",
              "  1.2872909307479858,\n",
              "  2.2895448207855225,\n",
              "  2.2477126121520996,\n",
              "  1.4148837327957153,\n",
              "  1.4460670948028564],\n",
              " [2.926009178161621,\n",
              "  3.817948818206787,\n",
              "  2.0746960639953613,\n",
              "  3.8793983459472656,\n",
              "  3.845229148864746,\n",
              "  2.2626254558563232,\n",
              "  2.3452858924865723],\n",
              " [1.7622649669647217,\n",
              "  2.4263901710510254,\n",
              "  1.363410472869873,\n",
              "  2.4441537857055664,\n",
              "  2.403737783432007,\n",
              "  1.5000468492507935,\n",
              "  1.533478021621704],\n",
              " [2.676577568054199,\n",
              "  3.529519557952881,\n",
              "  1.9254350662231445,\n",
              "  3.583944320678711,\n",
              "  3.553377151489258,\n",
              "  2.094634771347046,\n",
              "  2.1737093925476074],\n",
              " [2.9592559337615967,\n",
              "  3.857111692428589,\n",
              "  2.0921454429626465,\n",
              "  3.9200456142425537,\n",
              "  3.882675886154175,\n",
              "  2.279468536376953,\n",
              "  2.3703646659851074],\n",
              " [1.9490448236465454,\n",
              "  2.655996799468994,\n",
              "  1.4796494245529175,\n",
              "  2.6799545288085938,\n",
              "  2.6413865089416504,\n",
              "  1.6266142129898071,\n",
              "  1.6657989025115967],\n",
              " [1.4493619203567505,\n",
              "  2.0357723236083984,\n",
              "  1.165753960609436,\n",
              "  2.0439722537994385,\n",
              "  2.0008320808410645,\n",
              "  1.2790446281433105,\n",
              "  1.3096412420272827],\n",
              " [2.7797231674194336,\n",
              "  3.6487529277801514,\n",
              "  1.9871783256530762,\n",
              "  3.7055275440216064,\n",
              "  3.6746177673339844,\n",
              "  2.1644134521484375,\n",
              "  2.245126724243164],\n",
              " [2.9118025302886963,\n",
              "  3.802992343902588,\n",
              "  2.065687894821167,\n",
              "  3.864933729171753,\n",
              "  3.8291542530059814,\n",
              "  2.249676465988159,\n",
              "  2.338163375854492],\n",
              " [1.9074100255966187,\n",
              "  2.604999303817749,\n",
              "  1.454802393913269,\n",
              "  2.628361225128174,\n",
              "  2.58998441696167,\n",
              "  1.5987392663955688,\n",
              "  1.6370428800582886],\n",
              " [2.2299890518188477,\n",
              "  2.9995882511138916,\n",
              "  1.656195044517517,\n",
              "  3.034489631652832,\n",
              "  2.9987759590148926,\n",
              "  1.8132710456848145,\n",
              "  1.8644758462905884],\n",
              " [2.2064223289489746,\n",
              "  2.968350887298584,\n",
              "  1.6395962238311768,\n",
              "  3.0023818016052246,\n",
              "  2.967528820037842,\n",
              "  1.7951533794403076,\n",
              "  1.8450491428375244],\n",
              " [1.825587272644043,\n",
              "  2.504408597946167,\n",
              "  1.40525221824646,\n",
              "  2.524179697036743,\n",
              "  2.4838945865631104,\n",
              "  1.5439587831497192,\n",
              "  1.5795185565948486],\n",
              " [2.3835668563842773,\n",
              "  3.18274188041687,\n",
              "  1.7487746477127075,\n",
              "  3.2250773906707764,\n",
              "  3.1927390098571777,\n",
              "  1.9120702743530273,\n",
              "  1.970400094985962],\n",
              " [2.5847907066345215,\n",
              "  3.4183030128479004,\n",
              "  1.8696506023406982,\n",
              "  3.4700281620025635,\n",
              "  3.43791127204895,\n",
              "  2.040125608444214,\n",
              "  2.1086325645446777],\n",
              " [1.9922746419906616,\n",
              "  2.710876703262329,\n",
              "  1.5074763298034668,\n",
              "  2.737647533416748,\n",
              "  2.6981780529022217,\n",
              "  1.6565555334091187,\n",
              "  1.6993708610534668],\n",
              " [2.912576198577881,\n",
              "  3.808840274810791,\n",
              "  2.0656676292419434,\n",
              "  3.868124485015869,\n",
              "  3.8262178897857666,\n",
              "  2.252346992492676,\n",
              "  2.339547634124756],\n",
              " [1.2069857120513916,\n",
              "  1.7295104265213013,\n",
              "  1.0091356039047241,\n",
              "  1.7335723638534546,\n",
              "  1.6872029304504395,\n",
              "  1.1032593250274658,\n",
              "  1.1338146924972534],\n",
              " [1.2228983640670776,\n",
              "  1.7484767436981201,\n",
              "  1.0188957452774048,\n",
              "  1.7535372972488403,\n",
              "  1.7088837623596191,\n",
              "  1.1136094331741333,\n",
              "  1.1456693410873413],\n",
              " [2.3998355865478516,\n",
              "  3.2024002075195312,\n",
              "  1.7594904899597168,\n",
              "  3.2467551231384277,\n",
              "  3.212388515472412,\n",
              "  1.9214451313018799,\n",
              "  1.9836432933807373],\n",
              " [2.207329750061035,\n",
              "  2.9701294898986816,\n",
              "  1.6396937370300293,\n",
              "  3.0036568641662598,\n",
              "  2.96848726272583,\n",
              "  1.794787049293518,\n",
              "  1.8465476036071777],\n",
              " [2.835420608520508,\n",
              "  3.7106058597564697,\n",
              "  2.0199127197265625,\n",
              "  3.7699408531188965,\n",
              "  3.739480972290039,\n",
              "  2.2020423412323,\n",
              "  2.281355857849121],\n",
              " [2.803772211074829,\n",
              "  3.674506902694702,\n",
              "  2.0017154216766357,\n",
              "  3.7341816425323486,\n",
              "  3.7054173946380615,\n",
              "  2.173844337463379,\n",
              "  2.2587485313415527],\n",
              " [1.3339155912399292,\n",
              "  1.8903695344924927,\n",
              "  1.090512990951538,\n",
              "  1.8967556953430176,\n",
              "  1.8516343832015991,\n",
              "  1.1965422630310059,\n",
              "  1.2288278341293335],\n",
              " [2.9372780323028564,\n",
              "  3.8324718475341797,\n",
              "  2.079810857772827,\n",
              "  3.8918824195861816,\n",
              "  3.855220317840576,\n",
              "  2.2592177391052246,\n",
              "  2.3543362617492676],\n",
              " [1.9599531888961792,\n",
              "  2.6702983379364014,\n",
              "  1.4865081310272217,\n",
              "  2.693800449371338,\n",
              "  2.657582998275757,\n",
              "  1.6311814785003662,\n",
              "  1.672644853591919],\n",
              " [2.8525733947753906,\n",
              "  3.728825330734253,\n",
              "  2.0297484397888184,\n",
              "  3.791062355041504,\n",
              "  3.760688543319702,\n",
              "  2.206099033355713,\n",
              "  2.292922019958496],\n",
              " [2.939279317855835,\n",
              "  3.8389203548431396,\n",
              "  2.082540512084961,\n",
              "  3.897667646408081,\n",
              "  3.859407901763916,\n",
              "  2.263193130493164,\n",
              "  2.357849597930908],\n",
              " [2.911191940307617,\n",
              "  3.802417516708374,\n",
              "  2.0633671283721924,\n",
              "  3.862738847732544,\n",
              "  3.829395055770874,\n",
              "  2.248026132583618,\n",
              "  2.3356003761291504],\n",
              " [2.768455743789673,\n",
              "  3.6352996826171875,\n",
              "  1.9800552129745483,\n",
              "  3.6937460899353027,\n",
              "  3.663114309310913,\n",
              "  2.154388904571533,\n",
              "  2.2369794845581055],\n",
              " [2.364257574081421,\n",
              "  3.1600282192230225,\n",
              "  1.736278772354126,\n",
              "  3.200725793838501,\n",
              "  3.164210557937622,\n",
              "  1.896067500114441,\n",
              "  1.9577884674072266],\n",
              " [1.15373957157135,\n",
              "  1.6607953310012817,\n",
              "  0.9743911027908325,\n",
              "  1.6652592420578003,\n",
              "  1.6193104982376099,\n",
              "  1.064851999282837,\n",
              "  1.0957425832748413],\n",
              " [2.109168529510498,\n",
              "  2.8505451679229736,\n",
              "  1.579884648323059,\n",
              "  2.8808741569519043,\n",
              "  2.843608856201172,\n",
              "  1.732295036315918,\n",
              "  1.7774125337600708],\n",
              " [1.8808189630508423,\n",
              "  2.57243013381958,\n",
              "  1.4374017715454102,\n",
              "  2.5940325260162354,\n",
              "  2.5539710521698,\n",
              "  1.580944299697876,\n",
              "  1.617960810661316],\n",
              " [2.5622777938842773,\n",
              "  3.398297071456909,\n",
              "  1.8570587635040283,\n",
              "  3.445237159729004,\n",
              "  3.4082539081573486,\n",
              "  2.0311198234558105,\n",
              "  2.0963830947875977],\n",
              " [1.4351227283477783,\n",
              "  2.0181593894958496,\n",
              "  1.1567227840423584,\n",
              "  2.0267245769500732,\n",
              "  1.9838497638702393,\n",
              "  1.270472764968872,\n",
              "  1.3006213903427124],\n",
              " [2.051011800765991,\n",
              "  2.781076192855835,\n",
              "  1.5448362827301025,\n",
              "  2.808486223220825,\n",
              "  2.7699527740478516,\n",
              "  1.6952736377716064,\n",
              "  1.7374862432479858],\n",
              " [2.3223254680633545,\n",
              "  3.1103127002716064,\n",
              "  1.709763526916504,\n",
              "  3.150050163269043,\n",
              "  3.112584114074707,\n",
              "  1.874220609664917,\n",
              "  1.9276354312896729],\n",
              " [2.9338741302490234,\n",
              "  3.832643508911133,\n",
              "  2.078972816467285,\n",
              "  3.8909618854522705,\n",
              "  3.8541719913482666,\n",
              "  2.265212297439575,\n",
              "  2.3547072410583496],\n",
              " [2.2784805297851562,\n",
              "  3.0554165840148926,\n",
              "  1.6845605373382568,\n",
              "  3.0934736728668213,\n",
              "  3.0585622787475586,\n",
              "  1.8455216884613037,\n",
              "  1.8968766927719116],\n",
              " [1.421189785003662,\n",
              "  2.000809669494629,\n",
              "  1.1476125717163086,\n",
              "  2.0085058212280273,\n",
              "  1.9643759727478027,\n",
              "  1.2590796947479248,\n",
              "  1.2895525693893433],\n",
              " [2.566288709640503,\n",
              "  3.401456117630005,\n",
              "  1.8602571487426758,\n",
              "  3.4504001140594482,\n",
              "  3.4195363521575928,\n",
              "  2.029677152633667,\n",
              "  2.098137378692627],\n",
              " [1.674268126487732,\n",
              "  2.317563772201538,\n",
              "  1.3079400062561035,\n",
              "  2.331644058227539,\n",
              "  2.290431499481201,\n",
              "  1.4384405612945557,\n",
              "  1.470580816268921],\n",
              " [2.937999963760376,\n",
              "  3.83201265335083,\n",
              "  2.081810235977173,\n",
              "  3.893263101577759,\n",
              "  3.8588976860046387,\n",
              "  2.2687456607818604,\n",
              "  2.3550472259521484],\n",
              " [2.0902867317199707,\n",
              "  2.8287787437438965,\n",
              "  1.5672900676727295,\n",
              "  2.8579585552215576,\n",
              "  2.8195393085479736,\n",
              "  1.7193306684494019,\n",
              "  1.7640936374664307],\n",
              " [1.7441668510437012,\n",
              "  2.4060959815979004,\n",
              "  1.3522393703460693,\n",
              "  2.4221861362457275,\n",
              "  2.380526065826416,\n",
              "  1.4873322248458862,\n",
              "  1.5228196382522583],\n",
              " [2.392320156097412,\n",
              "  3.1912455558776855,\n",
              "  1.7537562847137451,\n",
              "  3.233858108520508,\n",
              "  3.1992340087890625,\n",
              "  1.9176599979400635,\n",
              "  1.9743058681488037],\n",
              " [2.286902666091919,\n",
              "  3.0684735774993896,\n",
              "  1.6890770196914673,\n",
              "  3.1067051887512207,\n",
              "  3.0685572624206543,\n",
              "  1.8512682914733887,\n",
              "  1.9045966863632202],\n",
              " [1.7728320360183716,\n",
              "  2.4410390853881836,\n",
              "  1.372409701347351,\n",
              "  2.458120107650757,\n",
              "  2.419196605682373,\n",
              "  1.5076971054077148,\n",
              "  1.542114496231079],\n",
              " [2.861710548400879,\n",
              "  3.7425343990325928,\n",
              "  2.0360264778137207,\n",
              "  3.8045966625213623,\n",
              "  3.7718241214752197,\n",
              "  2.213466167449951,\n",
              "  2.302609443664551],\n",
              " [1.535822868347168,\n",
              "  2.146798849105835,\n",
              "  1.2198878526687622,\n",
              "  2.155801773071289,\n",
              "  2.1149423122406006,\n",
              "  1.3417656421661377,\n",
              "  1.3713302612304688],\n",
              " [1.6907154321670532,\n",
              "  2.337186813354492,\n",
              "  1.3175982236862183,\n",
              "  2.3527214527130127,\n",
              "  2.3103792667388916,\n",
              "  1.4516007900238037,\n",
              "  1.4834026098251343],\n",
              " [2.921140670776367,\n",
              "  3.813918113708496,\n",
              "  2.071690797805786,\n",
              "  3.873594284057617,\n",
              "  3.8381667137145996,\n",
              "  2.2556700706481934,\n",
              "  2.343081474304199],\n",
              " [2.657081365585327,\n",
              "  3.5061848163604736,\n",
              "  1.9141020774841309,\n",
              "  3.558821439743042,\n",
              "  3.5255117416381836,\n",
              "  2.088376522064209,\n",
              "  2.160046100616455],\n",
              " [2.9325060844421387,\n",
              "  3.8249263763427734,\n",
              "  2.0765254497528076,\n",
              "  3.8853530883789062,\n",
              "  3.853066921234131,\n",
              "  2.25545072555542,\n",
              "  2.3494553565979004],\n",
              " [2.7708938121795654,\n",
              "  3.637763023376465,\n",
              "  1.981046199798584,\n",
              "  3.697476863861084,\n",
              "  3.6656711101531982,\n",
              "  2.1592185497283936,\n",
              "  2.2378993034362793],\n",
              " [2.7596499919891357,\n",
              "  3.6245133876800537,\n",
              "  1.9754796028137207,\n",
              "  3.6836559772491455,\n",
              "  3.6533141136169434,\n",
              "  2.151825189590454,\n",
              "  2.2300362586975098],\n",
              " [2.7995550632476807,\n",
              "  3.6693811416625977,\n",
              "  1.9982225894927979,\n",
              "  3.728717803955078,\n",
              "  3.700284004211426,\n",
              "  2.1734724044799805,\n",
              "  2.256575584411621],\n",
              " [2.7276508808135986,\n",
              "  3.5933234691619873,\n",
              "  1.9565858840942383,\n",
              "  3.6452412605285645,\n",
              "  3.60200572013855,\n",
              "  2.133322238922119,\n",
              "  2.213470935821533],\n",
              " [2.4483511447906494,\n",
              "  3.259962558746338,\n",
              "  1.7888706922531128,\n",
              "  3.3043863773345947,\n",
              "  3.270691156387329,\n",
              "  1.9500327110290527,\n",
              "  2.016172170639038],\n",
              " [1.5743013620376587,\n",
              "  2.1950509548187256,\n",
              "  1.2457040548324585,\n",
              "  2.206294536590576,\n",
              "  2.1643218994140625,\n",
              "  1.3710606098175049,\n",
              "  1.4004892110824585],\n",
              " [2.4378864765167236,\n",
              "  3.248582363128662,\n",
              "  1.7819563150405884,\n",
              "  3.2910044193267822,\n",
              "  3.2573606967926025,\n",
              "  1.9486615657806396,\n",
              "  2.0067901611328125],\n",
              " [1.5049365758895874,\n",
              "  2.1053316593170166,\n",
              "  1.2002782821655273,\n",
              "  2.11542010307312,\n",
              "  2.07283091545105,\n",
              "  1.320238709449768,\n",
              "  1.3506428003311157],\n",
              " [2.6726980209350586,\n",
              "  3.522876262664795,\n",
              "  1.9237749576568604,\n",
              "  3.577653408050537,\n",
              "  3.5482676029205322,\n",
              "  2.0938124656677246,\n",
              "  2.169489860534668],\n",
              " [1.7500879764556885,\n",
              "  2.4138593673706055,\n",
              "  1.35418701171875,\n",
              "  2.4289095401763916,\n",
              "  2.3889448642730713,\n",
              "  1.4906251430511475,\n",
              "  1.5233651399612427],\n",
              " [1.8544235229492188,\n",
              "  2.540219306945801,\n",
              "  1.420997977256775,\n",
              "  2.5619890689849854,\n",
              "  2.5217199325561523,\n",
              "  1.5637116432189941,\n",
              "  1.598962664604187],\n",
              " [2.7245001792907715,\n",
              "  3.5854172706604004,\n",
              "  1.9536808729171753,\n",
              "  3.642143726348877,\n",
              "  3.6056106090545654,\n",
              "  2.1300430297851562,\n",
              "  2.2097277641296387],\n",
              " [2.8824193477630615,\n",
              "  3.7661502361297607,\n",
              "  2.0477023124694824,\n",
              "  3.8277523517608643,\n",
              "  3.797320604324341,\n",
              "  2.2256479263305664,\n",
              "  2.3147101402282715],\n",
              " [2.515104055404663,\n",
              "  3.3383662700653076,\n",
              "  1.8273680210113525,\n",
              "  3.384986639022827,\n",
              "  3.35237455368042,\n",
              "  1.9979400634765625,\n",
              "  2.061875820159912],\n",
              " [2.4014241695404053,\n",
              "  3.203390121459961,\n",
              "  1.7590482234954834,\n",
              "  3.2456891536712646,\n",
              "  3.211592674255371,\n",
              "  1.9234249591827393,\n",
              "  1.982850432395935],\n",
              " [2.931417942047119,\n",
              "  3.8233790397644043,\n",
              "  2.0758421421051025,\n",
              "  3.8848254680633545,\n",
              "  3.8498945236206055,\n",
              "  2.2540602684020996,\n",
              "  2.3486881256103516],\n",
              " [2.1886773109436035,\n",
              "  2.9501194953918457,\n",
              "  1.6309325695037842,\n",
              "  2.9845147132873535,\n",
              "  2.9487624168395996,\n",
              "  1.789535641670227,\n",
              "  1.835501790046692],\n",
              " [2.859079599380493,\n",
              "  3.737330675125122,\n",
              "  2.0341579914093018,\n",
              "  3.797417402267456,\n",
              "  3.765876054763794,\n",
              "  2.202037811279297,\n",
              "  2.2954936027526855],\n",
              " [2.421254873275757,\n",
              "  3.227083206176758,\n",
              "  1.77165687084198,\n",
              "  3.2705166339874268,\n",
              "  3.2377164363861084,\n",
              "  1.932464599609375,\n",
              "  1.9970169067382812],\n",
              " [2.9567630290985107,\n",
              "  3.8561229705810547,\n",
              "  2.0914106369018555,\n",
              "  3.9154961109161377,\n",
              "  3.8814053535461426,\n",
              "  2.2770164012908936,\n",
              "  2.3663101196289062],\n",
              " [1.1078128814697266,\n",
              "  1.6011536121368408,\n",
              "  0.9442254900932312,\n",
              "  1.6051381826400757,\n",
              "  1.558465600013733,\n",
              "  1.0280519723892212,\n",
              "  1.063209891319275],\n",
              " [2.9509215354919434,\n",
              "  3.8463947772979736,\n",
              "  2.0895416736602783,\n",
              "  3.9095654487609863,\n",
              "  3.8746113777160645,\n",
              "  2.279047966003418,\n",
              "  2.362914562225342],\n",
              " [1.9757500886917114,\n",
              "  2.689408779144287,\n",
              "  1.4982264041900635,\n",
              "  2.715026617050171,\n",
              "  2.6761932373046875,\n",
              "  1.6463727951049805,\n",
              "  1.6866282224655151],\n",
              " [1.5001450777053833,\n",
              "  2.099708080291748,\n",
              "  1.19725501537323,\n",
              "  2.1098296642303467,\n",
              "  2.06851863861084,\n",
              "  1.3172600269317627,\n",
              "  1.346353530883789],\n",
              " [2.4306561946868896,\n",
              "  3.237406015396118,\n",
              "  1.776606798171997,\n",
              "  3.28108549118042,\n",
              "  3.2469558715820312,\n",
              "  1.9391508102416992,\n",
              "  2.0024237632751465],\n",
              " [2.1151790618896484,\n",
              "  2.8590140342712402,\n",
              "  1.582628846168518,\n",
              "  2.888472557067871,\n",
              "  2.850511074066162,\n",
              "  1.736576795578003,\n",
              "  1.7815124988555908],\n",
              " [1.3076262474060059,\n",
              "  1.8587981462478638,\n",
              "  1.0728346109390259,\n",
              "  1.8638174533843994,\n",
              "  1.8197821378707886,\n",
              "  1.1767261028289795,\n",
              "  1.2075984477996826],\n",
              " [2.208178997039795,\n",
              "  2.970270872116089,\n",
              "  1.6405662298202515,\n",
              "  3.005645990371704,\n",
              "  2.9712893962860107,\n",
              "  1.798846960067749,\n",
              "  1.8476293087005615],\n",
              " [1.2611619234085083,\n",
              "  1.7974295616149902,\n",
              "  1.043894648551941,\n",
              "  1.802842378616333,\n",
              "  1.7573777437210083,\n",
              "  1.1435050964355469,\n",
              "  1.174320101737976],\n",
              " [1.3321888446807861,\n",
              "  1.887282371520996,\n",
              "  1.0908108949661255,\n",
              "  1.895150065422058,\n",
              "  1.849959135055542,\n",
              "  1.1972278356552124,\n",
              "  1.2264854907989502],\n",
              " [1.2670128345489502,\n",
              "  1.8050358295440674,\n",
              "  1.0492820739746094,\n",
              "  1.8096420764923096,\n",
              "  1.7654995918273926,\n",
              "  1.148337721824646,\n",
              "  1.1778783798217773],\n",
              " [2.394456624984741,\n",
              "  3.194110155105591,\n",
              "  1.7548115253448486,\n",
              "  3.2371666431427,\n",
              "  3.203737735748291,\n",
              "  1.9170823097229004,\n",
              "  1.9769572019577026],\n",
              " [2.134812116622925,\n",
              "  2.882152795791626,\n",
              "  1.5970664024353027,\n",
              "  2.914001226425171,\n",
              "  2.8772289752960205,\n",
              "  1.7486540079116821,\n",
              "  1.7971090078353882],\n",
              " [2.9729015827178955,\n",
              "  3.8749587535858154,\n",
              "  2.102494239807129,\n",
              "  3.936958074569702,\n",
              "  3.89863920211792,\n",
              "  2.294248342514038,\n",
              "  2.38067626953125],\n",
              " [1.2877898216247559,\n",
              "  1.8323843479156494,\n",
              "  1.0605254173278809,\n",
              "  1.8369767665863037,\n",
              "  1.793184518814087,\n",
              "  1.1629945039749146,\n",
              "  1.192321538925171],\n",
              " [2.6980152130126953,\n",
              "  3.552412509918213,\n",
              "  1.9382163286209106,\n",
              "  3.6089835166931152,\n",
              "  3.5776522159576416,\n",
              "  2.110116481781006,\n",
              "  2.1881446838378906],\n",
              " [1.941386342048645,\n",
              "  2.647033214569092,\n",
              "  1.4750244617462158,\n",
              "  2.671555757522583,\n",
              "  2.6318447589874268,\n",
              "  1.6207737922668457,\n",
              "  1.6609487533569336],\n",
              " [1.0056068897247314,\n",
              "  1.469449520111084,\n",
              "  0.8765043020248413,\n",
              "  1.471851110458374,\n",
              "  1.4251476526260376,\n",
              "  0.9504753351211548,\n",
              "  0.9862104654312134],\n",
              " [2.761486053466797,\n",
              "  3.625430107116699,\n",
              "  1.9758950471878052,\n",
              "  3.6841654777526855,\n",
              "  3.6552491188049316,\n",
              "  2.147524356842041,\n",
              "  2.2305002212524414],\n",
              " [2.0275940895080566,\n",
              "  2.7530195713043213,\n",
              "  1.5297797918319702,\n",
              "  2.7791311740875244,\n",
              "  2.7400529384613037,\n",
              "  1.6770130395889282,\n",
              "  1.7196409702301025],\n",
              " [0.9995208978652954,\n",
              "  1.4613112211227417,\n",
              "  0.8727272748947144,\n",
              "  1.4632422924041748,\n",
              "  1.4176735877990723,\n",
              "  0.944938063621521,\n",
              "  0.981608510017395],\n",
              " [1.4725334644317627,\n",
              "  2.067430257797241,\n",
              "  1.1809415817260742,\n",
              "  2.077378273010254,\n",
              "  2.0338313579559326,\n",
              "  1.2984791994094849,\n",
              "  1.3287111520767212],\n",
              " [2.022155523300171,\n",
              "  2.74676251411438,\n",
              "  1.5271427631378174,\n",
              "  2.7714853286743164,\n",
              "  2.7369186878204346,\n",
              "  1.6732887029647827,\n",
              "  1.7171043157577515],\n",
              " [2.9439544677734375,\n",
              "  3.837109327316284,\n",
              "  2.0840253829956055,\n",
              "  3.8979976177215576,\n",
              "  3.8654706478118896,\n",
              "  2.263148546218872,\n",
              "  2.355839252471924],\n",
              " [2.882458448410034,\n",
              "  3.7637939453125,\n",
              "  2.0477755069732666,\n",
              "  3.8275842666625977,\n",
              "  3.796276092529297,\n",
              "  2.23075008392334,\n",
              "  2.3152737617492676],\n",
              " [2.823906183242798,\n",
              "  3.698965072631836,\n",
              "  2.0137970447540283,\n",
              "  3.7603819370269775,\n",
              "  3.729418992996216,\n",
              "  2.1928870677948,\n",
              "  2.275935649871826],\n",
              " [1.2847583293914795,\n",
              "  1.8272606134414673,\n",
              "  1.058384656906128,\n",
              "  1.832773208618164,\n",
              "  1.789196252822876,\n",
              "  1.1590919494628906,\n",
              "  1.1902862787246704],\n",
              " [2.0352885723114014,\n",
              "  2.761240243911743,\n",
              "  1.5329340696334839,\n",
              "  2.788224697113037,\n",
              "  2.750058174133301,\n",
              "  1.6833323240280151,\n",
              "  1.7256044149398804],\n",
              " [2.9983596801757812,\n",
              "  3.9080917835235596,\n",
              "  2.117467164993286,\n",
              "  3.968064785003662,\n",
              "  3.9273791313171387,\n",
              "  2.313077926635742,\n",
              "  2.3995089530944824],\n",
              " [2.802241563796997,\n",
              "  3.6753933429718018,\n",
              "  2.000483274459839,\n",
              "  3.7352395057678223,\n",
              "  3.7032036781311035,\n",
              "  2.175903797149658,\n",
              "  2.2614693641662598],\n",
              " [2.4434974193573,\n",
              "  3.255045175552368,\n",
              "  1.7845189571380615,\n",
              "  3.2992851734161377,\n",
              "  3.2622272968292236,\n",
              "  1.9507031440734863,\n",
              "  2.01243257522583],\n",
              " [2.6750431060791016,\n",
              "  3.526198625564575,\n",
              "  1.925202488899231,\n",
              "  3.581580400466919,\n",
              "  3.5522961616516113,\n",
              "  2.09649658203125,\n",
              "  2.171436309814453],\n",
              " [1.7912369966506958,\n",
              "  2.464301109313965,\n",
              "  1.382529377937317,\n",
              "  2.48372745513916,\n",
              "  2.4425158500671387,\n",
              "  1.5212565660476685,\n",
              "  1.556681513786316],\n",
              " [1.0902762413024902,\n",
              "  1.5791782140731812,\n",
              "  0.9328814744949341,\n",
              "  1.582261323928833,\n",
              "  1.5356340408325195,\n",
              "  1.0171228647232056,\n",
              "  1.0489307641983032],\n",
              " [1.8168203830718994,\n",
              "  2.4939498901367188,\n",
              "  1.3977055549621582,\n",
              "  2.512550115585327,\n",
              "  2.4729275703430176,\n",
              "  1.5363235473632812,\n",
              "  1.57171630859375],\n",
              " [1.5233094692230225,\n",
              "  2.1292707920074463,\n",
              "  1.213261365890503,\n",
              "  2.1391663551330566,\n",
              "  2.0970308780670166,\n",
              "  1.3337467908859253,\n",
              "  1.3632662296295166],\n",
              " [1.8255529403686523,\n",
              "  2.504828929901123,\n",
              "  1.4040356874465942,\n",
              "  2.524362087249756,\n",
              "  2.484928846359253,\n",
              "  1.5431348085403442,\n",
              "  1.578794002532959],\n",
              " [2.9941720962524414,\n",
              "  3.9030425548553467,\n",
              "  2.114152431488037,\n",
              "  3.9604365825653076,\n",
              "  3.9197230339050293,\n",
              "  2.3032546043395996,\n",
              "  2.3971152305603027],\n",
              " [2.8691885471343994,\n",
              "  3.749490976333618,\n",
              "  2.0399134159088135,\n",
              "  3.811284303665161,\n",
              "  3.779404640197754,\n",
              "  2.218993663787842,\n",
              "  2.3049373626708984],\n",
              " [1.2606629133224487,\n",
              "  1.796372890472412,\n",
              "  1.044433832168579,\n",
              "  1.8016265630722046,\n",
              "  1.7581807374954224,\n",
              "  1.1437900066375732,\n",
              "  1.1729185581207275],\n",
              " [1.1778936386108398,\n",
              "  1.6909105777740479,\n",
              "  0.9897863864898682,\n",
              "  1.6946070194244385,\n",
              "  1.6499884128570557,\n",
              "  1.0816361904144287,\n",
              "  1.1119312047958374],\n",
              " [2.9879558086395264,\n",
              "  3.8992230892181396,\n",
              "  2.1108195781707764,\n",
              "  3.9557628631591797,\n",
              "  3.9090511798858643,\n",
              "  2.3017821311950684,\n",
              "  2.3962721824645996],\n",
              " [1.6892294883728027,\n",
              "  2.338433265686035,\n",
              "  1.3177947998046875,\n",
              "  2.352309226989746,\n",
              "  2.3111095428466797,\n",
              "  1.450060486793518,\n",
              "  1.4827767610549927],\n",
              " [1.2837014198303223,\n",
              "  1.825432538986206,\n",
              "  1.0600745677947998,\n",
              "  1.8319751024246216,\n",
              "  1.786794662475586,\n",
              "  1.1609036922454834,\n",
              "  1.1907035112380981],\n",
              " [2.8808469772338867,\n",
              "  3.7608861923217773,\n",
              "  2.0462563037872314,\n",
              "  3.824449062347412,\n",
              "  3.792022466659546,\n",
              "  2.2183878421783447,\n",
              "  2.3134474754333496],\n",
              " [2.98821759223938,\n",
              "  3.8972909450531006,\n",
              "  2.1112561225891113,\n",
              "  3.956660032272339,\n",
              "  3.916560411453247,\n",
              "  2.3024497032165527,\n",
              "  2.396069049835205],\n",
              " [1.2452024221420288,\n",
              "  1.7773641347885132,\n",
              "  1.033522129058838,\n",
              "  1.7814377546310425,\n",
              "  1.7364383935928345,\n",
              "  1.1295548677444458,\n",
              "  1.161411166191101],\n",
              " [1.9529045820236206,\n",
              "  2.661835193634033,\n",
              "  1.4843679666519165,\n",
              "  2.6855249404907227,\n",
              "  2.6493587493896484,\n",
              "  1.6277837753295898,\n",
              "  1.6693085432052612],\n",
              " [2.376075267791748,\n",
              "  3.172569513320923,\n",
              "  1.744120717048645,\n",
              "  3.2144646644592285,\n",
              "  3.1773269176483154,\n",
              "  1.9082282781600952,\n",
              "  1.9637516736984253],\n",
              " [1.8275277614593506,\n",
              "  2.507737874984741,\n",
              "  1.4044660329818726,\n",
              "  2.52665114402771,\n",
              "  2.487020969390869,\n",
              "  1.5429000854492188,\n",
              "  1.5794585943222046],\n",
              " [1.0210802555084229,\n",
              "  1.489610195159912,\n",
              "  0.886741042137146,\n",
              "  1.4916496276855469,\n",
              "  1.4455225467681885,\n",
              "  0.960077166557312,\n",
              "  0.9986072778701782],\n",
              " [2.367830753326416,\n",
              "  3.163449764251709,\n",
              "  1.7383595705032349,\n",
              "  3.2051761150360107,\n",
              "  3.169649362564087,\n",
              "  1.902221441268921,\n",
              "  1.9597221612930298],\n",
              " [1.2416211366653442,\n",
              "  1.772873044013977,\n",
              "  1.0318882465362549,\n",
              "  1.7777117490768433,\n",
              "  1.7325941324234009,\n",
              "  1.1281027793884277,\n",
              "  1.1586970090866089],\n",
              " [1.3767879009246826,\n",
              "  1.945326328277588,\n",
              "  1.1178056001663208,\n",
              "  1.951554775238037,\n",
              "  1.908004641532898,\n",
              "  1.2283644676208496,\n",
              "  1.2566810846328735],\n",
              " [1.6222623586654663,\n",
              "  2.253295421600342,\n",
              "  1.2770776748657227,\n",
              "  2.2668325901031494,\n",
              "  2.2249670028686523,\n",
              "  1.4056458473205566,\n",
              "  1.4342578649520874],\n",
              " [2.542529821395874,\n",
              "  3.3686745166778564,\n",
              "  1.8457739353179932,\n",
              "  3.4171810150146484,\n",
              "  3.384822368621826,\n",
              "  2.0111544132232666,\n",
              "  2.078941822052002],\n",
              " [2.9461796283721924,\n",
              "  3.844496965408325,\n",
              "  2.086442470550537,\n",
              "  3.9033915996551514,\n",
              "  3.866328239440918,\n",
              "  2.268606185913086,\n",
              "  2.3585238456726074],\n",
              " [2.416482448577881,\n",
              "  3.223104238510132,\n",
              "  1.769473671913147,\n",
              "  3.2668795585632324,\n",
              "  3.233699083328247,\n",
              "  1.9311110973358154,\n",
              "  1.9945262670516968],\n",
              " [1.100879430770874,\n",
              "  1.5920506715774536,\n",
              "  0.9397255778312683,\n",
              "  1.5962159633636475,\n",
              "  1.5503627061843872,\n",
              "  1.0236698389053345,\n",
              "  1.0570666790008545],\n",
              " [2.159050226211548,\n",
              "  2.9125592708587646,\n",
              "  1.6094496250152588,\n",
              "  2.9432566165924072,\n",
              "  2.9051616191864014,\n",
              "  1.7637741565704346,\n",
              "  1.812111496925354],\n",
              " [2.93196964263916,\n",
              "  3.8252804279327393,\n",
              "  2.078916311264038,\n",
              "  3.886894941329956,\n",
              "  3.85068416595459,\n",
              "  2.265308380126953,\n",
              "  2.3510985374450684],\n",
              " [2.9442145824432373,\n",
              "  3.8389406204223633,\n",
              "  2.083643913269043,\n",
              "  3.9007558822631836,\n",
              "  3.8667664527893066,\n",
              "  2.268012285232544,\n",
              "  2.359241008758545],\n",
              " [1.9964138269424438,\n",
              "  2.7149529457092285,\n",
              "  1.5104079246520996,\n",
              "  2.740841865539551,\n",
              "  2.703260660171509,\n",
              "  1.6584365367889404,\n",
              "  1.6984939575195312],\n",
              " [2.632301092147827,\n",
              "  3.4761693477630615,\n",
              "  1.8996119499206543,\n",
              "  3.5296084880828857,\n",
              "  3.497680902481079,\n",
              "  2.0669639110565186,\n",
              "  2.1425180435180664],\n",
              " [2.2817041873931885,\n",
              "  3.0606517791748047,\n",
              "  1.684138298034668,\n",
              "  3.098464012145996,\n",
              "  3.0616939067840576,\n",
              "  1.8446495532989502,\n",
              "  1.8997541666030884],\n",
              " [1.5112063884735107,\n",
              "  2.1142385005950928,\n",
              "  1.2036643028259277,\n",
              "  2.1235785484313965,\n",
              "  2.081019639968872,\n",
              "  1.324039101600647,\n",
              "  1.353716254234314],\n",
              " [2.200986385345459,\n",
              "  2.963468313217163,\n",
              "  1.636757731437683,\n",
              "  2.9975945949554443,\n",
              "  2.962705612182617,\n",
              "  1.7934083938598633,\n",
              "  1.8434299230575562],\n",
              " [1.145134687423706,\n",
              "  1.6496840715408325,\n",
              "  0.9669980406761169,\n",
              "  1.6525578498840332,\n",
              "  1.607529640197754,\n",
              "  1.0568642616271973,\n",
              "  1.087398648262024],\n",
              " [1.262727975845337,\n",
              "  1.8005775213241577,\n",
              "  1.0453816652297974,\n",
              "  1.8055006265640259,\n",
              "  1.7611851692199707,\n",
              "  1.1457934379577637,\n",
              "  1.1757701635360718],\n",
              " [2.779775857925415,\n",
              "  3.6479320526123047,\n",
              "  1.985619068145752,\n",
              "  3.7054896354675293,\n",
              "  3.677906036376953,\n",
              "  2.161051034927368,\n",
              "  2.2441139221191406],\n",
              " [2.1413583755493164,\n",
              "  2.890986442565918,\n",
              "  1.6004501581192017,\n",
              "  2.9225571155548096,\n",
              "  2.8857688903808594,\n",
              "  1.75390625,\n",
              "  1.8016612529754639],\n",
              " [2.7682738304138184,\n",
              "  3.6330394744873047,\n",
              "  1.9795551300048828,\n",
              "  3.6924543380737305,\n",
              "  3.660630464553833,\n",
              "  2.1573054790496826,\n",
              "  2.23599910736084],\n",
              " [1.2724859714508057,\n",
              "  1.8122422695159912,\n",
              "  1.0520260334014893,\n",
              "  1.8170216083526611,\n",
              "  1.7724543809890747,\n",
              "  1.1509953737258911,\n",
              "  1.1816614866256714],\n",
              " [2.8657987117767334,\n",
              "  3.7474067211151123,\n",
              "  2.0389721393585205,\n",
              "  3.808521032333374,\n",
              "  3.7749533653259277,\n",
              "  2.2101075649261475,\n",
              "  2.303534507751465],\n",
              " [2.813524007797241,\n",
              "  3.685544967651367,\n",
              "  2.006087064743042,\n",
              "  3.7470543384552,\n",
              "  3.7165720462799072,\n",
              "  2.1817173957824707,\n",
              "  2.2672290802001953],\n",
              " [2.721616268157959,\n",
              "  3.579185724258423,\n",
              "  1.951454520225525,\n",
              "  3.636610984802246,\n",
              "  3.6055126190185547,\n",
              "  2.1206893920898438,\n",
              "  2.203418731689453],\n",
              " [2.3447165489196777,\n",
              "  3.135232448577881,\n",
              "  1.7235054969787598,\n",
              "  3.1742584705352783,\n",
              "  3.138021469116211,\n",
              "  1.8830069303512573,\n",
              "  1.9421725273132324],\n",
              " [2.5348896980285645,\n",
              "  3.3609564304351807,\n",
              "  1.840712070465088,\n",
              "  3.4094090461730957,\n",
              "  3.377110242843628,\n",
              "  2.0063490867614746,\n",
              "  2.0736141204833984],\n",
              " [2.330260753631592,\n",
              "  3.1162006855010986,\n",
              "  1.7157455682754517,\n",
              "  3.1563236713409424,\n",
              "  3.1198227405548096,\n",
              "  1.8760374784469604,\n",
              "  1.931961178779602],\n",
              " [2.6227214336395264,\n",
              "  3.464571475982666,\n",
              "  1.894209861755371,\n",
              "  3.5181589126586914,\n",
              "  3.4881770610809326,\n",
              "  2.0621073246002197,\n",
              "  2.135220527648926],\n",
              " [1.7121977806091309,\n",
              "  2.3661675453186035,\n",
              "  1.3312270641326904,\n",
              "  2.3800623416900635,\n",
              "  2.3403477668762207,\n",
              "  1.466099739074707,\n",
              "  1.4988913536071777],\n",
              " [1.3739972114562988,\n",
              "  1.941150426864624,\n",
              "  1.117214560508728,\n",
              "  1.9498683214187622,\n",
              "  1.9053900241851807,\n",
              "  1.2270015478134155,\n",
              "  1.256606101989746],\n",
              " [2.907731533050537,\n",
              "  3.7973074913024902,\n",
              "  2.0625617504119873,\n",
              "  3.8599469661712646,\n",
              "  3.8245112895965576,\n",
              "  2.247537136077881,\n",
              "  2.333284854888916],\n",
              " [1.08758544921875,\n",
              "  1.5750207901000977,\n",
              "  0.9301000833511353,\n",
              "  1.5783793926239014,\n",
              "  1.5328431129455566,\n",
              "  1.011347770690918,\n",
              "  1.0467262268066406],\n",
              " [2.485001564025879,\n",
              "  3.3042657375335693,\n",
              "  1.8096368312835693,\n",
              "  3.3503212928771973,\n",
              "  3.312318801879883,\n",
              "  1.9772148132324219,\n",
              "  2.040281295776367],\n",
              " [2.6780447959899902,\n",
              "  3.5286130905151367,\n",
              "  1.9250679016113281,\n",
              "  3.583233118057251,\n",
              "  3.550567626953125,\n",
              "  2.099571704864502,\n",
              "  2.172478675842285],\n",
              " [2.762594699859619,\n",
              "  3.6262123584747314,\n",
              "  1.975624680519104,\n",
              "  3.6844491958618164,\n",
              "  3.656137704849243,\n",
              "  2.1505160331726074,\n",
              "  2.230654716491699],\n",
              " [1.9287906885147095,\n",
              "  2.632533311843872,\n",
              "  1.4695055484771729,\n",
              "  2.6565542221069336,\n",
              "  2.616572856903076,\n",
              "  1.6132330894470215,\n",
              "  1.6521331071853638],\n",
              " [1.9978209733963013,\n",
              "  2.716972827911377,\n",
              "  1.5108658075332642,\n",
              "  2.7424917221069336,\n",
              "  2.7062692642211914,\n",
              "  1.659255862236023,\n",
              "  1.7008774280548096],\n",
              " [2.939755439758301,\n",
              "  3.8374440670013428,\n",
              "  2.0826313495635986,\n",
              "  3.895251512527466,\n",
              "  3.8593802452087402,\n",
              "  2.260406732559204,\n",
              "  2.3582496643066406],\n",
              " [2.58048677444458,\n",
              "  3.4154508113861084,\n",
              "  1.8667945861816406,\n",
              "  3.4660394191741943,\n",
              "  3.432494640350342,\n",
              "  2.0420613288879395,\n",
              "  2.107384204864502],\n",
              " [2.625612258911133,\n",
              "  3.466356039047241,\n",
              "  1.8942841291427612,\n",
              "  3.5189261436462402,\n",
              "  3.486356019973755,\n",
              "  2.069180488586426,\n",
              "  2.135835647583008],\n",
              " [2.942260980606079,\n",
              "  3.838460922241211,\n",
              "  2.083448648452759,\n",
              "  3.8994240760803223,\n",
              "  3.862706422805786,\n",
              "  2.2694478034973145,\n",
              "  2.358372211456299],\n",
              " [2.6954052448272705,\n",
              "  3.5507447719573975,\n",
              "  1.9372398853302002,\n",
              "  3.6071488857269287,\n",
              "  3.576848030090332,\n",
              "  2.1050021648406982,\n",
              "  2.1857824325561523],\n",
              " [2.5313615798950195,\n",
              "  3.3553078174591064,\n",
              "  1.8377665281295776,\n",
              "  3.4047398567199707,\n",
              "  3.3699488639831543,\n",
              "  2.0092451572418213,\n",
              "  2.071599006652832],\n",
              " [2.7243611812591553,\n",
              "  3.585092067718506,\n",
              "  1.9549713134765625,\n",
              "  3.641799211502075,\n",
              "  3.609494924545288,\n",
              "  2.1227712631225586,\n",
              "  2.206538200378418],\n",
              " [1.2388006448745728,\n",
              "  1.7702239751815796,\n",
              "  1.0296391248703003,\n",
              "  1.7751078605651855,\n",
              "  1.72948157787323,\n",
              "  1.1270318031311035,\n",
              "  1.157281517982483],\n",
              " [2.6227307319641113,\n",
              "  3.465837240219116,\n",
              "  1.8927431106567383,\n",
              "  3.5183963775634766,\n",
              "  3.485093355178833,\n",
              "  2.0681354999542236,\n",
              "  2.136808395385742],\n",
              " [1.8973369598388672,\n",
              "  2.5927553176879883,\n",
              "  1.4471924304962158,\n",
              "  2.614483594894409,\n",
              "  2.5750601291656494,\n",
              "  1.5948126316070557,\n",
              "  1.6276211738586426],\n",
              " [2.9709270000457764,\n",
              "  3.8715672492980957,\n",
              "  2.1001698970794678,\n",
              "  3.9336044788360596,\n",
              "  3.8970093727111816,\n",
              "  2.2906436920166016,\n",
              "  2.377410411834717],\n",
              " [1.1117466688156128,\n",
              "  1.6057854890823364,\n",
              "  0.9476673007011414,\n",
              "  1.6083272695541382,\n",
              "  1.5634006261825562,\n",
              "  1.0323160886764526,\n",
              "  1.0644488334655762],\n",
              " [2.9683995246887207,\n",
              "  3.8709914684295654,\n",
              "  2.0994741916656494,\n",
              "  3.9322474002838135,\n",
              "  3.89389705657959,\n",
              "  2.287642478942871,\n",
              "  2.378018856048584],\n",
              " [2.261798858642578,\n",
              "  3.0365395545959473,\n",
              "  1.6735820770263672,\n",
              "  3.073758125305176,\n",
              "  3.035674571990967,\n",
              "  1.830122947692871,\n",
              "  1.885684847831726],\n",
              " [2.7115797996520996,\n",
              "  3.5700905323028564,\n",
              "  1.946905255317688,\n",
              "  3.6271259784698486,\n",
              "  3.5942223072052,\n",
              "  2.1221773624420166,\n",
              "  2.2002053260803223],\n",
              " [2.0332372188568115,\n",
              "  2.758307695388794,\n",
              "  1.5312551259994507,\n",
              "  2.785773992538452,\n",
              "  2.7470858097076416,\n",
              "  1.6827644109725952,\n",
              "  1.72404944896698],\n",
              " [2.772780418395996,\n",
              "  3.638760805130005,\n",
              "  1.983119010925293,\n",
              "  3.699638605117798,\n",
              "  3.668295383453369,\n",
              "  2.1580538749694824,\n",
              "  2.2396154403686523],\n",
              " [1.588955044746399,\n",
              "  2.210845708847046,\n",
              "  1.254828691482544,\n",
              "  2.2235021591186523,\n",
              "  2.1819636821746826,\n",
              "  1.3792719841003418,\n",
              "  1.4097599983215332],\n",
              " [1.532886028289795,\n",
              "  2.14163875579834,\n",
              "  1.2191798686981201,\n",
              "  2.152627944946289,\n",
              "  2.109618663787842,\n",
              "  1.3406354188919067,\n",
              "  1.3701997995376587],\n",
              " [3.0009803771972656,\n",
              "  3.911851406097412,\n",
              "  2.118739128112793,\n",
              "  3.9726643562316895,\n",
              "  3.9304022789001465,\n",
              "  2.3163766860961914,\n",
              "  2.404602527618408],\n",
              " [0.9926220178604126,\n",
              "  1.4537301063537598,\n",
              "  0.8674460053443909,\n",
              "  1.454635500907898,\n",
              "  1.4094345569610596,\n",
              "  0.9381895065307617,\n",
              "  0.9764808416366577],\n",
              " [2.8134522438049316,\n",
              "  3.6880502700805664,\n",
              "  2.0067124366760254,\n",
              "  3.7459909915924072,\n",
              "  3.711665153503418,\n",
              "  2.1859097480773926,\n",
              "  2.267005443572998],\n",
              " [2.9181759357452393,\n",
              "  3.8080151081085205,\n",
              "  2.068418264389038,\n",
              "  3.871504783630371,\n",
              "  3.8368592262268066,\n",
              "  2.2524712085723877,\n",
              "  2.339876651763916],\n",
              " [2.936410427093506,\n",
              "  3.8314616680145264,\n",
              "  2.080753803253174,\n",
              "  3.892487049102783,\n",
              "  3.8599133491516113,\n",
              "  2.265645742416382,\n",
              "  2.3534059524536133],\n",
              " [2.9074857234954834,\n",
              "  3.795226573944092,\n",
              "  2.062412977218628,\n",
              "  3.855881690979004,\n",
              "  3.8211264610290527,\n",
              "  2.240978717803955,\n",
              "  2.3298850059509277],\n",
              " [2.709554433822632,\n",
              "  3.5650393962860107,\n",
              "  1.9444465637207031,\n",
              "  3.6221048831939697,\n",
              "  3.588984966278076,\n",
              "  2.1213157176971436,\n",
              "  2.195988178253174],\n",
              " [1.6624302864074707,\n",
              "  2.3033969402313232,\n",
              "  1.300877332687378,\n",
              "  2.3178961277008057,\n",
              "  2.2757647037506104,\n",
              "  1.4288136959075928,\n",
              "  1.4633105993270874],\n",
              " [1.3755007982254028,\n",
              "  1.9434436559677124,\n",
              "  1.11860191822052,\n",
              "  1.9508835077285767,\n",
              "  1.9079926013946533,\n",
              "  1.2287367582321167,\n",
              "  1.2567245960235596],\n",
              " [2.4238224029541016,\n",
              "  3.2286832332611084,\n",
              "  1.772043228149414,\n",
              "  3.2736971378326416,\n",
              "  3.2366843223571777,\n",
              "  1.9380621910095215,\n",
              "  1.9969598054885864],\n",
              " [1.3407031297683716,\n",
              "  1.898850679397583,\n",
              "  1.0935766696929932,\n",
              "  1.9043338298797607,\n",
              "  1.8614745140075684,\n",
              "  1.199873685836792,\n",
              "  1.2307612895965576],\n",
              " [1.2482088804244995,\n",
              "  1.78229558467865,\n",
              "  1.0357609987258911,\n",
              "  1.7859829664230347,\n",
              "  1.742120385169983,\n",
              "  1.1322447061538696,\n",
              "  1.1647688150405884],\n",
              " [1.1307272911071777,\n",
              "  1.631426215171814,\n",
              "  0.9585174322128296,\n",
              "  1.634352684020996,\n",
              "  1.5880521535873413,\n",
              "  1.045969843864441,\n",
              "  1.0792927742004395],\n",
              " [2.941688060760498,\n",
              "  3.8376550674438477,\n",
              "  2.084688186645508,\n",
              "  3.898585319519043,\n",
              "  3.863750457763672,\n",
              "  2.2733092308044434,\n",
              "  2.357574462890625],\n",
              " [1.4786288738250732,\n",
              "  2.0741989612579346,\n",
              "  1.1836283206939697,\n",
              "  2.083914279937744,\n",
              "  2.04086971282959,\n",
              "  1.3021475076675415,\n",
              "  1.331507682800293],\n",
              " [2.10383939743042,\n",
              "  2.8484156131744385,\n",
              "  1.5760688781738281,\n",
              "  2.878880262374878,\n",
              "  2.84051775932312,\n",
              "  1.732378363609314,\n",
              "  1.7771565914154053],\n",
              " [1.3124985694885254,\n",
              "  1.8630365133285522,\n",
              "  1.077467441558838,\n",
              "  1.8692069053649902,\n",
              "  1.8260631561279297,\n",
              "  1.1814963817596436,\n",
              "  1.2110884189605713],\n",
              " [2.7140893936157227,\n",
              "  3.5705010890960693,\n",
              "  1.9474424123764038,\n",
              "  3.6264326572418213,\n",
              "  3.5942728519439697,\n",
              "  2.1262333393096924,\n",
              "  2.1974687576293945],\n",
              " [1.3827780485153198,\n",
              "  1.9542454481124878,\n",
              "  1.1222612857818604,\n",
              "  1.961108684539795,\n",
              "  1.9171911478042603,\n",
              "  1.2343862056732178,\n",
              "  1.2644190788269043],\n",
              " [1.025596022605896,\n",
              "  1.4953868389129639,\n",
              "  0.8899506330490112,\n",
              "  1.497302532196045,\n",
              "  1.4512550830841064,\n",
              "  0.9642133712768555,\n",
              "  1.0000951290130615],\n",
              " [1.3080174922943115,\n",
              "  1.8572580814361572,\n",
              "  1.0748673677444458,\n",
              "  1.8631850481033325,\n",
              "  1.8185805082321167,\n",
              "  1.1774659156799316,\n",
              "  1.2093532085418701],\n",
              " [1.124776840209961,\n",
              "  1.6240043640136719,\n",
              "  0.9546554684638977,\n",
              "  1.6268826723098755,\n",
              "  1.58122718334198,\n",
              "  1.0414812564849854,\n",
              "  1.0734766721725464],\n",
              " [1.1085565090179443,\n",
              "  1.602975845336914,\n",
              "  0.9446545839309692,\n",
              "  1.605467438697815,\n",
              "  1.5604667663574219,\n",
              "  1.0278340578079224,\n",
              "  1.0624970197677612],\n",
              " [2.8526718616485596,\n",
              "  3.731455087661743,\n",
              "  2.030123233795166,\n",
              "  3.7915401458740234,\n",
              "  3.760354518890381,\n",
              "  2.203853130340576,\n",
              "  2.293539047241211],\n",
              " [1.6953331232070923,\n",
              "  2.345350980758667,\n",
              "  1.3213860988616943,\n",
              "  2.3593997955322266,\n",
              "  2.319406032562256,\n",
              "  1.4538938999176025,\n",
              "  1.4874423742294312],\n",
              " [2.89123797416687,\n",
              "  3.776498317718506,\n",
              "  2.0537357330322266,\n",
              "  3.8399014472961426,\n",
              "  3.80717134475708,\n",
              "  2.2390897274017334,\n",
              "  2.3221435546875],\n",
              " [2.909543514251709,\n",
              "  3.7991132736206055,\n",
              "  2.064279794692993,\n",
              "  3.8600339889526367,\n",
              "  3.8272037506103516,\n",
              "  2.2490081787109375,\n",
              "  2.3326773643493652],\n",
              " [2.206169366836548,\n",
              "  2.9683563709259033,\n",
              "  1.6402766704559326,\n",
              "  3.0025925636291504,\n",
              "  2.9668922424316406,\n",
              "  1.796189546585083,\n",
              "  1.845334529876709],\n",
              " [2.1842007637023926,\n",
              "  2.9421324729919434,\n",
              "  1.6264023780822754,\n",
              "  2.9765632152557373,\n",
              "  2.9414710998535156,\n",
              "  1.7837518453598022,\n",
              "  1.8309434652328491],\n",
              " [2.1842596530914307,\n",
              "  2.942303419113159,\n",
              "  1.626326322555542,\n",
              "  2.9756019115448,\n",
              "  2.939307689666748,\n",
              "  1.7829114198684692,\n",
              "  1.8307634592056274],\n",
              " [2.062241315841675,\n",
              "  2.795830011367798,\n",
              "  1.5510485172271729,\n",
              "  2.8239665031433105,\n",
              "  2.7865331172943115,\n",
              "  1.7039121389389038,\n",
              "  1.745221734046936],\n",
              " [1.9116958379745483,\n",
              "  2.6117045879364014,\n",
              "  1.4582512378692627,\n",
              "  2.634157419204712,\n",
              "  2.595885753631592,\n",
              "  1.602837324142456,\n",
              "  1.640425205230713],\n",
              " [1.0571473836898804,\n",
              "  1.5356844663619995,\n",
              "  0.9101495146751404,\n",
              "  1.5394840240478516,\n",
              "  1.4925317764282227,\n",
              "  0.9878697395324707,\n",
              "  1.0244985818862915],\n",
              " [1.1464935541152954,\n",
              "  1.649291753768921,\n",
              "  0.9687584042549133,\n",
              "  1.6538619995117188,\n",
              "  1.6080374717712402,\n",
              "  1.0567303895950317,\n",
              "  1.0891337394714355],\n",
              " [1.6975566148757935,\n",
              "  2.347787380218506,\n",
              "  1.322153091430664,\n",
              "  2.3638811111450195,\n",
              "  2.322354555130005,\n",
              "  1.4546213150024414,\n",
              "  1.488100290298462],\n",
              " [1.98053777217865,\n",
              "  2.6962780952453613,\n",
              "  1.5010323524475098,\n",
              "  2.7234156131744385,\n",
              "  2.6845858097076416,\n",
              "  1.6498072147369385,\n",
              "  1.6902340650558472],\n",
              " [1.5909879207611084,\n",
              "  2.2137718200683594,\n",
              "  1.2562627792358398,\n",
              "  2.2264339923858643,\n",
              "  2.1848716735839844,\n",
              "  1.3822702169418335,\n",
              "  1.4125491380691528],\n",
              " [2.912071943283081,\n",
              "  3.801809787750244,\n",
              "  2.0650064945220947,\n",
              "  3.863602638244629,\n",
              "  3.832760810852051,\n",
              "  2.2507107257843018,\n",
              "  2.3358187675476074],\n",
              " [1.223248839378357,\n",
              "  1.7488240003585815,\n",
              "  1.0195369720458984,\n",
              "  1.7535979747772217,\n",
              "  1.7082560062408447,\n",
              "  1.114936113357544,\n",
              "  1.146360158920288],\n",
              " [1.0630160570144653,\n",
              "  1.5435643196105957,\n",
              "  0.9140039682388306,\n",
              "  1.546177625656128,\n",
              "  1.4994252920150757,\n",
              "  0.992497444152832,\n",
              "  1.0288543701171875],\n",
              " [2.476156234741211,\n",
              "  3.2928314208984375,\n",
              "  1.8039828538894653,\n",
              "  3.3378353118896484,\n",
              "  3.305697441101074,\n",
              "  1.9720146656036377,\n",
              "  2.0351474285125732],\n",
              " [2.41318416595459,\n",
              "  3.2166857719421387,\n",
              "  1.7661470174789429,\n",
              "  3.259880542755127,\n",
              "  3.2259421348571777,\n",
              "  1.933361530303955,\n",
              "  1.9895334243774414],\n",
              " [1.3933558464050293,\n",
              "  1.9663387537002563,\n",
              "  1.1286722421646118,\n",
              "  1.9728007316589355,\n",
              "  1.929274082183838,\n",
              "  1.237497091293335,\n",
              "  1.269250512123108],\n",
              " [2.9186861515045166,\n",
              "  3.8107352256774902,\n",
              "  2.070652961730957,\n",
              "  3.8730061054229736,\n",
              "  3.8380448818206787,\n",
              "  2.2550599575042725,\n",
              "  2.341909408569336],\n",
              " [2.7004952430725098,\n",
              "  3.5564825534820557,\n",
              "  1.9400428533554077,\n",
              "  3.6128363609313965,\n",
              "  3.5825393199920654,\n",
              "  2.1064505577087402,\n",
              "  2.1903443336486816],\n",
              " [2.95928955078125,\n",
              "  3.86419939994812,\n",
              "  2.0942349433898926,\n",
              "  3.921027898788452,\n",
              "  3.878390073776245,\n",
              "  2.279910087585449,\n",
              "  2.3744163513183594],\n",
              " [1.869372010231018,\n",
              "  2.55997371673584,\n",
              "  1.4316203594207764,\n",
              "  2.58182430267334,\n",
              "  2.5428285598754883,\n",
              "  1.5757732391357422,\n",
              "  1.6114201545715332],\n",
              " [2.7836573123931885,\n",
              "  3.65362286567688,\n",
              "  1.9891902208328247,\n",
              "  3.7128803730010986,\n",
              "  3.679882287979126,\n",
              "  2.162999153137207,\n",
              "  2.2478132247924805],\n",
              " [2.607530355453491,\n",
              "  3.4473886489868164,\n",
              "  1.8845865726470947,\n",
              "  3.4995367527008057,\n",
              "  3.4680917263031006,\n",
              "  2.0547544956207275,\n",
              "  2.125678062438965],\n",
              " [2.5672788619995117,\n",
              "  3.4010274410247803,\n",
              "  1.859262228012085,\n",
              "  3.4516265392303467,\n",
              "  3.416931629180908,\n",
              "  2.0276007652282715,\n",
              "  2.099771499633789],\n",
              " [2.744246244430542,\n",
              "  3.607537031173706,\n",
              "  1.9661312103271484,\n",
              "  3.6659045219421387,\n",
              "  3.6329429149627686,\n",
              "  2.1393861770629883,\n",
              "  2.2211761474609375],\n",
              " [2.6372931003570557,\n",
              "  3.4823801517486572,\n",
              "  1.9004950523376465,\n",
              "  3.534238338470459,\n",
              "  3.499729871749878,\n",
              "  2.066009998321533,\n",
              "  2.145735740661621],\n",
              " [1.5348924398422241,\n",
              "  2.143336772918701,\n",
              "  1.2206110954284668,\n",
              "  2.1538541316986084,\n",
              "  2.1114308834075928,\n",
              "  1.3393244743347168,\n",
              "  1.3717396259307861],\n",
              " [2.8022689819335938,\n",
              "  3.6740942001342773,\n",
              "  2.00140380859375,\n",
              "  3.732539176940918,\n",
              "  3.7032220363616943,\n",
              "  2.1779589653015137,\n",
              "  2.2588963508605957],\n",
              " [2.2411949634552,\n",
              "  3.011641263961792,\n",
              "  1.6608437299728394,\n",
              "  3.0477638244628906,\n",
              "  3.011448621749878,\n",
              "  1.8140923976898193,\n",
              "  1.8714121580123901],\n",
              " [3.000735282897949,\n",
              "  3.9121227264404297,\n",
              "  2.120011329650879,\n",
              "  3.9719972610473633,\n",
              "  3.929798126220703,\n",
              "  2.3150289058685303,\n",
              "  2.403611183166504],\n",
              " [2.836902618408203,\n",
              "  3.7177915573120117,\n",
              "  2.021883964538574,\n",
              "  3.776061773300171,\n",
              "  3.740602970123291,\n",
              "  2.2042770385742188,\n",
              "  2.286990165710449],\n",
              " [2.8330154418945312,\n",
              "  3.7094578742980957,\n",
              "  2.0185956954956055,\n",
              "  3.769953727722168,\n",
              "  3.7384908199310303,\n",
              "  2.197061538696289,\n",
              "  2.2819266319274902],\n",
              " [2.002249240875244,\n",
              "  2.721930980682373,\n",
              "  1.513979434967041,\n",
              "  2.7477314472198486,\n",
              "  2.7087996006011963,\n",
              "  1.6629295349121094,\n",
              "  1.7027987241744995],\n",
              " [2.972066879272461,\n",
              "  3.8726727962493896,\n",
              "  2.101626396179199,\n",
              "  3.935068130493164,\n",
              "  3.8966317176818848,\n",
              "  2.2897069454193115,\n",
              "  2.3801870346069336],\n",
              " [2.599456787109375,\n",
              "  3.4387905597686768,\n",
              "  1.8789204359054565,\n",
              "  3.489528179168701,\n",
              "  3.455127477645874,\n",
              "  2.0487914085388184,\n",
              "  2.1197896003723145],\n",
              " [1.1177922487258911,\n",
              "  1.6142773628234863,\n",
              "  0.9512768387794495,\n",
              "  1.6170669794082642,\n",
              "  1.5708109140396118,\n",
              "  1.0361119508743286,\n",
              "  1.0694680213928223],\n",
              " [1.8596551418304443,\n",
              "  2.5499889850616455,\n",
              "  1.425862193107605,\n",
              "  2.5701658725738525,\n",
              "  2.5299530029296875,\n",
              "  1.570347547531128,\n",
              "  1.6055740118026733],\n",
              " [1.8031284809112549,\n",
              "  2.478630781173706,\n",
              "  1.3895188570022583,\n",
              "  2.4972617626190186,\n",
              "  2.4566266536712646,\n",
              "  1.527777910232544,\n",
              "  1.5636903047561646],\n",
              " [2.867492437362671,\n",
              "  3.750286817550659,\n",
              "  2.0393121242523193,\n",
              "  3.8101887702941895,\n",
              "  3.780484437942505,\n",
              "  2.217062473297119,\n",
              "  2.3043832778930664],\n",
              " [2.965488910675049,\n",
              "  3.8700101375579834,\n",
              "  2.096585273742676,\n",
              "  3.930213212966919,\n",
              "  3.8920674324035645,\n",
              "  2.286911964416504,\n",
              "  2.3776822090148926],\n",
              " [1.8622033596038818,\n",
              "  2.5509684085845947,\n",
              "  1.4256576299667358,\n",
              "  2.5720977783203125,\n",
              "  2.5308563709259033,\n",
              "  1.5717308521270752,\n",
              "  1.6059374809265137],\n",
              " [2.9212698936462402,\n",
              "  3.815704584121704,\n",
              "  2.0701355934143066,\n",
              "  3.8751115798950195,\n",
              "  3.8382880687713623,\n",
              "  2.2507035732269287,\n",
              "  2.3424715995788574],\n",
              " [2.4344420433044434,\n",
              "  3.2447330951690674,\n",
              "  1.7800636291503906,\n",
              "  3.289935350418091,\n",
              "  3.254354238510132,\n",
              "  1.9457135200500488,\n",
              "  2.0088021755218506],\n",
              " [2.85593318939209,\n",
              "  3.736591339111328,\n",
              "  2.032670021057129,\n",
              "  3.7963547706604004,\n",
              "  3.765439987182617,\n",
              "  2.2105746269226074,\n",
              "  2.295621871948242],\n",
              " [1.3847445249557495,\n",
              "  1.9545522928237915,\n",
              "  1.1233952045440674,\n",
              "  1.9613919258117676,\n",
              "  1.917838454246521,\n",
              "  1.2345187664031982,\n",
              "  1.2624410390853882],\n",
              " [2.972175359725952,\n",
              "  3.874150514602661,\n",
              "  2.1019744873046875,\n",
              "  3.9361536502838135,\n",
              "  3.899949073791504,\n",
              "  2.293527603149414,\n",
              "  2.380992889404297],\n",
              " [1.5756781101226807,\n",
              "  2.19574236869812,\n",
              "  1.2471261024475098,\n",
              "  2.206914186477661,\n",
              "  2.1654789447784424,\n",
              "  1.368729591369629,\n",
              "  1.4013919830322266],\n",
              " [2.243255853652954,\n",
              "  3.0128087997436523,\n",
              "  1.6635209321975708,\n",
              "  3.0500831604003906,\n",
              "  3.0135550498962402,\n",
              "  1.820960521697998,\n",
              "  1.872918963432312],\n",
              " [2.958982229232788,\n",
              "  3.859816789627075,\n",
              "  2.094078779220581,\n",
              "  3.9200074672698975,\n",
              "  3.880152463912964,\n",
              "  2.2841989994049072,\n",
              "  2.3703713417053223],\n",
              " [3.003727436065674,\n",
              "  3.9134700298309326,\n",
              "  2.120896816253662,\n",
              "  3.974553108215332,\n",
              "  3.9330270290374756,\n",
              "  2.317220687866211,\n",
              "  2.4046249389648438],\n",
              " [1.7186425924301147,\n",
              "  2.3735387325286865,\n",
              "  1.3350144624710083,\n",
              "  2.3886983394622803,\n",
              "  2.3486835956573486,\n",
              "  1.4693981409072876,\n",
              "  1.5007392168045044],\n",
              " [2.047124147415161,\n",
              "  2.7760016918182373,\n",
              "  1.542884111404419,\n",
              "  2.803194999694824,\n",
              "  2.76737380027771,\n",
              "  1.691487193107605,\n",
              "  1.7342971563339233],\n",
              " [2.4234535694122314,\n",
              "  3.230903148651123,\n",
              "  1.77423894405365,\n",
              "  3.2753422260284424,\n",
              "  3.24120831489563,\n",
              "  1.9360244274139404,\n",
              "  1.9989453554153442],\n",
              " [1.283311367034912,\n",
              "  1.825490951538086,\n",
              "  1.0578566789627075,\n",
              "  1.8312819004058838,\n",
              "  1.7867794036865234,\n",
              "  1.1576637029647827,\n",
              "  1.1891521215438843],\n",
              " [2.847980499267578,\n",
              "  3.724499464035034,\n",
              "  2.026214838027954,\n",
              "  3.785935878753662,\n",
              "  3.756593942642212,\n",
              "  2.202528476715088,\n",
              "  2.289322853088379],\n",
              " [2.678140878677368,\n",
              "  3.5295920372009277,\n",
              "  1.9265069961547852,\n",
              "  3.5855162143707275,\n",
              "  3.5537166595458984,\n",
              "  2.0924839973449707,\n",
              "  2.174976348876953],\n",
              " [1.5430940389633179,\n",
              "  2.1543967723846436,\n",
              "  1.2263157367706299,\n",
              "  2.1658883094787598,\n",
              "  2.1241729259490967,\n",
              "  1.34803307056427,\n",
              "  1.3783949613571167],\n",
              " [2.6487579345703125,\n",
              "  3.4958810806274414,\n",
              "  1.9090975522994995,\n",
              "  3.550008773803711,\n",
              "  3.5190746784210205,\n",
              "  2.07705020904541,\n",
              "  2.1536264419555664],\n",
              " [2.7596933841705322,\n",
              "  3.6232593059539795,\n",
              "  1.974806547164917,\n",
              "  3.6815757751464844,\n",
              "  3.649966239929199,\n",
              "  2.144386053085327,\n",
              "  2.2281765937805176],\n",
              " [1.2210770845413208,\n",
              "  1.7474726438522339,\n",
              "  1.017557978630066,\n",
              "  1.751546859741211,\n",
              "  1.706426739692688,\n",
              "  1.1135540008544922,\n",
              "  1.144491195678711],\n",
              " [1.5858793258666992,\n",
              "  2.207141637802124,\n",
              "  1.2515950202941895,\n",
              "  2.2197892665863037,\n",
              "  2.178497076034546,\n",
              "  1.3751884698867798,\n",
              "  1.4076176881790161],\n",
              " [2.90875244140625,\n",
              "  3.799253225326538,\n",
              "  2.064387321472168,\n",
              "  3.8596317768096924,\n",
              "  3.8256895542144775,\n",
              "  2.2431869506835938,\n",
              "  2.33404541015625],\n",
              " [1.659302830696106,\n",
              "  2.299041509628296,\n",
              "  1.3000342845916748,\n",
              "  2.314657688140869,\n",
              "  2.2730069160461426,\n",
              "  1.4295423030853271,\n",
              "  1.461108922958374],\n",
              " [1.8326514959335327,\n",
              "  2.513568639755249,\n",
              "  1.4084287881851196,\n",
              "  2.5337038040161133,\n",
              "  2.493608236312866,\n",
              "  1.5491516590118408,\n",
              "  1.5840367078781128],\n",
              " [2.8857524394989014,\n",
              "  3.7692341804504395,\n",
              "  2.050093173980713,\n",
              "  3.83182954788208,\n",
              "  3.799478054046631,\n",
              "  2.2336947917938232,\n",
              "  2.3170928955078125],\n",
              " [2.9342668056488037,\n",
              "  3.8292133808135986,\n",
              "  2.07844877243042,\n",
              "  3.890181303024292,\n",
              "  3.8553452491760254,\n",
              "  2.258852958679199,\n",
              "  2.3536319732666016],\n",
              " [2.631885051727295,\n",
              "  3.474250555038452,\n",
              "  1.898984670639038,\n",
              "  3.527433395385742,\n",
              "  3.4984076023101807,\n",
              "  2.06886625289917,\n",
              "  2.1400680541992188],\n",
              " [1.6633448600769043,\n",
              "  2.3044583797454834,\n",
              "  1.3021222352981567,\n",
              "  2.31864333152771,\n",
              "  2.276606798171997,\n",
              "  1.431503415107727,\n",
              "  1.463655710220337],\n",
              " [2.113792896270752,\n",
              "  2.8566274642944336,\n",
              "  1.5830775499343872,\n",
              "  2.8875224590301514,\n",
              "  2.8500866889953613,\n",
              "  1.7360124588012695,\n",
              "  1.781741976737976],\n",
              " [2.790370464324951,\n",
              "  3.660214424133301,\n",
              "  1.9939863681793213,\n",
              "  3.719069004058838,\n",
              "  3.689342975616455,\n",
              "  2.1721763610839844,\n",
              "  2.2515087127685547],\n",
              " [2.656125068664551,\n",
              "  3.5027735233306885,\n",
              "  1.9128179550170898,\n",
              "  3.5564959049224854,\n",
              "  3.525580644607544,\n",
              "  2.083927869796753,\n",
              "  2.1575875282287598],\n",
              " [2.257192611694336,\n",
              "  3.03007435798645,\n",
              "  1.6717877388000488,\n",
              "  3.067610502243042,\n",
              "  3.0329782962799072,\n",
              "  1.8274047374725342,\n",
              "  1.8836246728897095],\n",
              " [2.6770472526550293,\n",
              "  3.528162956237793,\n",
              "  1.9255940914154053,\n",
              "  3.5836715698242188,\n",
              "  3.5543699264526367,\n",
              "  2.097024917602539,\n",
              "  2.1728105545043945],\n",
              " [3.0019707679748535,\n",
              "  3.913311004638672,\n",
              "  2.119232654571533,\n",
              "  3.9732861518859863,\n",
              "  3.931082010269165,\n",
              "  2.3180508613586426,\n",
              "  2.4045896530151367],\n",
              " [2.381868839263916,\n",
              "  3.1810765266418457,\n",
              "  1.7458044290542603,\n",
              "  3.2212436199188232,\n",
              "  3.1849305629730225,\n",
              "  1.9065672159194946,\n",
              "  1.9678598642349243],\n",
              " [2.548246383666992,\n",
              "  3.377202272415161,\n",
              "  1.847427487373352,\n",
              "  3.4264421463012695,\n",
              "  3.393399238586426,\n",
              "  2.0136239528656006,\n",
              "  2.0846426486968994],\n",
              " [2.826367139816284,\n",
              "  3.70320725440979,\n",
              "  2.0148422718048096,\n",
              "  3.7636897563934326,\n",
              "  3.73097562789917,\n",
              "  2.1917762756347656,\n",
              "  2.2781944274902344],\n",
              " [1.8119773864746094,\n",
              "  2.487370491027832,\n",
              "  1.3944876194000244,\n",
              "  2.506382465362549,\n",
              "  2.4672019481658936,\n",
              "  1.5358517169952393,\n",
              "  1.5690019130706787],\n",
              " [1.5769634246826172,\n",
              "  2.197445869445801,\n",
              "  1.2459392547607422,\n",
              "  2.2081828117370605,\n",
              "  2.1662235260009766,\n",
              "  1.370467185974121,\n",
              "  1.4008162021636963],\n",
              " [1.4551026821136475,\n",
              "  2.0435550212860107,\n",
              "  1.1678296327590942,\n",
              "  2.052194356918335,\n",
              "  2.008760690689087,\n",
              "  1.2833740711212158,\n",
              "  1.312886118888855],\n",
              " [2.8344624042510986,\n",
              "  3.7129948139190674,\n",
              "  2.018958568572998,\n",
              "  3.773982048034668,\n",
              "  3.7412467002868652,\n",
              "  2.1989316940307617,\n",
              "  2.284555435180664],\n",
              " [1.9256490468978882,\n",
              "  2.6297712326049805,\n",
              "  1.466822624206543,\n",
              "  2.653108835220337,\n",
              "  2.614441394805908,\n",
              "  1.6110459566116333,\n",
              "  1.650199055671692],\n",
              " [1.650477647781372,\n",
              "  2.288663148880005,\n",
              "  1.291724443435669,\n",
              "  2.30177640914917,\n",
              "  2.2597367763519287,\n",
              "  1.422835111618042,\n",
              "  1.4526209831237793],\n",
              " [1.1512072086334229,\n",
              "  1.657267451286316,\n",
              "  0.9734254479408264,\n",
              "  1.6597068309783936,\n",
              "  1.613232135772705,\n",
              "  1.0602837800979614,\n",
              "  1.0929539203643799],\n",
              " [2.692887306213379,\n",
              "  3.5504162311553955,\n",
              "  1.936414361000061,\n",
              "  3.602982759475708,\n",
              "  3.5665979385375977,\n",
              "  2.106151819229126,\n",
              "  2.1853251457214355],\n",
              " [2.8020706176757812,\n",
              "  3.6710760593414307,\n",
              "  2.0004003047943115,\n",
              "  3.7315049171447754,\n",
              "  3.7013399600982666,\n",
              "  2.1758270263671875,\n",
              "  2.257984161376953],\n",
              " [1.3993861675262451,\n",
              "  1.9735208749771118,\n",
              "  1.1335434913635254,\n",
              "  1.980760931968689,\n",
              "  1.9358855485916138,\n",
              "  1.243261456489563,\n",
              "  1.2745474576950073],\n",
              " [2.912163019180298,\n",
              "  3.80025315284729,\n",
              "  2.06457257270813,\n",
              "  3.8600213527679443,\n",
              "  3.829096555709839,\n",
              "  2.2424323558807373,\n",
              "  2.332313060760498],\n",
              " [1.1951812505722046,\n",
              "  1.7134464979171753,\n",
              "  1.0020378828048706,\n",
              "  1.7172231674194336,\n",
              "  1.6710093021392822,\n",
              "  1.0937068462371826,\n",
              "  1.1253044605255127],\n",
              " [1.4489721059799194,\n",
              "  2.0357346534729004,\n",
              "  1.1659735441207886,\n",
              "  2.0455286502838135,\n",
              "  2.0024704933166504,\n",
              "  1.2816954851150513,\n",
              "  1.311076045036316],\n",
              " [1.271383285522461,\n",
              "  1.810488224029541,\n",
              "  1.0518115758895874,\n",
              "  1.8159323930740356,\n",
              "  1.771183729171753,\n",
              "  1.151092529296875,\n",
              "  1.1813074350357056],\n",
              " [2.5777502059936523,\n",
              "  3.411979913711548,\n",
              "  1.8660039901733398,\n",
              "  3.462287664413452,\n",
              "  3.42869234085083,\n",
              "  2.0290966033935547,\n",
              "  2.1040759086608887],\n",
              " [2.347107172012329,\n",
              "  3.1369407176971436,\n",
              "  1.7265875339508057,\n",
              "  3.177807331085205,\n",
              "  3.144231081008911,\n",
              "  1.8874077796936035,\n",
              "  1.9437379837036133],\n",
              " [2.8074464797973633,\n",
              "  3.678619146347046,\n",
              "  2.003755807876587,\n",
              "  3.7376747131347656,\n",
              "  3.70703125,\n",
              "  2.180953025817871,\n",
              "  2.2624154090881348],\n",
              " [2.8266985416412354,\n",
              "  3.705352783203125,\n",
              "  2.015108823776245,\n",
              "  3.765458106994629,\n",
              "  3.730685234069824,\n",
              "  2.195957660675049,\n",
              "  2.279573917388916],\n",
              " [2.412365674972534,\n",
              "  3.2158472537994385,\n",
              "  1.765730381011963,\n",
              "  3.258319139480591,\n",
              "  3.224912166595459,\n",
              "  1.9298322200775146,\n",
              "  1.9894590377807617],\n",
              " [2.573478937149048,\n",
              "  3.4056894779205322,\n",
              "  1.8625422716140747,\n",
              "  3.4546549320220947,\n",
              "  3.425764560699463,\n",
              "  2.0318312644958496,\n",
              "  2.101449489593506],\n",
              " [1.921897530555725,\n",
              "  2.624922513961792,\n",
              "  1.4642834663391113,\n",
              "  2.6480162143707275,\n",
              "  2.608760356903076,\n",
              "  1.6106971502304077,\n",
              "  1.6483234167099],\n",
              " [2.7393972873687744,\n",
              "  3.600749969482422,\n",
              "  1.9622482061386108,\n",
              "  3.6570210456848145,\n",
              "  3.6252737045288086,\n",
              "  2.138424873352051,\n",
              "  2.2163496017456055],\n",
              " [2.5711700916290283,\n",
              "  3.4052090644836426,\n",
              "  1.8611257076263428,\n",
              "  3.4547908306121826,\n",
              "  3.421692132949829,\n",
              "  2.029266834259033,\n",
              "  2.1017327308654785],\n",
              " [2.912992000579834,\n",
              "  3.8058485984802246,\n",
              "  2.0667526721954346,\n",
              "  3.8658721446990967,\n",
              "  3.828554153442383,\n",
              "  2.2550010681152344,\n",
              "  2.3371787071228027],\n",
              " [2.465513229370117,\n",
              "  3.2790005207061768,\n",
              "  1.798216700553894,\n",
              "  3.3241562843322754,\n",
              "  3.2897181510925293,\n",
              "  1.963564395904541,\n",
              "  2.0260133743286133],\n",
              " [1.3746551275253296,\n",
              "  1.9415725469589233,\n",
              "  1.1174956560134888,\n",
              "  1.9489415884017944,\n",
              "  1.905478835105896,\n",
              "  1.2268611192703247,\n",
              "  1.256080150604248],\n",
              " [2.346451759338379,\n",
              "  3.1368765830993652,\n",
              "  1.7254537343978882,\n",
              "  3.177339792251587,\n",
              "  3.143649101257324,\n",
              "  1.8897396326065063,\n",
              "  1.9435808658599854],\n",
              " [1.4047857522964478,\n",
              "  1.9803130626678467,\n",
              "  1.1370444297790527,\n",
              "  1.9875611066818237,\n",
              "  1.9459245204925537,\n",
              "  1.2465832233428955,\n",
              "  1.2779579162597656],\n",
              " [1.5315489768981934,\n",
              "  2.138944149017334,\n",
              "  1.2170056104660034,\n",
              "  2.150223731994629,\n",
              "  2.1069891452789307,\n",
              "  1.339456558227539,\n",
              "  1.3683815002441406],\n",
              " [2.1234383583068848,\n",
              "  2.8680148124694824,\n",
              "  1.590006947517395,\n",
              "  2.899477958679199,\n",
              "  2.863440752029419,\n",
              "  1.743604063987732,\n",
              "  1.7885932922363281],\n",
              " [1.9773160219192505,\n",
              "  2.690448760986328,\n",
              "  1.4976835250854492,\n",
              "  2.7155823707580566,\n",
              "  2.6775035858154297,\n",
              "  1.6444547176361084,\n",
              "  1.6849279403686523],\n",
              " [2.395051956176758,\n",
              "  3.1955432891845703,\n",
              "  1.756054162979126,\n",
              "  3.2382309436798096,\n",
              "  3.2069907188415527,\n",
              "  1.9160387516021729,\n",
              "  1.9787191152572632],\n",
              " [1.5659960508346558,\n",
              "  2.182170867919922,\n",
              "  1.2403658628463745,\n",
              "  2.1951866149902344,\n",
              "  2.1524546146392822,\n",
              "  1.3632384538650513,\n",
              "  1.3953156471252441],\n",
              " [1.922711730003357,\n",
              "  2.6257450580596924,\n",
              "  1.4640073776245117,\n",
              "  2.6499054431915283,\n",
              "  2.609874725341797,\n",
              "  1.6126682758331299,\n",
              "  1.6499603986740112],\n",
              " [2.6124014854431152,\n",
              "  3.4528393745422363,\n",
              "  1.8870962858200073,\n",
              "  3.5044052600860596,\n",
              "  3.473865032196045,\n",
              "  2.0560719966888428,\n",
              "  2.1284170150756836],\n",
              " [2.6939892768859863,\n",
              "  3.5467307567596436,\n",
              "  1.9363576173782349,\n",
              "  3.601686477661133,\n",
              "  3.5714685916900635,\n",
              "  2.1113457679748535,\n",
              "  2.182384967803955],\n",
              " [1.5246225595474243,\n",
              "  2.1324079036712646,\n",
              "  1.2135523557662964,\n",
              "  2.1412200927734375,\n",
              "  2.100113868713379,\n",
              "  1.3359370231628418,\n",
              "  1.3631207942962646],\n",
              " [1.2733116149902344,\n",
              "  1.813510537147522,\n",
              "  1.0515438318252563,\n",
              "  1.8197640180587769,\n",
              "  1.77443528175354,\n",
              "  1.1538382768630981,\n",
              "  1.1835495233535767],\n",
              " [1.957229733467102,\n",
              "  2.664187431335449,\n",
              "  1.4862416982650757,\n",
              "  2.6893293857574463,\n",
              "  2.6519503593444824,\n",
              "  1.6322864294052124,\n",
              "  1.6711235046386719],\n",
              " [2.218510150909424,\n",
              "  2.9837992191314697,\n",
              "  1.647932767868042,\n",
              "  3.016613721847534,\n",
              "  2.9832098484039307,\n",
              "  1.803454875946045,\n",
              "  1.8545376062393188],\n",
              " [2.0039994716644287,\n",
              "  2.7244176864624023,\n",
              "  1.5115410089492798,\n",
              "  2.7473506927490234,\n",
              "  2.7078959941864014,\n",
              "  1.6625492572784424,\n",
              "  1.703389286994934],\n",
              " [2.8151352405548096,\n",
              "  3.6879336833953857,\n",
              "  2.007751226425171,\n",
              "  3.745523691177368,\n",
              "  3.7175374031066895,\n",
              "  2.1838009357452393,\n",
              "  2.265761375427246],\n",
              " [1.691904067993164,\n",
              "  2.3405001163482666,\n",
              "  1.3199571371078491,\n",
              "  2.354830026626587,\n",
              "  2.31592059135437,\n",
              "  1.4531930685043335,\n",
              "  1.483797311782837],\n",
              " [2.250602960586548,\n",
              "  3.024313449859619,\n",
              "  1.6658823490142822,\n",
              "  3.059476137161255,\n",
              "  3.0202724933624268,\n",
              "  1.82841157913208,\n",
              "  1.8779736757278442],\n",
              " [2.1881585121154785,\n",
              "  2.945589542388916,\n",
              "  1.6276354789733887,\n",
              "  2.9792191982269287,\n",
              "  2.9419875144958496,\n",
              "  1.784619927406311,\n",
              "  1.8314822912216187],\n",
              " [1.6895544528961182,\n",
              "  2.337358236312866,\n",
              "  1.3172049522399902,\n",
              "  2.351931095123291,\n",
              "  2.3116369247436523,\n",
              "  1.450189232826233,\n",
              "  1.4819270372390747],\n",
              " [2.3769028186798096,\n",
              "  3.172128915786743,\n",
              "  1.7437450885772705,\n",
              "  3.213989734649658,\n",
              "  3.18015456199646,\n",
              "  1.909398078918457,\n",
              "  1.9634350538253784],\n",
              " [2.253661870956421,\n",
              "  3.0271265506744385,\n",
              "  1.6696621179580688,\n",
              "  3.062283754348755,\n",
              "  3.0284948348999023,\n",
              "  1.8321267366409302,\n",
              "  1.878423810005188],\n",
              " [1.6762077808380127,\n",
              "  2.319418430328369,\n",
              "  1.309994101524353,\n",
              "  2.3348002433776855,\n",
              "  2.293473958969116,\n",
              "  1.4401808977127075,\n",
              "  1.4729015827178955],\n",
              " [1.102885127067566,\n",
              "  1.5952507257461548,\n",
              "  0.941979169845581,\n",
              "  1.5984562635421753,\n",
              "  1.5531647205352783,\n",
              "  1.0252352952957153,\n",
              "  1.0573878288269043],\n",
              " [2.843823194503784,\n",
              "  3.7202608585357666,\n",
              "  2.0243172645568848,\n",
              "  3.779721975326538,\n",
              "  3.75154447555542,\n",
              "  2.202606678009033,\n",
              "  2.2845849990844727],\n",
              " [1.2617636919021606,\n",
              "  1.7991783618927002,\n",
              "  1.0437153577804565,\n",
              "  1.804760456085205,\n",
              "  1.7591371536254883,\n",
              "  1.1423733234405518,\n",
              "  1.1736996173858643],\n",
              " [1.2803161144256592,\n",
              "  1.8230315446853638,\n",
              "  1.0568292140960693,\n",
              "  1.8279391527175903,\n",
              "  1.7830902338027954,\n",
              "  1.157329797744751,\n",
              "  1.1888911724090576],\n",
              " [2.2279367446899414,\n",
              "  2.997288703918457,\n",
              "  1.6528875827789307,\n",
              "  3.0319724082946777,\n",
              "  2.994248390197754,\n",
              "  1.8119584321975708,\n",
              "  1.8635002374649048],\n",
              " [2.8303959369659424,\n",
              "  3.7076728343963623,\n",
              "  2.0168190002441406,\n",
              "  3.7680246829986572,\n",
              "  3.7356927394866943,\n",
              "  2.1994736194610596,\n",
              "  2.2795629501342773],\n",
              " [1.1455618143081665,\n",
              "  1.65221107006073,\n",
              "  0.9687154293060303,\n",
              "  1.655022144317627,\n",
              "  1.60921049118042,\n",
              "  1.0572642087936401,\n",
              "  1.0908843278884888],\n",
              " [2.899756669998169,\n",
              "  3.784104824066162,\n",
              "  2.056375026702881,\n",
              "  3.846956729888916,\n",
              "  3.815859317779541,\n",
              "  2.2328639030456543,\n",
              "  2.3260068893432617],\n",
              " [1.3579946756362915,\n",
              "  1.9204109907150269,\n",
              "  1.107202410697937,\n",
              "  1.9284117221832275,\n",
              "  1.8845239877700806,\n",
              "  1.2158102989196777,\n",
              "  1.2448818683624268],\n",
              " [2.306187629699707,\n",
              "  3.088655710220337,\n",
              "  1.701799988746643,\n",
              "  3.1272666454315186,\n",
              "  3.0932271480560303,\n",
              "  1.8595616817474365,\n",
              "  1.9153170585632324],\n",
              " [2.934969902038574,\n",
              "  3.8277885913848877,\n",
              "  2.0783283710479736,\n",
              "  3.8903679847717285,\n",
              "  3.8567144870758057,\n",
              "  2.2600812911987305,\n",
              "  2.3504409790039062],\n",
              " [1.8371756076812744,\n",
              "  2.520143985748291,\n",
              "  1.4105428457260132,\n",
              "  2.5390431880950928,\n",
              "  2.498819589614868,\n",
              "  1.5493948459625244,\n",
              "  1.586450457572937],\n",
              " [1.3498252630233765,\n",
              "  1.9090893268585205,\n",
              "  1.100992202758789,\n",
              "  1.916353702545166,\n",
              "  1.871836543083191,\n",
              "  1.2095623016357422,\n",
              "  1.2378616333007812],\n",
              " [2.883747100830078,\n",
              "  3.767383098602295,\n",
              "  2.0494697093963623,\n",
              "  3.829610586166382,\n",
              "  3.7972657680511475,\n",
              "  2.2288284301757812,\n",
              "  2.3172507286071777],\n",
              " [2.1976351737976074,\n",
              "  2.957371473312378,\n",
              "  1.6335170269012451,\n",
              "  2.991379976272583,\n",
              "  2.954758405685425,\n",
              "  1.793269395828247,\n",
              "  1.8385493755340576],\n",
              " [2.800114631652832,\n",
              "  3.6742441654205322,\n",
              "  1.998997449874878,\n",
              "  3.7303802967071533,\n",
              "  3.696363687515259,\n",
              "  2.1796627044677734,\n",
              "  2.2586865425109863],\n",
              " [1.1691662073135376,\n",
              "  1.6806503534317017,\n",
              "  0.9840558171272278,\n",
              "  1.6841899156570435,\n",
              "  1.6390728950500488,\n",
              "  1.0743399858474731,\n",
              "  1.106986165046692],\n",
              " [2.6090188026428223,\n",
              "  3.4509458541870117,\n",
              "  1.8853826522827148,\n",
              "  3.500077962875366,\n",
              "  3.463671922683716,\n",
              "  2.053661823272705,\n",
              "  2.1259875297546387],\n",
              " [1.2943006753921509,\n",
              "  1.840522289276123,\n",
              "  1.063966155052185,\n",
              "  1.846099615097046,\n",
              "  1.8014202117919922,\n",
              "  1.1671772003173828,\n",
              "  1.1990619897842407],\n",
              " [2.100038528442383,\n",
              "  2.8416225910186768,\n",
              "  1.572211503982544,\n",
              "  2.8708033561706543,\n",
              "  2.8310539722442627,\n",
              "  1.7266221046447754,\n",
              "  1.7712275981903076],\n",
              " [2.920283794403076,\n",
              "  3.8103315830230713,\n",
              "  2.071265935897827,\n",
              "  3.8731298446655273,\n",
              "  3.840407133102417,\n",
              "  2.2567362785339355,\n",
              "  2.3415846824645996],\n",
              " [2.058908700942993,\n",
              "  2.78948974609375,\n",
              "  1.5495436191558838,\n",
              "  2.8179306983947754,\n",
              "  2.7795450687408447,\n",
              "  1.699122428894043,\n",
              "  1.7422889471054077],\n",
              " [1.6626906394958496,\n",
              "  2.305448055267334,\n",
              "  1.3000832796096802,\n",
              "  2.3191463947296143,\n",
              "  2.276670455932617,\n",
              "  1.4298595190048218,\n",
              "  1.4618147611618042],\n",
              " [1.9195038080215454,\n",
              "  2.620690107345581,\n",
              "  1.461436152458191,\n",
              "  2.643782377243042,\n",
              "  2.604306936264038,\n",
              "  1.6073471307754517,\n",
              "  1.6463148593902588],\n",
              " [2.264284372329712,\n",
              "  3.038337469100952,\n",
              "  1.674014925956726,\n",
              "  3.075208902359009,\n",
              "  3.040090322494507,\n",
              "  1.8358330726623535,\n",
              "  1.885428547859192],\n",
              " [1.9720250368118286,\n",
              "  2.6865923404693604,\n",
              "  1.493039846420288,\n",
              "  2.710465431213379,\n",
              "  2.6684155464172363,\n",
              "  1.643953561782837,\n",
              "  1.6829503774642944],\n",
              " [2.6100804805755615,\n",
              "  3.447611093521118,\n",
              "  1.885041356086731,\n",
              "  3.4992868900299072,\n",
              "  3.4703845977783203,\n",
              "  2.0473477840423584,\n",
              "  2.1255335807800293],\n",
              " [2.8258068561553955,\n",
              "  3.7008731365203857,\n",
              "  2.0142316818237305,\n",
              "  3.7607481479644775,\n",
              "  3.732089042663574,\n",
              "  2.1901602745056152,\n",
              "  2.2755980491638184],\n",
              " [2.3096582889556885,\n",
              "  3.0938773155212402,\n",
              "  1.7026115655899048,\n",
              "  3.132101535797119,\n",
              "  3.098118782043457,\n",
              "  1.8605817556381226,\n",
              "  1.9175556898117065],\n",
              " [2.945863723754883,\n",
              "  3.843200445175171,\n",
              "  2.085109233856201,\n",
              "  3.9037091732025146,\n",
              "  3.868817090988159,\n",
              "  2.269017219543457,\n",
              "  2.358933925628662],\n",
              " [1.2369368076324463,\n",
              "  1.7672244310379028,\n",
              "  1.0284463167190552,\n",
              "  1.7718629837036133,\n",
              "  1.7255847454071045,\n",
              "  1.1248434782028198,\n",
              "  1.1575169563293457],\n",
              " [1.1119381189346313,\n",
              "  1.605837345123291,\n",
              "  0.9466396570205688,\n",
              "  1.6087323427200317,\n",
              "  1.5630491971969604,\n",
              "  1.029948353767395,\n",
              "  1.0623284578323364],\n",
              " [2.057715892791748,\n",
              "  2.788390874862671,\n",
              "  1.5477120876312256,\n",
              "  2.817150115966797,\n",
              "  2.7775590419769287,\n",
              "  1.698392629623413,\n",
              "  1.741127371788025],\n",
              " [1.2653870582580566,\n",
              "  1.8027533292770386,\n",
              "  1.0468865633010864,\n",
              "  1.8086254596710205,\n",
              "  1.7642911672592163,\n",
              "  1.1464588642120361,\n",
              "  1.1771783828735352],\n",
              " [2.4478299617767334,\n",
              "  3.2620790004730225,\n",
              "  1.7883491516113281,\n",
              "  3.3052268028259277,\n",
              "  3.27336049079895,\n",
              "  1.9562697410583496,\n",
              "  2.0164754390716553],\n",
              " [1.552870750427246,\n",
              "  2.1672658920288086,\n",
              "  1.2316093444824219,\n",
              "  2.177753448486328,\n",
              "  2.134880304336548,\n",
              "  1.3542290925979614,\n",
              "  1.3853846788406372],\n",
              " [2.241157293319702,\n",
              "  3.008754253387451,\n",
              "  1.6601742506027222,\n",
              "  3.045130968093872,\n",
              "  3.009453535079956,\n",
              "  1.8191165924072266,\n",
              "  1.8688490390777588],\n",
              " [2.6675314903259277,\n",
              "  3.5179600715637207,\n",
              "  1.920423150062561,\n",
              "  3.573007583618164,\n",
              "  3.540950298309326,\n",
              "  2.089000940322876,\n",
              "  2.166806221008301],\n",
              " [1.6501379013061523,\n",
              "  2.288635492324829,\n",
              "  1.2941219806671143,\n",
              "  2.3025872707366943,\n",
              "  2.260690927505493,\n",
              "  1.4233416318893433,\n",
              "  1.455058217048645],\n",
              " [2.0045416355133057,\n",
              "  2.7244701385498047,\n",
              "  1.5152870416641235,\n",
              "  2.750776529312134,\n",
              "  2.712815523147583,\n",
              "  1.66611647605896,\n",
              "  1.7058682441711426],\n",
              " [2.339120864868164,\n",
              "  3.127934694290161,\n",
              "  1.722044825553894,\n",
              "  3.169191360473633,\n",
              "  3.1354238986968994,\n",
              "  1.8819059133529663,\n",
              "  1.9393181800842285],\n",
              " [2.63533091545105,\n",
              "  3.480752944946289,\n",
              "  1.9014884233474731,\n",
              "  3.53305721282959,\n",
              "  3.500981330871582,\n",
              "  2.0688393115997314,\n",
              "  2.1449098587036133],\n",
              " [2.97666597366333,\n",
              "  3.8802237510681152,\n",
              "  2.1045734882354736,\n",
              "  3.9416885375976562,\n",
              "  3.904581069946289,\n",
              "  2.2981133460998535,\n",
              "  2.3847298622131348],\n",
              " [1.1010385751724243,\n",
              "  1.593677282333374,\n",
              "  0.9390284419059753,\n",
              "  1.595826268196106,\n",
              "  1.5507235527038574,\n",
              "  1.0234031677246094,\n",
              "  1.0565128326416016],\n",
              " [1.6299904584884644,\n",
              "  2.2627644538879395,\n",
              "  1.2806051969528198,\n",
              "  2.275801658630371,\n",
              "  2.234375476837158,\n",
              "  1.408532738685608,\n",
              "  1.44057035446167],\n",
              " [2.0949630737304688,\n",
              "  2.836731195449829,\n",
              "  1.5716636180877686,\n",
              "  2.866626024246216,\n",
              "  2.829317092895508,\n",
              "  1.7241638898849487,\n",
              "  1.7707264423370361],\n",
              " [1.7312506437301636,\n",
              "  2.388437032699585,\n",
              "  1.3448972702026367,\n",
              "  2.405393600463867,\n",
              "  2.3654165267944336,\n",
              "  1.4797130823135376,\n",
              "  1.5124881267547607],\n",
              " [2.3773412704467773,\n",
              "  3.17425799369812,\n",
              "  1.7426941394805908,\n",
              "  3.214752674102783,\n",
              "  3.181914806365967,\n",
              "  1.9058154821395874,\n",
              "  1.9635422229766846],\n",
              " [1.043494462966919,\n",
              "  1.5176392793655396,\n",
              "  0.9019094109535217,\n",
              "  1.521664023399353,\n",
              "  1.4754490852355957,\n",
              "  0.9798257350921631,\n",
              "  1.015139102935791],\n",
              " [2.1783947944641113,\n",
              "  2.935997724533081,\n",
              "  1.6222633123397827,\n",
              "  2.968646287918091,\n",
              "  2.9328975677490234,\n",
              "  1.7774817943572998,\n",
              "  1.825286865234375],\n",
              " [1.0632820129394531,\n",
              "  1.543658971786499,\n",
              "  0.9142017364501953,\n",
              "  1.5457463264465332,\n",
              "  1.4998589754104614,\n",
              "  0.9942054748535156,\n",
              "  1.0276824235916138],\n",
              " [2.528559446334839,\n",
              "  3.3540382385253906,\n",
              "  1.8364497423171997,\n",
              "  3.403085947036743,\n",
              "  3.3689730167388916,\n",
              "  2.0064072608947754,\n",
              "  2.071389675140381],\n",
              " [1.6778831481933594,\n",
              "  2.323777198791504,\n",
              "  1.309158444404602,\n",
              "  2.336944818496704,\n",
              "  2.2960610389709473,\n",
              "  1.4428876638412476,\n",
              "  1.4739655256271362],\n",
              " [2.786456823348999,\n",
              "  3.6585490703582764,\n",
              "  1.990678310394287,\n",
              "  3.71608567237854,\n",
              "  3.6829159259796143,\n",
              "  2.170123815536499,\n",
              "  2.2507524490356445],\n",
              " [2.218055248260498,\n",
              "  2.984680652618408,\n",
              "  1.6481205224990845,\n",
              "  3.0193090438842773,\n",
              "  2.9846279621124268,\n",
              "  1.8033957481384277,\n",
              "  1.8552638292312622],\n",
              " [1.3876630067825317,\n",
              "  1.9590028524398804,\n",
              "  1.1257609128952026,\n",
              "  1.9658538103103638,\n",
              "  1.9209840297698975,\n",
              "  1.234682321548462,\n",
              "  1.2678228616714478],\n",
              " [2.3703696727752686,\n",
              "  3.165095090866089,\n",
              "  1.739301085472107,\n",
              "  3.206342935562134,\n",
              "  3.170146942138672,\n",
              "  1.903664469718933,\n",
              "  1.9602634906768799],\n",
              " [2.7404377460479736,\n",
              "  3.6051948070526123,\n",
              "  1.961162805557251,\n",
              "  3.6607282161712646,\n",
              "  3.6235718727111816,\n",
              "  2.1335136890411377,\n",
              "  2.2203760147094727],\n",
              " [2.8603124618530273,\n",
              "  3.7405385971069336,\n",
              "  2.035094738006592,\n",
              "  3.8008697032928467,\n",
              "  3.7685086727142334,\n",
              "  2.207710027694702,\n",
              "  2.299149513244629],\n",
              " [2.2896621227264404,\n",
              "  3.0693674087524414,\n",
              "  1.6900333166122437,\n",
              "  3.1065971851348877,\n",
              "  3.0709707736968994,\n",
              "  1.8517811298370361,\n",
              "  1.9040064811706543],\n",
              " [2.9869186878204346,\n",
              "  3.8935348987579346,\n",
              "  2.1107828617095947,\n",
              "  3.9545822143554688,\n",
              "  3.9136810302734375,\n",
              "  2.304389476776123,\n",
              "  2.3918027877807617],\n",
              " [1.342491865158081,\n",
              "  1.9013500213623047,\n",
              "  1.0969674587249756,\n",
              "  1.9066492319107056,\n",
              "  1.8630427122116089,\n",
              "  1.2020108699798584,\n",
              "  1.2324376106262207],\n",
              " [2.839634656906128,\n",
              "  3.7143983840942383,\n",
              "  2.021895408630371,\n",
              "  3.77593994140625,\n",
              "  3.7442264556884766,\n",
              "  2.200047016143799,\n",
              "  2.2834396362304688],\n",
              " [1.405381679534912,\n",
              "  1.9812419414520264,\n",
              "  1.1369140148162842,\n",
              "  1.9888815879821777,\n",
              "  1.9451408386230469,\n",
              "  1.2495605945587158,\n",
              "  1.2785272598266602],\n",
              " [2.4433910846710205,\n",
              "  3.2533063888549805,\n",
              "  1.783947467803955,\n",
              "  3.298079490661621,\n",
              "  3.263225793838501,\n",
              "  1.947204828262329,\n",
              "  2.0124168395996094],\n",
              " [2.4356706142425537,\n",
              "  3.2430660724639893,\n",
              "  1.7808955907821655,\n",
              "  3.2879292964935303,\n",
              "  3.2552568912506104,\n",
              "  1.9457073211669922,\n",
              "  2.006870746612549],\n",
              " [1.7787048816680908,\n",
              "  2.4492764472961426,\n",
              "  1.3735864162445068,\n",
              "  2.4671573638916016,\n",
              "  2.4260921478271484,\n",
              "  1.5098986625671387,\n",
              "  1.5464965105056763],\n",
              " [2.9893407821655273,\n",
              "  3.8963217735290527,\n",
              "  2.1122915744781494,\n",
              "  3.9569034576416016,\n",
              "  3.916895866394043,\n",
              "  2.30779767036438,\n",
              "  2.3940181732177734],\n",
              " [2.9056639671325684,\n",
              "  3.796950578689575,\n",
              "  2.061967611312866,\n",
              "  3.857945680618286,\n",
              "  3.82258939743042,\n",
              "  2.248988389968872,\n",
              "  2.333707809448242],\n",
              " [1.4521576166152954,\n",
              "  2.041037082672119,\n",
              "  1.1674591302871704,\n",
              "  2.048696756362915,\n",
              "  2.00565505027771,\n",
              "  1.2837104797363281,\n",
              "  1.3117702007293701],\n",
              " [1.7905930280685425,\n",
              "  2.466017723083496,\n",
              "  1.3796756267547607,\n",
              "  2.4822964668273926,\n",
              "  2.4416120052337646,\n",
              "  1.5167924165725708,\n",
              "  1.5536125898361206],\n",
              " [1.2219393253326416,\n",
              "  1.746645450592041,\n",
              "  1.020363450050354,\n",
              "  1.7504990100860596,\n",
              "  1.705195665359497,\n",
              "  1.1130690574645996,\n",
              "  1.1445667743682861],\n",
              " [2.8974061012268066,\n",
              "  3.785125732421875,\n",
              "  2.05645489692688,\n",
              "  3.846573829650879,\n",
              "  3.812267541885376,\n",
              "  2.2431325912475586,\n",
              "  2.325817584991455],\n",
              " [2.6359024047851562,\n",
              "  3.480030059814453,\n",
              "  1.900482177734375,\n",
              "  3.5335118770599365,\n",
              "  3.5021743774414062,\n",
              "  2.0719738006591797,\n",
              "  2.145566940307617],\n",
              " [1.3758248090744019,\n",
              "  1.9441754817962646,\n",
              "  1.1180557012557983,\n",
              "  1.9505095481872559,\n",
              "  1.9066364765167236,\n",
              "  1.2267547845840454,\n",
              "  1.2560789585113525],\n",
              " [2.484232187271118,\n",
              "  3.3022754192352295,\n",
              "  1.8084235191345215,\n",
              "  3.34883713722229,\n",
              "  3.3143668174743652,\n",
              "  1.9727981090545654,\n",
              "  2.0396318435668945],\n",
              " [1.6088389158248901,\n",
              "  2.2359817028045654,\n",
              "  1.2667299509048462,\n",
              "  2.2480878829956055,\n",
              "  2.2063746452331543,\n",
              "  1.3937386274337769,\n",
              "  1.4238954782485962],\n",
              " [2.61248779296875,\n",
              "  3.455070734024048,\n",
              "  1.8869174718856812,\n",
              "  3.505896806716919,\n",
              "  3.4688796997070312,\n",
              "  2.058373212814331,\n",
              "  2.1321096420288086],\n",
              " [1.126052975654602,\n",
              "  1.6248477697372437,\n",
              "  0.9563746452331543,\n",
              "  1.6270747184753418,\n",
              "  1.5818853378295898,\n",
              "  1.0408661365509033,\n",
              "  1.0741931200027466],\n",
              " [1.922974705696106,\n",
              "  2.625807285308838,\n",
              "  1.464167594909668,\n",
              "  2.648893117904663,\n",
              "  2.609790802001953,\n",
              "  1.6106114387512207,\n",
              "  1.6483319997787476],\n",
              " [2.465869665145874,\n",
              "  3.2798097133636475,\n",
              "  1.7973473072052002,\n",
              "  3.32555890083313,\n",
              "  3.289661169052124,\n",
              "  1.9663448333740234,\n",
              "  2.027164936065674],\n",
              " [1.336483359336853,\n",
              "  1.8955882787704468,\n",
              "  1.0936698913574219,\n",
              "  1.9006454944610596,\n",
              "  1.8572208881378174,\n",
              "  1.1993741989135742,\n",
              "  1.2287815809249878],\n",
              " [1.9430228471755981,\n",
              "  2.651125431060791,\n",
              "  1.4782187938690186,\n",
              "  2.676351547241211,\n",
              "  2.6355438232421875,\n",
              "  1.6233644485473633,\n",
              "  1.664156436920166],\n",
              " [2.2663872241973877,\n",
              "  3.0416650772094727,\n",
              "  1.6764817237854004,\n",
              "  3.0803372859954834,\n",
              "  3.04349684715271,\n",
              "  1.835597276687622,\n",
              "  1.8904805183410645],\n",
              " [2.9265034198760986,\n",
              "  3.821624279022217,\n",
              "  2.0740625858306885,\n",
              "  3.8817484378814697,\n",
              "  3.8471217155456543,\n",
              "  2.2552993297576904,\n",
              "  2.3473100662231445],\n",
              " [2.1932666301727295,\n",
              "  2.9545795917510986,\n",
              "  1.6331369876861572,\n",
              "  2.989602565765381,\n",
              "  2.9531021118164062,\n",
              "  1.7900402545928955,\n",
              "  1.8394086360931396],\n",
              " [2.4017577171325684,\n",
              "  3.2042088508605957,\n",
              "  1.7603179216384888,\n",
              "  3.246941328048706,\n",
              "  3.212850332260132,\n",
              "  1.9226694107055664,\n",
              "  1.9833731651306152],\n",
              " [2.8398356437683105,\n",
              "  3.7162814140319824,\n",
              "  2.0223021507263184,\n",
              "  3.7764382362365723,\n",
              "  3.7416481971740723,\n",
              "  2.1908111572265625,\n",
              "  2.2851338386535645],\n",
              " [1.5479553937911987,\n",
              "  2.1608030796051025,\n",
              "  1.228244662284851,\n",
              "  2.170837640762329,\n",
              "  2.129505157470703,\n",
              "  1.3503128290176392,\n",
              "  1.381808876991272],\n",
              " [1.8741685152053833,\n",
              "  2.569272994995117,\n",
              "  1.4324768781661987,\n",
              "  2.588533401489258,\n",
              "  2.5476157665252686,\n",
              "  1.5760632753372192,\n",
              "  1.613774061203003],\n",
              " [2.4688720703125,\n",
              "  3.2857706546783447,\n",
              "  1.8016116619110107,\n",
              "  3.3310625553131104,\n",
              "  3.2962982654571533,\n",
              "  1.9660494327545166,\n",
              "  2.0304460525512695],\n",
              " [2.966526985168457,\n",
              "  3.8688812255859375,\n",
              "  2.098987579345703,\n",
              "  3.9320831298828125,\n",
              "  3.8915607929229736,\n",
              "  2.2903339862823486,\n",
              "  2.3779916763305664],\n",
              " [1.8295423984527588,\n",
              "  2.5096967220306396,\n",
              "  1.4064538478851318,\n",
              "  2.530334711074829,\n",
              "  2.491270065307617,\n",
              "  1.547493577003479,\n",
              "  1.5821917057037354],\n",
              " [1.3213047981262207,\n",
              "  1.8737279176712036,\n",
              "  1.083204984664917,\n",
              "  1.8799045085906982,\n",
              "  1.8358733654022217,\n",
              "  1.1870694160461426,\n",
              "  1.2174875736236572],\n",
              " [1.3868210315704346,\n",
              "  1.9576021432876587,\n",
              "  1.1253606081008911,\n",
              "  1.9638513326644897,\n",
              "  1.9210983514785767,\n",
              "  1.2355846166610718,\n",
              "  1.2646270990371704],\n",
              " [1.6963372230529785,\n",
              "  2.346012830734253,\n",
              "  1.3216934204101562,\n",
              "  2.3608973026275635,\n",
              "  2.3200368881225586,\n",
              "  1.4556678533554077,\n",
              "  1.4878488779067993],\n",
              " [2.369367837905884,\n",
              "  3.164250373840332,\n",
              "  1.740126371383667,\n",
              "  3.2064454555511475,\n",
              "  3.171461820602417,\n",
              "  1.8993748426437378,\n",
              "  1.9593278169631958],\n",
              " [1.1874053478240967,\n",
              "  1.7023138999938965,\n",
              "  0.9956540465354919,\n",
              "  1.7054483890533447,\n",
              "  1.6617058515548706,\n",
              "  1.08600914478302,\n",
              "  1.1185029745101929],\n",
              " [1.0186032056808472,\n",
              "  1.4869438409805298,\n",
              "  0.8840458393096924,\n",
              "  1.4889156818389893,\n",
              "  1.442239761352539,\n",
              "  0.9579211473464966,\n",
              "  0.9956278204917908],\n",
              " [0.9364372491836548,\n",
              "  1.3804688453674316,\n",
              "  0.8288511633872986,\n",
              "  1.3806973695755005,\n",
              "  1.3360978364944458,\n",
              "  0.8935874700546265,\n",
              "  0.9345901012420654],\n",
              " [2.4084391593933105,\n",
              "  3.2104945182800293,\n",
              "  1.7638169527053833,\n",
              "  3.2544639110565186,\n",
              "  3.2212142944335938,\n",
              "  1.9231104850769043,\n",
              "  1.9876750707626343],\n",
              " [1.986129641532898,\n",
              "  2.7023425102233887,\n",
              "  1.503962516784668,\n",
              "  2.726853609085083,\n",
              "  2.6899678707122803,\n",
              "  1.6504426002502441,\n",
              "  1.6905494928359985],\n",
              " [1.907762050628662,\n",
              "  2.60559344291687,\n",
              "  1.4543412923812866,\n",
              "  2.6276886463165283,\n",
              "  2.587761402130127,\n",
              "  1.6002923250198364,\n",
              "  1.636215090751648],\n",
              " [2.9563536643981934,\n",
              "  3.8566765785217285,\n",
              "  2.092118263244629,\n",
              "  3.9166462421417236,\n",
              "  3.880873680114746,\n",
              "  2.2817909717559814,\n",
              "  2.369333267211914],\n",
              " [1.6896519660949707,\n",
              "  2.338930130004883,\n",
              "  1.3175485134124756,\n",
              "  2.3545453548431396,\n",
              "  2.3130998611450195,\n",
              "  1.4517873525619507,\n",
              "  1.4842948913574219],\n",
              " [2.4642467498779297,\n",
              "  3.2788643836975098,\n",
              "  1.7981681823730469,\n",
              "  3.3247194290161133,\n",
              "  3.2915520668029785,\n",
              "  1.9639382362365723,\n",
              "  2.02730655670166],\n",
              " [2.1295273303985596,\n",
              "  2.875431776046753,\n",
              "  1.5934988260269165,\n",
              "  2.9083030223846436,\n",
              "  2.87221622467041,\n",
              "  1.7459888458251953,\n",
              "  1.7933332920074463],\n",
              " [1.658992886543274,\n",
              "  2.299064874649048,\n",
              "  1.2989329099655151,\n",
              "  2.3122565746307373,\n",
              "  2.273137092590332,\n",
              "  1.429284691810608,\n",
              "  1.459769368171692],\n",
              " [1.957396388053894,\n",
              "  2.6679279804229736,\n",
              "  1.486818552017212,\n",
              "  2.690554141998291,\n",
              "  2.653169631958008,\n",
              "  1.6319106817245483,\n",
              "  1.6708519458770752],\n",
              " [2.8710179328918457,\n",
              "  3.752028703689575,\n",
              "  2.038814067840576,\n",
              "  3.8131299018859863,\n",
              "  3.780268430709839,\n",
              "  2.2109627723693848,\n",
              "  2.3055739402770996],\n",
              " [1.6312123537063599,\n",
              "  2.263766050338745,\n",
              "  1.2809019088745117,\n",
              "  2.276898145675659,\n",
              "  2.2362685203552246,\n",
              "  1.408134937286377,\n",
              "  1.4405760765075684],\n",
              " [2.582629442214966,\n",
              "  3.4165749549865723,\n",
              "  1.8697651624679565,\n",
              "  3.467620372772217,\n",
              "  3.4362285137176514,\n",
              "  2.0370874404907227,\n",
              "  2.107257843017578],\n",
              " [1.0445809364318848,\n",
              "  1.5201383829116821,\n",
              "  0.9013271927833557,\n",
              "  1.5211678743362427,\n",
              "  1.4763182401657104,\n",
              "  0.9773207902908325,\n",
              "  1.0143402814865112],\n",
              " [1.986864447593689,\n",
              "  2.7029573917388916,\n",
              "  1.5038959980010986,\n",
              "  2.728231906890869,\n",
              "  2.68865704536438,\n",
              "  1.651440143585205,\n",
              "  1.6921371221542358],\n",
              " [2.895728588104248,\n",
              "  3.7815654277801514,\n",
              "  2.0542407035827637,\n",
              "  3.8418595790863037,\n",
              "  3.8092639446258545,\n",
              "  2.2342450618743896,\n",
              "  2.32204008102417],\n",
              " [2.904025077819824,\n",
              "  3.7910268306732178,\n",
              "  2.0599842071533203,\n",
              "  3.853328227996826,\n",
              "  3.821580410003662,\n",
              "  2.241910219192505,\n",
              "  2.3313980102539062],\n",
              " [2.294919967651367,\n",
              "  3.0763680934906006,\n",
              "  1.6944279670715332,\n",
              "  3.1140053272247314,\n",
              "  3.0797157287597656,\n",
              "  1.853208065032959,\n",
              "  1.909454107284546],\n",
              " [2.6496479511260986,\n",
              "  3.4961745738983154,\n",
              "  1.909688949584961,\n",
              "  3.549772262573242,\n",
              "  3.5180418491363525,\n",
              "  2.081403970718384,\n",
              "  2.155938148498535],\n",
              " [1.530289888381958,\n",
              "  2.138448715209961,\n",
              "  1.2183510065078735,\n",
              "  2.148693561553955,\n",
              "  2.1064114570617676,\n",
              "  1.3396610021591187,\n",
              "  1.3688527345657349],\n",
              " [1.3318723440170288,\n",
              "  1.8878382444381714,\n",
              "  1.0899957418441772,\n",
              "  1.8936967849731445,\n",
              "  1.849187970161438,\n",
              "  1.195390224456787,\n",
              "  1.225372076034546],\n",
              " [1.762208342552185,\n",
              "  2.4271812438964844,\n",
              "  1.3637974262237549,\n",
              "  2.445885181427002,\n",
              "  2.4055514335632324,\n",
              "  1.5034562349319458,\n",
              "  1.535548210144043],\n",
              " [2.9194447994232178,\n",
              "  3.809304714202881,\n",
              "  2.068971633911133,\n",
              "  3.8693175315856934,\n",
              "  3.8330461978912354,\n",
              "  2.2424278259277344,\n",
              "  2.3398890495300293],\n",
              " [2.1356561183929443,\n",
              "  2.8853185176849365,\n",
              "  1.5958938598632812,\n",
              "  2.9168856143951416,\n",
              "  2.8766443729400635,\n",
              "  1.7499043941497803,\n",
              "  1.7972087860107422],\n",
              " [2.4765608310699463,\n",
              "  3.293884754180908,\n",
              "  1.8045423030853271,\n",
              "  3.339768648147583,\n",
              "  3.3085408210754395,\n",
              "  1.9678516387939453,\n",
              "  2.0357158184051514],\n",
              " [1.3376717567443848,\n",
              "  1.8957170248031616,\n",
              "  1.093722939491272,\n",
              "  1.9018487930297852,\n",
              "  1.8581697940826416,\n",
              "  1.1991418600082397,\n",
              "  1.230002760887146],\n",
              " [1.7549546957015991,\n",
              "  2.4197754859924316,\n",
              "  1.3586732149124146,\n",
              "  2.43558931350708,\n",
              "  2.394808053970337,\n",
              "  1.4965088367462158,\n",
              "  1.528185486793518],\n",
              " [2.933399200439453,\n",
              "  3.8273470401763916,\n",
              "  2.079449415206909,\n",
              "  3.8895671367645264,\n",
              "  3.854297399520874,\n",
              "  2.265380382537842,\n",
              "  2.352297782897949],\n",
              " [1.586459994316101,\n",
              "  2.2071027755737305,\n",
              "  1.2528282403945923,\n",
              "  2.2190229892730713,\n",
              "  2.177537679672241,\n",
              "  1.377217411994934,\n",
              "  1.4073362350463867],\n",
              " [2.2936646938323975,\n",
              "  3.0751266479492188,\n",
              "  1.6925010681152344,\n",
              "  3.113023519515991,\n",
              "  3.077110528945923,\n",
              "  1.8524736166000366,\n",
              "  1.9077733755111694],\n",
              " [2.8066468238830566,\n",
              "  3.6821844577789307,\n",
              "  2.002326726913452,\n",
              "  3.738426446914673,\n",
              "  3.7038071155548096,\n",
              "  2.178999662399292,\n",
              "  2.2637224197387695],\n",
              " [2.098951578140259,\n",
              "  2.840545415878296,\n",
              "  1.5730206966400146,\n",
              "  2.8701205253601074,\n",
              "  2.832798480987549,\n",
              "  1.7253073453903198,\n",
              "  1.7713420391082764],\n",
              " [2.9009437561035156,\n",
              "  3.7863705158233643,\n",
              "  2.056748390197754,\n",
              "  3.8470356464385986,\n",
              "  3.8163580894470215,\n",
              "  2.234635353088379,\n",
              "  2.324042797088623],\n",
              " [2.3292932510375977,\n",
              "  3.1154627799987793,\n",
              "  1.713710069656372,\n",
              "  3.1559982299804688,\n",
              "  3.122617721557617,\n",
              "  1.8768820762634277,\n",
              "  1.9316775798797607],\n",
              " [2.915987014770508,\n",
              "  3.806334972381592,\n",
              "  2.066908597946167,\n",
              "  3.8686206340789795,\n",
              "  3.8340890407562256,\n",
              "  2.253999948501587,\n",
              "  2.339909076690674],\n",
              " [2.8170533180236816,\n",
              "  3.690692186355591,\n",
              "  2.007655143737793,\n",
              "  3.750369071960449,\n",
              "  3.719783067703247,\n",
              "  2.181432008743286,\n",
              "  2.269303798675537],\n",
              " [2.2737414836883545,\n",
              "  3.0493528842926025,\n",
              "  1.6802911758422852,\n",
              "  3.0868728160858154,\n",
              "  3.0507030487060547,\n",
              "  1.842279076576233,\n",
              "  1.8927412033081055],\n",
              " [1.5459709167480469,\n",
              "  2.1584441661834717,\n",
              "  1.2277123928070068,\n",
              "  2.1691744327545166,\n",
              "  2.127690315246582,\n",
              "  1.3488612174987793,\n",
              "  1.3801144361495972],\n",
              " [2.959587574005127,\n",
              "  3.8599772453308105,\n",
              "  2.0930681228637695,\n",
              "  3.920426845550537,\n",
              "  3.8832414150238037,\n",
              "  2.278898000717163,\n",
              "  2.3725500106811523],\n",
              " [1.553689956665039,\n",
              "  2.1677486896514893,\n",
              "  1.231994390487671,\n",
              "  2.1778171062469482,\n",
              "  2.1375222206115723,\n",
              "  1.3543795347213745,\n",
              "  1.3848628997802734],\n",
              " [1.3432101011276245,\n",
              "  1.9016972780227661,\n",
              "  1.0979946851730347,\n",
              "  1.9095396995544434,\n",
              "  1.8643946647644043,\n",
              "  1.2030977010726929,\n",
              "  1.2345938682556152],\n",
              " [1.7745884656906128,\n",
              "  2.442028760910034,\n",
              "  1.370501160621643,\n",
              "  2.4611384868621826,\n",
              "  2.419987201690674,\n",
              "  1.5093697309494019,\n",
              "  1.5438662767410278],\n",
              " [2.402179718017578,\n",
              "  3.203714370727539,\n",
              "  1.7606323957443237,\n",
              "  3.246840476989746,\n",
              "  3.214238166809082,\n",
              "  1.922231912612915,\n",
              "  1.9826308488845825],\n",
              " [1.6515029668807983,\n",
              "  2.2898216247558594,\n",
              "  1.2934179306030273,\n",
              "  2.3035037517547607,\n",
              "  2.262259006500244,\n",
              "  1.4215946197509766,\n",
              "  1.4548439979553223],\n",
              " [1.4287770986557007,\n",
              "  2.0099546909332275,\n",
              "  1.1526844501495361,\n",
              "  2.0194661617279053,\n",
              "  1.9758927822113037,\n",
              "  1.2666646242141724,\n",
              "  1.2957704067230225],\n",
              " [1.1500377655029297,\n",
              "  1.65542733669281,\n",
              "  0.9710054397583008,\n",
              "  1.6595228910446167,\n",
              "  1.6137604713439941,\n",
              "  1.0577164888381958,\n",
              "  1.0935111045837402],\n",
              " [1.4320454597473145,\n",
              "  2.0156285762786865,\n",
              "  1.1546522378921509,\n",
              "  2.022624969482422,\n",
              "  1.978703260421753,\n",
              "  1.2662171125411987,\n",
              "  1.298417091369629],\n",
              " [1.7791191339492798,\n",
              "  2.447526454925537,\n",
              "  1.3752135038375854,\n",
              "  2.4654085636138916,\n",
              "  2.4267849922180176,\n",
              "  1.5113681554794312,\n",
              "  1.5461091995239258],\n",
              " [1.2486592531204224,\n",
              "  1.7824327945709229,\n",
              "  1.0367000102996826,\n",
              "  1.787384033203125,\n",
              "  1.7408162355422974,\n",
              "  1.1363129615783691,\n",
              "  1.1653187274932861],\n",
              " [1.2797956466674805,\n",
              "  1.822288990020752,\n",
              "  1.055396556854248,\n",
              "  1.8270193338394165,\n",
              "  1.7818089723587036,\n",
              "  1.1591664552688599,\n",
              "  1.1870797872543335],\n",
              " [2.328639507293701,\n",
              "  3.114795684814453,\n",
              "  1.7139239311218262,\n",
              "  3.153831720352173,\n",
              "  3.1180479526519775,\n",
              "  1.8769491910934448,\n",
              "  1.930478811264038],\n",
              " [2.5876529216766357,\n",
              "  3.423888921737671,\n",
              "  1.8714439868927002,\n",
              "  3.475342273712158,\n",
              "  3.4389488697052,\n",
              "  2.0388500690460205,\n",
              "  2.1126327514648438],\n",
              " [2.88265061378479,\n",
              "  3.7666475772857666,\n",
              "  2.0480613708496094,\n",
              "  3.8292622566223145,\n",
              "  3.7962422370910645,\n",
              "  2.2259421348571777,\n",
              "  2.3175315856933594],\n",
              " [1.54746675491333,\n",
              "  2.1591298580169678,\n",
              "  1.2281831502914429,\n",
              "  2.170919895172119,\n",
              "  2.128572463989258,\n",
              "  1.3510057926177979,\n",
              "  1.380948543548584],\n",
              " [2.081658124923706,\n",
              "  2.816879987716675,\n",
              "  1.5635221004486084,\n",
              "  2.8471264839172363,\n",
              "  2.8091392517089844,\n",
              "  1.713832974433899,\n",
              "  1.759405493736267],\n",
              " [2.9951632022857666,\n",
              "  3.9055123329162598,\n",
              "  2.114501476287842,\n",
              "  3.962581157684326,\n",
              "  3.9196722507476807,\n",
              "  2.304896116256714,\n",
              "  2.395962715148926],\n",
              " [2.9620652198791504,\n",
              "  3.8618037700653076,\n",
              "  2.0931942462921143,\n",
              "  3.920915365219116,\n",
              "  3.887991428375244,\n",
              "  2.280329704284668,\n",
              "  2.371067523956299],\n",
              " [2.672865629196167,\n",
              "  3.5235276222229004,\n",
              "  1.9232758283615112,\n",
              "  3.57840633392334,\n",
              "  3.5492265224456787,\n",
              "  2.092007637023926,\n",
              "  2.171929359436035],\n",
              " [1.5618054866790771,\n",
              "  2.177495241165161,\n",
              "  1.2371712923049927,\n",
              "  2.189171314239502,\n",
              "  2.1473469734191895,\n",
              "  1.362181305885315,\n",
              "  1.3916133642196655],\n",
              " [2.318685293197632,\n",
              "  3.1024155616760254,\n",
              "  1.7094159126281738,\n",
              "  3.143205404281616,\n",
              "  3.1056315898895264,\n",
              "  1.8682548999786377,\n",
              "  1.9241899251937866],\n",
              " [2.8362507820129395,\n",
              "  3.7116332054138184,\n",
              "  2.020113468170166,\n",
              "  3.772406816482544,\n",
              "  3.741508960723877,\n",
              "  2.1915197372436523,\n",
              "  2.2812857627868652],\n",
              " [2.1536741256713867,\n",
              "  2.9056944847106934,\n",
              "  1.6068062782287598,\n",
              "  2.9375550746917725,\n",
              "  2.900747299194336,\n",
              "  1.7636367082595825,\n",
              "  1.8084617853164673],\n",
              " [2.3091001510620117,\n",
              "  3.093327283859253,\n",
              "  1.7030442953109741,\n",
              "  3.1303534507751465,\n",
              "  3.095564603805542,\n",
              "  1.8612834215164185,\n",
              "  1.9162977933883667],\n",
              " [1.771605372428894,\n",
              "  2.4387378692626953,\n",
              "  1.368843913078308,\n",
              "  2.455303192138672,\n",
              "  2.4149508476257324,\n",
              "  1.5064027309417725,\n",
              "  1.5398008823394775],\n",
              " [2.7271509170532227,\n",
              "  3.587075710296631,\n",
              "  1.955936074256897,\n",
              "  3.642333984375,\n",
              "  3.6114540100097656,\n",
              "  2.130014657974243,\n",
              "  2.2064719200134277],\n",
              " [2.499037742614746,\n",
              "  3.31852388381958,\n",
              "  1.8193879127502441,\n",
              "  3.366037607192993,\n",
              "  3.3348381519317627,\n",
              "  1.9868569374084473,\n",
              "  2.05002498626709],\n",
              " [1.735999345779419,\n",
              "  2.3947646617889404,\n",
              "  1.3473637104034424,\n",
              "  2.4106273651123047,\n",
              "  2.3701558113098145,\n",
              "  1.4825661182403564,\n",
              "  1.5141032934188843],\n",
              " [1.3547192811965942,\n",
              "  1.9180688858032227,\n",
              "  1.1059224605560303,\n",
              "  1.9248181581497192,\n",
              "  1.8808554410934448,\n",
              "  1.2133896350860596,\n",
              "  1.2429189682006836],\n",
              " [2.694175958633423,\n",
              "  3.5475733280181885,\n",
              "  1.9367659091949463,\n",
              "  3.6028542518615723,\n",
              "  3.5719988346099854,\n",
              "  2.1078455448150635,\n",
              "  2.184152126312256],\n",
              " [2.5173375606536865,\n",
              "  3.340864658355713,\n",
              "  1.8302195072174072,\n",
              "  3.3894917964935303,\n",
              "  3.3572192192077637,\n",
              "  1.9960863590240479,\n",
              "  2.063859462738037],\n",
              " [1.8913452625274658,\n",
              "  2.586639404296875,\n",
              "  1.4442548751831055,\n",
              "  2.608423948287964,\n",
              "  2.5697340965270996,\n",
              "  1.5885151624679565,\n",
              "  1.625939130783081],\n",
              " [2.64798641204834,\n",
              "  3.4958205223083496,\n",
              "  1.908674716949463,\n",
              "  3.548633337020874,\n",
              "  3.5168585777282715,\n",
              "  2.0807509422302246,\n",
              "  2.1538033485412598],\n",
              " [1.8651288747787476,\n",
              "  2.554563045501709,\n",
              "  1.4296486377716064,\n",
              "  2.575788974761963,\n",
              "  2.5374011993408203,\n",
              "  1.568739414215088,\n",
              "  1.608747124671936],\n",
              " [2.8710994720458984,\n",
              "  3.752690076828003,\n",
              "  2.0412607192993164,\n",
              "  3.8127143383026123,\n",
              "  3.7824785709381104,\n",
              "  2.2207419872283936,\n",
              "  2.3066110610961914],\n",
              " [2.768734931945801,\n",
              "  3.636836051940918,\n",
              "  1.9813134670257568,\n",
              "  3.695612907409668,\n",
              "  3.66412091255188,\n",
              "  2.152576446533203,\n",
              "  2.2382450103759766],\n",
              " [1.9255422353744507,\n",
              "  2.6284282207489014,\n",
              "  1.4645764827728271,\n",
              "  2.649646282196045,\n",
              "  2.612175226211548,\n",
              "  1.6086891889572144,\n",
              "  1.6487613916397095],\n",
              " [1.5217701196670532,\n",
              "  2.128079414367676,\n",
              "  1.210762858390808,\n",
              "  2.1371612548828125,\n",
              "  2.0949547290802,\n",
              "  1.3296571969985962,\n",
              "  1.362015962600708],\n",
              " [1.1993927955627441,\n",
              "  1.718932867050171,\n",
              "  1.003859281539917,\n",
              "  1.7246977090835571,\n",
              "  1.6787487268447876,\n",
              "  1.0990517139434814,\n",
              "  1.1294738054275513],\n",
              " [2.739612340927124,\n",
              "  3.5980584621429443,\n",
              "  1.9627028703689575,\n",
              "  3.6562869548797607,\n",
              "  3.6263623237609863,\n",
              "  2.1348092555999756,\n",
              "  2.215261936187744],\n",
              " [1.2406892776489258,\n",
              "  1.7710883617401123,\n",
              "  1.0305653810501099,\n",
              "  1.7759639024734497,\n",
              "  1.7321587800979614,\n",
              "  1.1274043321609497,\n",
              "  1.1582742929458618],\n",
              " [2.148836374282837,\n",
              "  2.898930311203003,\n",
              "  1.6044987440109253,\n",
              "  2.930311918258667,\n",
              "  2.896092176437378,\n",
              "  1.7592524290084839,\n",
              "  1.8057059049606323],\n",
              " [2.727240800857544,\n",
              "  3.58821702003479,\n",
              "  1.9549355506896973,\n",
              "  3.6459779739379883,\n",
              "  3.617013931274414,\n",
              "  2.128957748413086,\n",
              "  2.210381031036377],\n",
              " [1.8769868612289429,\n",
              "  2.567505121231079,\n",
              "  1.4359194040298462,\n",
              "  2.589519739151001,\n",
              "  2.551229953765869,\n",
              "  1.5799858570098877,\n",
              "  1.614881992340088],\n",
              " [2.9091029167175293,\n",
              "  3.797806978225708,\n",
              "  2.0647964477539062,\n",
              "  3.8604888916015625,\n",
              "  3.828007221221924,\n",
              "  2.2467195987701416,\n",
              "  2.334066390991211],\n",
              " [1.9418648481369019,\n",
              "  2.6479592323303223,\n",
              "  1.4762401580810547,\n",
              "  2.6730563640594482,\n",
              "  2.6342737674713135,\n",
              "  1.6241952180862427,\n",
              "  1.6623170375823975],\n",
              " [1.9128762483596802,\n",
              "  2.6121294498443604,\n",
              "  1.4593316316604614,\n",
              "  2.6347496509552,\n",
              "  2.598158836364746,\n",
              "  1.6047227382659912,\n",
              "  1.641305685043335],\n",
              " [2.8965768814086914,\n",
              "  3.781059980392456,\n",
              "  2.054631233215332,\n",
              "  3.8412294387817383,\n",
              "  3.809966802597046,\n",
              "  2.2339437007904053,\n",
              "  2.32004976272583],\n",
              " [1.1988693475723267,\n",
              "  1.7190150022506714,\n",
              "  1.0036370754241943,\n",
              "  1.7224993705749512,\n",
              "  1.6772081851959229,\n",
              "  1.0967631340026855,\n",
              "  1.1281970739364624],\n",
              " [2.8675477504730225,\n",
              "  3.7472455501556396,\n",
              "  2.0386593341827393,\n",
              "  3.8084559440612793,\n",
              "  3.778815269470215,\n",
              "  2.218212127685547,\n",
              "  2.302380084991455],\n",
              " [1.776495337486267,\n",
              "  2.444683074951172,\n",
              "  1.372299313545227,\n",
              "  2.462672233581543,\n",
              "  2.421579122543335,\n",
              "  1.510996699333191,\n",
              "  1.543172836303711],\n",
              " [2.8951332569122314,\n",
              "  3.781702756881714,\n",
              "  2.0551834106445312,\n",
              "  3.842132091522217,\n",
              "  3.8108444213867188,\n",
              "  2.232578754425049,\n",
              "  2.323390007019043],\n",
              " [2.8910181522369385,\n",
              "  3.777113676071167,\n",
              "  2.0522279739379883,\n",
              "  3.837650775909424,\n",
              "  3.8060431480407715,\n",
              "  2.235682249069214,\n",
              "  2.3192076683044434],\n",
              " [1.7277671098709106,\n",
              "  2.384575605392456,\n",
              "  1.3420253992080688,\n",
              "  2.401481866836548,\n",
              "  2.3607330322265625,\n",
              "  1.4775711297988892,\n",
              "  1.5102146863937378],\n",
              " [2.0712814331054688,\n",
              "  2.8056273460388184,\n",
              "  1.5584676265716553,\n",
              "  2.83432936668396,\n",
              "  2.797495126724243,\n",
              "  1.7073283195495605,\n",
              "  1.7527129650115967],\n",
              " [1.3343108892440796,\n",
              "  1.8905787467956543,\n",
              "  1.090908169746399,\n",
              "  1.8966552019119263,\n",
              "  1.8522604703903198,\n",
              "  1.1970046758651733,\n",
              "  1.2267884016036987],\n",
              " [2.0630722045898438,\n",
              "  2.796116352081299,\n",
              "  1.5515568256378174,\n",
              "  2.824495553970337,\n",
              "  2.786181688308716,\n",
              "  1.702909231185913,\n",
              "  1.7447775602340698],\n",
              " [2.648477792739868,\n",
              "  3.4941980838775635,\n",
              "  1.9096561670303345,\n",
              "  3.5489046573638916,\n",
              "  3.5163142681121826,\n",
              "  2.0787041187286377,\n",
              "  2.153459072113037],\n",
              " [2.221529245376587,\n",
              "  2.985363245010376,\n",
              "  1.6483947038650513,\n",
              "  3.021188497543335,\n",
              "  2.9856810569763184,\n",
              "  1.8086614608764648,\n",
              "  1.8554526567459106],\n",
              " [1.1762059926986694,\n",
              "  1.6889047622680664,\n",
              "  0.9879418611526489,\n",
              "  1.6915407180786133,\n",
              "  1.647600531578064,\n",
              "  1.0797615051269531,\n",
              "  1.1111528873443604],\n",
              " [2.0487051010131836,\n",
              "  2.778005838394165,\n",
              "  1.5436654090881348,\n",
              "  2.80698561668396,\n",
              "  2.7688331604003906,\n",
              "  1.6939396858215332,\n",
              "  1.7369565963745117],\n",
              " [2.960036516189575,\n",
              "  3.860311508178711,\n",
              "  2.09427809715271,\n",
              "  3.921236515045166,\n",
              "  3.884221315383911,\n",
              "  2.2807605266571045,\n",
              "  2.3710951805114746],\n",
              " [1.809838056564331,\n",
              "  2.486717700958252,\n",
              "  1.39402437210083,\n",
              "  2.5054173469543457,\n",
              "  2.4666061401367188,\n",
              "  1.5341659784317017,\n",
              "  1.567914605140686],\n",
              " [1.3835859298706055,\n",
              "  1.9542732238769531,\n",
              "  1.1228834390640259,\n",
              "  1.9611090421676636,\n",
              "  1.9174810647964478,\n",
              "  1.2313785552978516,\n",
              "  1.2630947828292847],\n",
              " [2.6000208854675293,\n",
              "  3.438429832458496,\n",
              "  1.8798688650131226,\n",
              "  3.488818407058716,\n",
              "  3.4571077823638916,\n",
              "  2.048325300216675,\n",
              "  2.119555950164795],\n",
              " [1.4886772632598877,\n",
              "  2.086082696914673,\n",
              "  1.1905534267425537,\n",
              "  2.0953409671783447,\n",
              "  2.050812005996704,\n",
              "  1.308316707611084,\n",
              "  1.3390381336212158],\n",
              " [2.875159502029419,\n",
              "  3.7572648525238037,\n",
              "  2.0442988872528076,\n",
              "  3.818864107131958,\n",
              "  3.7876832485198975,\n",
              "  2.2227940559387207,\n",
              "  2.3101282119750977],\n",
              " [1.3358505964279175,\n",
              "  1.8931509256362915,\n",
              "  1.091562271118164,\n",
              "  1.899473786354065,\n",
              "  1.8550894260406494,\n",
              "  1.1988251209259033,\n",
              "  1.2274824380874634],\n",
              " [2.891315460205078,\n",
              "  3.7769405841827393,\n",
              "  2.0533955097198486,\n",
              "  3.8372702598571777,\n",
              "  3.8031985759735107,\n",
              "  2.232243776321411,\n",
              "  2.319492816925049],\n",
              " [2.769364833831787,\n",
              "  3.6324944496154785,\n",
              "  1.978461742401123,\n",
              "  3.692798137664795,\n",
              "  3.66273832321167,\n",
              "  2.1475300788879395,\n",
              "  2.2342567443847656],\n",
              " [2.208548069000244,\n",
              "  2.97163724899292,\n",
              "  1.6402779817581177,\n",
              "  3.006499767303467,\n",
              "  2.9690895080566406,\n",
              "  1.796476125717163,\n",
              "  1.8472394943237305],\n",
              " [1.6055068969726562,\n",
              "  2.230776071548462,\n",
              "  1.265684723854065,\n",
              "  2.2440199851989746,\n",
              "  2.202834129333496,\n",
              "  1.3922796249389648,\n",
              "  1.4224193096160889],\n",
              " [1.3011853694915771,\n",
              "  1.8478604555130005,\n",
              "  1.0707728862762451,\n",
              "  1.853297233581543,\n",
              "  1.81063711643219,\n",
              "  1.1732972860336304,\n",
              "  1.201880693435669],\n",
              " [1.5497575998306274,\n",
              "  2.1626157760620117,\n",
              "  1.2307064533233643,\n",
              "  2.1738672256469727,\n",
              "  2.13214111328125,\n",
              "  1.3519457578659058,\n",
              "  1.3826788663864136],\n",
              " [2.987276315689087,\n",
              "  3.8928370475769043,\n",
              "  2.109689712524414,\n",
              "  3.9524013996124268,\n",
              "  3.9144320487976074,\n",
              "  2.302304744720459,\n",
              "  2.3899760246276855],\n",
              " [2.5563199520111084,\n",
              "  3.3862664699554443,\n",
              "  1.853654384613037,\n",
              "  3.4359829425811768,\n",
              "  3.4029183387756348,\n",
              "  2.021364450454712,\n",
              "  2.088942050933838],\n",
              " [2.9642693996429443,\n",
              "  3.863651752471924,\n",
              "  2.0972936153411865,\n",
              "  3.925328254699707,\n",
              "  3.888845443725586,\n",
              "  2.2845563888549805,\n",
              "  2.3726840019226074],\n",
              " [1.9590238332748413,\n",
              "  2.6680264472961426,\n",
              "  1.4856867790222168,\n",
              "  2.6913139820098877,\n",
              "  2.6537508964538574,\n",
              "  1.6341813802719116,\n",
              "  1.670707106590271],\n",
              " [2.9082043170928955,\n",
              "  3.7971243858337402,\n",
              "  2.0622177124023438,\n",
              "  3.8587417602539062,\n",
              "  3.826482057571411,\n",
              "  2.2446682453155518,\n",
              "  2.3336315155029297],\n",
              " [2.9030940532684326,\n",
              "  3.7908082008361816,\n",
              "  2.0597126483917236,\n",
              "  3.85139799118042,\n",
              "  3.8214731216430664,\n",
              "  2.2396674156188965,\n",
              "  2.3292617797851562],\n",
              " [1.304408311843872,\n",
              "  1.8527418375015259,\n",
              "  1.0714929103851318,\n",
              "  1.8575270175933838,\n",
              "  1.8135510683059692,\n",
              "  1.1735559701919556,\n",
              "  1.2039378881454468],\n",
              " [1.381025791168213,\n",
              "  1.9506094455718994,\n",
              "  1.1220307350158691,\n",
              "  1.9581620693206787,\n",
              "  1.9152432680130005,\n",
              "  1.2340128421783447,\n",
              "  1.260949969291687],\n",
              " [1.3514503240585327,\n",
              "  1.9126368761062622,\n",
              "  1.1028660535812378,\n",
              "  1.9200475215911865,\n",
              "  1.8750932216644287,\n",
              "  1.2097561359405518,\n",
              "  1.2402161359786987],\n",
              " [2.333956480026245,\n",
              "  3.1242661476135254,\n",
              "  1.71869695186615,\n",
              "  3.1641476154327393,\n",
              "  3.1300177574157715,\n",
              "  1.876240611076355,\n",
              "  1.9362760782241821],\n",
              " [1.4307255744934082,\n",
              "  2.0125348567962646,\n",
              "  1.1538264751434326,\n",
              "  2.0224239826202393,\n",
              "  1.9793986082077026,\n",
              "  1.2679111957550049,\n",
              "  1.2982407808303833],\n",
              " [2.4856464862823486,\n",
              "  3.3048667907714844,\n",
              "  1.8103890419006348,\n",
              "  3.3507120609283447,\n",
              "  3.3185391426086426,\n",
              "  1.97833251953125,\n",
              "  2.0427145957946777],\n",
              " [2.9225144386291504,\n",
              "  3.8126635551452637,\n",
              "  2.071805477142334,\n",
              "  3.8756086826324463,\n",
              "  3.841848611831665,\n",
              "  2.259675979614258,\n",
              "  2.3432836532592773],\n",
              " [1.323706030845642,\n",
              "  1.8769786357879639,\n",
              "  1.0852068662643433,\n",
              "  1.8830801248550415,\n",
              "  1.8389540910720825,\n",
              "  1.1896719932556152,\n",
              "  1.2200566530227661],\n",
              " [1.6496177911758423,\n",
              "  2.2877376079559326,\n",
              "  1.2924679517745972,\n",
              "  2.299976348876953,\n",
              "  2.2586233615875244,\n",
              "  1.4218966960906982,\n",
              "  1.4525548219680786],\n",
              " [1.4235388040542603,\n",
              "  2.00483775138855,\n",
              "  1.1495156288146973,\n",
              "  2.0116729736328125,\n",
              "  1.9704294204711914,\n",
              "  1.2626612186431885,\n",
              "  1.2921217679977417],\n",
              " [2.9563381671905518,\n",
              "  3.853609800338745,\n",
              "  2.0905725955963135,\n",
              "  3.9146668910980225,\n",
              "  3.8781898021698,\n",
              "  2.273061990737915,\n",
              "  2.3663430213928223],\n",
              " [1.3902758359909058,\n",
              "  1.9619860649108887,\n",
              "  1.1270755529403687,\n",
              "  1.969417691230774,\n",
              "  1.9239226579666138,\n",
              "  1.238356351852417,\n",
              "  1.269166111946106],\n",
              " [2.4880645275115967,\n",
              "  3.302971124649048,\n",
              "  1.8112291097640991,\n",
              "  3.351011037826538,\n",
              "  3.3163344860076904,\n",
              "  1.976940393447876,\n",
              "  2.041661262512207],\n",
              " [2.9533884525299072,\n",
              "  3.851811647415161,\n",
              "  2.0915110111236572,\n",
              "  3.9137516021728516,\n",
              "  3.8750641345977783,\n",
              "  2.2777390480041504,\n",
              "  2.3687314987182617],\n",
              " [1.3218868970870972,\n",
              "  1.8743133544921875,\n",
              "  1.0842148065567017,\n",
              "  1.8809168338775635,\n",
              "  1.8365200757980347,\n",
              "  1.1887396574020386,\n",
              "  1.2178046703338623],\n",
              " [1.279085397720337,\n",
              "  1.8211023807525635,\n",
              "  1.0558390617370605,\n",
              "  1.8266669511795044,\n",
              "  1.782536506652832,\n",
              "  1.1571226119995117,\n",
              "  1.1871992349624634],\n",
              " [2.9620521068573,\n",
              "  3.864008903503418,\n",
              "  2.0951290130615234,\n",
              "  3.923435926437378,\n",
              "  3.8839073181152344,\n",
              "  2.28214693069458,\n",
              "  2.374570369720459],\n",
              " [2.581252336502075,\n",
              "  3.4191696643829346,\n",
              "  1.868410348892212,\n",
              "  3.4682939052581787,\n",
              "  3.4296035766601562,\n",
              "  2.0398595333099365,\n",
              "  2.1077842712402344],\n",
              " [2.3318028450012207,\n",
              "  3.1181395053863525,\n",
              "  1.7164109945297241,\n",
              "  3.158212661743164,\n",
              "  3.1235814094543457,\n",
              "  1.8789759874343872,\n",
              "  1.9335683584213257],\n",
              " [2.897726535797119,\n",
              "  3.782822847366333,\n",
              "  2.0578606128692627,\n",
              "  3.8460676670074463,\n",
              "  3.813349962234497,\n",
              "  2.24139142036438,\n",
              "  2.3264899253845215],\n",
              " [1.2449570894241333,\n",
              "  1.778550624847412,\n",
              "  1.0345011949539185,\n",
              "  1.7820788621902466,\n",
              "  1.7374275922775269,\n",
              "  1.131544828414917,\n",
              "  1.1625829935073853],\n",
              " [2.8245904445648193,\n",
              "  3.7005579471588135,\n",
              "  2.0135209560394287,\n",
              "  3.758416175842285,\n",
              "  3.7256288528442383,\n",
              "  2.1849451065063477,\n",
              "  2.2742972373962402],\n",
              " [2.2508463859558105,\n",
              "  3.0225448608398438,\n",
              "  1.6683719158172607,\n",
              "  3.0595719814300537,\n",
              "  3.0241572856903076,\n",
              "  1.8272401094436646,\n",
              "  1.877063274383545],\n",
              " [2.2406375408172607,\n",
              "  3.0140395164489746,\n",
              "  1.6607197523117065,\n",
              "  3.0481631755828857,\n",
              "  3.009634494781494,\n",
              "  1.8124134540557861,\n",
              "  1.8721224069595337],\n",
              " [1.7949414253234863,\n",
              "  2.466508626937866,\n",
              "  1.3842427730560303,\n",
              "  2.4850969314575195,\n",
              "  2.4453866481781006,\n",
              "  1.5223884582519531,\n",
              "  1.557665228843689],\n",
              " [2.289299488067627,\n",
              "  3.068613052368164,\n",
              "  1.690995454788208,\n",
              "  3.1065642833709717,\n",
              "  3.0731472969055176,\n",
              "  1.8501248359680176,\n",
              "  1.9042110443115234],\n",
              " [2.785057544708252,\n",
              "  3.6520938873291016,\n",
              "  1.9905009269714355,\n",
              "  3.7110025882720947,\n",
              "  3.68229079246521,\n",
              "  2.161207675933838,\n",
              "  2.24509859085083],\n",
              " [1.3699419498443604,\n",
              "  1.9374409914016724,\n",
              "  1.1153429746627808,\n",
              "  1.9427648782730103,\n",
              "  1.9004639387130737,\n",
              "  1.2234079837799072,\n",
              "  1.2527046203613281],\n",
              " [2.978776454925537,\n",
              "  3.883622884750366,\n",
              "  2.104642152786255,\n",
              "  3.945646047592163,\n",
              "  3.9049792289733887,\n",
              "  2.2953929901123047,\n",
              "  2.3880362510681152],\n",
              " [2.6848952770233154,\n",
              "  3.538809061050415,\n",
              "  1.9298328161239624,\n",
              "  3.593705177307129,\n",
              "  3.5593202114105225,\n",
              "  2.1016101837158203,\n",
              "  2.17897891998291],\n",
              " [2.246964693069458,\n",
              "  3.020718812942505,\n",
              "  1.6639662981033325,\n",
              "  3.0548768043518066,\n",
              "  3.0160186290740967,\n",
              "  1.8242263793945312,\n",
              "  1.8752038478851318],\n",
              " [2.3193771839141846,\n",
              "  3.1051652431488037,\n",
              "  1.708287000656128,\n",
              "  3.143498659133911,\n",
              "  3.1053783893585205,\n",
              "  1.8715828657150269,\n",
              "  1.9243383407592773],\n",
              " [2.824669122695923,\n",
              "  3.6995973587036133,\n",
              "  2.012995719909668,\n",
              "  3.7598628997802734,\n",
              "  3.7285828590393066,\n",
              "  2.195361852645874,\n",
              "  2.27506160736084],\n",
              " [2.655332326889038,\n",
              "  3.502199411392212,\n",
              "  1.913588047027588,\n",
              "  3.5557310581207275,\n",
              "  3.5231027603149414,\n",
              "  2.0819907188415527,\n",
              "  2.157029628753662],\n",
              " [1.7323282957077026,\n",
              "  2.3904502391815186,\n",
              "  1.3452398777008057,\n",
              "  2.40598201751709,\n",
              "  2.3653576374053955,\n",
              "  1.4809705018997192,\n",
              "  1.5127754211425781],\n",
              " [2.0972061157226562,\n",
              "  2.8396573066711426,\n",
              "  1.5721603631973267,\n",
              "  2.867766857147217,\n",
              "  2.8314177989959717,\n",
              "  1.7278170585632324,\n",
              "  1.771096110343933],\n",
              " [1.4655784368515015,\n",
              "  2.0564913749694824,\n",
              "  1.1757794618606567,\n",
              "  2.0653271675109863,\n",
              "  2.022188901901245,\n",
              "  1.2912490367889404,\n",
              "  1.3216142654418945],\n",
              " [2.3862597942352295,\n",
              "  3.1862449645996094,\n",
              "  1.7501888275146484,\n",
              "  3.228196144104004,\n",
              "  3.1938705444335938,\n",
              "  1.914395809173584,\n",
              "  1.9719115495681763],\n",
              " [1.2281707525253296,\n",
              "  1.75519859790802,\n",
              "  1.0228909254074097,\n",
              "  1.760695457458496,\n",
              "  1.7148659229278564,\n",
              "  1.11758291721344,\n",
              "  1.1498302221298218],\n",
              " [2.552155017852783,\n",
              "  3.3834354877471924,\n",
              "  1.8519307374954224,\n",
              "  3.432586193084717,\n",
              "  3.3982136249542236,\n",
              "  2.019801139831543,\n",
              "  2.088407278060913],\n",
              " [2.99467134475708,\n",
              "  3.9050486087799072,\n",
              "  2.1166257858276367,\n",
              "  3.960569143295288,\n",
              "  3.919807195663452,\n",
              "  2.3063206672668457,\n",
              "  2.398125171661377],\n",
              " [2.0538532733917236,\n",
              "  2.784466028213501,\n",
              "  1.5463005304336548,\n",
              "  2.8129422664642334,\n",
              "  2.77571964263916,\n",
              "  1.6968234777450562,\n",
              "  1.740407109260559],\n",
              " [1.571933388710022,\n",
              "  2.1905860900878906,\n",
              "  1.2442545890808105,\n",
              "  2.2016451358795166,\n",
              "  2.159874200820923,\n",
              "  1.367441177368164,\n",
              "  1.398813247680664],\n",
              " [2.5070362091064453,\n",
              "  3.3306665420532227,\n",
              "  1.824477195739746,\n",
              "  3.3783135414123535,\n",
              "  3.3463306427001953,\n",
              "  1.9907774925231934,\n",
              "  2.057079792022705],\n",
              " [2.6536507606506348,\n",
              "  3.502046823501587,\n",
              "  1.9116008281707764,\n",
              "  3.5552337169647217,\n",
              "  3.52364444732666,\n",
              "  2.0827627182006836,\n",
              "  2.158141613006592],\n",
              " [2.7433695793151855,\n",
              "  3.6080384254455566,\n",
              "  1.9652701616287231,\n",
              "  3.665018320083618,\n",
              "  3.632351875305176,\n",
              "  2.1398708820343018,\n",
              "  2.220653533935547],\n",
              " [2.263648509979248,\n",
              "  3.0383572578430176,\n",
              "  1.6748958826065063,\n",
              "  3.07564640045166,\n",
              "  3.039464235305786,\n",
              "  1.8329687118530273,\n",
              "  1.8862367868423462],\n",
              " [2.5510082244873047,\n",
              "  3.381479263305664,\n",
              "  1.8500146865844727,\n",
              "  3.4327211380004883,\n",
              "  3.3989856243133545,\n",
              "  2.020822763442993,\n",
              "  2.088298797607422],\n",
              " [1.8454378843307495,\n",
              "  2.529369592666626,\n",
              "  1.4162135124206543,\n",
              "  2.548771619796753,\n",
              "  2.5102827548980713,\n",
              "  1.5535893440246582,\n",
              "  1.5916788578033447],\n",
              " [2.8320062160491943,\n",
              "  3.713395357131958,\n",
              "  2.0187556743621826,\n",
              "  3.770082712173462,\n",
              "  3.7340643405914307,\n",
              "  2.200974702835083,\n",
              "  2.2833786010742188],\n",
              " [2.9340949058532715,\n",
              "  3.828200101852417,\n",
              "  2.0781893730163574,\n",
              "  3.890364408493042,\n",
              "  3.8567910194396973,\n",
              "  2.2675769329071045,\n",
              "  2.3518519401550293],\n",
              " [2.4121153354644775,\n",
              "  3.215869665145874,\n",
              "  1.7671688795089722,\n",
              "  3.2608413696289062,\n",
              "  3.2256205081939697,\n",
              "  1.9316153526306152,\n",
              "  1.9904460906982422],\n",
              " [2.407670259475708,\n",
              "  3.2088699340820312,\n",
              "  1.7617326974868774,\n",
              "  3.252182722091675,\n",
              "  3.2173941135406494,\n",
              "  1.9302983283996582,\n",
              "  1.9851356744766235],\n",
              " [1.1341769695281982,\n",
              "  1.635253667831421,\n",
              "  0.961287260055542,\n",
              "  1.6393764019012451,\n",
              "  1.5938397645950317,\n",
              "  1.048109531402588,\n",
              "  1.0817333459854126],\n",
              " [1.178259253501892,\n",
              "  1.6920907497406006,\n",
              "  0.9904229044914246,\n",
              "  1.6957001686096191,\n",
              "  1.650895595550537,\n",
              "  1.082184076309204,\n",
              "  1.1129565238952637],\n",
              " [2.8423938751220703,\n",
              "  3.7182836532592773,\n",
              "  2.0242204666137695,\n",
              "  3.778958559036255,\n",
              "  3.745575428009033,\n",
              "  2.1940860748291016,\n",
              "  2.285633087158203],\n",
              " [2.7196266651153564,\n",
              "  3.581716537475586,\n",
              "  1.9506502151489258,\n",
              "  3.6368677616119385,\n",
              "  3.5992021560668945,\n",
              "  2.1278023719787598,\n",
              "  2.2071218490600586],\n",
              " [2.763838529586792,\n",
              "  3.628110647201538,\n",
              "  1.9781190156936646,\n",
              "  3.686898946762085,\n",
              "  3.6572165489196777,\n",
              "  2.1491527557373047,\n",
              "  2.232438087463379],\n",
              " [1.8917330503463745,\n",
              "  2.587303400039673,\n",
              "  1.44587242603302,\n",
              "  2.6097240447998047,\n",
              "  2.569981336593628,\n",
              "  1.589398741722107,\n",
              "  1.6266342401504517],\n",
              " [1.0096787214279175,\n",
              "  1.4748940467834473,\n",
              "  0.8794603943824768,\n",
              "  1.4777159690856934,\n",
              "  1.4314203262329102,\n",
              "  0.9545813798904419,\n",
              "  0.9893187284469604],\n",
              " [2.917736053466797,\n",
              "  3.8088595867156982,\n",
              "  2.069685220718384,\n",
              "  3.870624303817749,\n",
              "  3.8377766609191895,\n",
              "  2.253045082092285,\n",
              "  2.3400325775146484],\n",
              " [1.742541790008545,\n",
              "  2.4016687870025635,\n",
              "  1.3511848449707031,\n",
              "  2.41813588142395,\n",
              "  2.3775763511657715,\n",
              "  1.4875648021697998,\n",
              "  1.5198297500610352],\n",
              " [2.4976303577423096,\n",
              "  3.318885087966919,\n",
              "  1.8181209564208984,\n",
              "  3.3651061058044434,\n",
              "  3.330613374710083,\n",
              "  1.9856207370758057,\n",
              "  2.049185276031494],\n",
              " [2.3547146320343018,\n",
              "  3.147430896759033,\n",
              "  1.7307498455047607,\n",
              "  3.188168525695801,\n",
              "  3.153243064880371,\n",
              "  1.8932127952575684,\n",
              "  1.9501503705978394],\n",
              " [1.409614086151123,\n",
              "  1.9864295721054077,\n",
              "  1.1402032375335693,\n",
              "  1.9954042434692383,\n",
              "  1.9520291090011597,\n",
              "  1.2541121244430542,\n",
              "  1.2828375101089478],\n",
              " [2.9013495445251465,\n",
              "  3.7886624336242676,\n",
              "  2.0599119663238525,\n",
              "  3.8508150577545166,\n",
              "  3.8170862197875977,\n",
              "  2.243155002593994,\n",
              "  2.327277660369873],\n",
              " [2.0535316467285156,\n",
              "  2.7836225032806396,\n",
              "  1.545355200767517,\n",
              "  2.8116743564605713,\n",
              "  2.774301052093506,\n",
              "  1.6978033781051636,\n",
              "  1.7394449710845947],\n",
              " [2.82315731048584,\n",
              "  3.6946322917938232,\n",
              "  2.01237154006958,\n",
              "  3.755153179168701,\n",
              "  3.724822998046875,\n",
              "  2.1865434646606445,\n",
              "  2.2724947929382324],\n",
              " [2.4391703605651855,\n",
              "  3.249976396560669,\n",
              "  1.781790018081665,\n",
              "  3.2938718795776367,\n",
              "  3.2586045265197754,\n",
              "  1.9503600597381592,\n",
              "  2.0088348388671875],\n",
              " [2.440237045288086,\n",
              "  3.247568368911743,\n",
              "  1.7837580442428589,\n",
              "  3.2942464351654053,\n",
              "  3.261021852493286,\n",
              "  1.9457981586456299,\n",
              "  2.0100526809692383],\n",
              " [1.7173906564712524,\n",
              "  2.3704581260681152,\n",
              "  1.3355218172073364,\n",
              "  2.3863253593444824,\n",
              "  2.3462491035461426,\n",
              "  1.4678001403808594,\n",
              "  1.5023891925811768],\n",
              " [2.480962038040161,\n",
              "  3.2972497940063477,\n",
              "  1.8071041107177734,\n",
              "  3.343679189682007,\n",
              "  3.310009002685547,\n",
              "  1.972482681274414,\n",
              "  2.037688732147217],\n",
              " [2.1528260707855225,\n",
              "  2.907332181930542,\n",
              "  1.6055331230163574,\n",
              "  2.9358034133911133,\n",
              "  2.8951683044433594,\n",
              "  1.7567793130874634,\n",
              "  1.8090336322784424],\n",
              " [1.624843716621399,\n",
              "  2.256588935852051,\n",
              "  1.2770087718963623,\n",
              "  2.269181251525879,\n",
              "  2.2271900177001953,\n",
              "  1.4041557312011719,\n",
              "  1.4351627826690674],\n",
              " [2.950152635574341,\n",
              "  3.847907066345215,\n",
              "  2.0890302658081055,\n",
              "  3.910370349884033,\n",
              "  3.8752026557922363,\n",
              "  2.2768187522888184,\n",
              "  2.3651318550109863],\n",
              " [2.9964871406555176,\n",
              "  3.904981851577759,\n",
              "  2.116318702697754,\n",
              "  3.9647793769836426,\n",
              "  3.9253990650177,\n",
              "  2.3093068599700928,\n",
              "  2.399311065673828],\n",
              " [2.1666791439056396,\n",
              "  2.9222161769866943,\n",
              "  1.6154435873031616,\n",
              "  2.955127239227295,\n",
              "  2.917248010635376,\n",
              "  1.7736984491348267,\n",
              "  1.819619059562683],\n",
              " [2.496199607849121,\n",
              "  3.3145346641540527,\n",
              "  1.818122386932373,\n",
              "  3.362111806869507,\n",
              "  3.331099510192871,\n",
              "  1.9825379848480225,\n",
              "  2.048074722290039],\n",
              " [1.124343752861023,\n",
              "  1.6223344802856445,\n",
              "  0.954269528388977,\n",
              "  1.6256327629089355,\n",
              "  1.5792232751846313,\n",
              "  1.040323257446289,\n",
              "  1.0739754438400269],\n",
              " [1.4490805864334106,\n",
              "  2.0357139110565186,\n",
              "  1.1646207571029663,\n",
              "  2.044736623764038,\n",
              "  2.0008199214935303,\n",
              "  1.2785215377807617,\n",
              "  1.3103742599487305],\n",
              " [1.2732348442077637,\n",
              "  1.8118401765823364,\n",
              "  1.051637053489685,\n",
              "  1.8174183368682861,\n",
              "  1.772334337234497,\n",
              "  1.150842547416687,\n",
              "  1.1815000772476196],\n",
              " [2.690335750579834,\n",
              "  3.542179584503174,\n",
              "  1.9342775344848633,\n",
              "  3.5967628955841064,\n",
              "  3.5682473182678223,\n",
              "  2.1004703044891357,\n",
              "  2.179577350616455],\n",
              " [2.6391665935516357,\n",
              "  3.4847869873046875,\n",
              "  1.9024747610092163,\n",
              "  3.5377633571624756,\n",
              "  3.5053746700286865,\n",
              "  2.077666997909546,\n",
              "  2.1472978591918945],\n",
              " [1.2362732887268066,\n",
              "  1.7662241458892822,\n",
              "  1.0275517702102661,\n",
              "  1.771174669265747,\n",
              "  1.7253214120864868,\n",
              "  1.1243047714233398,\n",
              "  1.1564267873764038],\n",
              " [2.567193031311035,\n",
              "  3.398597002029419,\n",
              "  1.8597644567489624,\n",
              "  3.4487574100494385,\n",
              "  3.41668701171875,\n",
              "  2.0279269218444824,\n",
              "  2.097334861755371],\n",
              " [1.3064262866973877,\n",
              "  1.855634093284607,\n",
              "  1.0737643241882324,\n",
              "  1.8599793910980225,\n",
              "  1.8175638914108276,\n",
              "  1.1779123544692993,\n",
              "  1.2060869932174683],\n",
              " [2.5158188343048096,\n",
              "  3.339855670928955,\n",
              "  1.8287017345428467,\n",
              "  3.3876454830169678,\n",
              "  3.3561348915100098,\n",
              "  1.9975786209106445,\n",
              "  2.0611743927001953],\n",
              " [1.674250602722168,\n",
              "  2.319856643676758,\n",
              "  1.3077056407928467,\n",
              "  2.333240032196045,\n",
              "  2.2927494049072266,\n",
              "  1.4393360614776611,\n",
              "  1.471526026725769],\n",
              " [2.872377872467041,\n",
              "  3.754756450653076,\n",
              "  2.0414347648620605,\n",
              "  3.814384937286377,\n",
              "  3.7853400707244873,\n",
              "  2.222551107406616,\n",
              "  2.3068580627441406],\n",
              " [2.3132119178771973,\n",
              "  3.098317861557007,\n",
              "  1.7056703567504883,\n",
              "  3.136002540588379,\n",
              "  3.102365493774414,\n",
              "  1.8642629384994507,\n",
              "  1.9214328527450562],\n",
              " [1.5382623672485352,\n",
              "  2.1477766036987305,\n",
              "  1.2210997343063354,\n",
              "  2.1582419872283936,\n",
              "  2.116785764694214,\n",
              "  1.3436367511749268,\n",
              "  1.3734767436981201],\n",
              " [2.323977470397949,\n",
              "  3.109675884246826,\n",
              "  1.7109453678131104,\n",
              "  3.148653268814087,\n",
              "  3.1147661209106445,\n",
              "  1.8676635026931763,\n",
              "  1.9288692474365234],\n",
              " [2.8278286457061768,\n",
              "  3.7049524784088135,\n",
              "  2.015728712081909,\n",
              "  3.7637252807617188,\n",
              "  3.733059883117676,\n",
              "  2.1884329319000244,\n",
              "  2.276604175567627],\n",
              " [2.897341251373291,\n",
              "  3.784695863723755,\n",
              "  2.0569605827331543,\n",
              "  3.847632884979248,\n",
              "  3.812654495239258,\n",
              "  2.2359371185302734,\n",
              "  2.3261260986328125],\n",
              " [2.2405927181243896,\n",
              "  3.0096304416656494,\n",
              "  1.6620560884475708,\n",
              "  3.0457022190093994,\n",
              "  3.013568878173828,\n",
              "  1.8156532049179077,\n",
              "  1.8709330558776855],\n",
              " [1.5858134031295776,\n",
              "  2.209641218185425,\n",
              "  1.2511205673217773,\n",
              "  2.220386028289795,\n",
              "  2.1792612075805664,\n",
              "  1.3773349523544312,\n",
              "  1.407615065574646],\n",
              " [2.8561816215515137,\n",
              "  3.738581418991089,\n",
              "  2.030919313430786,\n",
              "  3.7977752685546875,\n",
              "  3.7637417316436768,\n",
              "  2.207016706466675,\n",
              "  2.29838228225708],\n",
              " [1.8658193349838257,\n",
              "  2.5552732944488525,\n",
              "  1.4283479452133179,\n",
              "  2.575490951538086,\n",
              "  2.5363869667053223,\n",
              "  1.572776436805725,\n",
              "  1.6066538095474243],\n",
              " [1.4023693799972534,\n",
              "  1.9776320457458496,\n",
              "  1.1360424757003784,\n",
              "  1.9837661981582642,\n",
              "  1.9414461851119995,\n",
              "  1.2447935342788696,\n",
              "  1.2765494585037231],\n",
              " [2.6051242351531982,\n",
              "  3.4444034099578857,\n",
              "  1.8824260234832764,\n",
              "  3.4971835613250732,\n",
              "  3.46286678314209,\n",
              "  2.050482749938965,\n",
              "  2.124382972717285],\n",
              " [1.6766047477722168,\n",
              "  2.3200249671936035,\n",
              "  1.3098907470703125,\n",
              "  2.334796667098999,\n",
              "  2.29354190826416,\n",
              "  1.4405426979064941,\n",
              "  1.473227620124817],\n",
              " [1.422269582748413,\n",
              "  2.001955509185791,\n",
              "  1.148878574371338,\n",
              "  2.010611057281494,\n",
              "  1.9653600454330444,\n",
              "  1.262794017791748,\n",
              "  1.2926301956176758],\n",
              " [2.399538278579712,\n",
              "  3.2015058994293213,\n",
              "  1.7576744556427002,\n",
              "  3.2456095218658447,\n",
              "  3.211671829223633,\n",
              "  1.9223427772521973,\n",
              "  1.9823163747787476],\n",
              " [2.8051772117614746,\n",
              "  3.6778197288513184,\n",
              "  2.003019094467163,\n",
              "  3.735436201095581,\n",
              "  3.7060208320617676,\n",
              "  2.1759278774261475,\n",
              "  2.2612547874450684],\n",
              " [2.7006046772003174,\n",
              "  3.554462432861328,\n",
              "  1.9398432970046997,\n",
              "  3.6118059158325195,\n",
              "  3.5817692279815674,\n",
              "  2.1081700325012207,\n",
              "  2.189757823944092],\n",
              " [1.617537260055542,\n",
              "  2.246544122695923,\n",
              "  1.2730907201766968,\n",
              "  2.259578227996826,\n",
              "  2.218126058578491,\n",
              "  1.3989861011505127,\n",
              "  1.4308439493179321],\n",
              " [2.542630910873413,\n",
              "  3.374572515487671,\n",
              "  1.8472398519515991,\n",
              "  3.422661066055298,\n",
              "  3.386301040649414,\n",
              "  2.0172817707061768,\n",
              "  2.0836052894592285],\n",
              " [2.4678118228912354,\n",
              "  3.2814886569976807,\n",
              "  1.7990992069244385,\n",
              "  3.3273508548736572,\n",
              "  3.293600082397461,\n",
              "  1.9672789573669434,\n",
              "  2.029088020324707],\n",
              " [2.887188673019409,\n",
              "  3.7760555744171143,\n",
              "  2.0517191886901855,\n",
              "  3.8342623710632324,\n",
              "  3.7988452911376953,\n",
              "  2.231450080871582,\n",
              "  2.320246696472168],\n",
              " [1.7624831199645996,\n",
              "  2.4282007217407227,\n",
              "  1.363075852394104,\n",
              "  2.443962574005127,\n",
              "  2.4032015800476074,\n",
              "  1.499129056930542,\n",
              "  1.531973123550415],\n",
              " [2.658428192138672,\n",
              "  3.5052201747894287,\n",
              "  1.9138466119766235,\n",
              "  3.559826135635376,\n",
              "  3.528545379638672,\n",
              "  2.088818311691284,\n",
              "  2.1583805084228516],\n",
              " [2.119107961654663,\n",
              "  2.8642446994781494,\n",
              "  1.5874909162521362,\n",
              "  2.8961169719696045,\n",
              "  2.8570563793182373,\n",
              "  1.7429404258728027,\n",
              "  1.7869670391082764],\n",
              " [2.3045690059661865,\n",
              "  3.088123321533203,\n",
              "  1.7001140117645264,\n",
              "  3.1273369789123535,\n",
              "  3.09236478805542,\n",
              "  1.8571501970291138,\n",
              "  1.9156711101531982],\n",
              " [1.4355995655059814,\n",
              "  2.0195538997650146,\n",
              "  1.1559230089187622,\n",
              "  2.027833938598633,\n",
              "  1.984811782836914,\n",
              "  1.2698254585266113,\n",
              "  1.3003913164138794],\n",
              " [1.3827060461044312,\n",
              "  1.9531266689300537,\n",
              "  1.1231226921081543,\n",
              "  1.9597370624542236,\n",
              "  1.9152642488479614,\n",
              "  1.2325379848480225,\n",
              "  1.262486457824707],\n",
              " [1.4483273029327393,\n",
              "  2.033585786819458,\n",
              "  1.1644047498703003,\n",
              "  2.0428261756896973,\n",
              "  2.000589370727539,\n",
              "  1.280559778213501,\n",
              "  1.308879017829895],\n",
              " [2.983816623687744,\n",
              "  3.8907411098480225,\n",
              "  2.1082663536071777,\n",
              "  3.9523472785949707,\n",
              "  3.911372661590576,\n",
              "  2.303250312805176,\n",
              "  2.39093017578125],\n",
              " [2.2473437786102295,\n",
              "  3.0190622806549072,\n",
              "  1.6636641025543213,\n",
              "  3.054905652999878,\n",
              "  3.017056465148926,\n",
              "  1.8213449716567993,\n",
              "  1.8762894868850708],\n",
              " [2.00850248336792,\n",
              "  2.7294418811798096,\n",
              "  1.5171318054199219,\n",
              "  2.755720853805542,\n",
              "  2.717128276824951,\n",
              "  1.6676421165466309,\n",
              "  1.7064998149871826],\n",
              " [2.4309725761413574,\n",
              "  3.2366695404052734,\n",
              "  1.777228832244873,\n",
              "  3.2815351486206055,\n",
              "  3.247466802597046,\n",
              "  1.940185546875,\n",
              "  2.0029499530792236],\n",
              " [1.995399832725525,\n",
              "  2.7158455848693848,\n",
              "  1.5103330612182617,\n",
              "  2.740072011947632,\n",
              "  2.7022130489349365,\n",
              "  1.6597355604171753,\n",
              "  1.6980845928192139],\n",
              " [1.159233808517456,\n",
              "  1.6680140495300293,\n",
              "  0.976841151714325,\n",
              "  1.671262264251709,\n",
              "  1.626929521560669,\n",
              "  1.0674471855163574,\n",
              "  1.0991538763046265],\n",
              " [1.543988585472107,\n",
              "  2.1542115211486816,\n",
              "  1.2254326343536377,\n",
              "  2.1657633781433105,\n",
              "  2.124359130859375,\n",
              "  1.3473701477050781,\n",
              "  1.3779629468917847],\n",
              " [2.50537371635437,\n",
              "  3.327944040298462,\n",
              "  1.8216915130615234,\n",
              "  3.3747780323028564,\n",
              "  3.336174488067627,\n",
              "  1.9890727996826172,\n",
              "  2.056027889251709],\n",
              " [1.0270017385482788,\n",
              "  1.49736750125885,\n",
              "  0.8898088932037354,\n",
              "  1.4985394477844238,\n",
              "  1.453830599784851,\n",
              "  0.9661002159118652,\n",
              "  1.0014249086380005],\n",
              " [2.4442827701568604,\n",
              "  3.2515931129455566,\n",
              "  1.7845869064331055,\n",
              "  3.2961246967315674,\n",
              "  3.263124942779541,\n",
              "  1.9487509727478027,\n",
              "  2.0096826553344727],\n",
              " [1.7293274402618408,\n",
              "  2.3867883682250977,\n",
              "  1.3430486917495728,\n",
              "  2.40289044380188,\n",
              "  2.3619868755340576,\n",
              "  1.478690505027771,\n",
              "  1.5109676122665405],\n",
              " [2.4611592292785645,\n",
              "  3.275024652481079,\n",
              "  1.7969642877578735,\n",
              "  3.3213858604431152,\n",
              "  3.286008834838867,\n",
              "  1.9605255126953125,\n",
              "  2.0249290466308594],\n",
              " [1.1420143842697144,\n",
              "  1.6443517208099365,\n",
              "  0.9665892720222473,\n",
              "  1.648836612701416,\n",
              "  1.6021039485931396,\n",
              "  1.0519864559173584,\n",
              "  1.0879602432250977],\n",
              " [2.492323160171509,\n",
              "  3.3125970363616943,\n",
              "  1.8160653114318848,\n",
              "  3.3593671321868896,\n",
              "  3.3264007568359375,\n",
              "  1.9793720245361328,\n",
              "  2.045530319213867],\n",
              " [2.991361379623413,\n",
              "  3.9008095264434814,\n",
              "  2.113687753677368,\n",
              "  3.9613380432128906,\n",
              "  3.918154239654541,\n",
              "  2.305729866027832,\n",
              "  2.398176670074463],\n",
              " [1.6887465715408325,\n",
              "  2.3362159729003906,\n",
              "  1.3174448013305664,\n",
              "  2.3506593704223633,\n",
              "  2.3078629970550537,\n",
              "  1.4487378597259521,\n",
              "  1.480660319328308]]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "htrPeO9nGXMq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}