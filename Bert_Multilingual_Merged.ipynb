{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Jayoti Devi\n",
        "Fine-Tuning Bert_Multilingual Model for Quantifying News Article Similarities."
      ],
      "metadata": {
        "id": "Vtpv_DB_eCLA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Fine-Tuning Bert_Multilingual Model with Standerd dataset"
      ],
      "metadata": {
        "id": "pddzSnqafYb1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bhj8tK3WESKl"
      },
      "source": [
        "## Installing and importing libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGNVMtmuS5QS"
      },
      "source": [
        "### Using testing_set.csv and training_data.csv file for this task and both are stored in the same folder with this .ipynb file. In case you have different location , please update the path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "lE4n2nHy5kgv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f391184-1426-4d4f-afff-f77e571d47a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Attach your google drive if you are running this file using google colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Q-Mlm41yMmLS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f41b74-88a6-4f5e-a58f-df76f9305ad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "#In case you are running this notebook using google colab then uncomment the below lines otherwiese make sure it is installed in your system if running using VS code.\n",
        "\n",
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "lH_HtKSJLeWh"
      },
      "outputs": [],
      "source": [
        "#Imporint required packages.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import regex as re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sentencepiece\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import XLMRobertaConfig, XLMRobertaModel, XLMRobertaTokenizer\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# LIBRARY_PATH = '/content/drive/MyDrive/Colab Notebooks/training_data.csv'\n",
        "\n",
        "# Seed\n",
        "seed = 123 #setting fix value for the rendom seeds to ensure rendom number generator used in Pytorch\n",
        "torch.manual_seed(seed) #to ensure any operation used in Pytorch is deterministic when same seed is used.\n",
        "torch.cuda.manual_seed(seed) #setting the seeds for Pytorch rendom number generator.\n",
        "torch.cuda.manual_seed_all(seed) #setting renodom seed for all GPU.\n",
        "np.random.seed(seed)#setting renodm seed for NumPy rendom number generator.\n",
        "random.seed(seed) #setting seeds for Python stnaderd rendom libray\n",
        "torch.backends.cudnn.benchmark = False # cunfiguring CUDA deep nural network library in Pytorch and setting false to ensure that cuDNN will determine the best algorithem.\n",
        "torch.backends.cudnn.deterministic = True #to ensure  deterministic way."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataFilePath = \"/content/drive/MyDrive/Colab Notebooks/training_data.csv\"\n"
      ],
      "metadata": {
        "id": "THd1NIT78E1z"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ix5rLCPFh-iU",
        "outputId": "6a444d3d-f88c-4fac-eabd-fafb9f33b7e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0 url1_lang url2_lang  \\\n",
              "3              3        en        en   \n",
              "5              5        en        en   \n",
              "6              6        en        en   \n",
              "7              7        en        en   \n",
              "8              8        en        en   \n",
              "...          ...       ...       ...   \n",
              "2926        2926        ar        ar   \n",
              "2928        2928        ar        ar   \n",
              "2929        2929        ar        ar   \n",
              "2931        2931        ar        ar   \n",
              "2932        2932        ar        ar   \n",
              "\n",
              "                                                  link1  \\\n",
              "3     https://gadgets.ndtv.com/apps/news/zomato-uber...   \n",
              "5     https://jewishjournal.com/news/nation/309033/w...   \n",
              "6     https://www.financialexpress.com/market/commod...   \n",
              "7     https://www.opednews.com/articles/The-biggest-...   \n",
              "8     https://www.amazon.com/dp/154173016X/?tag=slat...   \n",
              "...                                                 ...   \n",
              "2926                 https://www.omandaily.om/?p=786245   \n",
              "2928               https://www.albawabhnews.com/3962000   \n",
              "2929  https://www.masrawy.com/news/news_egypt/detail...   \n",
              "2931  http://www.ahewar.org/news/s.news.asp?nid=3945815   \n",
              "2932  https://www.arabstoday.net/329/201953-%D8%A7%D...   \n",
              "\n",
              "                                                  link2  \\\n",
              "3     https://gadgets.ndtv.com/internet/news/indian-...   \n",
              "5     https://jewishjournal.com/online/309000/jewish...   \n",
              "6     https://www.financialexpress.com/india-news/de...   \n",
              "7     https://nypost.com/2019/12/31/the-lefts-consta...   \n",
              "8     https://www.amazon.com/dp/1610399579/?tag=slat...   \n",
              "...                                                 ...   \n",
              "2926  https://www.masrawy.com/news/news_publicaffair...   \n",
              "2928  https://www.vetogate.com/3959908/%D8%B6%D8%A8%...   \n",
              "2929   https://www.elwatannews.com/news/details/4728427   \n",
              "2931  https://arabic.sputniknews.com/arab_world/2020...   \n",
              "2932  https://www.al-madina.com/article/678086/دولية...   \n",
              "\n",
              "                                               ia_link1  \\\n",
              "3     https://web.archive.org/web/gadgets.ndtv.com/a...   \n",
              "5     https://web.archive.org/web/jewishjournal.com/...   \n",
              "6     https://web.archive.org/web/www.financialexpre...   \n",
              "7     https://web.archive.org/web/www.opednews.com/a...   \n",
              "8     https://web.archive.org/web/www.amazon.com/dp/...   \n",
              "...                                                 ...   \n",
              "2926  https://web.archive.org/web/www.omandaily.om/?...   \n",
              "2928  https://web.archive.org/web/www.albawabhnews.c...   \n",
              "2929  https://web.archive.org/web/www.masrawy.com/ne...   \n",
              "2931  https://web.archive.org/web/www.ahewar.org/new...   \n",
              "2932  https://web.archive.org/web/www.arabstoday.net...   \n",
              "\n",
              "                                               ia_link2  Geography  Entities  \\\n",
              "3     https://web.archive.org/web/gadgets.ndtv.com/i...   1.000000  2.333333   \n",
              "5     https://web.archive.org/web/jewishjournal.com/...   1.250000  1.750000   \n",
              "6     https://web.archive.org/web/www.financialexpre...   3.000000  4.000000   \n",
              "7     https://web.archive.org/web/nypost.com/2019/12...   2.333333  3.666667   \n",
              "8     https://web.archive.org/web/www.amazon.com/dp/...   1.000000  4.000000   \n",
              "...                                                 ...        ...       ...   \n",
              "2926  https://web.archive.org/web/www.masrawy.com/ne...   1.000000  1.000000   \n",
              "2928  https://web.archive.org/web/www.vetogate.com/3...   2.000000  3.000000   \n",
              "2929  https://web.archive.org/web/www.elwatannews.co...   1.000000  2.000000   \n",
              "2931  https://web.archive.org/web/arabic.sputniknews...   1.000000  2.000000   \n",
              "2932  https://web.archive.org/web/www.al-madina.com/...   1.000000  1.000000   \n",
              "\n",
              "          Time  Narrative   Overall     Style      Tone        id_1  \\\n",
              "3     2.666667   1.666667  2.000000  1.666667  1.666667  1576314516   \n",
              "5     1.250000   1.750000  2.000000  1.000000  1.250000  1484189120   \n",
              "6     1.333333   4.000000  3.666667  1.333333  1.333333  1484034982   \n",
              "7     1.333333   3.666667  3.333333  1.333333  1.333333  1484188439   \n",
              "8     4.000000   1.000000  4.000000  1.000000  1.000000  1484011751   \n",
              "...        ...        ...       ...       ...       ...         ...   \n",
              "2926  3.000000   1.000000  1.000000  1.000000  1.000000  1592085965   \n",
              "2928  3.000000   2.000000  4.000000  1.000000  1.000000  1566447642   \n",
              "2929  4.000000   4.000000  4.000000  1.000000  1.000000  1644102363   \n",
              "2931  1.000000   1.000000  1.000000  1.000000  3.000000  1640724079   \n",
              "2932  1.000000   1.000000  1.000000  1.000000  2.000000  1552392654   \n",
              "\n",
              "            id_2                                             text_1  \\\n",
              "3     1576455088  Uber has sold its online food-ordering busines...   \n",
              "5     1484113136  The Simon Wiesenthal Center called on the Whit...   \n",
              "6     1483785560  The government on Wednesday slashed import dut...   \n",
              "7     1484378177  From The Guardian\\n\\nFrom Boeing to Whole Food...   \n",
              "8     1483920335  Review\\n\\nCrimeReads best nonfiction crime boo...   \n",
              "...          ...                                                ...   \n",
              "2926  1567830952  الطيران العماني يواصل رحلات الشحن لتعزيز الأمن...   \n",
              "2928  1582626838  تمكن رجال مباحث القاهرة تحت إشراف اللواء أشرف ...   \n",
              "2929  1594269711  كتب- مصراوي:\\n\\nأكدت الشركة المتحدة للخدمات ال...   \n",
              "2931  1641509405  التبرع للموقع - ادعمونا\\n\\n\\n\\n\\n\\nالموقع الرئ...   \n",
              "2932  1552514260  حكمت محكمة جنايات مدينة طشقند على غولنارا كريم...   \n",
              "\n",
              "                                                 text_2  \\\n",
              "3     Rapid digitisation and growth in both online b...   \n",
              "5     Jewish groups have expressed shock and horror ...   \n",
              "6     Delhiites continued to remain in grip of cold ...   \n",
              "7     Police have arrested a 38-year-old black man f...   \n",
              "8     Enter the characters you see below\\n\\nSorry, w...   \n",
              "...                                                 ...   \n",
              "2926  مسقط - أ ش أ\\n\\nقام الطيران العماني، الناقل ال...   \n",
              "2928  ألقى رجال المباحث بمديرية أمن القاهرة برئاسة ا...   \n",
              "2929  قال الإمام الأكبر الدكتور أحمد الطيب، شيخ الأز...   \n",
              "2931  وقال نصر الله في الشريط المصور: \"إننا اليوم لس...   \n",
              "2932  حكمت محكمة جنايات مدينة طشقند على غولنارا كريم...   \n",
              "\n",
              "                                                title_1  \\\n",
              "3     Zomato Buys Uber's Food Delivery Business in I...   \n",
              "5     Wiesenthal Center Calls for FBI Task Force to ...   \n",
              "6     Big cut on import duty on crude and refined pa...   \n",
              "7     The biggest business con of 2019: fleecing wor...   \n",
              "8     The Compatriots: The Brutal and Chaotic Histor...   \n",
              "...                                                 ...   \n",
              "2926  الطيران العماني يواصل رحلات الشحن لتعزيز الأمن...   \n",
              "2928  القبض على عنصر إجرامي تخصص في سرقة السيارات با...   \n",
              "2929  المتحدة للخدمات الإعلامية: نثمن دور الأزهر كإش...   \n",
              "2931                                 وكالة أنباء اليسار   \n",
              "2932   الحكم على ابنة أول رئيس لأوزبكستان بالسجن 13عاما   \n",
              "\n",
              "                                                title_2  \n",
              "3     Indian Online Food Delivery Market to Hit $8 B...  \n",
              "5               Jewish Groups React to Monsey Stabbings  \n",
              "6     Delhi weather update: Delhiites shiver at 2.4 ...  \n",
              "7     The left’s constant victimhood olympics is a g...  \n",
              "8                                            Amazon.com  \n",
              "...                                                 ...  \n",
              "2926  الطيران العماني يسيّر رحلات شحن إلى الهند لتوف...  \n",
              "2928  ضبط ترزى لتصنيعه 1600 كمامة ورداء طبى بدون تصر...  \n",
              "2929  شيخ الأزهر: التوكل على الله دون أخذٍ بالأسباب ...  \n",
              "2931  \"انتهى الأمر\"... \"حزب الله\" ينشر فيديو لأهداف ...  \n",
              "2932         13عاما بالسجن على ابنة أول رئيس لأوزبكستان  \n",
              "\n",
              "[1580 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6132b6fb-6a60-4a0f-a8b7-3ca78eb62e82\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>url1_lang</th>\n",
              "      <th>url2_lang</th>\n",
              "      <th>link1</th>\n",
              "      <th>link2</th>\n",
              "      <th>ia_link1</th>\n",
              "      <th>ia_link2</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Entities</th>\n",
              "      <th>Time</th>\n",
              "      <th>Narrative</th>\n",
              "      <th>Overall</th>\n",
              "      <th>Style</th>\n",
              "      <th>Tone</th>\n",
              "      <th>id_1</th>\n",
              "      <th>id_2</th>\n",
              "      <th>text_1</th>\n",
              "      <th>text_2</th>\n",
              "      <th>title_1</th>\n",
              "      <th>title_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>https://gadgets.ndtv.com/apps/news/zomato-uber...</td>\n",
              "      <td>https://gadgets.ndtv.com/internet/news/indian-...</td>\n",
              "      <td>https://web.archive.org/web/gadgets.ndtv.com/a...</td>\n",
              "      <td>https://web.archive.org/web/gadgets.ndtv.com/i...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>1576314516</td>\n",
              "      <td>1576455088</td>\n",
              "      <td>Uber has sold its online food-ordering busines...</td>\n",
              "      <td>Rapid digitisation and growth in both online b...</td>\n",
              "      <td>Zomato Buys Uber's Food Delivery Business in I...</td>\n",
              "      <td>Indian Online Food Delivery Market to Hit $8 B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>https://jewishjournal.com/news/nation/309033/w...</td>\n",
              "      <td>https://jewishjournal.com/online/309000/jewish...</td>\n",
              "      <td>https://web.archive.org/web/jewishjournal.com/...</td>\n",
              "      <td>https://web.archive.org/web/jewishjournal.com/...</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1484189120</td>\n",
              "      <td>1484113136</td>\n",
              "      <td>The Simon Wiesenthal Center called on the Whit...</td>\n",
              "      <td>Jewish groups have expressed shock and horror ...</td>\n",
              "      <td>Wiesenthal Center Calls for FBI Task Force to ...</td>\n",
              "      <td>Jewish Groups React to Monsey Stabbings</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>https://www.financialexpress.com/market/commod...</td>\n",
              "      <td>https://www.financialexpress.com/india-news/de...</td>\n",
              "      <td>https://web.archive.org/web/www.financialexpre...</td>\n",
              "      <td>https://web.archive.org/web/www.financialexpre...</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1484034982</td>\n",
              "      <td>1483785560</td>\n",
              "      <td>The government on Wednesday slashed import dut...</td>\n",
              "      <td>Delhiites continued to remain in grip of cold ...</td>\n",
              "      <td>Big cut on import duty on crude and refined pa...</td>\n",
              "      <td>Delhi weather update: Delhiites shiver at 2.4 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>https://www.opednews.com/articles/The-biggest-...</td>\n",
              "      <td>https://nypost.com/2019/12/31/the-lefts-consta...</td>\n",
              "      <td>https://web.archive.org/web/www.opednews.com/a...</td>\n",
              "      <td>https://web.archive.org/web/nypost.com/2019/12...</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1484188439</td>\n",
              "      <td>1484378177</td>\n",
              "      <td>From The Guardian\\n\\nFrom Boeing to Whole Food...</td>\n",
              "      <td>Police have arrested a 38-year-old black man f...</td>\n",
              "      <td>The biggest business con of 2019: fleecing wor...</td>\n",
              "      <td>The left’s constant victimhood olympics is a g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>https://www.amazon.com/dp/154173016X/?tag=slat...</td>\n",
              "      <td>https://www.amazon.com/dp/1610399579/?tag=slat...</td>\n",
              "      <td>https://web.archive.org/web/www.amazon.com/dp/...</td>\n",
              "      <td>https://web.archive.org/web/www.amazon.com/dp/...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1484011751</td>\n",
              "      <td>1483920335</td>\n",
              "      <td>Review\\n\\nCrimeReads best nonfiction crime boo...</td>\n",
              "      <td>Enter the characters you see below\\n\\nSorry, w...</td>\n",
              "      <td>The Compatriots: The Brutal and Chaotic Histor...</td>\n",
              "      <td>Amazon.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2926</th>\n",
              "      <td>2926</td>\n",
              "      <td>ar</td>\n",
              "      <td>ar</td>\n",
              "      <td>https://www.omandaily.om/?p=786245</td>\n",
              "      <td>https://www.masrawy.com/news/news_publicaffair...</td>\n",
              "      <td>https://web.archive.org/web/www.omandaily.om/?...</td>\n",
              "      <td>https://web.archive.org/web/www.masrawy.com/ne...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1592085965</td>\n",
              "      <td>1567830952</td>\n",
              "      <td>الطيران العماني يواصل رحلات الشحن لتعزيز الأمن...</td>\n",
              "      <td>مسقط - أ ش أ\\n\\nقام الطيران العماني، الناقل ال...</td>\n",
              "      <td>الطيران العماني يواصل رحلات الشحن لتعزيز الأمن...</td>\n",
              "      <td>الطيران العماني يسيّر رحلات شحن إلى الهند لتوف...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2928</th>\n",
              "      <td>2928</td>\n",
              "      <td>ar</td>\n",
              "      <td>ar</td>\n",
              "      <td>https://www.albawabhnews.com/3962000</td>\n",
              "      <td>https://www.vetogate.com/3959908/%D8%B6%D8%A8%...</td>\n",
              "      <td>https://web.archive.org/web/www.albawabhnews.c...</td>\n",
              "      <td>https://web.archive.org/web/www.vetogate.com/3...</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1566447642</td>\n",
              "      <td>1582626838</td>\n",
              "      <td>تمكن رجال مباحث القاهرة تحت إشراف اللواء أشرف ...</td>\n",
              "      <td>ألقى رجال المباحث بمديرية أمن القاهرة برئاسة ا...</td>\n",
              "      <td>القبض على عنصر إجرامي تخصص في سرقة السيارات با...</td>\n",
              "      <td>ضبط ترزى لتصنيعه 1600 كمامة ورداء طبى بدون تصر...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2929</th>\n",
              "      <td>2929</td>\n",
              "      <td>ar</td>\n",
              "      <td>ar</td>\n",
              "      <td>https://www.masrawy.com/news/news_egypt/detail...</td>\n",
              "      <td>https://www.elwatannews.com/news/details/4728427</td>\n",
              "      <td>https://web.archive.org/web/www.masrawy.com/ne...</td>\n",
              "      <td>https://web.archive.org/web/www.elwatannews.co...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1644102363</td>\n",
              "      <td>1594269711</td>\n",
              "      <td>كتب- مصراوي:\\n\\nأكدت الشركة المتحدة للخدمات ال...</td>\n",
              "      <td>قال الإمام الأكبر الدكتور أحمد الطيب، شيخ الأز...</td>\n",
              "      <td>المتحدة للخدمات الإعلامية: نثمن دور الأزهر كإش...</td>\n",
              "      <td>شيخ الأزهر: التوكل على الله دون أخذٍ بالأسباب ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2931</th>\n",
              "      <td>2931</td>\n",
              "      <td>ar</td>\n",
              "      <td>ar</td>\n",
              "      <td>http://www.ahewar.org/news/s.news.asp?nid=3945815</td>\n",
              "      <td>https://arabic.sputniknews.com/arab_world/2020...</td>\n",
              "      <td>https://web.archive.org/web/www.ahewar.org/new...</td>\n",
              "      <td>https://web.archive.org/web/arabic.sputniknews...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1640724079</td>\n",
              "      <td>1641509405</td>\n",
              "      <td>التبرع للموقع - ادعمونا\\n\\n\\n\\n\\n\\nالموقع الرئ...</td>\n",
              "      <td>وقال نصر الله في الشريط المصور: \"إننا اليوم لس...</td>\n",
              "      <td>وكالة أنباء اليسار</td>\n",
              "      <td>\"انتهى الأمر\"... \"حزب الله\" ينشر فيديو لأهداف ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2932</th>\n",
              "      <td>2932</td>\n",
              "      <td>ar</td>\n",
              "      <td>ar</td>\n",
              "      <td>https://www.arabstoday.net/329/201953-%D8%A7%D...</td>\n",
              "      <td>https://www.al-madina.com/article/678086/دولية...</td>\n",
              "      <td>https://web.archive.org/web/www.arabstoday.net...</td>\n",
              "      <td>https://web.archive.org/web/www.al-madina.com/...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1552392654</td>\n",
              "      <td>1552514260</td>\n",
              "      <td>حكمت محكمة جنايات مدينة طشقند على غولنارا كريم...</td>\n",
              "      <td>حكمت محكمة جنايات مدينة طشقند على غولنارا كريم...</td>\n",
              "      <td>الحكم على ابنة أول رئيس لأوزبكستان بالسجن 13عاما</td>\n",
              "      <td>13عاما بالسجن على ابنة أول رئيس لأوزبكستان</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1580 rows × 20 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6132b6fb-6a60-4a0f-a8b7-3ca78eb62e82')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6132b6fb-6a60-4a0f-a8b7-3ca78eb62e82 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6132b6fb-6a60-4a0f-a8b7-3ca78eb62e82');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1068f5af-69c3-41c2-9122-33fc5debf8e1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1068f5af-69c3-41c2-9122-33fc5debf8e1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1068f5af-69c3-41c2-9122-33fc5debf8e1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ab4866f6-8346-4e25-91bd-9b289a330396\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('training_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ab4866f6-8346-4e25-91bd-9b289a330396 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('training_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "training_data",
              "summary": "{\n  \"name\": \"training_data\",\n  \"rows\": 1580,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 856,\n        \"min\": 3,\n        \"max\": 2932,\n        \"num_unique_values\": 1580,\n        \"samples\": [\n          2352,\n          1548,\n          2250\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url1_lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"en\",\n          \"de\",\n          \"fr\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url2_lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"en\",\n          \"de\",\n          \"fr\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"link1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1576,\n        \"samples\": [\n          \"https://euobserver.com/green-deal/147691?utm_source=euobs&utm_medium=rss\",\n          \"https://www.thestar.com.my/news/regional/2020/01/02/halim-perdanakusuma-airport-back-to-normal-after-massive-flooding\",\n          \"https://wiadomosci.wp.pl/ptasia-grypa-wykryto-ognisko-grozne-dla-ludzi-6462996770326657a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"link2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1453,\n        \"samples\": [\n          \"https://www.wp.de/staedte/bottrop/bottrop-100-stunden-im-einsatz-fuer-die-gute-sache-id228033781.html\",\n          \"http://kcpw.org/blog/local-news/politics-local-news/2020-01-02/senate-impeachment-trial-and-a-citizen-referendum-on-state-tax-reform/\",\n          \"http://www.capitalcoahuila.com.mx/show/comediante-kathy-griffin-se-casa-en-ao-nuevo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ia_link1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1576,\n        \"samples\": [\n          \"https://web.archive.org/web/euobserver.com/green-deal/147691?utm_source=euobs&utm_medium=rss\",\n          \"https://web.archive.org/web/www.thestar.com.my/news/regional/2020/01/02/halim-perdanakusuma-airport-back-to-normal-after-massive-flooding\",\n          \"https://web.archive.org/web/wiadomosci.wp.pl/ptasia-grypa-wykryto-ognisko-grozne-dla-ludzi-6462996770326657a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ia_link2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1453,\n        \"samples\": [\n          \"https://web.archive.org/web/www.wp.de/staedte/bottrop/bottrop-100-stunden-im-einsatz-fuer-die-gute-sache-id228033781.html\",\n          \"https://web.archive.org/web/kcpw.org/blog/local-news/politics-local-news/2020-01-02/senate-impeachment-trial-and-a-citizen-referendum-on-state-tax-reform/\",\n          \"https://web.archive.org/web/www.capitalcoahuila.com.mx/show/comediante-kathy-griffin-se-casa-en-ao-nuevo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Geography\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1627291610939356,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          2.0,\n          3.25,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Entities\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1108191597266168,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          3.0,\n          1.2,\n          2.333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9267573379331435,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          1.571428571,\n          1.75,\n          2.666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Narrative\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0832544110268651,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          2.0,\n          3.25,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Overall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.121045402352774,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          3.0,\n          3.857142857,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Style\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8835547860040831,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          4.0,\n          1.285714286,\n          1.666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tone\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8407367153486796,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          3.666666667,\n          2.142857143,\n          1.666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29615206,\n        \"min\": 1483758771,\n        \"max\": 1766871114,\n        \"num_unique_values\": 1580,\n        \"samples\": [\n          1512801291,\n          1484759168,\n          1483758774\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30883255,\n        \"min\": 1469729742,\n        \"max\": 1766951389,\n        \"num_unique_values\": 1463,\n        \"samples\": [\n          1580472854,\n          1483993058,\n          1484106773\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1500,\n        \"samples\": [\n          \"Rok 2019 przeszed\\u0142 do historii. W nocy powitali\\u015bmy 2020, w zwi\\u0105zku z czym gwiazdy ch\\u0119tnie chwali\\u0142y si\\u0119 na Instagramie zdj\\u0119ciami i relacjami z imprez, na kt\\u00f3rych si\\u0119 bawi\\u0142y. Zalicza si\\u0119 do nich m.in. Ma\\u0142gorzata Rozenek, kt\\u00f3ra od kilku dni jest w Zakopanem. Nasz\\u0105 uwag\\u0119 zwr\\u00f3ci\\u0142a stylizacja prezenterki. Naprawd\\u0119 nale\\u017c\\u0105 jej si\\u0119 wielkie brawa.\\n\\nREKLAMA\\n\\nSylwestrowa stylizacja Ma\\u0142gorzaty Rozenek\\n\\nOdk\\u0105d wysz\\u0142o na jaw, \\u017ce Ma\\u0142gorzata jest w ci\\u0105\\u017cy, nie ma dnia, by w sieci nie powsta\\u0142 news na jej temat. Jest obecnie wyj\\u0105tkowo popularn\\u0105 gwiazd\\u0105, a co za tym idzie, bardzo dobrze op\\u0142acan\\u0105 je\\u015bli chodzi o wsp\\u00f3\\u0142prace na Instagramie. Nie dziwi wi\\u0119c fakt, \\u017ce na jednym z ostatnich zdj\\u0119\\u0107 oznaczy\\u0142a mark\\u0119, w kt\\u00f3rej sukience sp\\u0119dzi\\u0142a sylwestrow\\u0105 noc.\\n\\nW lata 20. wkraczamy w klimacie lat 20., \\u017cycz\\u0105c Wam wszelkiej pomy\\u015blno\\u015bci i \\u017ceby ten rok by\\u0142 dla Was tak szczeg\\u00f3lny jak dla nas. Szampa\\u0144skiej zabawy i trudnego poranka. Do siego roku - podpisa\\u0142a post.\\n\\nMusimy przyzna\\u0107, \\u017ce Rozenek wygl\\u0105da\\u0142a naprawd\\u0119 \\u015bwietnie! Kreacja nie by\\u0142a przesadzona, a elegancka suknia idealnie wpasowa\\u0142a si\\u0119 w klimat sylwestra. Nasz\\u0105 uwag\\u0119 zwr\\u00f3ci\\u0142o r\\u00f3wnie\\u017c rozci\\u0119cie po lewej stronie. Nie ka\\u017cda kobieta by si\\u0119 na to odwa\\u017cy\\u0142a. Fani nie kryli zachwyt\\u00f3w. Suknia oczywi\\u015bcie delikatnie podkre\\u015bli\\u0142a ci\\u0105\\u017cowy brzuszek gwiazdy.\\n\\nPani Ma\\u0142gosiu, wygl\\u0105da pani jak milion dolar\\u00f3w.\\n\\nPi\\u0119knie!\\n\\nWow!\\n\\nA Wy jak oceniacie look Ma\\u0142gorzaty?\\n\\nCW\\n\\nMa\\u0142gorzata Rozenek w wywiadzie na temat in vitro.\",\n          \"\\n\\n\\n\\n\\u201cVamos a trabajar estos 16 meses 24x7, sin vacaciones que se toman usualmente en diciembre, enero y febrero (\\u2026) tenemos que trabajar estos 16 meses para el pa\\u00eds y lo mejor y es hacerlo sin receso parlamentario\\u201d, dijo Roel al programa Elecciones 2020 de Andina Canal Online.\\n\\n\\n\\n\\n\\nEl candidato dijo tambi\\u00e9n que de tener una bancada, Acci\\u00f3n Popular, plantear\\u00e1 que la elecci\\u00f3n de los miembros del Tribunal Constitucional (TC) se realice mediante un concurso p\\u00fablico de m\\u00e9ritos a fin que no haya \\u201crepartija o dedocracia\\u201d. \\\"Eso tiene que cambiar\\\", afirm\\u00f3.\\n\\n\\n\\n\\n\\nOtra de las iniciativas que impulsar\\u00e1 su partido, indic\\u00f3, ser\\u00e1 la eliminaci\\u00f3n de la inmunidad parlamentaria de arresto y de proceso para evitar el mal uso que se ha hecho de esta prerrogativa.\\n\\n\\n\\n\\n\\n\\u201cVamos a cambiar la noci\\u00f3n de inmunidad que se asocia mucho con la impunidad. Vamos a cambiar este concepto de figura jur\\u00eddica a fin que quienes entren al Congreso con procesos penales e investigaciones y si son arrestados o condenados, se vayan inmediatamente\\u201d, expres\\u00f3.\\n\\n\\n\\n\\n\\nLa reforma de las Administradoras de Fondos de Pensiones (AFP) es otra de las iniciativas que impulsar\\u00e1 Acci\\u00f3n Popular de llegar al pr\\u00f3ximo Parlamento. En este caso, la propuesta que estas compa\\u00f1\\u00edas funcionen conforme a gesti\\u00f3n por resultados.\\n\\n\\n\\n\\n\\n\\u201cSi tu fondo gana, ellos ganan su comisi\\u00f3n, pero si tu fondo no genera ganancias ellos no tendr\\u00e1n beneficios. Por qu\\u00e9 solo las AFP van a tener utilidades, por qu\\u00e9 van ser las \\u00fanicas que rentabilicen sobre nuestra pensi\\u00f3n\\u201d, cuestion\\u00f3.\\n\\n\\n\\n\\n\\nEn cuanto a la lucha contra la corrupci\\u00f3n, Roel Alva, resalt\\u00f3 que se pierden millones de soles por este flagelo que afecta el buen funcionamiento de todo el aparato estatal. En sentido, sostuvo que se debe perfeccionar el art\\u00edculo 41 de la Constituci\\u00f3n para que todos los delitos de corrupci\\u00f3n sean imprescriptibles.\\n\\n\\n\\n\\n\\nDe igual forma, indic\\u00f3, la declaraci\\u00f3n de intereses debe ser obligatoria para todos los altos funcionario como los miembros del TC, presidente de la Rep\\u00fablica, congresistas o ministros.\\n\\n\\n\\n\\n\\n(FIN) RMCH/CVC\\n\\n\\n\\n\\n\\nM\\u00e1s en Andina\\n\\n\\n\\n\\n\\nLa @FiscaliaPeru allana local de la universidad Alas Peruanas en el marco de la investigaci\\u00f3n fiscal al exsecretario general de Fuerza Popular, Joaqu\\u00edn Ram\\u00edrez https://t.co/4RG7ktlACy pic.twitter.com/49xYsbhWAg \\u2014 Agencia Andina (@Agencia_Andina) January 15, 2020\\n\\n\\n\\nEl candidato por Lima con el n\\u00famero 5 por Acci\\u00f3n Popular (AP), Luis Roel Alva, propuso que el pr\\u00f3ximo Congreso, que completar\\u00e1 el periodo del anterior hasta julio de 2021, trabaje sin receso durante 16 meses.Publicado: 15/1/2020\",\n          \"Enjoy your new year weekend with some street food and exhibitions happening around Doha. We have listed a few of the interesting events happening in Qatar.\\n\\nMetro Street Food \\u2013 Food Fest\\n\\nFirst ever outdoor metro event hosted by Q sports, with combination of food, beverages and a mini golf course setup at the DECC Metro station.\\n\\nWhen: Jan 1 \\u2013 April 2020\\n\\nWeekdays: 12:30 pm \\u2013 11 pm; Weekends: 2 pm \\u2013 12 midnight\\n\\nWhere: DECC Metro Station\\n\\nFor details, click here\\n\\n\\\"It is our right to dream\\\" exhibition\\n\\nKatara will host \\\"It is our right to dream\\\" exhibition by the sculptor Sabhi Chtioui\\n\\nWhen: Until January 18, 2020; 10 am - 10pm\\n\\nWhere: Building 47, Katara Cultural Village\\n\\nFor details, click here\\n\\nQatar, India & the Gulf: History, Culture and Society Exhibition\\n\\nQatar National library to exhibit connections between India, Qatar and the Gulf over 4,600 years as a part of the Qatar India 2019 Year of the Culture. The exhibition reveals hows this ancient relationship has influenced their history, culture and society in profound and surprising ways.\\n\\nWhen: Until February 29, 2020; 3pm \\u2013 8pm\\n\\nWhere: Qatar National Library\\n\\nFor details, click here\\n\\n\\\"Suspicion\\\" Exhibition\\n\\nKatara Culutural Village welcomes everyone one to attend the opening of the \\\"Suspicion\\\"exhibition by the Palestinian artist Nameer Qassim.\\n\\nWhen: 2 January, 2020; 12:00pm\\n\\nWhere: Building 18, Gallery 2; Katara\\n\\nFor details, click here\\n\\nSpring Festival at Souq Waqif and Souq Al Wakrah\\n\\nThe festival includes circus show, parades and mind and skills games. Popular groups from different countries entertain visitors with cultural presentation such as folk dances and songs with the accompaniment of native musical instruments. The festival features around 60 games and rides in the two souqs. Visitors can see wild animals like lion and tiger at the circus shows.\\n\\nWhen: Until January 4; 4pm until 10pm.\\n\\nWhere: Souq Waqif and Souq Al Wakrah\\n\\nFor details click here\\n\\nMahaseel Festival\\n\\nThe biggest edition of Mahaseel Festival is going on at Katara with more than 40 stalls to buy vegetables, flowers, honey, dairy and meat products offered by local companies at discounted prices. There is also a large area where children can enjoy inflatables in addition to a giant tent where they can play various computer games such as VR games making the festival a one-stop-shop for families.\\n\\nWhen: Open every day from 9am to 9pm until December 28, after which it will be open on Thursdays, Fridays and Saturdays until March 31.\\n\\nWhere: Building 22, Katara\\n\\nFor details, click here\\n\\nDifferent Dimension: An Energetic Place\\n\\nThe exhibition showcases 11 fascinating works by contemporary abstract artist Hala El Attar and marks a number of firsts for the young artist. El Attar visually manifests energy through her unique take on fluid art integrating different mediums and styles to achieve artworks that burst with colour and life.\\n\\nWhen: The exhibition is open for public viewing until January 20 from 10am to 10pm\\n\\nWhere: W Doha\\u2019s Art 29 gallery\\n\\nFor details click here\\n\\nStar Wars Activation Booth\\n\\nDiscover your side at the Star Wars Activation booth with the launch of Star Wars: The Rise of Sky-walker! Doha Festival City has set up a total of eight zones with each zone having different activities. The booth is open to all ages and no purchase is required. It requires registration and is on first come first served.\\n\\nWhen: December 12 \\u2013 January 12, 2020; 3pm-10pm\\n\\nWhere: Doha Festival City - Center Court Ground floor\\n\\nFor details, click here\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1402,\n        \"samples\": [\n          \"STATEN ISLAND, N.Y. \\u2013 A Graniteville man cut his losses midway through jury selection on Monday and pleaded guilty to sexually abusing a young girl two years ago.\\n\\nMarco Rodriguez, 43, subjected the victim to sexual contact between May 28 and 30, 2018, an indictment said.\\n\\nThe defendant touched the girl\\u2019s private parts, said a criminal complaint.\\n\\nThe girl was under age 13 then.\\n\\nRodriguez was arrested about a month later on June 26, 2018, based on an investigation.\\n\\nShe and the defendant knew each other, said police.\\n\\nRodriguez was charged with felony and misdemeanor counts of sexual abuse, and misdemeanor counts of forcible touching and child endangerment.\\n\\nRodriguez, over prosecutors\\u2019 objection, accepted the court\\u2019s offer to plead guilty to the top count of first-degree sexual abuse. In exchange, he\\u2019ll be sentenced to two years in prison and 10 years\\u2019 post-release supervision.\\n\\nThe defendant must register with state authorities as a sexual offender, and a full order of protection will be issued in the victim\\u2019s favor.\\n\\nProsecutors had originally offered the defendant a two-year sentence to plead guilty to the felony sex-abuse charge but withdrew the offer before the start of jury selection, said a source familiar with the case.\\n\\nRodriguez had shown no interest in the offer before Monday with jury selection underway, the source said.\\n\\nThe defendant also pleaded guilty to a misdemeanor count of criminal contempt for violating an order of protection in a separate case in September 2018.\\n\\nHe will be sentenced to one year behind bars to run concurrently to the sex-abuse conviction.\\n\\nThe defendant will be sentenced on March 23 in state Supreme Court, St. George.\\n\\nRodriguez, who is not a U.S. citizen, could face deportation after serving his sentence.\\n\\nDefense lawyer Michael Cirigliano declined comment on the cases.\\n\\nAssistant District Attorney John Signoriello is prosecuting them.\",\n          \"\\n\\n\\n\\n\\n\\nZamora, Mich, 01 de enero de 2020.- Los cuerpos sin vida de dos hombres que presentaban orificios producidos por proyectil de arma de fuego fueron localizados en una brecha que conduce al Relleno Sanitario, hecho que ya investigan las autoridades.\\n\\n\\n\\nEl hallazgo fue realizado el \\u00faltimo d\\u00eda del 2019 por conductores que circulaban sobre la carretera Zamora-La Barca, reportaron al 911 dos personas tiradas, por lo que se movilizaron los elementos de la Polic\\u00eda Municipal y localizaron a los dos hombres sin vida.\\n\\n\\n\\nPosteriormente se acordon\\u00f3 dicho sitio y comenzaron los peritajes donde se dijo que uno de los fallecidos, vest\\u00eda pantal\\u00f3n camuflado, as\\u00ed playera color azul y botas t\\u00e1cticas, mientras el otro estaba sin camisa y tra\\u00eda un pantal\\u00f3n azul y botas t\\u00e1cticas color negro.\\n\\n\\n\\nLos cuerpos fueron trasladados en al servicio m\\u00e9dico forense para realizar la autopsia que indica la ley.\\n\\n\\n\\nAsimismo se detall\\u00f3 que ambas v\\u00edctimas est\\u00e1n en calidad de desconocidas hasta el momento.\\n\\n\",\n          \"ST. PETERSBURG, Fla. \\u2014 It's been a perfect weather start to 2020 for the Tampa Bay region.\\n\\nWarmer Thursday/Friday\\n\\nRain early Saturday\\n\\nSEE BELOW: See our 7-day forecast \\u25bc\\n\\nSkies will be mostly clear overnight into early Thursday. Temperatures will be seasonably cool, dropping to the 50s to mid 40s.\\n\\nThursday will be mostly sunny with warmer highs in the upper 70s due to a southeast breeze.\\n\\nFriday will be partly cloudy and warm with highs in the low 80s.\\n\\nThe next cold front will push a line of showers through late Friday night into early Saturday morning.\\n\\nThat will set us up for a cooler weekend ahead.\\n\\n7-day forecast\\n\\nWe want your pictures!\\n\\nShow us what the weather looks like in your neighborhood. Your photo could end up on Spectrum Bay News 9.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1529,\n        \"samples\": [\n          \"'It Warmed My Heart': Sachin Tendulkar Rings in New Year With an Inspirational Message on Twitter\",\n          \"Providence Lost by Paul Lay review \\u2013 the rise and fall of Oliver Cromwell\\u2019s Protectorate\",\n          \"Regierung verabschiedet Stellungnahme betreffend die Ab\\u00e4nderung des Krankenversicherungsgesetzes und des Unfallversicherungsgesetzes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1420,\n        \"samples\": [\n          \"Iran Summons Swiss Envoy over US \\u2018Warmongering Statements\\u2019\",\n          \"Amid opposition, Centre planning to make process of granting citizenship online to bypass states\",\n          \"The future is bamboo - Jamaicans encouraged to go green with multiuse wonder plant\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "#Reading csv file using pandas from gogole drive location\n",
        "training_data = pd.read_csv(training_dataFilePath)\n",
        "training_data = training_data.dropna() #Removing null rows from training data frame.\n",
        "training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "V1JWq5jymzwr"
      },
      "outputs": [],
      "source": [
        "#Function to merge columns and returning the transformed data frame.\n",
        "def merge_clean_columns(df):\n",
        "    \"\"\"\n",
        "    Merge multiple columns into one and clean text\n",
        "    \"\"\"\n",
        "    df['merge1'] = df['text_1'].astype(str) + ', ' \\\n",
        "        + df['title_1'].astype(str)\n",
        "\n",
        "    df['merge2'] = df['text_2'].astype(str) + ', ' \\\n",
        "        + df['title_2'].astype(str)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "KNWWDBCcmwSh"
      },
      "outputs": [],
      "source": [
        "processed_data = merge_clean_columns(training_data) #Calling merge_clean_columns function.\n",
        "# split into train and development\n",
        "train, dev = train_test_split(processed_data, test_size=0.1, random_state = 42) #spliting processed data frame in to train and dev using train_test_split method from sklearn.model_selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZMXmR0_QNzQ"
      },
      "source": [
        "## 2. Model on data text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "9NYsKPM8QKjF"
      },
      "outputs": [],
      "source": [
        "\n",
        "# set parameters\n",
        "max_len = 512 #aetting the maximum sequence lenght of input text\n",
        "batch_size = 5 #setting batch size for training example in each pass\n",
        "lr = 5e-6 #setting the learning rate for the optimizer to control the model's weight update after each interation.\n",
        "weight_decay = 1e-4 #setting weight decay to prevent overfitting, given value add the panlty to the loss function here which is small.\n",
        "num_epochs = 8 # setting th number of epoces\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "LM33gaFg7rRE"
      },
      "outputs": [],
      "source": [
        "#Defining function get_data_loader for modeling\n",
        "def get_data_loader(data, batch_size_flg = True): #using flag to indicate whether use or not use the bach processing, if is is true means use bach processing.\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\") #loading pre-trained BERT tokenizer.\n",
        "  input_ids, attention_masks, labels = [], [], [] #lists to hold the processed inputs\n",
        "  for idx, row in data.iterrows(): #loop iteration over the row of the data\n",
        "      text1, text2 = row['merge1'], row['merge2']\n",
        "      encode_dict = tokenizer(text1,text2,          #tokenizning text1 and text2 to create the input for the bert_mulitilingual.\n",
        "                                  max_length=max_len,\n",
        "                                  padding='max_length',  #padding the sequences in max length if they are less.\n",
        "                                  truncation=True,\n",
        "                                  add_special_tokens=True\n",
        "                                  )\n",
        "\n",
        "      input_ids.append(encode_dict['input_ids']) # appending \"input_ids\" and \"attention_mask\" in their respective list.\n",
        "      attention_masks.append(encode_dict['attention_mask'])\n",
        "      # model is used to predict all labels?? -> should we convert to only 1 label\n",
        "      labels.append([float(x) for x in [row['Geography'],row['Entities'],row['Time'],row['Narrative'],row['Overall'],row['Style'],row['Tone']]])\n",
        "#converting all the inputs in Pytorch tensors.\n",
        "  input_ids = torch.tensor(input_ids)\n",
        "  attention_masks = torch.tensor(attention_masks)\n",
        "  labels = torch.tensor(labels)\n",
        "#creating TensorDataset, wrapper of three tenosors in a format to process efficinetly by DateLoader.\n",
        "  data = TensorDataset(input_ids, attention_masks, labels)\n",
        "  if(batch_size_flg):\n",
        "      data_loader = DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "  else:\n",
        "      data_loader = DataLoader(data)\n",
        "  return data_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "vg56V9t08atc"
      },
      "outputs": [],
      "source": [
        "#creating DataLoader objects for both training and development dataset.\n",
        "train_data_loader = get_data_loader(train)\n",
        "eval_data_loader = get_data_loader(dev, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "rTDTaFQmsA8O"
      },
      "outputs": [],
      "source": [
        "#Defining class Custom_BERT with construction and one formward method.\n",
        "class Custom_BERT(nn.Module):\n",
        "    def __init__(self, model, hidden_size):\n",
        "        super(Custom_BERT, self).__init__()\n",
        "        self.reg_model = model\n",
        "        #defining four fully connected layers(linear) in costum model.\n",
        "        self.fc1 = nn.Linear(hidden_size, 512)\n",
        "        # self.dropout = nn.Dropout(0.2)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 100)\n",
        "        self.fc4 = nn.Linear(100,7) # currently processes the 7 labels that we have defined for 7 output types\n",
        "        #defining activation function applying non-linear trasformaition to the data after it passes through the linear layers.\n",
        "        self.activation1 = nn.GELU()\n",
        "        self.activation2 = nn.GELU()\n",
        "        self.activation3 = nn.GELU()\n",
        "    #defining forward method to tell how the data flow throught the training\n",
        "    def forward(self, input_ids, attention_masks):\n",
        "        output1 = self.reg_model(input_ids, attention_masks)[1]\n",
        "        # output2 =\n",
        "        # x = self.dropout(x)\n",
        "        # logits1= s\n",
        "        logits1= self.fc3(self.activation2(self.fc2(self.activation1(self.fc1(output1)))))\n",
        "        logits1 = self.fc4(logits1) #pridicted value of output of the all seven layers.\n",
        "\n",
        "\n",
        "        return logits1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "1qwnWRlUanEu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "#Functing to calculate pearson values.\n",
        "def calculate_pearson_per_aspect(predictions, labels):\n",
        "    \"\"\"\n",
        "    Calculates Pearson correlation for each aspect (output dimension).\n",
        "\n",
        "    Args:\n",
        "    - predictions: numpy array of shape (N, 7) containing model predictions.\n",
        "    - labels: numpy array of shape (N, 7) containing ground truth scores.\n",
        "\n",
        "    Returns:\n",
        "    - correlations: List of Pearson correlation coefficients for each aspect.\n",
        "    \"\"\"\n",
        "    correlations = []\n",
        "    predictions = np.array(predictions)\n",
        "    labels = np.array(labels)\n",
        "    for i in range(predictions.shape[1]):  # Loop through each of the 7 output scores\n",
        "        r, _ = pearsonr(predictions[:, i], labels[:, i])\n",
        "        correlations.append(r)\n",
        "    return correlations\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "oWuuxWC9wvSs"
      },
      "outputs": [],
      "source": [
        "#initializing lists to track losses and pearson scores.\n",
        "train_losses=[] #loss foe each epoch during training\n",
        "val_losses =[] #loss for each epoch during validation.\n",
        "pearson_scores = [] #pearson correlation for the model's predication on the validation set.\n",
        "#Defining function to evaluate the model on given dataset.\n",
        "def evaluate(model, data_loader,criterion):\n",
        "  model.eval()\n",
        "  overall_pred, overall_true = [], []\n",
        "  with torch.no_grad():\n",
        "    val_loss_sum=0\n",
        "    for idx, (ids, att_msks, y) in enumerate(data_loader):\n",
        "      ids, att_msks, y = ids.to(device), att_msks.to(device), y.to(device)\n",
        "      y_pred = model(ids, att_msks)\n",
        "      loss = criterion(torch.squeeze(y_pred),torch.squeeze(y))\n",
        "      val_loss_sum += loss.item()\n",
        "\n",
        "      y_pred, y = torch.squeeze(y_pred).cpu().numpy().tolist(), torch.squeeze(y).cpu().numpy().tolist()\n",
        "      overall_pred.append(y_pred)\n",
        "      overall_true.append(y)\n",
        "  val_losses.append(val_loss_sum/len(data_loader))\n",
        "  return overall_pred, overall_true\n",
        "\n",
        "\n",
        "\n",
        "#Defining function to train the data.\n",
        "def train(model, model_path, train_data_loader, eval_data_loader, optimizer, loss_weights, epochs):\n",
        "  model.train()\n",
        "  criterion = nn.MSELoss()\n",
        "  best_pearson = 0\n",
        "  for i in range(epochs):\n",
        "    train_loss_sum = 0\n",
        "    for idx, (ids, att_msks, y) in enumerate(train_data_loader):\n",
        "      print(idx)\n",
        "      ids, att_msks, y = ids.to(device), att_msks.to(device), y.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      y_pred = model(ids, att_msks)\n",
        "      y_pred, y = torch.squeeze(y_pred), torch.squeeze(y) ## required because y is a vector\n",
        "      # loss = weighted_loss(y_pred, y, criterion, loss_weights)\n",
        "      print(y_pred)\n",
        "      loss = criterion(y_pred,y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_loss_sum += loss.item()\n",
        "\n",
        "    train_losses.append(train_loss_sum/len(train_data_loader))\n",
        "    print(f\"Loss at epoch {i}: {train_loss_sum:.4f}\")\n",
        "\n",
        "    ## Determine best epoch model using correlation coefficient for Overall in dev data\n",
        "    eval_pred_overall, eval_true_overall = evaluate(model, eval_data_loader,criterion)\n",
        "\n",
        "    pearson_correlations = calculate_pearson_per_aspect(eval_pred_overall, eval_true_overall)\n",
        "    for i, r in enumerate(pearson_correlations):\n",
        "        print(f\"Pearson correlation for aspect {i+1}: {r:.4f}\")\n",
        "\n",
        "    # Optionally, calculate the mean Pearson correlation\n",
        "    curr_pearson = np.mean(pearson_correlations)\n",
        "    print(f\"Mean Pearson correlation: {curr_pearson:.4f}\")\n",
        "    pearson_scores.append(curr_pearson)\n",
        "\n",
        "\n",
        "    # curr_pearson = np.corrcoef(eval_pred_overall, eval_true_overall)[0][1]\n",
        "    # print(curr_pearson)\n",
        "    if curr_pearson > best_pearson:\n",
        "      best_pearson = curr_pearson\n",
        "      torch.save(model.state_dict(), model_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loEOryJU53q8"
      },
      "source": [
        "### Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "IWCRvSxyPE29"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache() #using this function to free up the unused cache.\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")  #checking whether GPU is available or not ant according setting the device on which PyTorch run the computation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "LgNiobCSPrwb"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel, BertConfig, BertTokenizer\n",
        "\n",
        "# Load pre-trained multilingual BERT model and configuration\n",
        "pre_trained_model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "config = BertConfig.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Get the hidden size from the model configuration\n",
        "hidden_size = config.hidden_size\n",
        "\n",
        "# Define loss weights (assume 7 output classes)\n",
        "overall_weight = 0.25\n",
        "loss_weights = [overall_weight if i == 4 else (1-overall_weight)/6 for i in range(7)]\n",
        "\n",
        "# Initialize custom model\n",
        "model = Custom_BERT(pre_trained_model, hidden_size)\n",
        "model.to(device)\n",
        "\n",
        "# Path  to save the trained model\n",
        "model_path = \"BERT_Multilingual_0.25_overall_loss.pth\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ldBSUrA68uK",
        "outputId": "2f787ba2-f95d-43f9-90c0-e90a7f2b464d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        [1.0389, 1.5559, 0.9239, 1.5406, 1.4873, 1.0168, 1.0229],\n",
            "        [1.5454, 2.2096, 1.2543, 2.1931, 2.1464, 1.3842, 1.3854]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "142\n",
            "tensor([[2.8955, 3.8429, 2.0774, 3.8524, 3.8337, 2.2286, 2.3074],\n",
            "        [3.0595, 4.0384, 2.1746, 4.0449, 4.0127, 2.3499, 2.4247],\n",
            "        [1.9368, 2.7028, 1.4992, 2.6889, 2.6508, 1.6421, 1.6588],\n",
            "        [2.0771, 2.8739, 1.5863, 2.8643, 2.8268, 1.7352, 1.7553],\n",
            "        [3.0477, 4.0192, 2.1669, 4.0292, 3.9995, 2.3320, 2.4149]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "143\n",
            "tensor([[1.3445, 1.9563, 1.1263, 1.9371, 1.8882, 1.2437, 1.2440],\n",
            "        [1.1188, 1.6625, 0.9792, 1.6464, 1.5941, 1.0793, 1.0817],\n",
            "        [3.0548, 4.0349, 2.1710, 4.0371, 4.0029, 2.3476, 2.4234],\n",
            "        [1.1805, 1.7433, 1.0196, 1.7256, 1.6745, 1.1244, 1.1255],\n",
            "        [2.6472, 3.5585, 1.9302, 3.5612, 3.5383, 2.0804, 2.1419]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "144\n",
            "tensor([[1.0953, 1.6315, 0.9635, 1.6143, 1.5632, 1.0599, 1.0622],\n",
            "        [2.8382, 3.7790, 2.0428, 3.7857, 3.7664, 2.1989, 2.2670],\n",
            "        [2.9488, 3.9085, 2.1095, 3.9155, 3.8933, 2.2815, 2.3461],\n",
            "        [3.0540, 4.0322, 2.1703, 4.0368, 4.0097, 2.3439, 2.4170],\n",
            "        [2.6954, 3.6126, 1.9577, 3.6146, 3.5926, 2.1169, 2.1720]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "145\n",
            "tensor([[1.4133, 2.0439, 1.1700, 2.0218, 1.9782, 1.2899, 1.2882],\n",
            "        [0.8753, 1.3410, 0.8155, 1.3252, 1.2737, 0.8891, 0.8999],\n",
            "        [2.4016, 3.2649, 1.7834, 3.2603, 3.2332, 1.9387, 1.9726],\n",
            "        [1.0544, 1.5785, 0.9358, 1.5601, 1.5095, 1.0297, 1.0327],\n",
            "        [2.7524, 3.6797, 1.9933, 3.6834, 3.6633, 2.1524, 2.2070]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "146\n",
            "tensor([[2.5679, 3.4643, 1.8842, 3.4635, 3.4380, 2.0424, 2.0846],\n",
            "        [0.8571, 1.3179, 0.8038, 1.3036, 1.2508, 0.8780, 0.8879],\n",
            "        [1.0269, 1.5416, 0.9190, 1.5256, 1.4749, 1.0104, 1.0116],\n",
            "        [2.1934, 3.0146, 1.6593, 3.0043, 2.9741, 1.8102, 1.8298],\n",
            "        [1.0370, 1.5553, 0.9264, 1.5381, 1.4881, 1.0184, 1.0204]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "147\n",
            "tensor([[0.8583, 1.3190, 0.8039, 1.3031, 1.2528, 0.8755, 0.8873],\n",
            "        [2.3022, 3.1458, 1.7249, 3.1391, 3.1098, 1.8796, 1.9043],\n",
            "        [2.6170, 3.5192, 1.9130, 3.5207, 3.4976, 2.0657, 2.1157],\n",
            "        [0.9808, 1.4800, 0.8894, 1.4650, 1.4130, 0.9764, 0.9791],\n",
            "        [2.7857, 3.7158, 2.0150, 3.7201, 3.7017, 2.1667, 2.2269]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "148\n",
            "tensor([[1.9642, 2.7350, 1.5208, 2.7223, 2.6868, 1.6657, 1.6742],\n",
            "        [1.1417, 1.6937, 0.9981, 1.6772, 1.6275, 1.1013, 1.0974],\n",
            "        [2.9823, 3.9419, 2.1303, 3.9511, 3.9333, 2.2966, 2.3604],\n",
            "        [2.7838, 3.7160, 2.0142, 3.7210, 3.7025, 2.1723, 2.2271],\n",
            "        [1.9068, 2.6632, 1.4845, 2.6491, 2.6139, 1.6294, 1.6332]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "149\n",
            "tensor([[2.7644, 3.6958, 2.0068, 3.7022, 3.6794, 2.1668, 2.2168],\n",
            "        [0.9818, 1.4824, 0.8910, 1.4678, 1.4177, 0.9778, 0.9796],\n",
            "        [1.9972, 2.7775, 1.5436, 2.7650, 2.7324, 1.6865, 1.6977],\n",
            "        [0.9919, 1.4962, 0.8993, 1.4819, 1.4307, 0.9863, 0.9875],\n",
            "        [2.4941, 3.3789, 1.8460, 3.3787, 3.3542, 2.0042, 2.0355]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "150\n",
            "tensor([[1.3880, 2.0142, 1.1619, 1.9964, 1.9531, 1.2821, 1.2732],\n",
            "        [0.8639, 1.3280, 0.8126, 1.3150, 1.2634, 0.8844, 0.8939],\n",
            "        [2.7571, 3.6876, 2.0050, 3.6930, 3.6799, 2.1556, 2.2100],\n",
            "        [0.9188, 1.4021, 0.8500, 1.3884, 1.3366, 0.9308, 0.9344],\n",
            "        [1.1948, 1.7627, 1.0350, 1.7457, 1.6984, 1.1388, 1.1343]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "151\n",
            "tensor([[2.7653, 3.6959, 2.0118, 3.7041, 3.6874, 2.1720, 2.2150],\n",
            "        [3.0438, 4.0172, 2.1750, 4.0263, 4.0073, 2.3410, 2.4031],\n",
            "        [1.1423, 1.6953, 1.0027, 1.6811, 1.6319, 1.1033, 1.0987],\n",
            "        [0.9511, 1.4430, 0.8738, 1.4288, 1.3791, 0.9535, 0.9567],\n",
            "        [3.0510, 4.0278, 2.1807, 4.0384, 4.0158, 2.3507, 2.4126]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "152\n",
            "tensor([[1.9328, 2.6999, 1.5082, 2.6885, 2.6546, 1.6488, 1.6533],\n",
            "        [2.8632, 3.8098, 2.0724, 3.8220, 3.8074, 2.2231, 2.2807],\n",
            "        [2.7247, 3.6498, 1.9912, 3.6574, 3.6414, 2.1508, 2.1877],\n",
            "        [0.9134, 1.3949, 0.8478, 1.3802, 1.3300, 0.9244, 0.9294],\n",
            "        [1.5279, 2.1902, 1.2552, 2.1741, 2.1343, 1.3839, 1.3725]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "153\n",
            "tensor([[2.5934, 3.4936, 1.9149, 3.4991, 3.4757, 2.0600, 2.0986],\n",
            "        [1.5577, 2.2296, 1.2756, 2.2148, 2.1732, 1.4030, 1.3928],\n",
            "        [0.9784, 1.4784, 0.8939, 1.4660, 1.4146, 0.9781, 0.9782],\n",
            "        [1.5521, 2.2219, 1.2716, 2.2062, 2.1648, 1.3996, 1.3885],\n",
            "        [1.8371, 2.5768, 1.4525, 2.5667, 2.5307, 1.5894, 1.5862]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "154\n",
            "tensor([[3.0578, 4.0312, 2.1922, 4.0435, 4.0192, 2.3561, 2.4136],\n",
            "        [1.1880, 1.7519, 1.0368, 1.7383, 1.6889, 1.1379, 1.1293],\n",
            "        [1.5703, 2.2453, 1.2861, 2.2319, 2.1893, 1.4119, 1.4024],\n",
            "        [2.9418, 3.8962, 2.1252, 3.9121, 3.8952, 2.2764, 2.3329],\n",
            "        [1.0351, 1.5551, 0.9294, 1.5375, 1.4906, 1.0184, 1.0155]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "155\n",
            "tensor([[0.9374, 1.4231, 0.8690, 1.4115, 1.3596, 0.9449, 0.9476],\n",
            "        [2.7318, 3.6533, 2.0028, 3.6631, 3.6471, 2.1442, 2.1889],\n",
            "        [2.2446, 3.0767, 1.7092, 3.0741, 3.0446, 1.8493, 1.8627],\n",
            "        [3.0487, 4.0186, 2.1903, 4.0323, 4.0097, 2.3482, 2.4058],\n",
            "        [2.0289, 2.8152, 1.5762, 2.8060, 2.7717, 1.7143, 1.7182]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "156\n",
            "tensor([[1.2218, 1.7971, 1.0608, 1.7824, 1.7330, 1.1594, 1.1537],\n",
            "        [2.8817, 3.8270, 2.0920, 3.8404, 3.8189, 2.2407, 2.2915],\n",
            "        [1.1160, 1.6589, 0.9924, 1.6451, 1.5957, 1.0849, 1.0790],\n",
            "        [2.7355, 3.6571, 2.0050, 3.6671, 3.6489, 2.1484, 2.1916],\n",
            "        [1.0022, 1.5092, 0.9127, 1.4961, 1.4458, 0.9953, 0.9932]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "157\n",
            "tensor([[2.5059, 3.3891, 1.8694, 3.3920, 3.3681, 2.0095, 2.0381],\n",
            "        [2.8901, 3.8326, 2.0964, 3.8445, 3.8278, 2.2397, 2.2909],\n",
            "        [1.2889, 1.8833, 1.1056, 1.8675, 1.8200, 1.2088, 1.1989],\n",
            "        [3.0714, 4.0450, 2.2044, 4.0555, 4.0291, 2.3617, 2.4195],\n",
            "        [2.0960, 2.8955, 1.6178, 2.8907, 2.8572, 1.7538, 1.7618]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "158\n",
            "tensor([[1.1104, 1.6496, 0.9868, 1.6350, 1.5847, 1.0723, 1.0708],\n",
            "        [3.0231, 3.9817, 2.1733, 3.9941, 3.9756, 2.3105, 2.3783],\n",
            "        [1.0998, 1.6367, 0.9791, 1.6219, 1.5715, 1.0678, 1.0639],\n",
            "        [2.9811, 3.9396, 2.1497, 3.9526, 3.9344, 2.2926, 2.3521],\n",
            "        [2.3973, 3.2568, 1.8017, 3.2565, 3.2348, 1.9361, 1.9606]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "159\n",
            "tensor([[2.9676, 3.9161, 2.1394, 3.9297, 3.9145, 2.2717, 2.3371],\n",
            "        [0.9144, 1.3888, 0.8547, 1.3788, 1.3257, 0.9229, 0.9266],\n",
            "        [2.8329, 3.7676, 2.0620, 3.7777, 3.7631, 2.1926, 2.2486],\n",
            "        [0.9243, 1.4031, 0.8605, 1.3914, 1.3393, 0.9303, 0.9336],\n",
            "        [2.9301, 3.8765, 2.1175, 3.8903, 3.8737, 2.2528, 2.3130]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "160\n",
            "tensor([[2.7571, 3.6800, 2.0134, 3.6885, 3.6687, 2.1486, 2.1995],\n",
            "        [2.5329, 3.4175, 1.8814, 3.4209, 3.3970, 2.0167, 2.0497],\n",
            "        [1.1803, 1.7391, 1.0307, 1.7223, 1.6731, 1.1210, 1.1177],\n",
            "        [2.8310, 3.7647, 2.0584, 3.7739, 3.7579, 2.1992, 2.2479],\n",
            "        [1.6961, 2.3979, 1.3652, 2.3836, 2.3422, 1.4893, 1.4826]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "161\n",
            "tensor([[2.1110, 2.9116, 1.6235, 2.9057, 2.8707, 1.7544, 1.7685],\n",
            "        [2.6931, 3.6036, 1.9755, 3.6126, 3.5924, 2.1106, 2.1566],\n",
            "        [3.0619, 4.0299, 2.1912, 4.0410, 4.0190, 2.3403, 2.4052],\n",
            "        [1.1713, 1.7282, 1.0254, 1.7130, 1.6617, 1.1175, 1.1139],\n",
            "        [0.9847, 1.4833, 0.9019, 1.4706, 1.4188, 0.9767, 0.9783]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "162\n",
            "tensor([[3.0706, 4.0397, 2.1975, 4.0512, 4.0266, 2.3462, 2.4115],\n",
            "        [2.3514, 3.2017, 1.7698, 3.2013, 3.1735, 1.9038, 1.9286],\n",
            "        [2.1968, 3.0156, 1.6756, 3.0112, 2.9788, 1.8076, 1.8242],\n",
            "        [1.0427, 1.5590, 0.9399, 1.5470, 1.4937, 1.0187, 1.0215],\n",
            "        [0.9338, 1.4159, 0.8658, 1.4036, 1.3502, 0.9341, 0.9414]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "163\n",
            "tensor([[1.3850, 2.0035, 1.1652, 1.9896, 1.9416, 1.2726, 1.2661],\n",
            "        [3.0734, 4.0465, 2.1968, 4.0560, 4.0233, 2.3546, 2.4194],\n",
            "        [3.0657, 4.0321, 2.1923, 4.0471, 4.0263, 2.3441, 2.4067],\n",
            "        [3.0620, 4.0301, 2.1916, 4.0452, 4.0238, 2.3451, 2.4069],\n",
            "        [1.4208, 2.0505, 1.1871, 2.0350, 1.9877, 1.2985, 1.2910]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "164\n",
            "tensor([[2.3318, 3.1816, 1.7569, 3.1818, 3.1501, 1.8960, 1.9200],\n",
            "        [1.7767, 2.5002, 1.4136, 2.4889, 2.4483, 1.5440, 1.5401],\n",
            "        [1.4217, 2.0532, 1.1898, 2.0388, 1.9923, 1.3003, 1.2932],\n",
            "        [3.0364, 4.0001, 2.1737, 4.0124, 3.9915, 2.3148, 2.3889],\n",
            "        [1.2569, 1.8390, 1.0830, 1.8261, 1.7756, 1.1810, 1.1766]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "165\n",
            "tensor([[2.5717, 3.4616, 1.9018, 3.4706, 3.4484, 2.0364, 2.0784],\n",
            "        [3.0815, 4.0553, 2.2001, 4.0664, 4.0365, 2.3607, 2.4251],\n",
            "        [1.4316, 2.0658, 1.1969, 2.0516, 2.0038, 1.3067, 1.3007],\n",
            "        [2.6962, 3.6067, 1.9745, 3.6193, 3.5989, 2.1151, 2.1606],\n",
            "        [0.7342, 1.1523, 0.7273, 1.1430, 1.0914, 0.7761, 0.7941]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "166\n",
            "tensor([[3.0540, 4.0226, 2.1853, 4.0392, 4.0123, 2.3499, 2.4057],\n",
            "        [2.2098, 3.0306, 1.6835, 3.0309, 3.0001, 1.8206, 1.8366],\n",
            "        [1.3497, 1.9599, 1.1430, 1.9472, 1.8989, 1.2523, 1.2440],\n",
            "        [2.8017, 3.7314, 2.0374, 3.7477, 3.7302, 2.1801, 2.2334],\n",
            "        [3.0611, 4.0305, 2.1905, 4.0443, 4.0223, 2.3438, 2.4094]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "167\n",
            "tensor([[1.7865, 2.5108, 1.4227, 2.5028, 2.4639, 1.5501, 1.5497],\n",
            "        [1.1496, 1.7008, 1.0128, 1.6901, 1.6381, 1.1052, 1.1027],\n",
            "        [2.2342, 3.0624, 1.6995, 3.0637, 3.0326, 1.8425, 1.8550],\n",
            "        [1.8847, 2.6335, 1.4855, 2.6268, 2.5885, 1.6150, 1.6182],\n",
            "        [0.9445, 1.4299, 0.8762, 1.4207, 1.3672, 0.9471, 0.9520]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "168\n",
            "tensor([[3.0864, 4.0599, 2.2059, 4.0782, 4.0503, 2.3707, 2.4320],\n",
            "        [3.0542, 4.0207, 2.1853, 4.0371, 4.0142, 2.3447, 2.4089],\n",
            "        [2.6138, 3.5112, 1.9278, 3.5237, 3.5001, 2.0648, 2.1095],\n",
            "        [2.8787, 3.8184, 2.0844, 3.8391, 3.8183, 2.2366, 2.2896],\n",
            "        [1.2073, 1.7752, 1.0516, 1.7642, 1.7139, 1.1492, 1.1436]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "169\n",
            "tensor([[3.0552, 4.0190, 2.1850, 4.0402, 4.0180, 2.3443, 2.4060],\n",
            "        [2.7455, 3.6645, 2.0044, 3.6807, 3.6617, 2.1439, 2.1979],\n",
            "        [2.6073, 3.5031, 1.9228, 3.5154, 3.4895, 2.0626, 2.1072],\n",
            "        [2.8972, 3.8394, 2.0946, 3.8596, 3.8400, 2.2396, 2.3002],\n",
            "        [1.2017, 1.7682, 1.0472, 1.7556, 1.7057, 1.1428, 1.1393]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "170\n",
            "tensor([[2.8128, 3.7380, 2.0410, 3.7561, 3.7352, 2.1871, 2.2426],\n",
            "        [2.9362, 3.8832, 2.1160, 3.9042, 3.8827, 2.2663, 2.3287],\n",
            "        [1.5745, 2.2463, 1.2888, 2.2372, 2.1906, 1.4087, 1.4041],\n",
            "        [1.1362, 1.6827, 1.0030, 1.6723, 1.6191, 1.0944, 1.0932],\n",
            "        [3.0907, 4.0622, 2.2059, 4.0805, 4.0497, 2.3652, 2.4345]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "171\n",
            "tensor([[2.7703, 3.6923, 2.0168, 3.7098, 3.6877, 2.1560, 2.2148],\n",
            "        [2.0373, 2.8186, 1.5765, 2.8159, 2.7794, 1.7093, 1.7207],\n",
            "        [3.0882, 4.0611, 2.2032, 4.0776, 4.0449, 2.3664, 2.4324],\n",
            "        [1.8604, 2.6020, 1.4669, 2.5958, 2.5542, 1.5978, 1.6004],\n",
            "        [1.1545, 1.7041, 1.0151, 1.6955, 1.6407, 1.1068, 1.1054]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "172\n",
            "tensor([[1.5724, 2.2392, 1.2840, 2.2286, 2.1819, 1.4002, 1.4006],\n",
            "        [0.8973, 1.3668, 0.8417, 1.3587, 1.3043, 0.9104, 0.9177],\n",
            "        [2.8949, 3.8286, 2.0863, 3.8483, 3.8282, 2.2209, 2.2931],\n",
            "        [2.7021, 3.6108, 1.9744, 3.6261, 3.6042, 2.1086, 2.1659],\n",
            "        [3.0850, 4.0553, 2.1975, 4.0690, 4.0380, 2.3612, 2.4279]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "173\n",
            "tensor([[0.9655, 1.4569, 0.8878, 1.4476, 1.3910, 0.9628, 0.9681],\n",
            "        [1.2324, 1.8049, 1.0650, 1.7949, 1.7417, 1.1610, 1.1597],\n",
            "        [1.4441, 2.0807, 1.1984, 2.0665, 2.0180, 1.3159, 1.3102],\n",
            "        [2.3584, 3.2070, 1.7685, 3.2102, 3.1811, 1.9032, 1.9369],\n",
            "        [2.7249, 3.6352, 1.9870, 3.6483, 3.6250, 2.1152, 2.1777]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "174\n",
            "tensor([[3.0394, 3.9961, 2.1705, 4.0126, 3.9844, 2.3149, 2.3906],\n",
            "        [3.0666, 4.0264, 2.1857, 4.0478, 4.0200, 2.3381, 2.4101],\n",
            "        [2.7214, 3.6341, 1.9846, 3.6469, 3.6214, 2.1248, 2.1782],\n",
            "        [1.2320, 1.8043, 1.0640, 1.7916, 1.7378, 1.1582, 1.1566],\n",
            "        [2.9918, 3.9373, 2.1425, 3.9583, 3.9336, 2.2797, 2.3563]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "175\n",
            "tensor([[3.0591, 4.0160, 2.1810, 4.0361, 4.0088, 2.3288, 2.4041],\n",
            "        [1.7651, 2.4803, 1.4045, 2.4726, 2.4279, 1.5264, 1.5323],\n",
            "        [1.9661, 2.7297, 1.5310, 2.7264, 2.6839, 1.6565, 1.6701],\n",
            "        [2.9461, 3.8874, 2.1153, 3.9087, 3.8828, 2.2529, 2.3279],\n",
            "        [3.0796, 4.0413, 2.1935, 4.0603, 4.0304, 2.3470, 2.4185]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "176\n",
            "tensor([[0.9643, 1.4538, 0.8877, 1.4455, 1.3879, 0.9582, 0.9669],\n",
            "        [2.4897, 3.3591, 1.8481, 3.3679, 3.3404, 1.9727, 2.0214],\n",
            "        [2.0582, 2.8424, 1.5858, 2.8391, 2.8010, 1.7124, 1.7320],\n",
            "        [2.8631, 3.7940, 2.0663, 3.8123, 3.7892, 2.2016, 2.2711],\n",
            "        [1.0213, 1.5280, 0.9245, 1.5189, 1.4622, 1.0023, 1.0074]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "177\n",
            "tensor([[1.4547, 2.0885, 1.2098, 2.0781, 2.0263, 1.3174, 1.3159],\n",
            "        [2.8169, 3.7371, 2.0414, 3.7557, 3.7352, 2.1656, 2.2371],\n",
            "        [0.7487, 1.1687, 0.7385, 1.1613, 1.1048, 0.7867, 0.8053],\n",
            "        [3.0796, 4.0427, 2.1943, 4.0560, 4.0238, 2.3485, 2.4191],\n",
            "        [1.7483, 2.4588, 1.3945, 2.4504, 2.4032, 1.5156, 1.5193]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "178\n",
            "tensor([[1.3519, 1.9584, 1.1449, 1.9462, 1.8946, 1.2428, 1.2421],\n",
            "        [1.6352, 2.3196, 1.3290, 2.3097, 2.2625, 1.4423, 1.4418],\n",
            "        [2.4456, 3.3054, 1.8238, 3.3124, 3.2770, 1.9472, 1.9903],\n",
            "        [3.0474, 4.0023, 2.1770, 4.0217, 3.9917, 2.3221, 2.3932],\n",
            "        [1.2324, 1.8043, 1.0671, 1.7944, 1.7394, 1.1612, 1.1598]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "179\n",
            "tensor([[0.9785, 1.4737, 0.8998, 1.4644, 1.4076, 0.9703, 0.9754],\n",
            "        [1.2185, 1.7859, 1.0599, 1.7751, 1.7213, 1.1495, 1.1466],\n",
            "        [2.3466, 3.1856, 1.7658, 3.1896, 3.1558, 1.8918, 1.9234],\n",
            "        [1.3866, 2.0049, 1.1682, 1.9918, 1.9393, 1.2711, 1.2665],\n",
            "        [3.0663, 4.0232, 2.1911, 4.0409, 4.0129, 2.3351, 2.4047]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "180\n",
            "tensor([[2.9574, 3.8972, 2.1280, 3.9177, 3.8923, 2.2594, 2.3292],\n",
            "        [3.0284, 3.9790, 2.1692, 3.9964, 3.9705, 2.3099, 2.3745],\n",
            "        [0.9319, 1.4133, 0.8668, 1.4033, 1.3462, 0.9325, 0.9406],\n",
            "        [1.4663, 2.1034, 1.2199, 2.0926, 2.0412, 1.3239, 1.3213],\n",
            "        [3.0046, 3.9538, 2.1559, 3.9704, 3.9461, 2.2929, 2.3596]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "181\n",
            "tensor([[1.5516, 2.2121, 1.2761, 2.1989, 2.1503, 1.3823, 1.3781],\n",
            "        [1.9901, 2.7574, 1.5512, 2.7518, 2.7108, 1.6672, 1.6791],\n",
            "        [1.0719, 1.5947, 0.9637, 1.5839, 1.5281, 1.0391, 1.0403],\n",
            "        [2.8213, 3.7443, 2.0498, 3.7612, 3.7387, 2.1702, 2.2351],\n",
            "        [3.0815, 4.0407, 2.2016, 4.0568, 4.0277, 2.3436, 2.4109]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "182\n",
            "tensor([[1.3102, 1.9055, 1.1221, 1.8911, 1.8407, 1.2134, 1.2081],\n",
            "        [2.5980, 3.4852, 1.9198, 3.4934, 3.4665, 2.0398, 2.0836],\n",
            "        [1.6674, 2.3579, 1.3494, 2.3470, 2.2993, 1.4619, 1.4578],\n",
            "        [3.0901, 4.0510, 2.2080, 4.0677, 4.0339, 2.3494, 2.4155],\n",
            "        [2.5321, 3.4098, 1.8808, 3.4171, 3.3863, 2.0004, 2.0409]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "183\n",
            "tensor([[1.5809, 2.2512, 1.2960, 2.2373, 2.1906, 1.4008, 1.3963],\n",
            "        [2.9489, 3.8881, 2.1272, 3.9045, 3.8846, 2.2560, 2.3140],\n",
            "        [2.6302, 3.5233, 1.9401, 3.5329, 3.5077, 2.0567, 2.1040],\n",
            "        [1.2526, 1.8329, 1.0851, 1.8174, 1.7644, 1.1713, 1.1671],\n",
            "        [2.5591, 3.4436, 1.8993, 3.4519, 3.4241, 2.0152, 2.0581]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "184\n",
            "tensor([[2.3878, 3.2390, 1.7955, 3.2396, 3.2106, 1.9119, 1.9392],\n",
            "        [3.0952, 4.0615, 2.2119, 4.0717, 4.0423, 2.3559, 2.4121],\n",
            "        [2.7809, 3.6994, 2.0270, 3.7086, 3.6864, 2.1483, 2.1980],\n",
            "        [2.6740, 3.5757, 1.9657, 3.5828, 3.5569, 2.0918, 2.1294],\n",
            "        [2.7074, 3.6138, 1.9847, 3.6228, 3.6010, 2.1004, 2.1497]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "185\n",
            "tensor([[2.9530, 3.8946, 2.1284, 3.9069, 3.8868, 2.2515, 2.3064],\n",
            "        [1.7785, 2.4986, 1.4230, 2.4858, 2.4432, 1.5334, 1.5269],\n",
            "        [1.1458, 1.6938, 1.0154, 1.6793, 1.6260, 1.0942, 1.0875],\n",
            "        [1.6624, 2.3546, 1.3486, 2.3387, 2.2948, 1.4575, 1.4471],\n",
            "        [3.0136, 3.9622, 2.1648, 3.9749, 3.9534, 2.2961, 2.3483]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "186\n",
            "tensor([[2.9598, 3.9022, 2.1329, 3.9155, 3.8949, 2.2634, 2.3101],\n",
            "        [2.9740, 3.9188, 2.1397, 3.9295, 3.9067, 2.2762, 2.3200],\n",
            "        [1.1114, 1.6496, 0.9921, 1.6351, 1.5810, 1.0683, 1.0620],\n",
            "        [1.0457, 1.5632, 0.9484, 1.5498, 1.4947, 1.0213, 1.0143],\n",
            "        [2.9764, 3.9203, 2.1430, 3.9322, 3.9117, 2.2706, 2.3198]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "187\n",
            "tensor([[1.4319, 2.0621, 1.2004, 2.0459, 1.9966, 1.3014, 1.2856],\n",
            "        [1.4097, 2.0348, 1.1859, 2.0173, 1.9703, 1.2844, 1.2696],\n",
            "        [2.5189, 3.3947, 1.8702, 3.3956, 3.3703, 1.9920, 2.0170],\n",
            "        [3.0717, 4.0359, 2.1925, 4.0398, 4.0094, 2.3363, 2.3862],\n",
            "        [2.1605, 2.9670, 1.6573, 2.9594, 2.9254, 1.7760, 1.7793]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "188\n",
            "tensor([[2.6410, 3.5401, 1.9423, 3.5425, 3.5202, 2.0646, 2.0944],\n",
            "        [3.0601, 4.0146, 2.1844, 4.0248, 3.9978, 2.3165, 2.3707],\n",
            "        [2.8628, 3.7921, 2.0702, 3.7999, 3.7806, 2.2005, 2.2390],\n",
            "        [0.9995, 1.5023, 0.9146, 1.4881, 1.4338, 0.9861, 0.9781],\n",
            "        [1.1321, 1.6764, 1.0027, 1.6604, 1.6071, 1.0865, 1.0738]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "189\n",
            "tensor([[3.0512, 4.0008, 2.1765, 4.0114, 3.9895, 2.3159, 2.3611],\n",
            "        [1.5541, 2.2171, 1.2750, 2.2005, 2.1541, 1.3854, 1.3655],\n",
            "        [1.6151, 2.2934, 1.3129, 2.2758, 2.2307, 1.4214, 1.4060],\n",
            "        [1.4539, 2.0895, 1.2107, 2.0724, 2.0239, 1.3156, 1.2965],\n",
            "        [2.8499, 3.7736, 2.0588, 3.7829, 3.7608, 2.1884, 2.2271]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "190\n",
            "tensor([[2.6655, 3.5591, 1.9478, 3.5633, 3.5389, 2.0760, 2.1031],\n",
            "        [1.8363, 2.5666, 1.4477, 2.5520, 2.5103, 1.5674, 1.5546],\n",
            "        [2.1023, 2.8920, 1.6118, 2.8835, 2.8458, 1.7362, 1.7318],\n",
            "        [2.9225, 3.8527, 2.0962, 3.8608, 3.8407, 2.2329, 2.2692],\n",
            "        [3.0867, 4.0360, 2.1921, 4.0474, 4.0192, 2.3323, 2.3804]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "191\n",
            "tensor([[3.0192, 3.9578, 2.1477, 3.9702, 3.9466, 2.2913, 2.3317],\n",
            "        [1.9771, 2.7359, 1.5304, 2.7221, 2.6826, 1.6556, 1.6446],\n",
            "        [2.2603, 3.0813, 1.7031, 3.0738, 3.0407, 1.8296, 1.8339],\n",
            "        [1.1607, 1.7100, 1.0154, 1.6926, 1.6398, 1.1018, 1.0875],\n",
            "        [3.0912, 4.0439, 2.1890, 4.0494, 4.0256, 2.3358, 2.3772]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "192\n",
            "tensor([[2.4606, 3.3189, 1.8179, 3.3146, 3.2828, 1.9466, 1.9634],\n",
            "        [2.9841, 3.9167, 2.1211, 3.9237, 3.9057, 2.2597, 2.3011],\n",
            "        [3.0073, 3.9410, 2.1343, 3.9511, 3.9327, 2.2753, 2.3169],\n",
            "        [1.9238, 2.6696, 1.4963, 2.6543, 2.6153, 1.6140, 1.6061],\n",
            "        [1.4492, 2.0785, 1.1998, 2.0597, 2.0112, 1.3029, 1.2865]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "193\n",
            "tensor([[1.9783, 2.7380, 1.5251, 2.7227, 2.6831, 1.6481, 1.6430],\n",
            "        [2.2482, 3.0624, 1.6884, 3.0526, 3.0182, 1.8134, 1.8197],\n",
            "        [2.8055, 3.7149, 2.0144, 3.7174, 3.6930, 2.1514, 2.1862],\n",
            "        [2.1081, 2.8934, 1.6048, 2.8808, 2.8428, 1.7307, 1.7276],\n",
            "        [0.9995, 1.4982, 0.9059, 1.4830, 1.4276, 0.9781, 0.9723]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "194\n",
            "tensor([[1.5958, 2.2621, 1.2890, 2.2421, 2.1967, 1.3967, 1.3831],\n",
            "        [2.1880, 2.9893, 1.6522, 2.9773, 2.9437, 1.7711, 1.7797],\n",
            "        [3.0665, 4.0083, 2.1631, 4.0160, 3.9930, 2.3038, 2.3550],\n",
            "        [1.7420, 2.4432, 1.3779, 2.4226, 2.3801, 1.4924, 1.4798],\n",
            "        [1.5995, 2.2658, 1.2912, 2.2457, 2.2002, 1.3996, 1.3864]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "195\n",
            "tensor([[3.1258, 4.0756, 2.1969, 4.0763, 4.0476, 2.3424, 2.3945],\n",
            "        [2.6661, 3.5530, 1.9320, 3.5506, 3.5266, 2.0546, 2.0916],\n",
            "        [3.1167, 4.0674, 2.1920, 4.0672, 4.0398, 2.3339, 2.3881],\n",
            "        [0.9901, 1.4846, 0.8989, 1.4690, 1.4143, 0.9679, 0.9650],\n",
            "        [2.3206, 3.1473, 1.7289, 3.1355, 3.1046, 1.8487, 1.8657]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "196\n",
            "tensor([[1.4925, 2.1302, 1.2235, 2.1083, 2.0627, 1.3253, 1.3130],\n",
            "        [1.5858, 2.2490, 1.2817, 2.2278, 2.1840, 1.3879, 1.3780],\n",
            "        [0.8839, 1.3449, 0.8270, 1.3292, 1.2754, 0.8838, 0.8873],\n",
            "        [3.0944, 4.0331, 2.1752, 4.0381, 4.0184, 2.3063, 2.3683],\n",
            "        [1.8072, 2.5227, 1.4195, 2.5038, 2.4635, 1.5313, 1.5256]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "197\n",
            "tensor([[3.0896, 4.0329, 2.1747, 4.0340, 4.0120, 2.3112, 2.3697],\n",
            "        [3.1020, 4.0459, 2.1788, 4.0467, 4.0178, 2.3178, 2.3785],\n",
            "        [1.7517, 2.4554, 1.3841, 2.4331, 2.3942, 1.4926, 1.4869],\n",
            "        [2.2258, 3.0333, 1.6711, 3.0186, 2.9873, 1.7912, 1.8052],\n",
            "        [1.9277, 2.6714, 1.4920, 2.6519, 2.6153, 1.6061, 1.6064]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "198\n",
            "tensor([[1.1507, 1.6938, 1.0032, 1.6717, 1.6228, 1.0827, 1.0766],\n",
            "        [2.2908, 3.1088, 1.7106, 3.0954, 3.0673, 1.8267, 1.8459],\n",
            "        [1.3277, 1.9203, 1.1195, 1.8993, 1.8510, 1.2111, 1.1993],\n",
            "        [0.9123, 1.3815, 0.8462, 1.3646, 1.3124, 0.9045, 0.9076],\n",
            "        [1.0558, 1.5694, 0.9425, 1.5505, 1.4991, 1.0141, 1.0104]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "199\n",
            "tensor([[2.6590, 3.5382, 1.9250, 3.5316, 3.5182, 2.0327, 2.0834],\n",
            "        [1.1079, 1.6372, 0.9764, 1.6181, 1.5679, 1.0520, 1.0483],\n",
            "        [1.2735, 1.8508, 1.0836, 1.8287, 1.7812, 1.1704, 1.1628],\n",
            "        [2.1258, 2.9092, 1.6105, 2.8910, 2.8628, 1.7240, 1.7370],\n",
            "        [2.8842, 3.7973, 2.0545, 3.7943, 3.7785, 2.1770, 2.2344]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "200\n",
            "tensor([[2.0599, 2.8291, 1.5704, 2.8095, 2.7785, 1.6818, 1.6940],\n",
            "        [2.6796, 3.5641, 1.9358, 3.5568, 3.5356, 2.0491, 2.1023],\n",
            "        [2.5418, 3.3996, 1.8564, 3.3889, 3.3703, 1.9735, 2.0075],\n",
            "        [2.3409, 3.1611, 1.7387, 3.1472, 3.1235, 1.8510, 1.8748],\n",
            "        [2.1661, 2.9557, 1.6361, 2.9383, 2.9125, 1.7424, 1.7610]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "201\n",
            "tensor([[2.4187, 3.2547, 1.7850, 3.2418, 3.2211, 1.8982, 1.9285],\n",
            "        [3.0297, 3.9551, 2.1387, 3.9537, 3.9412, 2.2634, 2.3260],\n",
            "        [1.9968, 2.7488, 1.5322, 2.7273, 2.6968, 1.6399, 1.6505],\n",
            "        [2.9970, 3.9186, 2.1181, 3.9172, 3.9064, 2.2325, 2.3037],\n",
            "        [0.9201, 1.3891, 0.8521, 1.3719, 1.3200, 0.9081, 0.9141]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "202\n",
            "tensor([[1.9544, 2.6964, 1.5058, 2.6756, 2.6420, 1.6150, 1.6236],\n",
            "        [2.9121, 3.8204, 2.0676, 3.8174, 3.8073, 2.1785, 2.2488],\n",
            "        [1.5645, 2.2160, 1.2677, 2.1933, 2.1530, 1.3653, 1.3632],\n",
            "        [1.4021, 2.0104, 1.1655, 1.9862, 1.9438, 1.2543, 1.2505],\n",
            "        [3.0489, 3.9728, 2.1454, 3.9714, 3.9619, 2.2686, 2.3373]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "203\n",
            "tensor([[3.0333, 3.9553, 2.1381, 3.9524, 3.9449, 2.2637, 2.3312],\n",
            "        [3.0877, 4.0164, 2.1668, 4.0144, 4.0036, 2.2882, 2.3667],\n",
            "        [1.9860, 2.7332, 1.5246, 2.7108, 2.6831, 1.6344, 1.6449],\n",
            "        [3.1237, 4.0567, 2.1889, 4.0543, 4.0413, 2.3200, 2.3910],\n",
            "        [2.5045, 3.3531, 1.8325, 3.3407, 3.3265, 1.9432, 1.9856]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "204\n",
            "tensor([[2.8005, 3.6910, 2.0022, 3.6864, 3.6787, 2.1228, 2.1809],\n",
            "        [0.9778, 1.4627, 0.8893, 1.4439, 1.3956, 0.9522, 0.9564],\n",
            "        [2.7052, 3.5805, 1.9481, 3.5739, 3.5658, 2.0656, 2.1178],\n",
            "        [2.1519, 2.9302, 1.6228, 2.9131, 2.8902, 1.7368, 1.7573],\n",
            "        [3.0681, 3.9901, 2.1554, 3.9906, 3.9852, 2.2804, 2.3549]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "205\n",
            "tensor([[2.4900, 3.3326, 1.8222, 3.3216, 3.3096, 1.9391, 1.9812],\n",
            "        [2.7026, 3.5767, 1.9446, 3.5709, 3.5656, 2.0589, 2.1191],\n",
            "        [2.5871, 3.4409, 1.8764, 3.4335, 3.4233, 1.9974, 2.0446],\n",
            "        [2.1736, 2.9536, 1.6349, 2.9376, 2.9179, 1.7524, 1.7730],\n",
            "        [2.2653, 3.0681, 1.6884, 3.0528, 3.0343, 1.8029, 1.8352]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "206\n",
            "tensor([[2.5581, 3.4081, 1.8613, 3.4019, 3.3935, 1.9813, 2.0280],\n",
            "        [1.1000, 1.6224, 0.9696, 1.6020, 1.5594, 1.0441, 1.0473],\n",
            "        [1.6402, 2.3057, 1.3123, 2.2843, 2.2518, 1.4169, 1.4197],\n",
            "        [2.5680, 3.4207, 1.8667, 3.4141, 3.4078, 1.9876, 2.0357],\n",
            "        [3.1158, 4.0425, 2.1806, 4.0431, 4.0382, 2.3167, 2.3957]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "207\n",
            "tensor([[2.8228, 3.7111, 2.0094, 3.7109, 3.7095, 2.1337, 2.2021],\n",
            "        [2.6042, 3.4618, 1.8882, 3.4566, 3.4521, 2.0067, 2.0583],\n",
            "        [3.0975, 4.0182, 2.1663, 4.0232, 4.0233, 2.3073, 2.3835],\n",
            "        [1.4497, 2.0670, 1.1901, 2.0451, 2.0082, 1.2871, 1.2902],\n",
            "        [1.2915, 1.8666, 1.0914, 1.8451, 1.8057, 1.1837, 1.1828]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "208\n",
            "tensor([[2.1589, 2.9364, 1.6239, 2.9250, 2.9106, 1.7436, 1.7704],\n",
            "        [3.1070, 4.0310, 2.1714, 4.0354, 4.0330, 2.3152, 2.3941],\n",
            "        [0.8829, 1.3372, 0.8245, 1.3243, 1.2778, 0.8848, 0.8950],\n",
            "        [1.2474, 1.8098, 1.0639, 1.7922, 1.7513, 1.1569, 1.1534],\n",
            "        [2.9287, 3.8269, 2.0703, 3.8340, 3.8372, 2.2069, 2.2737]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "209\n",
            "tensor([[3.0693, 3.9801, 2.1472, 3.9937, 3.9942, 2.2916, 2.3694],\n",
            "        [1.0522, 1.5574, 0.9366, 1.5411, 1.4983, 1.0133, 1.0157],\n",
            "        [1.4194, 2.0304, 1.1679, 2.0077, 1.9772, 1.2703, 1.2701],\n",
            "        [3.0880, 4.0066, 2.1583, 4.0166, 4.0135, 2.3110, 2.3838],\n",
            "        [3.0848, 4.0006, 2.1566, 4.0110, 4.0115, 2.3053, 2.3798]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "210\n",
            "tensor([[3.0424, 3.9522, 2.1283, 3.9629, 3.9658, 2.2809, 2.3544],\n",
            "        [1.3868, 1.9864, 1.1460, 1.9691, 1.9334, 1.2530, 1.2493],\n",
            "        [3.0032, 3.9041, 2.1063, 3.9159, 3.9236, 2.2458, 2.3227],\n",
            "        [3.0669, 3.9780, 2.1436, 3.9910, 3.9957, 2.2983, 2.3689],\n",
            "        [1.0645, 1.5722, 0.9435, 1.5586, 1.5166, 1.0260, 1.0264]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "211\n",
            "tensor([[0.9622, 1.4372, 0.8759, 1.4251, 1.3809, 0.9501, 0.9528],\n",
            "        [1.7909, 2.4848, 1.3979, 2.4720, 2.4489, 1.5262, 1.5279],\n",
            "        [2.8234, 3.6992, 2.0034, 3.7108, 3.7204, 2.1468, 2.2064],\n",
            "        [2.9156, 3.8040, 2.0555, 3.8155, 3.8216, 2.2117, 2.2685],\n",
            "        [1.2598, 1.8207, 1.0704, 1.8051, 1.7696, 1.1689, 1.1633]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "212\n",
            "tensor([[2.2616, 3.0499, 1.6766, 3.0470, 3.0372, 1.8238, 1.8420],\n",
            "        [2.7058, 3.5665, 1.9354, 3.5770, 3.5794, 2.0840, 2.1357],\n",
            "        [1.0610, 1.5649, 0.9405, 1.5534, 1.5120, 1.0287, 1.0254],\n",
            "        [1.9949, 2.7325, 1.5200, 2.7249, 2.7075, 1.6620, 1.6664],\n",
            "        [3.1139, 4.0302, 2.1662, 4.0389, 4.0370, 2.3400, 2.4079]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "213\n",
            "tensor([[2.7551, 3.6226, 1.9627, 3.6361, 3.6457, 2.1197, 2.1680],\n",
            "        [2.6115, 3.4589, 1.8806, 3.4663, 3.4698, 2.0356, 2.0742],\n",
            "        [1.8752, 2.5865, 1.4492, 2.5776, 2.5594, 1.5875, 1.5875],\n",
            "        [2.9217, 3.8080, 2.0568, 3.8262, 3.8365, 2.2263, 2.2770],\n",
            "        [2.9562, 3.8475, 2.0766, 3.8659, 3.8736, 2.2454, 2.3014]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "214\n",
            "tensor([[2.6750, 3.5310, 1.9179, 3.5423, 3.5478, 2.0884, 2.1172],\n",
            "        [0.8580, 1.3025, 0.8069, 1.2944, 1.2492, 0.8786, 0.8810],\n",
            "        [1.7704, 2.4622, 1.3859, 2.4521, 2.4302, 1.5269, 1.5194],\n",
            "        [2.1692, 2.9434, 1.6251, 2.9418, 2.9324, 1.7793, 1.7859],\n",
            "        [0.9203, 1.3845, 0.8479, 1.3739, 1.3318, 0.9258, 0.9256]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "215\n",
            "tensor([[2.7313, 3.5976, 1.9511, 3.6127, 3.6191, 2.1247, 2.1552],\n",
            "        [1.6811, 2.3507, 1.3336, 2.3423, 2.3186, 1.4733, 1.4599],\n",
            "        [1.4792, 2.0998, 1.2099, 2.0893, 2.0597, 1.3387, 1.3207],\n",
            "        [2.9229, 3.8125, 2.0580, 3.8319, 3.8446, 2.2309, 2.2779],\n",
            "        [3.1213, 4.0369, 2.1705, 4.0572, 4.0603, 2.3699, 2.4148]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "216\n",
            "tensor([[2.3897, 3.2042, 1.7547, 3.2113, 3.2088, 1.9215, 1.9333],\n",
            "        [3.0346, 3.9404, 2.1241, 3.9616, 3.9720, 2.3143, 2.3563],\n",
            "        [2.9048, 3.7979, 2.0493, 3.8164, 3.8259, 2.2382, 2.2720],\n",
            "        [2.9962, 3.8963, 2.1016, 3.9180, 3.9303, 2.2835, 2.3294],\n",
            "        [2.2851, 3.0803, 1.6951, 3.0838, 3.0776, 1.8570, 1.8642]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "217\n",
            "tensor([[2.1514, 2.9254, 1.6168, 2.9261, 2.9181, 1.7799, 1.7778],\n",
            "        [1.0898, 1.6073, 0.9622, 1.5978, 1.5590, 1.0671, 1.0510],\n",
            "        [2.9609, 3.8582, 2.0835, 3.8833, 3.8954, 2.2762, 2.3094],\n",
            "        [1.2516, 1.8121, 1.0672, 1.8043, 1.7676, 1.1862, 1.1654],\n",
            "        [1.3199, 1.9017, 1.1109, 1.8918, 1.8571, 1.2343, 1.2130]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "218\n",
            "tensor([[1.3932, 1.9948, 1.1579, 1.9878, 1.9546, 1.2919, 1.2661],\n",
            "        [2.1365, 2.9126, 1.6123, 2.9154, 2.9048, 1.7805, 1.7722],\n",
            "        [1.1974, 1.7468, 1.0332, 1.7388, 1.7001, 1.1510, 1.1306],\n",
            "        [1.4677, 2.0888, 1.2047, 2.0799, 2.0497, 1.3424, 1.3183],\n",
            "        [3.0465, 3.9558, 2.1341, 3.9801, 3.9853, 2.3266, 2.3711]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "219\n",
            "tensor([[1.8918, 2.6161, 1.4650, 2.6147, 2.5964, 1.6312, 1.6090],\n",
            "        [2.7238, 3.5976, 1.9519, 3.6168, 3.6219, 2.1438, 2.1603],\n",
            "        [1.0510, 1.5582, 0.9402, 1.5513, 1.5086, 1.0444, 1.0262],\n",
            "        [3.0878, 4.0110, 2.1561, 4.0306, 4.0292, 2.3737, 2.4063],\n",
            "        [2.8696, 3.7616, 2.0356, 3.7861, 3.7958, 2.2359, 2.2559]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "220\n",
            "tensor([[3.1064, 4.0286, 2.1706, 4.0562, 4.0609, 2.3914, 2.4165],\n",
            "        [2.5343, 3.3813, 1.8449, 3.3986, 3.3987, 2.0327, 2.0380],\n",
            "        [1.0757, 1.5916, 0.9547, 1.5837, 1.5443, 1.0616, 1.0437],\n",
            "        [2.5193, 3.3609, 1.8362, 3.3787, 3.3782, 2.0227, 2.0277],\n",
            "        [1.0739, 1.5881, 0.9544, 1.5810, 1.5398, 1.0638, 1.0426]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "221\n",
            "tensor([[1.6210, 2.2826, 1.3026, 2.2785, 2.2524, 1.4555, 1.4269],\n",
            "        [1.2931, 1.8699, 1.0955, 1.8643, 1.8271, 1.2279, 1.1991],\n",
            "        [2.2673, 3.0662, 1.6894, 3.0762, 3.0672, 1.8692, 1.8632],\n",
            "        [1.3894, 1.9909, 1.1589, 1.9861, 1.9523, 1.2976, 1.2672],\n",
            "        [1.7266, 2.4133, 1.3668, 2.4117, 2.3865, 1.5287, 1.4995]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "222\n",
            "tensor([[1.1579, 1.6974, 1.0110, 1.6915, 1.6510, 1.1303, 1.1046],\n",
            "        [2.2339, 3.0244, 1.6720, 3.0335, 3.0241, 1.8552, 1.8384],\n",
            "        [2.9347, 3.8325, 2.0762, 3.8624, 3.8739, 2.2732, 2.3003],\n",
            "        [2.2810, 3.0823, 1.7005, 3.0925, 3.0871, 1.8809, 1.8710],\n",
            "        [0.9692, 1.4517, 0.8866, 1.4474, 1.4028, 0.9852, 0.9698]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "223\n",
            "tensor([[2.5202, 3.3631, 1.8436, 3.3813, 3.3803, 2.0308, 2.0292],\n",
            "        [2.7386, 3.6132, 1.9692, 3.6388, 3.6433, 2.1617, 2.1730],\n",
            "        [2.7810, 3.6630, 1.9926, 3.6897, 3.6950, 2.1899, 2.2015],\n",
            "        [1.0052, 1.4986, 0.9126, 1.4929, 1.4487, 1.0125, 0.9943],\n",
            "        [3.0368, 3.9476, 2.1385, 3.9793, 3.9856, 2.3520, 2.3694]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "224\n",
            "tensor([[3.0942, 4.0078, 2.1700, 4.0413, 4.0449, 2.3878, 2.4078],\n",
            "        [2.8201, 3.7050, 2.0165, 3.7342, 3.7410, 2.2097, 2.2242],\n",
            "        [1.8384, 2.5489, 1.4393, 2.5493, 2.5266, 1.6028, 1.5752],\n",
            "        [3.0579, 3.9665, 2.1489, 3.9993, 4.0059, 2.3517, 2.3767],\n",
            "        [1.0878, 1.6066, 0.9676, 1.5999, 1.5583, 1.0767, 1.0539]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "225\n",
            "tensor([[2.3791, 3.1971, 1.7650, 3.2127, 3.2058, 1.9454, 1.9370],\n",
            "        [3.0844, 3.9977, 2.1666, 4.0296, 4.0320, 2.3750, 2.3988],\n",
            "        [3.1194, 4.0351, 2.1865, 4.0683, 4.0694, 2.4038, 2.4230],\n",
            "        [3.0528, 3.9617, 2.1504, 3.9949, 4.0016, 2.3634, 2.3776],\n",
            "        [3.1077, 4.0213, 2.1787, 4.0550, 4.0577, 2.3931, 2.4142]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "226\n",
            "tensor([[1.2975, 1.8697, 1.1059, 1.8663, 1.8274, 1.2319, 1.1996],\n",
            "        [1.9613, 2.6956, 1.5166, 2.6995, 2.6797, 1.6800, 1.6556],\n",
            "        [3.0489, 3.9498, 2.1503, 3.9854, 3.9910, 2.3528, 2.3718],\n",
            "        [1.3529, 1.9398, 1.1404, 1.9354, 1.8980, 1.2719, 1.2374],\n",
            "        [1.9422, 2.6711, 1.5054, 2.6741, 2.6546, 1.6711, 1.6422]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "227\n",
            "tensor([[2.9274, 3.8113, 2.0834, 3.8445, 3.8524, 2.2742, 2.2895],\n",
            "        [3.0831, 3.9925, 2.1709, 4.0196, 4.0146, 2.3740, 2.3976],\n",
            "        [1.7094, 2.3839, 1.3647, 2.3822, 2.3571, 1.5144, 1.4823],\n",
            "        [1.7991, 2.4940, 1.4218, 2.4975, 2.4710, 1.5782, 1.5461],\n",
            "        [0.9725, 1.4506, 0.8939, 1.4473, 1.4011, 0.9873, 0.9691]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "228\n",
            "tensor([[3.1306, 4.0397, 2.2004, 4.0708, 4.0683, 2.4100, 2.4245],\n",
            "        [3.1236, 4.0277, 2.1962, 4.0614, 4.0639, 2.4002, 2.4177],\n",
            "        [1.1521, 1.6833, 1.0128, 1.6779, 1.6361, 1.1229, 1.0967],\n",
            "        [1.4496, 2.0594, 1.2054, 2.0553, 2.0206, 1.3389, 1.3037],\n",
            "        [1.7911, 2.4837, 1.4173, 2.4844, 2.4593, 1.5707, 1.5388]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "229\n",
            "tensor([[1.2789, 1.8414, 1.0952, 1.8371, 1.7973, 1.2153, 1.1845],\n",
            "        [2.9441, 3.8268, 2.0946, 3.8609, 3.8669, 2.2813, 2.2969],\n",
            "        [2.9691, 3.8541, 2.1103, 3.8860, 3.8935, 2.2877, 2.3120],\n",
            "        [1.0730, 1.5798, 0.9627, 1.5769, 1.5318, 1.0659, 1.0397],\n",
            "        [3.0604, 3.9527, 2.1625, 3.9882, 3.9955, 2.3510, 2.3723]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "230\n",
            "tensor([[3.0494, 3.9391, 2.1569, 3.9739, 3.9812, 2.3336, 2.3634],\n",
            "        [2.2286, 3.0038, 1.6834, 3.0173, 3.0021, 1.8465, 1.8284],\n",
            "        [1.0509, 1.5491, 0.9480, 1.5460, 1.4995, 1.0459, 1.0227],\n",
            "        [1.6350, 2.2864, 1.3228, 2.2865, 2.2547, 1.4625, 1.4312],\n",
            "        [0.8468, 1.2849, 0.8083, 1.2817, 1.2347, 0.8850, 0.8761]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "231\n",
            "tensor([[1.0526, 1.5506, 0.9499, 1.5461, 1.5032, 1.0447, 1.0220],\n",
            "        [2.5898, 3.4213, 1.8976, 3.4458, 3.4436, 2.0627, 2.0616],\n",
            "        [2.7589, 3.6162, 1.9944, 3.6442, 3.6487, 2.1599, 2.1736],\n",
            "        [1.4897, 2.1055, 1.2322, 2.1015, 2.0685, 1.3607, 1.3278],\n",
            "        [2.4843, 3.2982, 1.8354, 3.3212, 3.3149, 1.9956, 1.9942]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "232\n",
            "tensor([[1.4694, 2.0782, 1.2221, 2.0744, 2.0397, 1.3464, 1.3140],\n",
            "        [2.1087, 2.8566, 1.6162, 2.8678, 2.8488, 1.7656, 1.7447],\n",
            "        [2.8602, 3.7265, 2.0578, 3.7601, 3.7662, 2.2206, 2.2353],\n",
            "        [3.1353, 4.0344, 2.2130, 4.0668, 4.0591, 2.4002, 2.4215],\n",
            "        [1.3615, 1.9430, 1.1532, 1.9406, 1.9020, 1.2731, 1.2394]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "233\n",
            "tensor([[1.7801, 2.4597, 1.4178, 2.4610, 2.4329, 1.5561, 1.5227],\n",
            "        [3.0681, 3.9553, 2.1796, 3.9925, 3.9947, 2.3475, 2.3693],\n",
            "        [2.7451, 3.5956, 1.9951, 3.6262, 3.6265, 2.1438, 2.1557],\n",
            "        [3.1359, 4.0325, 2.2165, 4.0666, 4.0626, 2.3944, 2.4171],\n",
            "        [1.9886, 2.7161, 1.5457, 2.7219, 2.6995, 1.6911, 1.6645]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "234\n",
            "tensor([[3.0161, 3.8982, 2.1544, 3.9344, 3.9352, 2.3094, 2.3331],\n",
            "        [2.6459, 3.4810, 1.9413, 3.5083, 3.5032, 2.0896, 2.0924],\n",
            "        [1.2355, 1.7828, 1.0779, 1.7789, 1.7373, 1.1803, 1.1493],\n",
            "        [1.0566, 1.5543, 0.9587, 1.5511, 1.5054, 1.0461, 1.0231],\n",
            "        [0.8158, 1.2433, 0.7947, 1.2414, 1.1913, 0.8598, 0.8511]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "235\n",
            "tensor([[2.8490, 3.7094, 2.0627, 3.7419, 3.7402, 2.2175, 2.2207],\n",
            "        [1.2401, 1.7878, 1.0830, 1.7842, 1.7430, 1.1849, 1.1500],\n",
            "        [3.0675, 3.9521, 2.1876, 3.9893, 3.9910, 2.3480, 2.3639],\n",
            "        [2.7241, 3.5688, 1.9911, 3.5976, 3.5942, 2.1362, 2.1381],\n",
            "        [3.1130, 4.0012, 2.2139, 4.0411, 4.0381, 2.3751, 2.3943]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "236\n",
            "tensor([[1.0553, 1.5514, 0.9632, 1.5517, 1.5029, 1.0495, 1.0222],\n",
            "        [3.0402, 3.9215, 2.1745, 3.9580, 3.9607, 2.3239, 2.3426],\n",
            "        [2.0755, 2.8149, 1.6091, 2.8238, 2.8009, 1.7431, 1.7138],\n",
            "        [2.2413, 3.0135, 1.7084, 3.0278, 3.0075, 1.8516, 1.8264],\n",
            "        [2.8373, 3.6948, 2.0554, 3.7254, 3.7189, 2.2166, 2.2118]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "237\n",
            "tensor([[2.2070, 2.9705, 1.6914, 2.9851, 2.9642, 1.8246, 1.8001],\n",
            "        [2.8786, 3.7406, 2.0840, 3.7750, 3.7757, 2.2210, 2.2341],\n",
            "        [0.7683, 1.1797, 0.7662, 1.1796, 1.1287, 0.8203, 0.8146],\n",
            "        [1.2177, 1.7584, 1.0730, 1.7570, 1.7127, 1.1684, 1.1338],\n",
            "        [2.1519, 2.9075, 1.6575, 2.9203, 2.8991, 1.7926, 1.7661]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "238\n",
            "tensor([[0.8257, 1.2549, 0.8073, 1.2540, 1.2030, 0.8680, 0.8549],\n",
            "        [0.8812, 1.3266, 0.8449, 1.3251, 1.2744, 0.9110, 0.8943],\n",
            "        [0.9024, 1.3546, 0.8612, 1.3534, 1.3035, 0.9282, 0.9109],\n",
            "        [2.9404, 3.8099, 2.1234, 3.8483, 3.8459, 2.2674, 2.2725],\n",
            "        [2.1493, 2.9043, 1.6598, 2.9179, 2.8989, 1.7894, 1.7618]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "239\n",
            "tensor([[1.6822, 2.3372, 1.3733, 2.3432, 2.3080, 1.4925, 1.4494],\n",
            "        [0.7716, 1.1833, 0.7706, 1.1830, 1.1316, 0.8227, 0.8144],\n",
            "        [0.8076, 1.2307, 0.7963, 1.2312, 1.1797, 0.8532, 0.8411],\n",
            "        [2.5801, 3.4054, 1.9164, 3.4350, 3.4226, 2.0524, 2.0403],\n",
            "        [1.1640, 1.6901, 1.0388, 1.6901, 1.6428, 1.1286, 1.0949]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "240\n",
            "tensor([[2.4217, 3.2204, 1.8252, 3.2442, 3.2303, 1.9545, 1.9320],\n",
            "        [2.7241, 3.5701, 2.0017, 3.6052, 3.5947, 2.1303, 2.1314],\n",
            "        [0.9261, 1.3839, 0.8811, 1.3860, 1.3331, 0.9520, 0.9263],\n",
            "        [1.5132, 2.1305, 1.2672, 2.1331, 2.0918, 1.3796, 1.3348],\n",
            "        [0.9333, 1.3928, 0.8846, 1.3951, 1.3429, 0.9538, 0.9319]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "241\n",
            "tensor([[1.1606, 1.6851, 1.0375, 1.6860, 1.6363, 1.1240, 1.0895],\n",
            "        [1.2115, 1.7511, 1.0716, 1.7516, 1.7065, 1.1628, 1.1251],\n",
            "        [2.0970, 2.8383, 1.6318, 2.8550, 2.8276, 1.7575, 1.7207],\n",
            "        [2.9693, 3.8418, 2.1454, 3.8837, 3.8741, 2.2847, 2.2866],\n",
            "        [1.6840, 2.3394, 1.3761, 2.3454, 2.3095, 1.4873, 1.4471]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "242\n",
            "tensor([[2.5113, 3.3243, 1.8818, 3.3540, 3.3350, 2.0065, 1.9885],\n",
            "        [2.7652, 3.6124, 2.0290, 3.6504, 3.6381, 2.1593, 2.1507],\n",
            "        [2.8387, 3.6957, 2.0715, 3.7350, 3.7242, 2.2025, 2.1996],\n",
            "        [3.0974, 3.9837, 2.2214, 4.0283, 4.0164, 2.3664, 2.3679],\n",
            "        [1.0904, 1.5956, 0.9936, 1.5969, 1.5471, 1.0743, 1.0400]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "243\n",
            "tensor([[1.5475, 2.1724, 1.2929, 2.1774, 2.1360, 1.3974, 1.3529],\n",
            "        [3.1216, 4.0089, 2.2363, 4.0554, 4.0424, 2.3823, 2.3801],\n",
            "        [1.3005, 1.8628, 1.1328, 1.8658, 1.8173, 1.2254, 1.1853],\n",
            "        [1.0488, 1.5427, 0.9668, 1.5464, 1.4924, 1.0440, 1.0110],\n",
            "        [2.8727, 3.7339, 2.0927, 3.7751, 3.7674, 2.2212, 2.2183]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "244\n",
            "tensor([[2.0955, 2.8349, 1.6331, 2.8537, 2.8233, 1.7507, 1.7137],\n",
            "        [1.6085, 2.2453, 1.3319, 2.2536, 2.2122, 1.4413, 1.3926],\n",
            "        [1.5834, 2.2161, 1.3177, 2.2238, 2.1813, 1.4250, 1.3777],\n",
            "        [0.7401, 1.1412, 0.7530, 1.1438, 1.0896, 0.7970, 0.7891],\n",
            "        [2.4895, 3.2976, 1.8711, 3.3296, 3.3126, 1.9890, 1.9709]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "245\n",
            "tensor([[0.9961, 1.4738, 0.9301, 1.4769, 1.4230, 1.0012, 0.9715],\n",
            "        [3.0868, 3.9703, 2.2190, 4.0178, 4.0052, 2.3554, 2.3572],\n",
            "        [2.7158, 3.5501, 2.0024, 3.5910, 3.5768, 2.1277, 2.1134],\n",
            "        [1.0510, 1.5442, 0.9694, 1.5468, 1.4947, 1.0431, 1.0093],\n",
            "        [3.1302, 4.0138, 2.2416, 4.0635, 4.0501, 2.3784, 2.3822]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "246\n",
            "tensor([[2.5173, 3.3277, 1.8886, 3.3635, 3.3402, 2.0110, 1.9860],\n",
            "        [1.5220, 2.1381, 1.2795, 2.1464, 2.1026, 1.3795, 1.3322],\n",
            "        [3.0789, 3.9616, 2.2143, 4.0112, 3.9940, 2.3576, 2.3501],\n",
            "        [1.6430, 2.2852, 1.3556, 2.2979, 2.2560, 1.4627, 1.4142],\n",
            "        [3.1111, 3.9917, 2.2307, 4.0435, 4.0319, 2.3638, 2.3695]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "247\n",
            "tensor([[2.6579, 3.4839, 1.9697, 3.5264, 3.5104, 2.0910, 2.0745],\n",
            "        [1.1320, 1.6479, 1.0237, 1.6521, 1.6010, 1.1031, 1.0659],\n",
            "        [1.3208, 1.8866, 1.1475, 1.8928, 1.8442, 1.2425, 1.1967],\n",
            "        [2.3731, 3.1590, 1.8026, 3.1897, 3.1696, 1.9156, 1.8913],\n",
            "        [1.5460, 2.1677, 1.2953, 2.1771, 2.1335, 1.3973, 1.3504]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "248\n",
            "tensor([[3.0483, 3.9226, 2.1931, 3.9760, 3.9642, 2.3348, 2.3268],\n",
            "        [1.4789, 2.0829, 1.2515, 2.0951, 2.0475, 1.3541, 1.3047],\n",
            "        [3.0895, 3.9696, 2.2181, 4.0222, 4.0048, 2.3590, 2.3545],\n",
            "        [1.2804, 1.8344, 1.1207, 1.8405, 1.7910, 1.2086, 1.1669],\n",
            "        [2.8791, 3.7366, 2.0973, 3.7848, 3.7736, 2.2249, 2.2168]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "249\n",
            "tensor([[2.0018, 2.7203, 1.5755, 2.7431, 2.7077, 1.6945, 1.6520],\n",
            "        [1.1162, 1.6248, 1.0121, 1.6331, 1.5789, 1.0920, 1.0542],\n",
            "        [3.0182, 3.8863, 2.1736, 3.9404, 3.9255, 2.3099, 2.3055],\n",
            "        [2.0900, 2.8243, 1.6306, 2.8495, 2.8155, 1.7509, 1.7080],\n",
            "        [2.7456, 3.5815, 2.0167, 3.6295, 3.6181, 2.1370, 2.1272]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "250\n",
            "tensor([[0.9648, 1.4311, 0.9101, 1.4404, 1.3839, 0.9793, 0.9500],\n",
            "        [2.8810, 3.7326, 2.0944, 3.7867, 3.7721, 2.2233, 2.2183],\n",
            "        [1.6137, 2.2504, 1.3334, 2.2641, 2.2204, 1.4452, 1.3948],\n",
            "        [2.9438, 3.8019, 2.1292, 3.8569, 3.8414, 2.2708, 2.2596],\n",
            "        [1.0334, 1.5194, 0.9569, 1.5283, 1.4718, 1.0307, 0.9981]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "251\n",
            "tensor([[2.3529, 3.1312, 1.7842, 3.1685, 3.1380, 1.9107, 1.8800],\n",
            "        [2.3635, 3.1453, 1.7907, 3.1820, 3.1564, 1.9136, 1.8861],\n",
            "        [1.9540, 2.6617, 1.5431, 2.6846, 2.6461, 1.6692, 1.6192],\n",
            "        [1.7857, 2.4615, 1.4429, 2.4798, 2.4398, 1.5590, 1.5103],\n",
            "        [1.3766, 1.9543, 1.1835, 1.9675, 1.9168, 1.2853, 1.2362]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "252\n",
            "tensor([[1.4522, 2.0469, 1.2307, 2.0608, 2.0103, 1.3349, 1.2865],\n",
            "        [1.1082, 1.6151, 1.0072, 1.6242, 1.5692, 1.0890, 1.0506],\n",
            "        [1.9915, 2.7064, 1.5671, 2.7317, 2.6926, 1.6902, 1.6443],\n",
            "        [2.5168, 3.3206, 1.8797, 3.3637, 3.3382, 2.0126, 1.9857],\n",
            "        [1.0950, 1.5982, 0.9997, 1.6090, 1.5517, 1.0819, 1.0414]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "253\n",
            "tensor([[0.9091, 1.3602, 0.8715, 1.3683, 1.3109, 0.9359, 0.9112],\n",
            "        [1.8361, 2.5194, 1.4711, 2.5412, 2.5000, 1.5894, 1.5418],\n",
            "        [1.2058, 1.7394, 1.0712, 1.7488, 1.6955, 1.1596, 1.1170],\n",
            "        [2.3150, 3.0887, 1.7616, 3.1263, 3.0967, 1.8884, 1.8562],\n",
            "        [1.9833, 2.6968, 1.5627, 2.7247, 2.6861, 1.6861, 1.6411]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "254\n",
            "tensor([[2.2945, 3.0649, 1.7503, 3.1038, 3.0728, 1.8797, 1.8448],\n",
            "        [0.9926, 1.4646, 0.9281, 1.4770, 1.4182, 1.0037, 0.9700],\n",
            "        [2.7404, 3.5720, 2.0095, 3.6263, 3.6036, 2.1453, 2.1276],\n",
            "        [2.9523, 3.8104, 2.1327, 3.8700, 3.8543, 2.2835, 2.2659],\n",
            "        [3.0621, 3.9315, 2.1941, 3.9938, 3.9758, 2.3431, 2.3366]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "255\n",
            "tensor([[1.8121, 2.4894, 1.4575, 2.5137, 2.4700, 1.5759, 1.5278],\n",
            "        [1.9278, 2.6276, 1.5275, 2.6546, 2.6139, 1.6516, 1.6020],\n",
            "        [2.4480, 3.2437, 1.8420, 3.2897, 3.2598, 1.9720, 1.9435],\n",
            "        [1.2704, 1.8185, 1.1122, 1.8326, 1.7781, 1.2109, 1.1630],\n",
            "        [1.8314, 2.5117, 1.4685, 2.5369, 2.4934, 1.5896, 1.5393]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "256\n",
            "tensor([[3.0346, 3.8997, 2.1793, 3.9662, 3.9470, 2.3291, 2.3175],\n",
            "        [3.0439, 3.9116, 2.1850, 3.9762, 3.9567, 2.3321, 2.3264],\n",
            "        [1.0516, 1.5410, 0.9708, 1.5554, 1.4970, 1.0508, 1.0131],\n",
            "        [3.0859, 3.9565, 2.2107, 4.0232, 4.0020, 2.3622, 2.3532],\n",
            "        [1.3041, 1.8602, 1.1380, 1.8784, 1.8242, 1.2356, 1.1878]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "257\n",
            "tensor([[1.0314, 1.5167, 0.9560, 1.5312, 1.4719, 1.0355, 0.9989],\n",
            "        [2.6675, 3.4904, 1.9737, 3.5473, 3.5239, 2.0988, 2.0822],\n",
            "        [2.7332, 3.5604, 2.0056, 3.6196, 3.5906, 2.1387, 2.1240],\n",
            "        [2.9274, 3.7823, 2.1182, 3.8467, 3.8287, 2.2589, 2.2492],\n",
            "        [0.9711, 1.4360, 0.9163, 1.4516, 1.3913, 0.9884, 0.9552]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "258\n",
            "tensor([[1.3295, 1.8960, 1.1532, 1.9129, 1.8588, 1.2530, 1.2052],\n",
            "        [1.0516, 1.5413, 0.9672, 1.5559, 1.4991, 1.0494, 1.0123],\n",
            "        [1.5826, 2.2065, 1.3170, 2.2305, 2.1806, 1.4297, 1.3760],\n",
            "        [1.0058, 1.4808, 0.9368, 1.4951, 1.4351, 1.0098, 0.9779],\n",
            "        [2.4467, 3.2374, 1.8433, 3.2893, 3.2621, 1.9703, 1.9422]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "259\n",
            "tensor([[3.0288, 3.8925, 2.1780, 3.9642, 3.9406, 2.3306, 2.3183],\n",
            "        [1.2209, 1.7563, 1.0845, 1.7757, 1.7197, 1.1778, 1.1320],\n",
            "        [2.7321, 3.5631, 2.0066, 3.6244, 3.5912, 2.1369, 2.1286],\n",
            "        [1.7520, 2.4151, 1.4270, 2.4447, 2.3987, 1.5414, 1.4908],\n",
            "        [2.7680, 3.6034, 2.0315, 3.6691, 3.6463, 2.1695, 2.1525]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "260\n",
            "tensor([[3.0094, 3.8705, 2.1690, 3.9458, 3.9252, 2.3136, 2.3063],\n",
            "        [3.1293, 4.0057, 2.2370, 4.0779, 4.0520, 2.3949, 2.3866],\n",
            "        [3.0842, 3.9558, 2.2125, 4.0293, 4.0053, 2.3679, 2.3565],\n",
            "        [2.6153, 3.4310, 1.9437, 3.4930, 3.4701, 2.0680, 2.0516],\n",
            "        [3.1038, 3.9729, 2.2224, 4.0500, 4.0243, 2.3669, 2.3682]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "261\n",
            "tensor([[3.1257, 3.9976, 2.2335, 4.0743, 4.0494, 2.3882, 2.3828],\n",
            "        [1.8296, 2.5069, 1.4700, 2.5407, 2.4962, 1.5932, 1.5422],\n",
            "        [3.0077, 3.8654, 2.1668, 3.9414, 3.9235, 2.3041, 2.3026],\n",
            "        [2.8205, 3.6584, 2.0615, 3.7314, 3.7113, 2.1872, 2.1820],\n",
            "        [2.0509, 2.7714, 1.6052, 2.8141, 2.7766, 1.7316, 1.6869]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "262\n",
            "tensor([[1.9433, 2.6428, 1.5379, 2.6804, 2.6386, 1.6644, 1.6132],\n",
            "        [2.1502, 2.8897, 1.6648, 2.9356, 2.8970, 1.7943, 1.7510],\n",
            "        [3.1077, 3.9817, 2.2211, 4.0578, 4.0333, 2.3805, 2.3720],\n",
            "        [1.6677, 2.3119, 1.3709, 2.3418, 2.2930, 1.4817, 1.4360],\n",
            "        [3.1171, 3.9889, 2.2270, 4.0659, 4.0410, 2.3803, 2.3761]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "263\n",
            "tensor([[2.7014, 3.5295, 1.9906, 3.5980, 3.5782, 2.1199, 2.1051],\n",
            "        [3.1205, 3.9954, 2.2258, 4.0719, 4.0459, 2.3866, 2.3797],\n",
            "        [0.8728, 1.3091, 0.8467, 1.3269, 1.2676, 0.9103, 0.8856],\n",
            "        [0.9945, 1.4664, 0.9329, 1.4860, 1.4260, 1.0063, 0.9731],\n",
            "        [2.0699, 2.7993, 1.6194, 2.8447, 2.8069, 1.7479, 1.7014]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "264\n",
            "tensor([[0.9336, 1.3875, 0.8911, 1.4064, 1.3469, 0.9608, 0.9289],\n",
            "        [1.0482, 1.5344, 0.9692, 1.5563, 1.4979, 1.0478, 1.0109],\n",
            "        [3.1264, 4.0033, 2.2294, 4.0791, 4.0483, 2.3898, 2.3841],\n",
            "        [2.7820, 3.6180, 2.0320, 3.6887, 3.6646, 2.1649, 2.1540],\n",
            "        [2.7418, 3.5744, 2.0141, 3.6448, 3.6235, 2.1494, 2.1285]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "265\n",
            "tensor([[3.0939, 3.9655, 2.2088, 4.0428, 4.0129, 2.3687, 2.3600],\n",
            "        [2.1849, 2.9324, 1.6866, 2.9833, 2.9476, 1.8189, 1.7732],\n",
            "        [3.1118, 3.9842, 2.2227, 4.0620, 4.0371, 2.3765, 2.3719],\n",
            "        [1.0707, 1.5640, 0.9827, 1.5861, 1.5272, 1.0664, 1.0276],\n",
            "        [1.7695, 2.4366, 1.4347, 2.4740, 2.4270, 1.5567, 1.5017]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "266\n",
            "tensor([[2.5613, 3.3687, 1.9089, 3.4366, 3.4109, 2.0443, 2.0159],\n",
            "        [2.0035, 2.7161, 1.5778, 2.7602, 2.7197, 1.7054, 1.6544],\n",
            "        [2.4035, 3.1875, 1.8166, 3.2488, 3.2170, 1.9476, 1.9141],\n",
            "        [3.1101, 3.9811, 2.2189, 4.0625, 4.0359, 2.3775, 2.3698],\n",
            "        [3.1242, 3.9964, 2.2287, 4.0763, 4.0508, 2.3901, 2.3772]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "267\n",
            "tensor([[2.2062, 2.9556, 1.6987, 3.0086, 2.9745, 1.8325, 1.7867],\n",
            "        [1.6390, 2.2774, 1.3514, 2.3101, 2.2639, 1.4742, 1.4141],\n",
            "        [3.0911, 3.9568, 2.2085, 4.0376, 4.0201, 2.3571, 2.3528],\n",
            "        [2.1060, 2.8374, 1.6394, 2.8850, 2.8492, 1.7710, 1.7200],\n",
            "        [1.0400, 1.5252, 0.9636, 1.5473, 1.4896, 1.0460, 1.0054]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "268\n",
            "tensor([[0.9965, 1.4700, 0.9350, 1.4920, 1.4331, 1.0127, 0.9753],\n",
            "        [0.9930, 1.4634, 0.9326, 1.4846, 1.4273, 1.0083, 0.9720],\n",
            "        [1.0853, 1.5823, 0.9951, 1.6058, 1.5483, 1.0798, 1.0372],\n",
            "        [2.9349, 3.7959, 2.1143, 3.8597, 3.8298, 2.2793, 2.2579],\n",
            "        [1.8240, 2.5017, 1.4673, 2.5398, 2.4986, 1.5906, 1.5351]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "269\n",
            "tensor([[1.6772, 2.3224, 1.3781, 2.3572, 2.3116, 1.4974, 1.4408],\n",
            "        [1.7336, 2.3908, 1.4128, 2.4266, 2.3829, 1.5359, 1.4773],\n",
            "        [1.5314, 2.1416, 1.2864, 2.1722, 2.1236, 1.3996, 1.3428],\n",
            "        [1.4043, 1.9848, 1.2035, 2.0116, 1.9625, 1.3080, 1.2562],\n",
            "        [1.1095, 1.6149, 1.0111, 1.6352, 1.5798, 1.0977, 1.0540]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "270\n",
            "tensor([[1.3377, 1.9020, 1.1621, 1.9268, 1.8767, 1.2633, 1.2093],\n",
            "        [1.0721, 1.5651, 0.9877, 1.5881, 1.5317, 1.0710, 1.0272],\n",
            "        [0.9945, 1.4683, 0.9363, 1.4882, 1.4313, 1.0113, 0.9736],\n",
            "        [2.7284, 3.5562, 2.0066, 3.6279, 3.6113, 2.1427, 2.1204],\n",
            "        [3.1237, 3.9953, 2.2297, 4.0702, 4.0529, 2.3891, 2.3775]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "271\n",
            "tensor([[1.6154, 2.2449, 1.3399, 2.2770, 2.2331, 1.4577, 1.3962],\n",
            "        [1.8894, 2.5767, 1.5109, 2.6162, 2.5784, 1.6366, 1.5765],\n",
            "        [2.2588, 3.0140, 1.7331, 3.0671, 3.0374, 1.8674, 1.8174],\n",
            "        [0.8175, 1.2374, 0.8132, 1.2566, 1.1993, 0.8731, 0.8479],\n",
            "        [3.0238, 3.8789, 2.1758, 3.9603, 3.9492, 2.3242, 2.3058]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "272\n",
            "tensor([[0.8218, 1.2434, 0.8167, 1.2607, 1.2049, 0.8752, 0.8487],\n",
            "        [1.1801, 1.7022, 1.0626, 1.7276, 1.6731, 1.1537, 1.1024],\n",
            "        [1.0220, 1.5023, 0.9552, 1.5217, 1.4670, 1.0317, 0.9914],\n",
            "        [1.6030, 2.2312, 1.3336, 2.2613, 2.2183, 1.4493, 1.3888],\n",
            "        [3.0291, 3.8909, 2.1707, 3.9616, 3.9352, 2.3320, 2.3165]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "273\n",
            "tensor([[2.3036, 3.0722, 1.7652, 3.1258, 3.1036, 1.8970, 1.8483],\n",
            "        [3.1291, 3.9982, 2.2373, 4.0753, 4.0596, 2.3968, 2.3794],\n",
            "        [0.8459, 1.2745, 0.8339, 1.2929, 1.2365, 0.8933, 0.8657],\n",
            "        [3.1154, 3.9851, 2.2290, 4.0586, 4.0426, 2.3875, 2.3700],\n",
            "        [2.4073, 3.1868, 1.8231, 3.2461, 3.2233, 1.9566, 1.9120]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "274\n",
            "tensor([[1.2246, 1.7579, 1.0912, 1.7845, 1.7343, 1.1847, 1.1336],\n",
            "        [3.0420, 3.9004, 2.1894, 3.9825, 3.9740, 2.3400, 2.3201],\n",
            "        [2.1750, 2.9199, 1.6900, 2.9706, 2.9454, 1.8171, 1.7656],\n",
            "        [1.5397, 2.1545, 1.2969, 2.1846, 2.1412, 1.4102, 1.3474],\n",
            "        [2.8194, 3.6564, 2.0634, 3.7315, 3.7207, 2.2015, 2.1779]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "275\n",
            "tensor([[3.0939, 3.9639, 2.2206, 4.0398, 4.0234, 2.3802, 2.3579],\n",
            "        [1.1630, 1.6810, 1.0539, 1.7053, 1.6544, 1.1413, 1.0904],\n",
            "        [1.3877, 1.9667, 1.1990, 1.9936, 1.9473, 1.3054, 1.2447],\n",
            "        [2.6729, 3.4964, 1.9840, 3.5661, 3.5531, 2.1151, 2.0856],\n",
            "        [2.2302, 2.9842, 1.7211, 3.0362, 3.0128, 1.8474, 1.7994]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "276\n",
            "tensor([[2.1048, 2.8417, 1.6484, 2.8897, 2.8618, 1.7724, 1.7213],\n",
            "        [1.3629, 1.9360, 1.1857, 1.9616, 1.9164, 1.2841, 1.2271],\n",
            "        [2.5045, 3.3045, 1.8854, 3.3689, 3.3506, 2.0152, 1.9777],\n",
            "        [3.1026, 3.9752, 2.2280, 4.0536, 4.0433, 2.3846, 2.3607],\n",
            "        [0.9668, 1.4332, 0.9217, 1.4542, 1.4003, 0.9921, 0.9539]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "277\n",
            "tensor([[3.0062, 3.8631, 2.1741, 3.9427, 3.9424, 2.3021, 2.2896],\n",
            "        [1.4539, 2.0508, 1.2482, 2.0809, 2.0358, 1.3485, 1.2905],\n",
            "        [3.1124, 3.9869, 2.2350, 4.0656, 4.0529, 2.3878, 2.3669],\n",
            "        [2.9353, 3.7897, 2.1367, 3.8683, 3.8629, 2.2694, 2.2480],\n",
            "        [0.9794, 1.4478, 0.9325, 1.4712, 1.4176, 1.0028, 0.9621]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "278\n",
            "tensor([[2.6182, 3.4395, 1.9591, 3.5095, 3.4965, 2.0744, 2.0478],\n",
            "        [3.1026, 3.9776, 2.2335, 4.0566, 4.0454, 2.3755, 2.3584],\n",
            "        [3.1200, 3.9983, 2.2429, 4.0766, 4.0617, 2.3931, 2.3734],\n",
            "        [0.9620, 1.4283, 0.9222, 1.4505, 1.3957, 0.9898, 0.9509],\n",
            "        [2.8847, 3.7351, 2.1122, 3.8127, 3.8108, 2.2308, 2.2138]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "279\n",
            "tensor([[3.0957, 3.9701, 2.2309, 4.0489, 4.0363, 2.3723, 2.3551],\n",
            "        [2.4682, 3.2684, 1.8729, 3.3325, 3.3155, 1.9947, 1.9537],\n",
            "        [0.9124, 1.3646, 0.8887, 1.3852, 1.3293, 0.9474, 0.9160],\n",
            "        [1.3004, 1.8616, 1.1481, 1.8855, 1.8367, 1.2368, 1.1823],\n",
            "        [2.9612, 3.8204, 2.1556, 3.9014, 3.8976, 2.2774, 2.2651]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "280\n",
            "tensor([[1.7468, 2.4144, 1.4396, 2.4530, 2.4144, 1.5473, 1.4891],\n",
            "        [2.5863, 3.4038, 1.9445, 3.4735, 3.4581, 2.0605, 2.0314],\n",
            "        [3.1002, 3.9814, 2.2374, 4.0572, 4.0421, 2.3790, 2.3632],\n",
            "        [3.1167, 3.9960, 2.2475, 4.0747, 4.0615, 2.3894, 2.3714],\n",
            "        [1.9683, 2.6801, 1.5735, 2.7253, 2.6907, 1.6871, 1.6316]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "281\n",
            "tensor([[2.8721, 3.7273, 2.1114, 3.8050, 3.7944, 2.2354, 2.2147],\n",
            "        [2.9958, 3.8595, 2.1805, 3.9448, 3.9364, 2.3031, 2.2932],\n",
            "        [1.0281, 1.5137, 0.9714, 1.5378, 1.4821, 1.0389, 0.9994],\n",
            "        [0.8833, 1.3276, 0.8704, 1.3487, 1.2926, 0.9265, 0.8963],\n",
            "        [1.5496, 2.1720, 1.3151, 2.2055, 2.1621, 1.4169, 1.3555]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "282\n",
            "tensor([[2.5032, 3.3112, 1.8973, 3.3775, 3.3593, 2.0097, 1.9811],\n",
            "        [1.0030, 1.4818, 0.9558, 1.5067, 1.4497, 1.0205, 0.9832],\n",
            "        [1.8949, 2.5950, 1.5326, 2.6382, 2.6037, 1.6391, 1.5870],\n",
            "        [3.1163, 3.9978, 2.2489, 4.0773, 4.0609, 2.3899, 2.3763],\n",
            "        [1.8844, 2.5830, 1.5249, 2.6246, 2.5897, 1.6348, 1.5795]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "283\n",
            "tensor([[1.1942, 1.7275, 1.0846, 1.7540, 1.7005, 1.1615, 1.1176],\n",
            "        [2.3145, 3.0925, 1.7890, 3.1504, 3.1262, 1.8969, 1.8610],\n",
            "        [2.5320, 3.3435, 1.9163, 3.4102, 3.3908, 2.0323, 2.0020],\n",
            "        [3.0772, 3.9517, 2.2297, 4.0361, 4.0256, 2.3637, 2.3515],\n",
            "        [3.0019, 3.8663, 2.1863, 3.9486, 3.9455, 2.3055, 2.2971]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "Loss at epoch 5: 128.7169\n",
            "Pearson correlation for aspect 1: 0.6094\n",
            "Pearson correlation for aspect 2: 0.6857\n",
            "Pearson correlation for aspect 3: 0.2389\n",
            "Pearson correlation for aspect 4: 0.7030\n",
            "Pearson correlation for aspect 5: 0.7043\n",
            "Pearson correlation for aspect 6: 0.2972\n",
            "Pearson correlation for aspect 7: 0.3899\n",
            "Mean Pearson correlation: 0.5183\n",
            "0\n",
            "tensor([[1.0944, 1.5991, 1.0171, 1.6223, 1.5691, 1.0857, 1.0469],\n",
            "        [1.7478, 2.4173, 1.4417, 2.4554, 2.4165, 1.5447, 1.4929],\n",
            "        [2.3203, 3.0993, 1.7916, 3.1572, 3.1363, 1.8957, 1.8646],\n",
            "        [2.8428, 3.6963, 2.0972, 3.7746, 3.7678, 2.2027, 2.1994],\n",
            "        [0.8838, 1.3277, 0.8715, 1.3495, 1.2926, 0.9241, 0.8983]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "1\n",
            "tensor([[2.0847, 2.8212, 1.6488, 2.8706, 2.8405, 1.7548, 1.7135],\n",
            "        [3.0612, 3.9366, 2.2196, 4.0168, 4.0061, 2.3483, 2.3437],\n",
            "        [2.4314, 3.2286, 1.8550, 3.2905, 3.2672, 1.9672, 1.9400],\n",
            "        [1.1052, 1.6141, 1.0238, 1.6391, 1.5863, 1.0946, 1.0565],\n",
            "        [3.0754, 3.9536, 2.2274, 4.0311, 4.0216, 2.3459, 2.3534]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "2\n",
            "tensor([[1.3653, 1.9448, 1.1978, 1.9747, 1.9245, 1.2863, 1.2374],\n",
            "        [1.0998, 1.6095, 1.0202, 1.6323, 1.5817, 1.0904, 1.0529],\n",
            "        [3.1144, 3.9991, 2.2463, 4.0762, 4.0631, 2.3761, 2.3822],\n",
            "        [1.0143, 1.4983, 0.9647, 1.5228, 1.4659, 1.0268, 0.9947],\n",
            "        [3.0714, 3.9465, 2.2225, 4.0275, 4.0195, 2.3418, 2.3487]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "3\n",
            "tensor([[3.1114, 3.9987, 2.2456, 4.0770, 4.0630, 2.3802, 2.3842],\n",
            "        [1.0727, 1.5760, 1.0026, 1.5989, 1.5445, 1.0704, 1.0367],\n",
            "        [3.0849, 3.9664, 2.2279, 4.0409, 4.0272, 2.3479, 2.3632],\n",
            "        [1.2225, 1.7650, 1.1037, 1.7927, 1.7392, 1.1814, 1.1410],\n",
            "        [2.9502, 3.8166, 2.1557, 3.8959, 3.8884, 2.2685, 2.2731]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "4\n",
            "tensor([[3.1145, 4.0017, 2.2470, 4.0772, 4.0618, 2.3752, 2.3863],\n",
            "        [1.2175, 1.7622, 1.1018, 1.7870, 1.7340, 1.1805, 1.1390],\n",
            "        [2.4396, 3.2467, 1.8639, 3.3073, 3.2866, 1.9684, 1.9517],\n",
            "        [1.1443, 1.6667, 1.0520, 1.6917, 1.6367, 1.1230, 1.0887],\n",
            "        [2.7596, 3.6079, 2.0486, 3.6817, 3.6691, 2.1572, 2.1570]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "5\n",
            "tensor([[2.8922, 3.7543, 2.1227, 3.8338, 3.8218, 2.2340, 2.2446],\n",
            "        [0.8755, 1.3206, 0.8700, 1.3437, 1.2845, 0.9250, 0.8993],\n",
            "        [1.5067, 2.1256, 1.2902, 2.1561, 2.1096, 1.3806, 1.3385],\n",
            "        [0.8710, 1.3147, 0.8654, 1.3379, 1.2782, 0.9181, 0.8962],\n",
            "        [1.5098, 2.1292, 1.2910, 2.1599, 2.1133, 1.3862, 1.3406]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "6\n",
            "tensor([[3.1054, 3.9947, 2.2445, 4.0764, 4.0574, 2.3789, 2.3909],\n",
            "        [0.7032, 1.0968, 0.7458, 1.1156, 1.0571, 0.7805, 0.7746],\n",
            "        [3.1074, 4.0003, 2.2447, 4.0798, 4.0617, 2.3869, 2.3923],\n",
            "        [2.1757, 2.9392, 1.7077, 2.9931, 2.9607, 1.8156, 1.7863],\n",
            "        [1.1749, 1.7072, 1.0725, 1.7327, 1.6770, 1.1505, 1.1126]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "7\n",
            "tensor([[3.0350, 3.9193, 2.2062, 4.0020, 3.9876, 2.3382, 2.3469],\n",
            "        [1.4511, 2.0579, 1.2542, 2.0899, 2.0388, 1.3515, 1.3062],\n",
            "        [0.9643, 1.4385, 0.9314, 1.4626, 1.4038, 0.9950, 0.9671],\n",
            "        [3.0936, 3.9831, 2.2387, 4.0650, 4.0503, 2.3791, 2.3859],\n",
            "        [0.9930, 1.4754, 0.9494, 1.4986, 1.4404, 1.0139, 0.9849]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "8\n",
            "tensor([[2.8145, 3.6758, 2.0826, 3.7541, 3.7411, 2.2069, 2.2037],\n",
            "        [1.0266, 1.5196, 0.9751, 1.5455, 1.4859, 1.0443, 1.0121],\n",
            "        [2.3375, 3.1298, 1.7983, 3.1849, 3.1513, 1.9326, 1.8942],\n",
            "        [1.2506, 1.8074, 1.1254, 1.8359, 1.7808, 1.2150, 1.1705],\n",
            "        [3.1103, 4.0076, 2.2479, 4.0878, 4.0625, 2.3981, 2.4057]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "9\n",
            "tensor([[2.3482, 3.1482, 1.8107, 3.2108, 3.1781, 1.9359, 1.9094],\n",
            "        [1.4272, 2.0321, 1.2413, 2.0634, 2.0105, 1.3421, 1.2947],\n",
            "        [1.7587, 2.4412, 1.4518, 2.4816, 2.4359, 1.5663, 1.5185],\n",
            "        [2.0670, 2.8161, 1.6418, 2.8665, 2.8297, 1.7588, 1.7236],\n",
            "        [1.0551, 1.5565, 0.9948, 1.5813, 1.5233, 1.0691, 1.0331]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "10\n",
            "tensor([[1.4035, 2.0013, 1.2263, 2.0331, 1.9805, 1.3266, 1.2774],\n",
            "        [2.6331, 3.4791, 1.9804, 3.5518, 3.5278, 2.1125, 2.0951],\n",
            "        [3.0894, 3.9844, 2.2410, 4.0677, 4.0443, 2.3992, 2.3933],\n",
            "        [2.9922, 3.8765, 2.1842, 3.9580, 3.9424, 2.3147, 2.3261],\n",
            "        [2.9148, 3.7937, 2.1419, 3.8772, 3.8554, 2.2843, 2.2800]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "11\n",
            "tensor([[1.8685, 2.5773, 1.5221, 2.6225, 2.5784, 1.6446, 1.5966],\n",
            "        [3.0628, 3.9575, 2.2247, 4.0435, 4.0214, 2.3789, 2.3797],\n",
            "        [2.5863, 3.4228, 1.9522, 3.4950, 3.4701, 2.0876, 2.0676],\n",
            "        [2.2925, 3.0838, 1.7806, 3.1445, 3.1116, 1.9103, 1.8770],\n",
            "        [3.0436, 3.9425, 2.2116, 4.0256, 3.9958, 2.3689, 2.3728]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "12\n",
            "tensor([[3.1057, 4.0106, 2.2474, 4.0928, 4.0673, 2.4159, 2.4125],\n",
            "        [2.8616, 3.7351, 2.1081, 3.8149, 3.7945, 2.2404, 2.2459],\n",
            "        [1.7279, 2.4084, 1.4333, 2.4468, 2.3997, 1.5544, 1.5041],\n",
            "        [2.3258, 3.1261, 1.7999, 3.1865, 3.1541, 1.9280, 1.9009],\n",
            "        [1.0340, 1.5323, 0.9805, 1.5570, 1.4978, 1.0584, 1.0215]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "13\n",
            "tensor([[2.6831, 3.5415, 2.0058, 3.6157, 3.5894, 2.1492, 2.1375],\n",
            "        [3.1045, 4.0137, 2.2454, 4.0931, 4.0635, 2.4192, 2.4172],\n",
            "        [2.7672, 3.6342, 2.0559, 3.7122, 3.6904, 2.1941, 2.1900],\n",
            "        [0.8858, 1.3413, 0.8775, 1.3659, 1.3021, 0.9444, 0.9176],\n",
            "        [2.3689, 3.1793, 1.8223, 3.2414, 3.2103, 1.9573, 1.9326]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "14\n",
            "tensor([[1.2448, 1.8075, 1.1239, 1.8360, 1.7778, 1.2229, 1.1765],\n",
            "        [1.5715, 2.2182, 1.3333, 2.2526, 2.1991, 1.4548, 1.4026],\n",
            "        [2.6221, 3.4741, 1.9726, 3.5469, 3.5182, 2.1204, 2.1006],\n",
            "        [1.2338, 1.7925, 1.1155, 1.8211, 1.7637, 1.2141, 1.1680],\n",
            "        [0.9330, 1.4027, 0.9117, 1.4279, 1.3639, 0.9845, 0.9535]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "15\n",
            "tensor([[1.0743, 1.5889, 1.0064, 1.6143, 1.5511, 1.0901, 1.0553],\n",
            "        [2.4255, 3.2495, 1.8592, 3.3141, 3.2816, 2.0019, 1.9753],\n",
            "        [3.0978, 4.0107, 2.2441, 4.0925, 4.0633, 2.4233, 2.4187],\n",
            "        [1.1054, 1.6286, 1.0314, 1.6560, 1.5937, 1.1224, 1.0795],\n",
            "        [2.0993, 2.8616, 1.6628, 2.9142, 2.8722, 1.8035, 1.7599]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "16\n",
            "tensor([[3.0427, 3.9511, 2.2158, 4.0385, 4.0132, 2.3868, 2.3847],\n",
            "        [0.9795, 1.4660, 0.9451, 1.4938, 1.4292, 1.0274, 0.9909],\n",
            "        [0.8485, 1.2952, 0.8549, 1.3203, 1.2565, 0.9197, 0.8948],\n",
            "        [1.2233, 1.7826, 1.1109, 1.8137, 1.7527, 1.2121, 1.1658],\n",
            "        [1.7208, 2.4085, 1.4313, 2.4489, 2.3984, 1.5627, 1.5102]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "17\n",
            "tensor([[2.6366, 3.4980, 1.9847, 3.5749, 3.5465, 2.1410, 2.1198],\n",
            "        [0.9125, 1.3816, 0.8989, 1.4087, 1.3430, 0.9749, 0.9454],\n",
            "        [2.1332, 2.9078, 1.6847, 2.9642, 2.9209, 1.8333, 1.7896],\n",
            "        [1.7005, 2.3853, 1.4215, 2.4306, 2.3760, 1.5550, 1.5018],\n",
            "        [2.5057, 3.3505, 1.9082, 3.4236, 3.3899, 2.0662, 2.0384]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "18\n",
            "tensor([[2.5005, 3.3467, 1.9060, 3.4188, 3.3839, 2.0664, 2.0354],\n",
            "        [2.6039, 3.4645, 1.9654, 3.5423, 3.5091, 2.1292, 2.1046],\n",
            "        [1.2551, 1.8282, 1.1321, 1.8591, 1.7983, 1.2415, 1.1921],\n",
            "        [2.2917, 3.1058, 1.7812, 3.1684, 3.1292, 1.9359, 1.9011],\n",
            "        [2.9918, 3.8980, 2.1861, 3.9898, 3.9637, 2.3609, 2.3575]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "19\n",
            "tensor([[3.0698, 3.9954, 2.2327, 4.0831, 4.0475, 2.4271, 2.4168],\n",
            "        [2.7603, 3.6468, 2.0571, 3.7291, 3.7001, 2.2295, 2.2090],\n",
            "        [2.0331, 2.7971, 1.6272, 2.8520, 2.8055, 1.7766, 1.7295],\n",
            "        [1.5714, 2.2295, 1.3396, 2.2702, 2.2121, 1.4699, 1.4163],\n",
            "        [3.0018, 3.9205, 2.1939, 4.0079, 3.9763, 2.3796, 2.3717]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "20\n",
            "tensor([[2.0443, 2.8173, 1.6349, 2.8724, 2.8256, 1.7849, 1.7413],\n",
            "        [1.1645, 1.7156, 1.0734, 1.7465, 1.6824, 1.1760, 1.1318],\n",
            "        [1.5680, 2.2269, 1.3371, 2.2675, 2.2089, 1.4685, 1.4152],\n",
            "        [2.8291, 3.7289, 2.0968, 3.8137, 3.7838, 2.2694, 2.2588],\n",
            "        [2.4891, 3.3422, 1.8983, 3.4141, 3.3763, 2.0632, 2.0355]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "21\n",
            "tensor([[2.2398, 3.0524, 1.7528, 3.1151, 3.0691, 1.9081, 1.8737],\n",
            "        [1.8598, 2.5925, 1.5202, 2.6380, 2.5876, 1.6627, 1.6159],\n",
            "        [1.8750, 2.6121, 1.5322, 2.6609, 2.6082, 1.6781, 1.6279],\n",
            "        [1.5586, 2.2211, 1.3326, 2.2593, 2.2019, 1.4640, 1.4109],\n",
            "        [2.9356, 3.8536, 2.1566, 3.9391, 3.9062, 2.3413, 2.3320]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "22\n",
            "tensor([[2.2445, 3.0614, 1.7546, 3.1211, 3.0762, 1.9125, 1.8779],\n",
            "        [3.0478, 3.9825, 2.2233, 4.0696, 4.0353, 2.4207, 2.4092],\n",
            "        [2.9105, 3.8276, 2.1464, 3.9134, 3.8799, 2.3243, 2.3170],\n",
            "        [1.0477, 1.5672, 0.9946, 1.5947, 1.5280, 1.0869, 1.0491],\n",
            "        [3.0376, 3.9711, 2.2167, 4.0564, 4.0188, 2.4096, 2.4043]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "23\n",
            "tensor([[2.1038, 2.8963, 1.6750, 2.9526, 2.9032, 1.8296, 1.7858],\n",
            "        [2.9508, 3.8767, 2.1698, 3.9635, 3.9283, 2.3502, 2.3479],\n",
            "        [1.0438, 1.5636, 0.9936, 1.5923, 1.5246, 1.0855, 1.0476],\n",
            "        [0.9366, 1.4234, 0.9182, 1.4503, 1.3824, 1.0016, 0.9713],\n",
            "        [2.5470, 3.4184, 1.9386, 3.4898, 3.4531, 2.0931, 2.0773]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "24\n",
            "tensor([[1.9663, 2.7349, 1.5935, 2.7867, 2.7337, 1.7410, 1.6962],\n",
            "        [2.3615, 3.2050, 1.8290, 3.2712, 3.2263, 1.9961, 1.9603],\n",
            "        [1.8249, 2.5585, 1.5039, 2.6056, 2.5499, 1.6490, 1.6003],\n",
            "        [2.8017, 3.7124, 2.0878, 3.7943, 3.7614, 2.2587, 2.2492],\n",
            "        [2.2634, 3.0897, 1.7736, 3.1518, 3.1086, 1.9244, 1.8925]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "25\n",
            "tensor([[1.4898, 2.1419, 1.2919, 2.1769, 2.1148, 1.4210, 1.3682],\n",
            "        [2.6363, 3.5287, 1.9920, 3.6048, 3.5677, 2.1589, 2.1431],\n",
            "        [0.9367, 1.4263, 0.9217, 1.4529, 1.3832, 1.0052, 0.9733],\n",
            "        [1.5468, 2.2130, 1.3259, 2.2506, 2.1884, 1.4612, 1.4087],\n",
            "        [2.1231, 2.9239, 1.6883, 2.9801, 2.9312, 1.8405, 1.8023]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "26\n",
            "tensor([[3.0575, 4.0095, 2.2323, 4.0915, 4.0503, 2.4265, 2.4262],\n",
            "        [1.5317, 2.1959, 1.3190, 2.2331, 2.1704, 1.4506, 1.3985],\n",
            "        [1.8053, 2.5395, 1.4920, 2.5829, 2.5249, 1.6354, 1.5884],\n",
            "        [1.0769, 1.6118, 1.0191, 1.6401, 1.5708, 1.1137, 1.0761],\n",
            "        [3.0569, 4.0059, 2.2347, 4.0906, 4.0528, 2.4293, 2.4225]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "27\n",
            "tensor([[1.4507, 2.0943, 1.2684, 2.1306, 2.0672, 1.3930, 1.3442],\n",
            "        [2.0072, 2.7879, 1.6164, 2.8378, 2.7822, 1.7664, 1.7250],\n",
            "        [3.0464, 3.9942, 2.2260, 4.0802, 4.0423, 2.4227, 2.4159],\n",
            "        [2.6494, 3.5493, 2.0011, 3.6246, 3.5868, 2.1658, 2.1535],\n",
            "        [2.8856, 3.8130, 2.1345, 3.8977, 3.8664, 2.3121, 2.3067]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "28\n",
            "tensor([[1.5726, 2.2511, 1.3457, 2.2864, 2.2261, 1.4789, 1.4275],\n",
            "        [2.7043, 3.6130, 2.0330, 3.6910, 3.6540, 2.1942, 2.1883],\n",
            "        [2.6586, 3.5600, 2.0067, 3.6344, 3.5985, 2.1681, 2.1591],\n",
            "        [1.6126, 2.3009, 1.3712, 2.3382, 2.2773, 1.5061, 1.4569],\n",
            "        [1.7987, 2.5317, 1.4878, 2.5741, 2.5154, 1.6298, 1.5842]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "29\n",
            "tensor([[3.0320, 3.9849, 2.2191, 4.0678, 4.0261, 2.4152, 2.4105],\n",
            "        [3.0580, 4.0111, 2.2329, 4.0944, 4.0547, 2.4228, 2.4275],\n",
            "        [2.6825, 3.5880, 2.0179, 3.6620, 3.6246, 2.1864, 2.1758],\n",
            "        [3.0526, 4.0043, 2.2299, 4.0867, 4.0494, 2.4174, 2.4204],\n",
            "        [3.0752, 4.0326, 2.2416, 4.1122, 4.0697, 2.4421, 2.4393]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "30\n",
            "tensor([[2.2487, 3.0838, 1.7620, 3.1418, 3.0924, 1.9174, 1.8913],\n",
            "        [2.4552, 3.3277, 1.8854, 3.3942, 3.3515, 2.0473, 2.0278],\n",
            "        [2.7505, 3.6697, 2.0570, 3.7454, 3.7087, 2.2283, 2.2228],\n",
            "        [2.9742, 3.9166, 2.1842, 4.0008, 3.9653, 2.3666, 2.3695],\n",
            "        [3.0634, 4.0191, 2.2340, 4.1021, 4.0615, 2.4303, 2.4308]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "31\n",
            "tensor([[1.2821, 1.8806, 1.1539, 1.9103, 1.8433, 1.2671, 1.2245],\n",
            "        [3.0740, 4.0286, 2.2392, 4.1140, 4.0691, 2.4357, 2.4417],\n",
            "        [2.8378, 3.7646, 2.1065, 3.8470, 3.8116, 2.2767, 2.2796],\n",
            "        [2.0505, 2.8460, 1.6427, 2.8983, 2.8448, 1.7951, 1.7598],\n",
            "        [2.7063, 3.6169, 2.0309, 3.6932, 3.6556, 2.1914, 2.1932]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "32\n",
            "tensor([[1.3925, 2.0232, 1.2273, 2.0581, 1.9907, 1.3496, 1.3066],\n",
            "        [1.7645, 2.4936, 1.4629, 2.5346, 2.4759, 1.6056, 1.5648],\n",
            "        [2.3722, 3.2296, 1.8339, 3.2951, 3.2474, 1.9931, 1.9773],\n",
            "        [1.7246, 2.4444, 1.4396, 2.4865, 2.4254, 1.5814, 1.5390],\n",
            "        [1.9619, 2.7363, 1.5852, 2.7856, 2.7285, 1.7331, 1.7009]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "33\n",
            "tensor([[2.7262, 3.6414, 2.0385, 3.7207, 3.6821, 2.1990, 2.2132],\n",
            "        [2.8992, 3.8379, 2.1387, 3.9228, 3.8842, 2.3200, 2.3303],\n",
            "        [3.0786, 4.0365, 2.2398, 4.1225, 4.0793, 2.4416, 2.4499],\n",
            "        [2.7173, 3.6329, 2.0342, 3.7125, 3.6700, 2.1982, 2.2091],\n",
            "        [3.0386, 3.9912, 2.2181, 4.0780, 4.0386, 2.4142, 2.4222]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "34\n",
            "tensor([[2.3618, 3.2177, 1.8246, 3.2834, 3.2364, 1.9869, 1.9735],\n",
            "        [2.9602, 3.9025, 2.1687, 3.9890, 3.9497, 2.3609, 2.3695],\n",
            "        [3.0536, 4.0060, 2.2217, 4.0952, 4.0515, 2.4134, 2.4329],\n",
            "        [2.2365, 3.0724, 1.7496, 3.1306, 3.0791, 1.9058, 1.8897],\n",
            "        [2.5569, 3.4495, 1.9373, 3.5221, 3.4781, 2.1045, 2.1048]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "35\n",
            "tensor([[1.3972, 2.0320, 1.2247, 2.0648, 1.9975, 1.3483, 1.3126],\n",
            "        [3.0880, 4.0480, 2.2389, 4.1328, 4.0872, 2.4416, 2.4589],\n",
            "        [3.0911, 4.0515, 2.2413, 4.1346, 4.0914, 2.4477, 2.4602],\n",
            "        [0.8065, 1.2579, 0.8259, 1.2819, 1.2120, 0.8940, 0.8804],\n",
            "        [1.5416, 2.2152, 1.3170, 2.2503, 2.1862, 1.4520, 1.4128]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "36\n",
            "tensor([[2.6435, 3.5486, 1.9853, 3.6234, 3.5813, 2.1630, 2.1619],\n",
            "        [2.4380, 3.3088, 1.8653, 3.3755, 3.3302, 2.0367, 2.0246],\n",
            "        [2.3401, 3.1932, 1.8070, 3.2548, 3.2069, 1.9740, 1.9596],\n",
            "        [2.3227, 3.1758, 1.7974, 3.2365, 3.1850, 1.9633, 1.9491],\n",
            "        [3.0733, 4.0288, 2.2279, 4.1153, 4.0704, 2.4262, 2.4471]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "37\n",
            "tensor([[2.7824, 3.7086, 2.0651, 3.7865, 3.7544, 2.2330, 2.2501],\n",
            "        [1.6727, 2.3804, 1.3988, 2.4192, 2.3570, 1.5436, 1.5052],\n",
            "        [2.9699, 3.9184, 2.1705, 4.0008, 3.9615, 2.3648, 2.3795],\n",
            "        [2.9845, 3.9325, 2.1759, 4.0136, 3.9746, 2.3621, 2.3841],\n",
            "        [2.3455, 3.2061, 1.8110, 3.2655, 3.2188, 1.9754, 1.9651]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "38\n",
            "tensor([[2.4274, 3.2985, 1.8564, 3.3605, 3.3156, 2.0298, 2.0158],\n",
            "        [2.5527, 3.4503, 1.9323, 3.5179, 3.4771, 2.1046, 2.1013],\n",
            "        [1.3010, 1.9117, 1.1603, 1.9388, 1.8721, 1.2780, 1.2439],\n",
            "        [3.0778, 4.0414, 2.2294, 4.1225, 4.0793, 2.4368, 2.4519],\n",
            "        [2.5461, 3.4424, 1.9276, 3.5092, 3.4690, 2.0934, 2.0968]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "39\n",
            "tensor([[1.3229, 1.9418, 1.1744, 1.9688, 1.9023, 1.2969, 1.2593],\n",
            "        [2.0601, 2.8628, 1.6365, 2.9090, 2.8587, 1.7966, 1.7676],\n",
            "        [3.0638, 4.0285, 2.2194, 4.1064, 4.0615, 2.4258, 2.4395],\n",
            "        [1.1166, 1.6731, 1.0381, 1.6991, 1.6296, 1.1442, 1.1108],\n",
            "        [2.9507, 3.9049, 2.1543, 3.9810, 3.9397, 2.3506, 2.3656]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "40\n",
            "tensor([[1.7277, 2.4570, 1.4311, 2.4919, 2.4328, 1.5818, 1.5415],\n",
            "        [2.7756, 3.7116, 2.0555, 3.7817, 3.7439, 2.2406, 2.2478],\n",
            "        [1.2009, 1.7863, 1.0925, 1.8094, 1.7422, 1.2067, 1.1712],\n",
            "        [1.0731, 1.6180, 1.0064, 1.6401, 1.5724, 1.1106, 1.0781],\n",
            "        [2.9917, 3.9476, 2.1777, 4.0247, 3.9896, 2.3749, 2.3850]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "41\n",
            "tensor([[3.0356, 4.0004, 2.1982, 4.0728, 4.0273, 2.4028, 2.4166],\n",
            "        [2.2928, 3.1499, 1.7734, 3.2013, 3.1547, 1.9451, 1.9245],\n",
            "        [3.0739, 4.0430, 2.2229, 4.1160, 4.0741, 2.4343, 2.4423],\n",
            "        [1.1756, 1.7542, 1.0748, 1.7758, 1.7089, 1.1903, 1.1520],\n",
            "        [1.1955, 1.7798, 1.0873, 1.8023, 1.7352, 1.2060, 1.1657]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "42\n",
            "tensor([[1.0526, 1.5934, 0.9919, 1.6153, 1.5463, 1.0974, 1.0631],\n",
            "        [2.4380, 3.3204, 1.8560, 3.3761, 3.3318, 2.0356, 2.0186],\n",
            "        [0.8665, 1.3445, 0.8643, 1.3652, 1.2943, 0.9464, 0.9250],\n",
            "        [1.4599, 2.1193, 1.2551, 2.1443, 2.0801, 1.3947, 1.3516],\n",
            "        [1.0768, 1.6246, 1.0097, 1.6460, 1.5777, 1.1128, 1.0792]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "43\n",
            "tensor([[1.0302, 1.5643, 0.9763, 1.5857, 1.5148, 1.0788, 1.0469],\n",
            "        [2.8112, 3.7557, 2.0711, 3.8215, 3.7820, 2.2714, 2.2669],\n",
            "        [1.1540, 1.7274, 1.0608, 1.7484, 1.6811, 1.1733, 1.1354],\n",
            "        [1.6608, 2.3767, 1.3843, 2.4051, 2.3446, 1.5379, 1.4920],\n",
            "        [2.7057, 3.6314, 2.0101, 3.6952, 3.6549, 2.2066, 2.1957]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "44\n",
            "tensor([[3.0418, 4.0123, 2.2001, 4.0836, 4.0432, 2.4159, 2.4163],\n",
            "        [0.7945, 1.2518, 0.8123, 1.2705, 1.1998, 0.8858, 0.8713],\n",
            "        [0.9964, 1.5219, 0.9512, 1.5397, 1.4696, 1.0521, 1.0203],\n",
            "        [2.9989, 3.9611, 2.1753, 4.0329, 3.9932, 2.3774, 2.3864],\n",
            "        [2.1775, 3.0149, 1.7010, 3.0603, 3.0068, 1.8720, 1.8440]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "45\n",
            "tensor([[2.7487, 3.6851, 2.0330, 3.7468, 3.7051, 2.2261, 2.2212],\n",
            "        [1.7650, 2.5087, 1.4490, 2.5386, 2.4795, 1.6056, 1.5617],\n",
            "        [3.0200, 3.9882, 2.1874, 4.0562, 4.0197, 2.3981, 2.3997],\n",
            "        [1.5339, 2.2189, 1.3022, 2.2409, 2.1783, 1.4475, 1.4004],\n",
            "        [2.9530, 3.9137, 2.1518, 3.9833, 3.9452, 2.3567, 2.3570]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "46\n",
            "tensor([[2.7625, 3.7024, 2.0410, 3.7632, 3.7290, 2.2230, 2.2256],\n",
            "        [2.1375, 2.9691, 1.6769, 3.0092, 2.9568, 1.8494, 1.8156],\n",
            "        [3.0149, 3.9829, 2.1844, 4.0491, 4.0096, 2.3988, 2.3940],\n",
            "        [1.0660, 1.6130, 1.0005, 1.6329, 1.5626, 1.1062, 1.0695],\n",
            "        [3.0078, 3.9746, 2.1790, 4.0411, 4.0032, 2.3859, 2.3891]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "47\n",
            "tensor([[3.0536, 4.0222, 2.2031, 4.0880, 4.0453, 2.4112, 2.4189],\n",
            "        [2.5021, 3.3999, 1.8914, 3.4515, 3.4081, 2.0744, 2.0541],\n",
            "        [0.7639, 1.2098, 0.7887, 1.2259, 1.1571, 0.8596, 0.8447],\n",
            "        [1.5874, 2.2846, 1.3364, 2.3081, 2.2456, 1.4831, 1.4370],\n",
            "        [0.9517, 1.4598, 0.9206, 1.4764, 1.4075, 1.0125, 0.9834]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "48\n",
            "tensor([[2.8520, 3.7974, 2.0887, 3.8591, 3.8255, 2.2771, 2.2801],\n",
            "        [2.1014, 2.9194, 1.6533, 2.9559, 2.9047, 1.8180, 1.7859],\n",
            "        [2.1770, 3.0122, 1.6969, 3.0514, 3.0000, 1.8658, 1.8369],\n",
            "        [0.7708, 1.2167, 0.7938, 1.2335, 1.1642, 0.8634, 0.8486],\n",
            "        [1.5405, 2.2245, 1.3073, 2.2477, 2.1846, 1.4512, 1.4037]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "49\n",
            "tensor([[2.1183, 2.9405, 1.6620, 2.9757, 2.9240, 1.8257, 1.7954],\n",
            "        [2.5234, 3.4224, 1.9024, 3.4714, 3.4294, 2.0724, 2.0635],\n",
            "        [2.7338, 3.6637, 2.0203, 3.7202, 3.6755, 2.2099, 2.2039],\n",
            "        [2.7754, 3.7111, 2.0457, 3.7685, 3.7347, 2.2283, 2.2267],\n",
            "        [2.4366, 3.3207, 1.8484, 3.3674, 3.3218, 2.0225, 2.0074]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "50\n",
            "tensor([[3.0893, 4.0633, 2.2198, 4.1232, 4.0826, 2.4310, 2.4359],\n",
            "        [1.4346, 2.0893, 1.2375, 2.1074, 2.0437, 1.3651, 1.3266],\n",
            "        [1.3658, 2.0012, 1.1953, 2.0205, 1.9541, 1.3224, 1.2792],\n",
            "        [2.4226, 3.3039, 1.8396, 3.3480, 3.3057, 2.0100, 1.9944],\n",
            "        [1.0843, 1.6342, 1.0098, 1.6506, 1.5817, 1.1107, 1.0794]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "51\n",
            "tensor([[1.8650, 2.6335, 1.5068, 2.6582, 2.6050, 1.6574, 1.6221],\n",
            "        [1.1894, 1.7748, 1.0795, 1.7873, 1.7218, 1.1872, 1.1513],\n",
            "        [2.9143, 3.8676, 2.1212, 3.9269, 3.8916, 2.3124, 2.3160],\n",
            "        [2.5539, 3.4614, 1.9156, 3.5077, 3.4638, 2.0882, 2.0807],\n",
            "        [1.5631, 2.2533, 1.3197, 2.2724, 2.2107, 1.4581, 1.4165]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "52\n",
            "tensor([[1.5752, 2.2708, 1.3270, 2.2861, 2.2272, 1.4618, 1.4215],\n",
            "        [1.6632, 2.3829, 1.3842, 2.4017, 2.3420, 1.5241, 1.4834],\n",
            "        [1.3094, 1.9319, 1.1580, 1.9449, 1.8819, 1.2761, 1.2364],\n",
            "        [0.7956, 1.2529, 0.8099, 1.2652, 1.1975, 0.8791, 0.8651],\n",
            "        [2.0046, 2.8094, 1.5940, 2.8364, 2.7857, 1.7494, 1.7170]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "53\n",
            "tensor([[2.6992, 3.6376, 2.0008, 3.6827, 3.6486, 2.1620, 2.1737],\n",
            "        [3.0792, 4.0577, 2.2149, 4.1120, 4.0736, 2.4155, 2.4248],\n",
            "        [1.7881, 2.5423, 1.4605, 2.5608, 2.5068, 1.5998, 1.5671],\n",
            "        [3.0329, 4.0046, 2.1890, 4.0604, 4.0253, 2.3809, 2.3931],\n",
            "        [2.5361, 3.4483, 1.9057, 3.4874, 3.4484, 2.0687, 2.0681]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "54\n",
            "tensor([[3.0251, 3.9992, 2.1838, 4.0491, 4.0152, 2.3727, 2.3868],\n",
            "        [1.6650, 2.3881, 1.3840, 2.4033, 2.3450, 1.5163, 1.4816],\n",
            "        [1.7190, 2.4547, 1.4186, 2.4722, 2.4165, 1.5553, 1.5193],\n",
            "        [1.9907, 2.7946, 1.5844, 2.8167, 2.7649, 1.7318, 1.7049],\n",
            "        [0.9804, 1.5020, 0.9395, 1.5116, 1.4449, 1.0222, 0.9996]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "55\n",
            "tensor([[2.2281, 3.0824, 1.7260, 3.1107, 3.0649, 1.8759, 1.8629],\n",
            "        [2.8990, 3.8593, 2.1123, 3.9062, 3.8780, 2.2746, 2.2998],\n",
            "        [3.0910, 4.0717, 2.2198, 4.1188, 4.0825, 2.4108, 2.4275],\n",
            "        [1.9745, 2.7741, 1.5739, 2.7931, 2.7436, 1.7142, 1.6904],\n",
            "        [2.5279, 3.4366, 1.9014, 3.4723, 3.4346, 2.0567, 2.0569]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "56\n",
            "tensor([[0.9153, 1.4153, 0.8951, 1.4240, 1.3576, 0.9684, 0.9500],\n",
            "        [2.4775, 3.3765, 1.8704, 3.4091, 3.3696, 2.0307, 2.0232],\n",
            "        [1.5208, 2.2086, 1.2947, 2.2195, 2.1597, 1.4168, 1.3829],\n",
            "        [1.0568, 1.6032, 0.9905, 1.6127, 1.5449, 1.0798, 1.0537],\n",
            "        [3.0009, 3.9703, 2.1669, 4.0164, 3.9899, 2.3314, 2.3610]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "57\n",
            "tensor([[2.9491, 3.9166, 2.1360, 3.9565, 3.9315, 2.2883, 2.3277],\n",
            "        [1.6929, 2.4256, 1.3996, 2.4355, 2.3815, 1.5265, 1.4986],\n",
            "        [2.8941, 3.8559, 2.1086, 3.8996, 3.8669, 2.2785, 2.2957],\n",
            "        [1.9656, 2.7653, 1.5696, 2.7830, 2.7338, 1.7041, 1.6836],\n",
            "        [2.0262, 2.8378, 1.6040, 2.8548, 2.8084, 1.7414, 1.7226]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "58\n",
            "tensor([[1.7707, 2.5236, 1.4484, 2.5344, 2.4820, 1.5769, 1.5504],\n",
            "        [1.9854, 2.7894, 1.5769, 2.8060, 2.7573, 1.7136, 1.6973],\n",
            "        [0.9753, 1.4968, 0.9345, 1.5037, 1.4378, 1.0109, 0.9932],\n",
            "        [2.1540, 2.9973, 1.6811, 3.0189, 2.9740, 1.8199, 1.8098],\n",
            "        [2.3567, 3.2374, 1.8000, 3.2630, 3.2208, 1.9377, 1.9419]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "59\n",
            "tensor([[1.0846, 1.6426, 1.0114, 1.6497, 1.5821, 1.0970, 1.0739],\n",
            "        [2.3101, 3.1858, 1.7748, 3.2089, 3.1692, 1.9104, 1.9119],\n",
            "        [2.7885, 3.7423, 2.0487, 3.7789, 3.7515, 2.1921, 2.2246],\n",
            "        [2.2458, 3.1104, 1.7341, 3.1317, 3.0879, 1.8750, 1.8721],\n",
            "        [0.9299, 1.4368, 0.9045, 1.4439, 1.3759, 0.9751, 0.9602]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "60\n",
            "tensor([[3.0246, 4.0075, 2.1851, 4.0482, 4.0176, 2.3510, 2.3793],\n",
            "        [1.2927, 1.9188, 1.1474, 1.9242, 1.8604, 1.2483, 1.2227],\n",
            "        [2.1906, 3.0463, 1.7034, 3.0654, 3.0216, 1.8364, 1.8353],\n",
            "        [3.0290, 4.0133, 2.1891, 4.0549, 4.0238, 2.3589, 2.3867],\n",
            "        [2.6417, 3.5787, 1.9706, 3.6090, 3.5761, 2.1044, 2.1282]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "61\n",
            "tensor([[1.3544, 2.0008, 1.1896, 2.0049, 1.9430, 1.2912, 1.2660],\n",
            "        [3.0623, 4.0511, 2.2060, 4.0912, 4.0550, 2.3710, 2.4091],\n",
            "        [2.6005, 3.5331, 1.9467, 3.5623, 3.5288, 2.0849, 2.1046],\n",
            "        [2.7250, 3.6746, 2.0179, 3.7084, 3.6749, 2.1584, 2.1859],\n",
            "        [2.3527, 3.2409, 1.8013, 3.2637, 3.2204, 1.9403, 1.9425]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "62\n",
            "tensor([[1.4836, 2.1673, 1.2739, 2.1714, 2.1118, 1.3814, 1.3546],\n",
            "        [2.9847, 3.9682, 2.1678, 4.0080, 3.9742, 2.3217, 2.3563],\n",
            "        [3.0942, 4.0904, 2.2298, 4.1259, 4.0904, 2.3969, 2.4272],\n",
            "        [2.3126, 3.1969, 1.7811, 3.2164, 3.1739, 1.9132, 1.9158],\n",
            "        [1.3777, 2.0310, 1.2042, 2.0333, 1.9716, 1.3044, 1.2803]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "63\n",
            "tensor([[0.7984, 1.2638, 0.8166, 1.2690, 1.2016, 0.8693, 0.8628],\n",
            "        [1.3882, 2.0476, 1.2100, 2.0458, 1.9836, 1.3114, 1.2857],\n",
            "        [3.1050, 4.1034, 2.2356, 4.1380, 4.0991, 2.4058, 2.4345],\n",
            "        [2.5185, 3.4397, 1.9030, 3.4646, 3.4259, 2.0369, 2.0495],\n",
            "        [0.7864, 1.2477, 0.8076, 1.2513, 1.1852, 0.8585, 0.8528]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "64\n",
            "tensor([[1.8404, 2.6223, 1.4993, 2.6273, 2.5752, 1.6193, 1.5973],\n",
            "        [2.8832, 3.8590, 2.1128, 3.8905, 3.8598, 2.2552, 2.2858],\n",
            "        [2.2346, 3.1012, 1.7372, 3.1161, 3.0735, 1.8608, 1.8600],\n",
            "        [1.1398, 1.7205, 1.0517, 1.7226, 1.6569, 1.1359, 1.1112],\n",
            "        [1.0279, 1.5734, 0.9780, 1.5764, 1.5095, 1.0525, 1.0326]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "65\n",
            "tensor([[3.0600, 4.0520, 2.2118, 4.0825, 4.0525, 2.3710, 2.3976],\n",
            "        [0.8811, 1.3769, 0.8752, 1.3793, 1.3120, 0.9360, 0.9233],\n",
            "        [0.8644, 1.3545, 0.8630, 1.3566, 1.2904, 0.9215, 0.9117],\n",
            "        [1.1529, 1.7402, 1.0616, 1.7395, 1.6737, 1.1435, 1.1202],\n",
            "        [0.7799, 1.2401, 0.8039, 1.2427, 1.1753, 0.8525, 0.8475]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "66\n",
            "tensor([[2.3857, 3.2852, 1.8284, 3.2994, 3.2602, 1.9600, 1.9570],\n",
            "        [1.4933, 2.1827, 1.2821, 2.1808, 2.1214, 1.3871, 1.3580],\n",
            "        [1.7786, 2.5441, 1.4614, 2.5452, 2.4909, 1.5778, 1.5524],\n",
            "        [2.1660, 3.0184, 1.6962, 3.0268, 2.9809, 1.8227, 1.8102],\n",
            "        [1.7849, 2.5506, 1.4642, 2.5511, 2.4976, 1.5767, 1.5549]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "67\n",
            "tensor([[1.3401, 1.9855, 1.1834, 1.9811, 1.9190, 1.2798, 1.2489],\n",
            "        [1.0377, 1.5884, 0.9832, 1.5869, 1.5211, 1.0597, 1.0364],\n",
            "        [0.9699, 1.4979, 0.9378, 1.4983, 1.4302, 1.0068, 0.9879],\n",
            "        [1.7342, 2.4889, 1.4339, 2.4872, 2.4323, 1.5507, 1.5210],\n",
            "        [1.0862, 1.6528, 1.0169, 1.6514, 1.5849, 1.0952, 1.0715]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "68\n",
            "tensor([[2.7162, 3.6752, 2.0178, 3.6916, 3.6587, 2.1456, 2.1709],\n",
            "        [1.1949, 1.7987, 1.0893, 1.7934, 1.7286, 1.1739, 1.1481],\n",
            "        [1.5678, 2.2810, 1.3282, 2.2735, 2.2193, 1.4340, 1.4042],\n",
            "        [3.0076, 4.0032, 2.1838, 4.0239, 3.9922, 2.3418, 2.3618],\n",
            "        [2.2519, 3.1337, 1.7481, 3.1371, 3.0969, 1.8733, 1.8686]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "69\n",
            "tensor([[2.8724, 3.8527, 2.1060, 3.8694, 3.8416, 2.2494, 2.2698],\n",
            "        [2.8804, 3.8583, 2.1094, 3.8742, 3.8440, 2.2507, 2.2742],\n",
            "        [2.2220, 3.0942, 1.7293, 3.0961, 3.0519, 1.8547, 1.8466],\n",
            "        [2.5313, 3.4597, 1.9108, 3.4696, 3.4338, 2.0457, 2.0484],\n",
            "        [1.4835, 2.1734, 1.2780, 2.1669, 2.1079, 1.3804, 1.3496]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "70\n",
            "tensor([[2.6317, 3.5783, 1.9697, 3.5895, 3.5576, 2.1032, 2.1132],\n",
            "        [2.5436, 3.4770, 1.9188, 3.4826, 3.4513, 2.0495, 2.0538],\n",
            "        [0.8519, 1.3423, 0.8560, 1.3389, 1.2724, 0.9122, 0.9000],\n",
            "        [3.0777, 4.0805, 2.2183, 4.0946, 4.0559, 2.3816, 2.4073],\n",
            "        [1.1985, 1.8032, 1.0910, 1.7955, 1.7328, 1.1759, 1.1483]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "71\n",
            "tensor([[3.0257, 4.0241, 2.1929, 4.0371, 4.0067, 2.3475, 2.3690],\n",
            "        [2.9765, 3.9680, 2.1656, 3.9794, 3.9555, 2.3098, 2.3320],\n",
            "        [0.8242, 1.3073, 0.8282, 1.2954, 1.2370, 0.8811, 0.8737],\n",
            "        [1.7765, 2.5505, 1.4592, 2.5389, 2.4886, 1.5727, 1.5475],\n",
            "        [2.1178, 2.9683, 1.6654, 2.9617, 2.9186, 1.7890, 1.7741]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "72\n",
            "tensor([[0.9447, 1.4661, 0.9213, 1.4600, 1.3937, 0.9842, 0.9661],\n",
            "        [0.9966, 1.5363, 0.9579, 1.5280, 1.4632, 1.0261, 1.0051],\n",
            "        [1.7188, 2.4736, 1.4259, 2.4624, 2.4099, 1.5321, 1.5060],\n",
            "        [2.1025, 2.9524, 1.6630, 2.9463, 2.9044, 1.7759, 1.7657],\n",
            "        [1.8905, 2.6924, 1.5334, 2.6814, 2.6350, 1.6455, 1.6230]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "73\n",
            "tensor([[2.9184, 3.9023, 2.1362, 3.9129, 3.8880, 2.2750, 2.2953],\n",
            "        [0.8200, 1.2985, 0.8346, 1.2920, 1.2254, 0.8817, 0.8748],\n",
            "        [0.9062, 1.4146, 0.8951, 1.4077, 1.3410, 0.9526, 0.9383],\n",
            "        [2.3730, 3.2762, 1.8230, 3.2721, 3.2413, 1.9384, 1.9397],\n",
            "        [0.9544, 1.4789, 0.9305, 1.4733, 1.4060, 0.9921, 0.9736]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "74\n",
            "tensor([[2.6697, 3.6252, 1.9951, 3.6287, 3.5987, 2.1191, 2.1356],\n",
            "        [2.2337, 3.1082, 1.7397, 3.1012, 3.0595, 1.8552, 1.8499],\n",
            "        [1.6492, 2.3879, 1.3877, 2.3739, 2.3201, 1.4877, 1.4593],\n",
            "        [1.4675, 2.1534, 1.2708, 2.1397, 2.0821, 1.3646, 1.3349],\n",
            "        [0.9358, 1.4552, 0.9164, 1.4461, 1.3803, 0.9762, 0.9585]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "75\n",
            "tensor([[1.0401, 1.5945, 0.9877, 1.5831, 1.5189, 1.0546, 1.0341],\n",
            "        [2.0664, 2.9082, 1.6407, 2.8965, 2.8507, 1.7586, 1.7401],\n",
            "        [1.8643, 2.6561, 1.5185, 2.6435, 2.5952, 1.6296, 1.6047],\n",
            "        [2.6767, 3.6308, 2.0013, 3.6326, 3.6070, 2.1160, 2.1358],\n",
            "        [3.0422, 4.0406, 2.2093, 4.0482, 4.0227, 2.3510, 2.3751]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "76\n",
            "tensor([[1.1711, 1.7698, 1.0775, 1.7563, 1.6924, 1.1555, 1.1280],\n",
            "        [1.0003, 1.5423, 0.9640, 1.5329, 1.4659, 1.0292, 1.0074],\n",
            "        [3.0948, 4.1013, 2.2384, 4.1029, 4.0700, 2.3887, 2.4148],\n",
            "        [1.4975, 2.1941, 1.2900, 2.1773, 2.1207, 1.3855, 1.3559],\n",
            "        [2.5321, 3.4623, 1.9185, 3.4611, 3.4278, 2.0395, 2.0458]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "77\n",
            "tensor([[2.7651, 3.7333, 2.0502, 3.7353, 3.7090, 2.1740, 2.1958],\n",
            "        [0.7888, 1.2579, 0.8129, 1.2499, 1.1844, 0.8590, 0.8522],\n",
            "        [3.1070, 4.1125, 2.2455, 4.1186, 4.0902, 2.3976, 2.4214],\n",
            "        [1.1830, 1.7870, 1.0855, 1.7735, 1.7094, 1.1663, 1.1386],\n",
            "        [2.0847, 2.9302, 1.6535, 2.9201, 2.8758, 1.7700, 1.7526]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "78\n",
            "tensor([[2.6240, 3.5742, 1.9715, 3.5755, 3.5444, 2.0950, 2.1089],\n",
            "        [3.0130, 4.0141, 2.1934, 4.0192, 3.9958, 2.3374, 2.3615],\n",
            "        [1.5953, 2.3208, 1.3534, 2.3065, 2.2505, 1.4549, 1.4254],\n",
            "        [1.2501, 1.8751, 1.1303, 1.8623, 1.7978, 1.2156, 1.1876],\n",
            "        [2.5429, 3.4845, 1.9253, 3.4814, 3.4477, 2.0433, 2.0571]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "79\n",
            "tensor([[2.9787, 3.9734, 2.1728, 3.9829, 3.9577, 2.3136, 2.3408],\n",
            "        [1.0610, 1.6266, 1.0023, 1.6134, 1.5469, 1.0738, 1.0517],\n",
            "        [2.6079, 3.5566, 1.9606, 3.5568, 3.5272, 2.0789, 2.0995],\n",
            "        [2.7661, 3.7372, 2.0507, 3.7409, 3.7082, 2.1867, 2.2059],\n",
            "        [3.0859, 4.0936, 2.2317, 4.1034, 4.0714, 2.3834, 2.4153]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "80\n",
            "tensor([[3.0970, 4.1082, 2.2354, 4.1151, 4.0822, 2.3907, 2.4235],\n",
            "        [0.8180, 1.3001, 0.8337, 1.2923, 1.2249, 0.8843, 0.8776],\n",
            "        [2.6873, 3.6507, 2.0056, 3.6544, 3.6223, 2.1340, 2.1570],\n",
            "        [3.0755, 4.0840, 2.2214, 4.0897, 4.0565, 2.3775, 2.4094],\n",
            "        [1.8555, 2.6520, 1.5117, 2.6397, 2.5869, 1.6285, 1.6074]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "81\n",
            "tensor([[2.1137, 2.9704, 1.6679, 2.9623, 2.9146, 1.7891, 1.7822],\n",
            "        [3.0492, 4.0530, 2.2074, 4.0654, 4.0356, 2.3531, 2.3946],\n",
            "        [3.0901, 4.1002, 2.2286, 4.1075, 4.0747, 2.3876, 2.4233],\n",
            "        [1.5179, 2.2268, 1.3009, 2.2129, 2.1525, 1.4045, 1.3821],\n",
            "        [2.0661, 2.9130, 1.6396, 2.9025, 2.8583, 1.7554, 1.7496]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "82\n",
            "tensor([[0.8450, 1.3359, 0.8533, 1.3296, 1.2599, 0.9062, 0.9013],\n",
            "        [2.6954, 3.6577, 2.0036, 3.6602, 3.6310, 2.1236, 2.1630],\n",
            "        [1.0096, 1.5575, 0.9659, 1.5498, 1.4803, 1.0367, 1.0216],\n",
            "        [2.8525, 3.8395, 2.0947, 3.8463, 3.8185, 2.2249, 2.2675],\n",
            "        [1.6298, 2.3686, 1.3692, 2.3528, 2.2949, 1.4773, 1.4564]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "83\n",
            "tensor([[2.0553, 2.8944, 1.6245, 2.8852, 2.8363, 1.7478, 1.7431],\n",
            "        [2.0468, 2.8871, 1.6204, 2.8775, 2.8269, 1.7417, 1.7402],\n",
            "        [3.1045, 4.1113, 2.2285, 4.1153, 4.0793, 2.3893, 2.4350],\n",
            "        [0.8518, 1.3457, 0.8553, 1.3394, 1.2696, 0.9125, 0.9070],\n",
            "        [2.3718, 3.2767, 1.8135, 3.2740, 3.2319, 1.9376, 1.9548]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "84\n",
            "tensor([[3.0006, 3.9988, 2.1676, 4.0052, 3.9706, 2.3140, 2.3648],\n",
            "        [3.1106, 4.1191, 2.2281, 4.1247, 4.0838, 2.3931, 2.4413],\n",
            "        [0.9864, 1.5271, 0.9469, 1.5175, 1.4487, 1.0147, 1.0047],\n",
            "        [1.6443, 2.3839, 1.3741, 2.3704, 2.3114, 1.4793, 1.4684],\n",
            "        [2.4851, 3.4157, 1.8775, 3.4144, 3.3751, 2.0001, 2.0309]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "85\n",
            "tensor([[1.2078, 1.8211, 1.0923, 1.8064, 1.7405, 1.1770, 1.1640],\n",
            "        [3.0582, 4.0569, 2.1921, 4.0678, 4.0344, 2.3459, 2.4046],\n",
            "        [1.7384, 2.5061, 1.4278, 2.4904, 2.4340, 1.5417, 1.5342],\n",
            "        [3.0769, 4.0789, 2.2046, 4.0883, 4.0530, 2.3597, 2.4177],\n",
            "        [1.9354, 2.7496, 1.5475, 2.7362, 2.6828, 1.6674, 1.6662]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "86\n",
            "tensor([[3.0523, 4.0535, 2.1848, 4.0610, 4.0289, 2.3378, 2.4023],\n",
            "        [2.0710, 2.9165, 1.6246, 2.9045, 2.8562, 1.7462, 1.7585],\n",
            "        [3.1042, 4.1098, 2.2143, 4.1162, 4.0788, 2.3785, 2.4361],\n",
            "        [3.0632, 4.0665, 2.1888, 4.0681, 4.0270, 2.3463, 2.4133],\n",
            "        [0.8328, 1.3196, 0.8349, 1.3115, 1.2422, 0.8931, 0.8934]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "87\n",
            "tensor([[2.3711, 3.2765, 1.7953, 3.2704, 3.2280, 1.9257, 1.9568],\n",
            "        [3.1062, 4.1152, 2.2074, 4.1161, 4.0738, 2.3817, 2.4427],\n",
            "        [0.9991, 1.5426, 0.9476, 1.5310, 1.4617, 1.0188, 1.0148],\n",
            "        [2.5451, 3.4811, 1.8955, 3.4768, 3.4362, 2.0286, 2.0729],\n",
            "        [2.0210, 2.8522, 1.5889, 2.8408, 2.7866, 1.7145, 1.7264]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "88\n",
            "tensor([[3.1130, 4.1195, 2.2057, 4.1229, 4.0818, 2.3801, 2.4469],\n",
            "        [1.7836, 2.5599, 1.4448, 2.5452, 2.4877, 1.5675, 1.5659],\n",
            "        [1.2610, 1.8923, 1.1175, 1.8780, 1.8105, 1.2158, 1.2064],\n",
            "        [2.6016, 3.5469, 1.9225, 3.5456, 3.5066, 2.0613, 2.1101],\n",
            "        [2.7569, 3.7235, 2.0091, 3.7277, 3.6928, 2.1505, 2.2105]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "89\n",
            "tensor([[1.9396, 2.7533, 1.5347, 2.7399, 2.6860, 1.6603, 1.6715],\n",
            "        [0.8326, 1.3184, 0.8318, 1.3099, 1.2386, 0.8885, 0.8941],\n",
            "        [1.3891, 2.0572, 1.1981, 2.0402, 1.9750, 1.2998, 1.2936],\n",
            "        [3.0923, 4.0935, 2.1907, 4.0981, 4.0587, 2.3551, 2.4315],\n",
            "        [2.3575, 3.2621, 1.7801, 3.2553, 3.2087, 1.9125, 1.9513]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "90\n",
            "tensor([[1.0087, 1.5551, 0.9484, 1.5436, 1.4722, 1.0261, 1.0236],\n",
            "        [1.8835, 2.6842, 1.4983, 2.6678, 2.6144, 1.6221, 1.6344],\n",
            "        [2.7318, 3.6939, 1.9848, 3.6949, 3.6607, 2.1227, 2.1946],\n",
            "        [2.1789, 3.0426, 1.6695, 3.0308, 2.9806, 1.8044, 1.8304],\n",
            "        [2.7574, 3.7249, 2.0010, 3.7262, 3.6917, 2.1433, 2.2113]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "91\n",
            "tensor([[1.7401, 2.5050, 1.4107, 2.4875, 2.4289, 1.5300, 1.5382],\n",
            "        [0.9129, 1.4286, 0.8817, 1.4188, 1.3465, 0.9530, 0.9552],\n",
            "        [1.4582, 2.1453, 1.2351, 2.1282, 2.0643, 1.3477, 1.3438],\n",
            "        [1.8478, 2.6363, 1.4712, 2.6198, 2.5645, 1.5972, 1.6090],\n",
            "        [1.5255, 2.2329, 1.2785, 2.2170, 2.1533, 1.3920, 1.3922]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "92\n",
            "tensor([[3.1060, 4.1034, 2.1799, 4.1082, 4.0701, 2.3533, 2.4427],\n",
            "        [0.7744, 1.2388, 0.7841, 1.2311, 1.1610, 0.8388, 0.8503],\n",
            "        [3.0493, 4.0417, 2.1517, 4.0488, 4.0141, 2.3191, 2.4040],\n",
            "        [2.7769, 3.7391, 2.0008, 3.7415, 3.7037, 2.1520, 2.2235],\n",
            "        [3.1101, 4.1093, 2.1838, 4.1139, 4.0727, 2.3645, 2.4470]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "93\n",
            "tensor([[0.6774, 1.1071, 0.7168, 1.1005, 1.0310, 0.7604, 0.7763],\n",
            "        [3.0829, 4.0793, 2.1649, 4.0830, 4.0438, 2.3400, 2.4255],\n",
            "        [2.0381, 2.8719, 1.5784, 2.8582, 2.8040, 1.7121, 1.7387],\n",
            "        [3.1011, 4.0999, 2.1730, 4.0997, 4.0525, 2.3584, 2.4419],\n",
            "        [0.9716, 1.5056, 0.9199, 1.4960, 1.4239, 0.9955, 0.9973]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "94\n",
            "tensor([[2.4608, 3.3734, 1.8167, 3.3686, 3.3254, 1.9633, 2.0160],\n",
            "        [1.0082, 1.5533, 0.9409, 1.5420, 1.4695, 1.0224, 1.0240],\n",
            "        [1.7299, 2.4886, 1.3939, 2.4731, 2.4121, 1.5195, 1.5321],\n",
            "        [2.4148, 3.3268, 1.7940, 3.3200, 3.2764, 1.9335, 1.9893],\n",
            "        [1.4382, 2.1181, 1.2162, 2.1017, 2.0375, 1.3255, 1.3303]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "95\n",
            "tensor([[2.5821, 3.5178, 1.8844, 3.5160, 3.4741, 2.0293, 2.0979],\n",
            "        [1.4273, 2.1055, 1.2084, 2.0882, 2.0215, 1.3199, 1.3214],\n",
            "        [1.4655, 2.1539, 1.2323, 2.1370, 2.0716, 1.3474, 1.3493],\n",
            "        [1.5458, 2.2558, 1.2828, 2.2381, 2.1765, 1.3967, 1.4038],\n",
            "        [1.1036, 1.6816, 1.0046, 1.6698, 1.5972, 1.0946, 1.0938]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "96\n",
            "tensor([[1.8779, 2.6736, 1.4781, 2.6565, 2.6005, 1.6099, 1.6297],\n",
            "        [2.3715, 3.2765, 1.7660, 3.2668, 3.2212, 1.9060, 1.9601],\n",
            "        [2.2402, 3.1160, 1.6900, 3.1078, 3.0558, 1.8309, 1.8736],\n",
            "        [1.4852, 2.1754, 1.2445, 2.1575, 2.0947, 1.3588, 1.3613],\n",
            "        [2.7748, 3.7374, 1.9881, 3.7386, 3.7045, 2.1383, 2.2215]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "97\n",
            "tensor([[2.9050, 3.8855, 2.0593, 3.8890, 3.8596, 2.2122, 2.3052],\n",
            "        [1.2186, 1.8331, 1.0771, 1.8194, 1.7500, 1.1716, 1.1753],\n",
            "        [3.0945, 4.0940, 2.1616, 4.0954, 4.0540, 2.3430, 2.4348],\n",
            "        [2.0935, 2.9424, 1.6062, 2.9290, 2.8800, 1.7344, 1.7766],\n",
            "        [3.1013, 4.0997, 2.1645, 4.0999, 4.0592, 2.3488, 2.4416]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "98\n",
            "tensor([[3.0959, 4.0918, 2.1592, 4.0981, 4.0627, 2.3316, 2.4339],\n",
            "        [0.9658, 1.4995, 0.9127, 1.4879, 1.4180, 0.9839, 0.9935],\n",
            "        [2.9189, 3.9006, 2.0637, 3.9027, 3.8741, 2.2111, 2.3146],\n",
            "        [2.7367, 3.6957, 1.9654, 3.6968, 3.6608, 2.1178, 2.1976],\n",
            "        [3.0926, 4.0926, 2.1579, 4.0902, 4.0489, 2.3413, 2.4344]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "99\n",
            "tensor([[1.4035, 2.0742, 1.1940, 2.0593, 1.9946, 1.2996, 1.3066],\n",
            "        [2.3077, 3.1996, 1.7277, 3.1910, 3.1485, 1.8602, 1.9186],\n",
            "        [2.9875, 3.9729, 2.1020, 3.9791, 3.9528, 2.2543, 2.3601],\n",
            "        [2.3398, 3.2396, 1.7456, 3.2291, 3.1859, 1.8898, 1.9416],\n",
            "        [0.8546, 1.3492, 0.8392, 1.3411, 1.2687, 0.8980, 0.9132]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "100\n",
            "tensor([[0.9937, 1.5369, 0.9319, 1.5259, 1.4556, 1.0082, 1.0147],\n",
            "        [2.0247, 2.8581, 1.5633, 2.8436, 2.7907, 1.6911, 1.7316],\n",
            "        [0.6908, 1.1261, 0.7228, 1.1202, 1.0511, 0.7673, 0.7894],\n",
            "        [1.1286, 1.7144, 1.0196, 1.7036, 1.6331, 1.1072, 1.1124],\n",
            "        [0.8714, 1.3727, 0.8503, 1.3638, 1.2928, 0.9136, 0.9251]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "101\n",
            "tensor([[1.6036, 2.3341, 1.3107, 2.3147, 2.2523, 1.4315, 1.4437],\n",
            "        [1.0177, 1.5693, 0.9473, 1.5556, 1.4866, 1.0228, 1.0317],\n",
            "        [2.0903, 2.9390, 1.6002, 2.9239, 2.8772, 1.7335, 1.7747],\n",
            "        [2.1244, 2.9799, 1.6169, 2.9648, 2.9155, 1.7569, 1.7997],\n",
            "        [3.1030, 4.1016, 2.1603, 4.1049, 4.0670, 2.3378, 2.4427]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "102\n",
            "tensor([[1.8668, 2.6648, 1.4707, 2.6488, 2.5941, 1.5957, 1.6266],\n",
            "        [3.0867, 4.0860, 2.1522, 4.0880, 4.0530, 2.3214, 2.4318],\n",
            "        [0.6891, 1.1237, 0.7239, 1.1175, 1.0479, 0.7651, 0.7871],\n",
            "        [1.3422, 1.9963, 1.1538, 1.9803, 1.9158, 1.2563, 1.2643],\n",
            "        [1.1342, 1.7225, 1.0228, 1.7096, 1.6403, 1.1076, 1.1164]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "103\n",
            "tensor([[2.7624, 3.7320, 1.9754, 3.7319, 3.7025, 2.1138, 2.2176],\n",
            "        [2.2682, 3.1543, 1.7009, 3.1439, 3.0994, 1.8371, 1.8952],\n",
            "        [1.9967, 2.8217, 1.5446, 2.8076, 2.7550, 1.6735, 1.7138],\n",
            "        [0.8210, 1.3045, 0.8150, 1.2970, 1.2249, 0.8732, 0.8895],\n",
            "        [1.3853, 2.0537, 1.1785, 2.0359, 1.9708, 1.2837, 1.2964]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "104\n",
            "tensor([[1.6323, 2.3718, 1.3310, 2.3519, 2.2945, 1.4449, 1.4667],\n",
            "        [0.9878, 1.5308, 0.9271, 1.5183, 1.4475, 0.9998, 1.0117],\n",
            "        [2.0986, 2.9474, 1.6022, 2.9313, 2.8845, 1.7334, 1.7802],\n",
            "        [1.4990, 2.2020, 1.2492, 2.1811, 2.1190, 1.3599, 1.3736],\n",
            "        [0.7944, 1.2670, 0.7973, 1.2590, 1.1871, 0.8483, 0.8683]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "105\n",
            "tensor([[1.6140, 2.3478, 1.3173, 2.3258, 2.2681, 1.4334, 1.4527],\n",
            "        [0.8524, 1.3483, 0.8367, 1.3375, 1.2680, 0.8967, 0.9107],\n",
            "        [0.7573, 1.2183, 0.7721, 1.2108, 1.1401, 0.8209, 0.8412],\n",
            "        [1.5632, 2.2835, 1.2909, 2.2637, 2.2043, 1.3993, 1.4181],\n",
            "        [1.3300, 1.9810, 1.1448, 1.9642, 1.9011, 1.2420, 1.2556]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "106\n",
            "tensor([[2.4904, 3.4228, 1.8262, 3.4111, 3.3793, 1.9591, 2.0389],\n",
            "        [0.8611, 1.3607, 0.8442, 1.3491, 1.2803, 0.9018, 0.9169],\n",
            "        [0.8805, 1.3854, 0.8584, 1.3737, 1.3043, 0.9154, 0.9311],\n",
            "        [2.0585, 2.9038, 1.5815, 2.8851, 2.8382, 1.7073, 1.7544],\n",
            "        [2.8887, 3.8717, 2.0449, 3.8680, 3.8458, 2.1830, 2.2947]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "107\n",
            "tensor([[3.0182, 4.0171, 2.1083, 4.0093, 3.9705, 2.2882, 2.3887],\n",
            "        [1.7891, 2.5728, 1.4253, 2.5494, 2.4986, 1.5414, 1.5715],\n",
            "        [2.1997, 3.0757, 1.6643, 3.0595, 3.0168, 1.7952, 1.8498],\n",
            "        [2.9309, 3.9208, 2.0689, 3.9167, 3.8931, 2.2228, 2.3280],\n",
            "        [0.8057, 1.2853, 0.8078, 1.2756, 1.2065, 0.8602, 0.8755]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "108\n",
            "tensor([[3.0219, 4.0189, 2.1188, 4.0170, 3.9966, 2.2794, 2.3826],\n",
            "        [0.9802, 1.5215, 0.9224, 1.5044, 1.4381, 0.9885, 1.0023],\n",
            "        [3.0345, 4.0357, 2.1234, 4.0305, 4.0104, 2.2740, 2.3917],\n",
            "        [2.7569, 3.7334, 1.9753, 3.7235, 3.6980, 2.1096, 2.2124],\n",
            "        [1.6922, 2.4514, 1.3714, 2.4292, 2.3752, 1.4851, 1.5082]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "109\n",
            "tensor([[1.3938, 2.0676, 1.1872, 2.0460, 1.9841, 1.2846, 1.2988],\n",
            "        [2.2255, 3.1075, 1.6813, 3.0892, 3.0508, 1.8024, 1.8614],\n",
            "        [2.8214, 3.7983, 2.0077, 3.7923, 3.7758, 2.1373, 2.2464],\n",
            "        [2.3653, 3.2781, 1.7614, 3.2624, 3.2280, 1.8850, 1.9555],\n",
            "        [1.6456, 2.3923, 1.3444, 2.3685, 2.3153, 1.4514, 1.4742]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "110\n",
            "tensor([[2.8910, 3.8778, 2.0480, 3.8726, 3.8518, 2.1835, 2.2958],\n",
            "        [2.9978, 3.9919, 2.1054, 3.9892, 3.9672, 2.2521, 2.3651],\n",
            "        [2.0482, 2.8926, 1.5796, 2.8721, 2.8305, 1.6979, 1.7438],\n",
            "        [1.2571, 1.8895, 1.1069, 1.8700, 1.8070, 1.1912, 1.2014],\n",
            "        [2.9476, 3.9344, 2.0760, 3.9310, 3.9075, 2.2288, 2.3310]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "111\n",
            "tensor([[3.0570, 4.0543, 2.1346, 4.0515, 4.0285, 2.2802, 2.3999],\n",
            "        [3.0908, 4.0884, 2.1535, 4.0854, 4.0598, 2.3098, 2.4226],\n",
            "        [1.0876, 1.6614, 0.9953, 1.6448, 1.5806, 1.0681, 1.0770],\n",
            "        [2.7536, 3.7234, 1.9730, 3.7150, 3.6964, 2.0944, 2.1983],\n",
            "        [2.2890, 3.1786, 1.7155, 3.1606, 3.1270, 1.8337, 1.8959]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "112\n",
            "tensor([[2.6228, 3.5702, 1.9016, 3.5570, 3.5343, 2.0180, 2.1113],\n",
            "        [1.4517, 2.1396, 1.2256, 2.1156, 2.0612, 1.3202, 1.3310],\n",
            "        [1.0595, 1.6225, 0.9771, 1.6068, 1.5427, 1.0445, 1.0553],\n",
            "        [2.3267, 3.2198, 1.7347, 3.2019, 3.1711, 1.8511, 1.9160],\n",
            "        [0.9630, 1.4941, 0.9139, 1.4811, 1.4147, 0.9756, 0.9872]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "113\n",
            "tensor([[3.0695, 4.0624, 2.1395, 4.0553, 4.0377, 2.2845, 2.3980],\n",
            "        [1.2214, 1.8398, 1.0751, 1.8139, 1.7579, 1.1523, 1.1650],\n",
            "        [2.8325, 3.8031, 2.0122, 3.7958, 3.7773, 2.1367, 2.2433],\n",
            "        [1.4343, 2.1134, 1.2143, 2.0904, 2.0365, 1.3026, 1.3150],\n",
            "        [3.1102, 4.1057, 2.1612, 4.0979, 4.0782, 2.3144, 2.4240]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "114\n",
            "tensor([[0.9763, 1.5082, 0.9223, 1.4920, 1.4280, 0.9806, 0.9912],\n",
            "        [0.9067, 1.4166, 0.8763, 1.4029, 1.3372, 0.9290, 0.9418],\n",
            "        [1.6191, 2.3476, 1.3239, 2.3217, 2.2743, 1.4180, 1.4398],\n",
            "        [2.3886, 3.2903, 1.7665, 3.2718, 3.2468, 1.8748, 1.9491],\n",
            "        [2.4132, 3.3197, 1.7805, 3.3004, 3.2742, 1.8928, 1.9659]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "115\n",
            "tensor([[2.1081, 2.9511, 1.6099, 2.9287, 2.8936, 1.7117, 1.7645],\n",
            "        [2.3003, 3.1802, 1.7176, 3.1602, 3.1308, 1.8256, 1.8896],\n",
            "        [2.8542, 3.8188, 2.0209, 3.8099, 3.7998, 2.1336, 2.2446],\n",
            "        [1.7925, 2.5632, 1.4263, 2.5378, 2.4942, 1.5300, 1.5548],\n",
            "        [2.1622, 3.0161, 1.6400, 2.9934, 2.9610, 1.7438, 1.7976]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "116\n",
            "tensor([[1.0787, 1.6438, 0.9905, 1.6263, 1.5654, 1.0531, 1.0630],\n",
            "        [2.8022, 3.7580, 1.9928, 3.7481, 3.7375, 2.1052, 2.2111],\n",
            "        [3.0589, 4.0404, 2.1303, 4.0331, 4.0222, 2.2570, 2.3759],\n",
            "        [1.0524, 1.6080, 0.9729, 1.5904, 1.5294, 1.0317, 1.0419],\n",
            "        [2.3422, 3.2314, 1.7435, 3.2121, 3.1870, 1.8469, 1.9151]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "117\n",
            "tensor([[3.1041, 4.0870, 2.1555, 4.0787, 4.0663, 2.2988, 2.4059],\n",
            "        [2.1417, 2.9861, 1.6260, 2.9637, 2.9347, 1.7302, 1.7808],\n",
            "        [2.2665, 3.1412, 1.6980, 3.1211, 3.0933, 1.7977, 1.8639],\n",
            "        [2.9739, 3.9454, 2.0842, 3.9398, 3.9295, 2.2048, 2.3210],\n",
            "        [1.9690, 2.7773, 1.5292, 2.7552, 2.7182, 1.6313, 1.6687]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "118\n",
            "tensor([[2.0252, 2.8427, 1.5623, 2.8211, 2.7871, 1.6637, 1.7021],\n",
            "        [2.7582, 3.7057, 1.9698, 3.6958, 3.6840, 2.0797, 2.1772],\n",
            "        [2.4101, 3.2998, 1.7789, 3.2840, 3.2621, 1.8825, 1.9517],\n",
            "        [2.5433, 3.4608, 1.8542, 3.4460, 3.4288, 1.9605, 2.0402],\n",
            "        [0.8263, 1.3032, 0.8208, 1.2907, 1.2291, 0.8638, 0.8777]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "119\n",
            "tensor([[1.2426, 1.8557, 1.0920, 1.8339, 1.7778, 1.1646, 1.1716],\n",
            "        [2.8407, 3.7929, 2.0144, 3.7838, 3.7749, 2.1259, 2.2228],\n",
            "        [1.0139, 1.5512, 0.9480, 1.5356, 1.4752, 1.0028, 1.0104],\n",
            "        [2.0445, 2.8639, 1.5722, 2.8394, 2.8073, 1.6656, 1.7097],\n",
            "        [3.0197, 3.9880, 2.1091, 3.9804, 3.9720, 2.2356, 2.3424]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "120\n",
            "tensor([[3.0310, 3.9962, 2.1152, 3.9873, 3.9787, 2.2354, 2.3404],\n",
            "        [2.0616, 2.8825, 1.5820, 2.8598, 2.8275, 1.6746, 1.7180],\n",
            "        [0.7407, 1.1823, 0.7615, 1.1723, 1.1105, 0.7904, 0.8098],\n",
            "        [1.8525, 2.6244, 1.4604, 2.5984, 2.5639, 1.5528, 1.5794],\n",
            "        [2.0887, 2.9117, 1.5966, 2.8905, 2.8573, 1.6947, 1.7356]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "121\n",
            "tensor([[2.9696, 3.9214, 2.0782, 3.9135, 3.9094, 2.1884, 2.2923],\n",
            "        [1.0584, 1.6047, 0.9754, 1.5894, 1.5289, 1.0309, 1.0366],\n",
            "        [2.6823, 3.6044, 1.9264, 3.5914, 3.5816, 2.0275, 2.1106],\n",
            "        [3.0743, 4.0378, 2.1359, 4.0282, 4.0210, 2.2619, 2.3646],\n",
            "        [3.0825, 4.0448, 2.1414, 4.0384, 4.0313, 2.2586, 2.3693]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "122\n",
            "tensor([[1.4843, 2.1538, 1.2416, 2.1303, 2.0814, 1.3198, 1.3262],\n",
            "        [1.5150, 2.1953, 1.2599, 2.1703, 2.1225, 1.3388, 1.3470],\n",
            "        [2.4513, 3.3369, 1.7980, 3.3162, 3.2991, 1.8880, 1.9590],\n",
            "        [2.6342, 3.5505, 1.9003, 3.5334, 3.5240, 1.9949, 2.0749],\n",
            "        [2.8048, 3.7399, 1.9904, 3.7253, 3.7194, 2.0930, 2.1836]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "123\n",
            "tensor([[1.8869, 2.6551, 1.4783, 2.6277, 2.5929, 1.5677, 1.5889],\n",
            "        [3.1453, 4.1081, 2.1696, 4.0927, 4.0854, 2.2973, 2.3982],\n",
            "        [3.0539, 4.0035, 2.1203, 3.9885, 3.9885, 2.2212, 2.3328],\n",
            "        [3.0811, 4.0373, 2.1378, 4.0250, 4.0244, 2.2582, 2.3522],\n",
            "        [1.4722, 2.1393, 1.2337, 2.1119, 2.0660, 1.3098, 1.3136]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "124\n",
            "tensor([[2.0463, 2.8486, 1.5684, 2.8169, 2.7940, 1.6548, 1.6859],\n",
            "        [2.9649, 3.9094, 2.0714, 3.8904, 3.8930, 2.1617, 2.2683],\n",
            "        [1.3036, 1.9201, 1.1279, 1.8934, 1.8432, 1.1947, 1.1959],\n",
            "        [2.7704, 3.7006, 1.9694, 3.6781, 3.6792, 2.0630, 2.1477],\n",
            "        [0.8959, 1.3857, 0.8672, 1.3692, 1.3101, 0.9085, 0.9139]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "125\n",
            "tensor([[2.7247, 3.6435, 1.9449, 3.6181, 3.6198, 2.0325, 2.1133],\n",
            "        [3.0270, 3.9712, 2.1033, 3.9521, 3.9594, 2.2134, 2.3030],\n",
            "        [1.0256, 1.5561, 0.9521, 1.5358, 1.4803, 1.0022, 1.0028],\n",
            "        [1.2443, 1.8416, 1.0921, 1.8145, 1.7631, 1.1527, 1.1514],\n",
            "        [1.0347, 1.5680, 0.9587, 1.5474, 1.4890, 1.0084, 1.0096]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "126\n",
            "tensor([[3.1317, 4.0846, 2.1584, 4.0554, 4.0534, 2.2806, 2.3727],\n",
            "        [3.0077, 3.9511, 2.0962, 3.9257, 3.9337, 2.1989, 2.2836],\n",
            "        [2.6593, 3.5680, 1.9094, 3.5379, 3.5383, 1.9953, 2.0672],\n",
            "        [2.8884, 3.8163, 2.0298, 3.7886, 3.7977, 2.1130, 2.2038],\n",
            "        [1.4350, 2.0847, 1.2094, 2.0541, 2.0084, 1.2796, 1.2783]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "127\n",
            "tensor([[2.6383, 3.5356, 1.8964, 3.5033, 3.5027, 1.9778, 2.0479],\n",
            "        [1.3775, 2.0095, 1.1728, 1.9763, 1.9322, 1.2355, 1.2352],\n",
            "        [1.0104, 1.5315, 0.9407, 1.5085, 1.4525, 0.9866, 0.9865],\n",
            "        [1.0677, 1.6076, 0.9814, 1.5817, 1.5290, 1.0297, 1.0252],\n",
            "        [1.4755, 2.1320, 1.2346, 2.0997, 2.0581, 1.3025, 1.3015]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "128\n",
            "tensor([[2.2531, 3.0857, 1.6851, 3.0495, 3.0346, 1.7656, 1.8037],\n",
            "        [2.5634, 3.4465, 1.8555, 3.4122, 3.4092, 1.9397, 1.9970],\n",
            "        [0.8253, 1.2844, 0.8187, 1.2658, 1.2079, 0.8470, 0.8543],\n",
            "        [3.1617, 4.1077, 2.1751, 4.0754, 4.0795, 2.2943, 2.3784],\n",
            "        [0.8751, 1.3505, 0.8523, 1.3326, 1.2740, 0.8863, 0.8912]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "129\n",
            "tensor([[0.7725, 1.2140, 0.7828, 1.1963, 1.1378, 0.8054, 0.8157],\n",
            "        [1.6390, 2.3369, 1.3329, 2.2966, 2.2623, 1.4038, 1.4047],\n",
            "        [0.8113, 1.2643, 0.8092, 1.2469, 1.1897, 0.8363, 0.8443],\n",
            "        [1.7214, 2.4362, 1.3791, 2.3975, 2.3647, 1.4517, 1.4569],\n",
            "        [0.9384, 1.4320, 0.8963, 1.4119, 1.3544, 0.9313, 0.9337]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "130\n",
            "tensor([[3.0964, 4.0267, 2.1408, 3.9991, 4.0125, 2.2382, 2.3259],\n",
            "        [0.8982, 1.3790, 0.8663, 1.3572, 1.3006, 0.9005, 0.9038],\n",
            "        [1.6527, 2.3480, 1.3414, 2.3119, 2.2759, 1.4107, 1.4129],\n",
            "        [0.9315, 1.4208, 0.8901, 1.4003, 1.3430, 0.9260, 0.9281],\n",
            "        [1.4235, 2.0613, 1.2030, 2.0259, 1.9839, 1.2642, 1.2611]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "131\n",
            "tensor([[3.0717, 3.9944, 2.1268, 3.9640, 3.9814, 2.2139, 2.3025],\n",
            "        [1.7596, 2.4776, 1.4022, 2.4373, 2.4082, 1.4698, 1.4793],\n",
            "        [1.9473, 2.7093, 1.5125, 2.6671, 2.6470, 1.5787, 1.5983],\n",
            "        [2.7898, 3.6961, 1.9802, 3.6601, 3.6737, 2.0434, 2.1268],\n",
            "        [1.0556, 1.5829, 0.9728, 1.5566, 1.5045, 1.0142, 1.0117]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "132\n",
            "tensor([[1.7009, 2.4032, 1.3686, 2.3644, 2.3320, 1.4368, 1.4391],\n",
            "        [2.7330, 3.6251, 1.9481, 3.5884, 3.5958, 2.0210, 2.0899],\n",
            "        [2.5799, 3.4532, 1.8667, 3.4162, 3.4181, 1.9352, 1.9958],\n",
            "        [3.0611, 3.9804, 2.1217, 3.9489, 3.9675, 2.2023, 2.2932],\n",
            "        [3.1309, 4.0584, 2.1569, 4.0246, 4.0399, 2.2560, 2.3416]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "133\n",
            "tensor([[0.9505, 1.4425, 0.9036, 1.4201, 1.3648, 0.9398, 0.9376],\n",
            "        [0.9901, 1.4951, 0.9300, 1.4702, 1.4158, 0.9673, 0.9642],\n",
            "        [2.3955, 3.2374, 1.7668, 3.1984, 3.1945, 1.8321, 1.8773],\n",
            "        [0.9209, 1.4031, 0.8852, 1.3825, 1.3261, 0.9185, 0.9166],\n",
            "        [1.5020, 2.1523, 1.2498, 2.1136, 2.0777, 1.3085, 1.3063]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "134\n",
            "tensor([[2.3567, 3.1887, 1.7436, 3.1488, 3.1429, 1.8128, 1.8530],\n",
            "        [0.9148, 1.3940, 0.8809, 1.3730, 1.3175, 0.9147, 0.9123],\n",
            "        [2.2661, 3.0822, 1.6947, 3.0420, 3.0336, 1.7656, 1.7962],\n",
            "        [1.0588, 1.5833, 0.9735, 1.5571, 1.5052, 1.0165, 1.0117],\n",
            "        [3.0859, 3.9997, 2.1353, 3.9685, 3.9853, 2.2261, 2.3053]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "135\n",
            "tensor([[2.7463, 3.6321, 1.9583, 3.5935, 3.6056, 2.0279, 2.0891],\n",
            "        [2.3846, 3.2178, 1.7602, 3.1766, 3.1717, 1.8281, 1.8658],\n",
            "        [0.8606, 1.3211, 0.8435, 1.3012, 1.2431, 0.8718, 0.8726],\n",
            "        [1.4052, 2.0264, 1.1926, 1.9906, 1.9487, 1.2491, 1.2413],\n",
            "        [1.8971, 2.6387, 1.4863, 2.5972, 2.5721, 1.5525, 1.5601]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "136\n",
            "tensor([[2.7281, 3.6100, 1.9451, 3.5701, 3.5804, 2.0154, 2.0762],\n",
            "        [2.4568, 3.2992, 1.8004, 3.2574, 3.2562, 1.8679, 1.9075],\n",
            "        [1.5430, 2.1988, 1.2767, 2.1594, 2.1225, 1.3369, 1.3302],\n",
            "        [2.5087, 3.3621, 1.8286, 3.3202, 3.3217, 1.8969, 1.9426],\n",
            "        [1.5970, 2.2657, 1.3088, 2.2259, 2.1904, 1.3703, 1.3642]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "137\n",
            "tensor([[1.4776, 2.1157, 1.2358, 2.0776, 2.0370, 1.2961, 1.2865],\n",
            "        [2.9920, 3.8947, 2.0854, 3.8581, 3.8774, 2.1666, 2.2352],\n",
            "        [3.1111, 4.0230, 2.1489, 3.9877, 4.0046, 2.2386, 2.3131],\n",
            "        [2.6885, 3.5641, 1.9248, 3.5229, 3.5339, 1.9859, 2.0476],\n",
            "        [3.1173, 4.0298, 2.1525, 3.9924, 4.0125, 2.2470, 2.3160]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "138\n",
            "tensor([[2.9689, 3.8671, 2.0715, 3.8277, 3.8483, 2.1432, 2.2173],\n",
            "        [3.1670, 4.0827, 2.1777, 4.0399, 4.0548, 2.2722, 2.3452],\n",
            "        [3.1075, 4.0151, 2.1443, 3.9765, 3.9970, 2.2290, 2.3038],\n",
            "        [2.4401, 3.2763, 1.7889, 3.2328, 3.2282, 1.8596, 1.8937],\n",
            "        [3.1700, 4.0831, 2.1787, 4.0415, 4.0584, 2.2727, 2.3464]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "139\n",
            "tensor([[1.3198, 1.9136, 1.1378, 1.8772, 1.8313, 1.1956, 1.1786],\n",
            "        [3.0867, 3.9915, 2.1336, 3.9531, 3.9686, 2.2115, 2.2891],\n",
            "        [2.4596, 3.2954, 1.7993, 3.2511, 3.2500, 1.8690, 1.9013],\n",
            "        [0.8565, 1.3118, 0.8411, 1.2914, 1.2329, 0.8697, 0.8661],\n",
            "        [1.7711, 2.4780, 1.4112, 2.4344, 2.4069, 1.4762, 1.4713]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "140\n",
            "tensor([[2.4002, 3.2263, 1.7671, 3.1810, 3.1795, 1.8308, 1.8614],\n",
            "        [3.1459, 4.0540, 2.1639, 4.0141, 4.0270, 2.2690, 2.3268],\n",
            "        [2.2475, 3.0466, 1.6804, 3.0002, 2.9901, 1.7523, 1.7674],\n",
            "        [2.0778, 2.8500, 1.5870, 2.8018, 2.7847, 1.6609, 1.6625],\n",
            "        [0.8840, 1.3498, 0.8590, 1.3252, 1.2696, 0.8888, 0.8846]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "141\n",
            "tensor([[3.1532, 4.0592, 2.1658, 4.0171, 4.0347, 2.2640, 2.3270],\n",
            "        [3.1715, 4.0797, 2.1756, 4.0382, 4.0517, 2.2780, 2.3409],\n",
            "        [1.2898, 1.8710, 1.1191, 1.8367, 1.7892, 1.1761, 1.1564],\n",
            "        [0.9609, 1.4485, 0.9100, 1.4248, 1.3688, 0.9487, 0.9364],\n",
            "        [1.3120, 1.9008, 1.1354, 1.8650, 1.8202, 1.1893, 1.1707]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "142\n",
            "tensor([[1.2534, 1.8268, 1.0966, 1.7932, 1.7450, 1.1558, 1.1324],\n",
            "        [1.1314, 1.6710, 1.0189, 1.6396, 1.5880, 1.0702, 1.0518],\n",
            "        [1.1144, 1.6493, 1.0093, 1.6202, 1.5674, 1.0606, 1.0419],\n",
            "        [2.9766, 3.8718, 2.0724, 3.8290, 3.8462, 2.1510, 2.2134],\n",
            "        [3.1787, 4.0880, 2.1785, 4.0468, 4.0596, 2.2816, 2.3441]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "143\n",
            "tensor([[1.1645, 1.7130, 1.0408, 1.6821, 1.6307, 1.0965, 1.0739],\n",
            "        [1.8139, 2.5282, 1.4356, 2.4829, 2.4554, 1.5059, 1.4940],\n",
            "        [2.7865, 3.6672, 1.9740, 3.6241, 3.6360, 2.0523, 2.0982],\n",
            "        [1.4640, 2.0934, 1.2262, 2.0544, 2.0124, 1.2963, 1.2713],\n",
            "        [1.0316, 1.5419, 0.9567, 1.5147, 1.4593, 1.0018, 0.9855]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "144\n",
            "tensor([[0.8345, 1.2838, 0.8258, 1.2626, 1.2044, 0.8596, 0.8494],\n",
            "        [1.2324, 1.8007, 1.0866, 1.7691, 1.7171, 1.1461, 1.1206],\n",
            "        [2.4272, 3.2616, 1.7806, 3.2161, 3.2111, 1.8648, 1.8810],\n",
            "        [2.2416, 3.0412, 1.6771, 2.9962, 2.9823, 1.7599, 1.7651],\n",
            "        [3.1018, 4.0064, 2.1409, 3.9664, 3.9815, 2.2442, 2.2955]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "145\n",
            "tensor([[1.6571, 2.3354, 1.3432, 2.2937, 2.2580, 1.4225, 1.3972],\n",
            "        [1.0334, 1.5438, 0.9585, 1.5187, 1.4619, 1.0101, 0.9883],\n",
            "        [3.1058, 4.0094, 2.1432, 3.9726, 3.9875, 2.2499, 2.2979],\n",
            "        [1.6365, 2.3103, 1.3321, 2.2697, 2.2323, 1.4116, 1.3846],\n",
            "        [2.6521, 3.5176, 1.9042, 3.4753, 3.4785, 1.9884, 2.0185]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "146\n",
            "tensor([[3.0864, 3.9871, 2.1345, 3.9533, 3.9667, 2.2468, 2.2889],\n",
            "        [1.4354, 2.0582, 1.2111, 2.0209, 1.9778, 1.2822, 1.2542],\n",
            "        [2.0472, 2.8051, 1.5682, 2.7626, 2.7402, 1.6566, 1.6435],\n",
            "        [1.5872, 2.2478, 1.3014, 2.2084, 2.1700, 1.3779, 1.3512],\n",
            "        [3.1659, 4.0727, 2.1723, 4.0311, 4.0372, 2.3039, 2.3438]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "147\n",
            "tensor([[2.4749, 3.3063, 1.8088, 3.2693, 3.2613, 1.8985, 1.9107],\n",
            "        [2.7747, 3.6468, 1.9711, 3.6123, 3.6166, 2.0683, 2.0948],\n",
            "        [3.1776, 4.0827, 2.1818, 4.0482, 4.0574, 2.3075, 2.3472],\n",
            "        [1.1804, 1.7298, 1.0517, 1.7022, 1.6486, 1.1161, 1.0866],\n",
            "        [0.7572, 1.1802, 0.7742, 1.1645, 1.1032, 0.8052, 0.7976]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "148\n",
            "tensor([[2.4064, 3.2262, 1.7699, 3.1884, 3.1783, 1.8604, 1.8662],\n",
            "        [2.3706, 3.1849, 1.7499, 3.1471, 3.1345, 1.8391, 1.8431],\n",
            "        [2.6025, 3.4503, 1.8776, 3.4144, 3.4125, 1.9627, 1.9858],\n",
            "        [1.8886, 2.6135, 1.4802, 2.5754, 2.5459, 1.5642, 1.5440],\n",
            "        [1.9813, 2.7232, 1.5318, 2.6864, 2.6583, 1.6245, 1.6031]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "149\n",
            "tensor([[1.8845, 2.6088, 1.4766, 2.5715, 2.5391, 1.5636, 1.5414],\n",
            "        [1.2054, 1.7617, 1.0719, 1.7363, 1.6801, 1.1375, 1.1026],\n",
            "        [0.6625, 1.0516, 0.7075, 1.0404, 0.9791, 0.7294, 0.7289],\n",
            "        [1.9773, 2.7165, 1.5280, 2.6801, 2.6506, 1.6205, 1.5988],\n",
            "        [3.0981, 3.9899, 2.1406, 3.9618, 3.9745, 2.2495, 2.2879]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "150\n",
            "tensor([[3.0001, 3.8884, 2.0899, 3.8594, 3.8708, 2.1933, 2.2271],\n",
            "        [2.8126, 3.6876, 1.9905, 3.6572, 3.6603, 2.0797, 2.1138],\n",
            "        [0.9328, 1.4068, 0.8893, 1.3879, 1.3266, 0.9340, 0.9156],\n",
            "        [2.1434, 2.9138, 1.6230, 2.8781, 2.8547, 1.7174, 1.7009],\n",
            "        [3.1991, 4.0989, 2.1935, 4.0699, 4.0750, 2.3226, 2.3549]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "151\n",
            "tensor([[1.3657, 1.9599, 1.1640, 1.9315, 1.8816, 1.2348, 1.2043],\n",
            "        [2.4095, 3.2246, 1.7739, 3.1917, 3.1815, 1.8613, 1.8620],\n",
            "        [2.4009, 3.2155, 1.7686, 3.1832, 3.1686, 1.8610, 1.8604],\n",
            "        [2.0924, 2.8537, 1.5961, 2.8189, 2.7943, 1.6867, 1.6673],\n",
            "        [0.8667, 1.3178, 0.8494, 1.3034, 1.2413, 0.8900, 0.8704]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "152\n",
            "tensor([[2.2625, 3.0534, 1.6937, 3.0207, 3.0014, 1.7820, 1.7703],\n",
            "        [2.9512, 3.8316, 2.0659, 3.8059, 3.8123, 2.1645, 2.1941],\n",
            "        [1.1284, 1.6592, 1.0226, 1.6393, 1.5795, 1.0835, 1.0490],\n",
            "        [2.9194, 3.7990, 2.0499, 3.7729, 3.7791, 2.1448, 2.1733],\n",
            "        [0.8505, 1.2985, 0.8386, 1.2834, 1.2219, 0.8763, 0.8595]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "153\n",
            "tensor([[3.1978, 4.0905, 2.1959, 4.0683, 4.0706, 2.3168, 2.3488],\n",
            "        [2.7312, 3.5908, 1.9511, 3.5626, 3.5580, 2.0416, 2.0580],\n",
            "        [3.2111, 4.1063, 2.2029, 4.0815, 4.0780, 2.3326, 2.3614],\n",
            "        [0.8231, 1.2622, 0.8224, 1.2498, 1.1862, 0.8585, 0.8414],\n",
            "        [2.8597, 3.7312, 2.0177, 3.7055, 3.7060, 2.1183, 2.1396]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "154\n",
            "tensor([[3.0784, 3.9659, 2.1391, 3.9463, 3.9525, 2.2480, 2.2731],\n",
            "        [0.9451, 1.4214, 0.9055, 1.4076, 1.3447, 0.9526, 0.9263],\n",
            "        [1.8984, 2.6194, 1.4913, 2.5910, 2.5538, 1.5821, 1.5478],\n",
            "        [0.9893, 1.4794, 0.9342, 1.4642, 1.4020, 0.9868, 0.9560],\n",
            "        [2.4517, 3.2697, 1.7973, 3.2412, 3.2214, 1.8869, 1.8893]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "155\n",
            "tensor([[2.6534, 3.5042, 1.9169, 3.4831, 3.4763, 2.0018, 2.0130],\n",
            "        [1.5044, 2.1357, 1.2598, 2.1107, 2.0616, 1.3387, 1.2972],\n",
            "        [1.3405, 1.9291, 1.1575, 1.9072, 1.8536, 1.2331, 1.1901],\n",
            "        [3.1254, 4.0143, 2.1640, 3.9974, 3.9994, 2.2700, 2.3026],\n",
            "        [3.1822, 4.0712, 2.1938, 4.0552, 4.0578, 2.3123, 2.3383]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "156\n",
            "tensor([[1.9491, 2.6794, 1.5227, 2.6530, 2.6199, 1.6080, 1.5779],\n",
            "        [2.3991, 3.2077, 1.7775, 3.1853, 3.1646, 1.8670, 1.8582],\n",
            "        [3.1787, 4.0673, 2.1954, 4.0541, 4.0550, 2.3129, 2.3378],\n",
            "        [0.9383, 1.4108, 0.9015, 1.3991, 1.3352, 0.9493, 0.9217],\n",
            "        [2.8235, 3.6904, 2.0082, 3.6714, 3.6706, 2.1004, 2.1168]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "157\n",
            "tensor([[2.8899, 3.7577, 2.0453, 3.7440, 3.7430, 2.1400, 2.1565],\n",
            "        [1.0469, 1.5506, 0.9761, 1.5386, 1.4761, 1.0301, 0.9950],\n",
            "        [2.8519, 3.7179, 2.0251, 3.7044, 3.7012, 2.1175, 2.1339],\n",
            "        [2.9445, 3.8165, 2.0750, 3.8055, 3.8074, 2.1598, 2.1864],\n",
            "        [2.5495, 3.3833, 1.8642, 3.3657, 3.3505, 1.9525, 1.9503]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "158\n",
            "tensor([[1.3689, 1.9607, 1.1820, 1.9453, 1.8878, 1.2557, 1.2084],\n",
            "        [1.7487, 2.4332, 1.4096, 2.4132, 2.3691, 1.4930, 1.4535],\n",
            "        [3.2000, 4.0881, 2.2094, 4.0776, 4.0735, 2.3314, 2.3499],\n",
            "        [2.0624, 2.8098, 1.5920, 2.7890, 2.7547, 1.6801, 1.6489],\n",
            "        [3.1391, 4.0185, 2.1772, 4.0151, 4.0126, 2.2844, 2.3104]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "159\n",
            "tensor([[1.5351, 2.1672, 1.2815, 2.1498, 2.0979, 1.3619, 1.3151],\n",
            "        [2.3724, 3.1727, 1.7667, 3.1559, 3.1325, 1.8525, 1.8379],\n",
            "        [3.1771, 4.0587, 2.1981, 4.0540, 4.0503, 2.3128, 2.3325],\n",
            "        [1.2323, 1.7856, 1.0944, 1.7720, 1.7117, 1.1602, 1.1187],\n",
            "        [2.3270, 3.1222, 1.7421, 3.1079, 3.0813, 1.8286, 1.8143]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "160\n",
            "tensor([[3.1946, 4.0748, 2.2088, 4.0706, 4.0621, 2.3281, 2.3454],\n",
            "        [1.6042, 2.2508, 1.3263, 2.2361, 2.1846, 1.4063, 1.3593],\n",
            "        [3.1471, 4.0217, 2.1823, 4.0194, 4.0197, 2.2836, 2.3082],\n",
            "        [2.3259, 3.1181, 1.7443, 3.1034, 3.0794, 1.8239, 1.8082],\n",
            "        [1.2824, 1.8517, 1.1284, 1.8368, 1.7759, 1.1939, 1.1508]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "161\n",
            "tensor([[0.9070, 1.3655, 0.8843, 1.3604, 1.2927, 0.9264, 0.8979],\n",
            "        [0.7651, 1.1804, 0.7875, 1.1787, 1.1115, 0.8176, 0.8021],\n",
            "        [2.7150, 3.5569, 1.9561, 3.5529, 3.5384, 2.0370, 2.0456],\n",
            "        [3.0635, 3.9354, 2.1414, 3.9369, 3.9288, 2.2311, 2.2599],\n",
            "        [2.2567, 3.0348, 1.7053, 3.0235, 2.9915, 1.7940, 1.7675]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "162\n",
            "tensor([[2.0522, 2.7917, 1.5913, 2.7811, 2.7409, 1.6764, 1.6403],\n",
            "        [1.9869, 2.7152, 1.5529, 2.7022, 2.6614, 1.6334, 1.5993],\n",
            "        [0.6278, 1.0003, 0.6884, 0.9991, 0.9337, 0.7077, 0.7043],\n",
            "        [1.1290, 1.6539, 1.0316, 1.6469, 1.5818, 1.0932, 1.0513],\n",
            "        [1.0840, 1.5951, 1.0032, 1.5884, 1.5213, 1.0583, 1.0207]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "163\n",
            "tensor([[0.8489, 1.2895, 0.8463, 1.2868, 1.2178, 0.8822, 0.8597],\n",
            "        [2.0209, 2.7532, 1.5733, 2.7433, 2.7018, 1.6608, 1.6223],\n",
            "        [2.7953, 3.6458, 2.0034, 3.6456, 3.6304, 2.0970, 2.0961],\n",
            "        [3.0116, 3.8770, 2.1184, 3.8798, 3.8719, 2.2140, 2.2257],\n",
            "        [3.0361, 3.9082, 2.1316, 3.9111, 3.9025, 2.2249, 2.2424]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "164\n",
            "tensor([[0.9566, 1.4305, 0.9207, 1.4284, 1.3575, 0.9680, 0.9351],\n",
            "        [1.3307, 1.9093, 1.1607, 1.8988, 1.8374, 1.2282, 1.1825],\n",
            "        [0.7188, 1.1205, 0.7581, 1.1209, 1.0513, 0.7853, 0.7703],\n",
            "        [2.5570, 3.3804, 1.8758, 3.3775, 3.3549, 1.9552, 1.9503],\n",
            "        [1.0075, 1.4977, 0.9543, 1.4945, 1.4240, 1.0084, 0.9705]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "165\n",
            "tensor([[3.2088, 4.0884, 2.2258, 4.0943, 4.0775, 2.3451, 2.3555],\n",
            "        [1.2379, 1.7926, 1.1033, 1.7856, 1.7191, 1.1683, 1.1248],\n",
            "        [1.3154, 1.8894, 1.1555, 1.8801, 1.8166, 1.2202, 1.1746],\n",
            "        [3.1805, 4.0585, 2.2108, 4.0688, 4.0507, 2.3241, 2.3391],\n",
            "        [3.1824, 4.0596, 2.2101, 4.0695, 4.0517, 2.3236, 2.3400]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "166\n",
            "tensor([[2.4571, 3.2637, 1.8230, 3.2646, 3.2315, 1.9120, 1.8947],\n",
            "        [3.2228, 4.1003, 2.2323, 4.1105, 4.0874, 2.3570, 2.3698],\n",
            "        [2.8170, 3.6685, 2.0184, 3.6743, 3.6562, 2.1050, 2.1116],\n",
            "        [1.3745, 1.9622, 1.1897, 1.9565, 1.8923, 1.2600, 1.2146],\n",
            "        [3.2083, 4.0865, 2.2271, 4.0938, 4.0757, 2.3421, 2.3575]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "167\n",
            "tensor([[1.0374, 1.5323, 0.9753, 1.5317, 1.4596, 1.0298, 0.9926],\n",
            "        [1.6317, 2.2816, 1.3487, 2.2765, 2.2163, 1.4304, 1.3821],\n",
            "        [1.1488, 1.6761, 1.0488, 1.6722, 1.6035, 1.1094, 1.0673],\n",
            "        [2.0601, 2.7979, 1.5993, 2.7945, 2.7480, 1.6855, 1.6502],\n",
            "        [1.2372, 1.7866, 1.1040, 1.7833, 1.7139, 1.1712, 1.1248]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "168\n",
            "tensor([[3.2246, 4.0974, 2.2344, 4.1112, 4.0864, 2.3640, 2.3737],\n",
            "        [1.9167, 2.6255, 1.5152, 2.6210, 2.5720, 1.6034, 1.5626],\n",
            "        [3.1859, 4.0569, 2.2154, 4.0748, 4.0504, 2.3293, 2.3494],\n",
            "        [1.9432, 2.6563, 1.5335, 2.6551, 2.6030, 1.6206, 1.5804],\n",
            "        [3.0750, 3.9393, 2.1583, 3.9581, 3.9399, 2.2617, 2.2765]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "169\n",
            "tensor([[3.1536, 4.0191, 2.1986, 4.0417, 4.0189, 2.3107, 2.3273],\n",
            "        [0.9555, 1.4253, 0.9212, 1.4284, 1.3536, 0.9711, 0.9396],\n",
            "        [1.0218, 1.5113, 0.9668, 1.5136, 1.4396, 1.0210, 0.9842],\n",
            "        [2.7229, 3.5581, 1.9710, 3.5728, 3.5418, 2.0571, 2.0633],\n",
            "        [1.7330, 2.4026, 1.4089, 2.4004, 2.3403, 1.4961, 1.4501]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "170\n",
            "tensor([[1.4297, 2.0281, 1.2274, 2.0285, 1.9586, 1.3040, 1.2564],\n",
            "        [1.2204, 1.7653, 1.0949, 1.7676, 1.6931, 1.1611, 1.1196],\n",
            "        [1.1925, 1.7277, 1.0774, 1.7310, 1.6575, 1.1438, 1.1008],\n",
            "        [1.1679, 1.6990, 1.0618, 1.6996, 1.6264, 1.1250, 1.0839],\n",
            "        [1.8114, 2.4969, 1.4577, 2.4994, 2.4392, 1.5439, 1.5016]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "171\n",
            "tensor([[2.9390, 3.7928, 2.0889, 3.8182, 3.7911, 2.1790, 2.1994],\n",
            "        [1.1349, 1.6569, 1.0404, 1.6584, 1.5835, 1.1031, 1.0624],\n",
            "        [2.9684, 3.8254, 2.1064, 3.8506, 3.8234, 2.2084, 2.2193],\n",
            "        [1.8435, 2.5359, 1.4791, 2.5393, 2.4796, 1.5681, 1.5236],\n",
            "        [3.2165, 4.0848, 2.2344, 4.1091, 4.0694, 2.3662, 2.3822]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "172\n",
            "tensor([[3.2121, 4.0827, 2.2347, 4.1084, 4.0678, 2.3622, 2.3797],\n",
            "        [2.2054, 2.9643, 1.6885, 2.9772, 2.9221, 1.7831, 1.7542],\n",
            "        [3.1881, 4.0546, 2.2243, 4.0845, 4.0505, 2.3433, 2.3600],\n",
            "        [2.0879, 2.8257, 1.6206, 2.8342, 2.7773, 1.7120, 1.6782],\n",
            "        [1.8650, 2.5591, 1.4905, 2.5637, 2.5017, 1.5810, 1.5377]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "173\n",
            "tensor([[0.9775, 1.4531, 0.9393, 1.4599, 1.3816, 0.9939, 0.9587],\n",
            "        [3.1695, 4.0324, 2.2128, 4.0630, 4.0276, 2.3218, 2.3480],\n",
            "        [3.2242, 4.0947, 2.2427, 4.1241, 4.0865, 2.3786, 2.3871],\n",
            "        [2.5372, 3.3482, 1.8757, 3.3670, 3.3231, 1.9683, 1.9593],\n",
            "        [1.0535, 1.5503, 0.9909, 1.5563, 1.4790, 1.0478, 1.0103]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "174\n",
            "tensor([[3.1562, 4.0176, 2.2094, 4.0525, 4.0175, 2.3259, 2.3422],\n",
            "        [0.9835, 1.4597, 0.9462, 1.4692, 1.3888, 1.0010, 0.9642],\n",
            "        [1.0221, 1.5091, 0.9706, 1.5177, 1.4386, 1.0293, 0.9902],\n",
            "        [2.9234, 3.7733, 2.0868, 3.8020, 3.7687, 2.1884, 2.1967],\n",
            "        [3.0999, 3.9611, 2.1807, 3.9933, 3.9600, 2.3010, 2.3089]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "175\n",
            "tensor([[2.1051, 2.8488, 1.6384, 2.8606, 2.8044, 1.7304, 1.6954],\n",
            "        [3.0378, 3.8943, 2.1501, 3.9286, 3.8951, 2.2604, 2.2711],\n",
            "        [2.9443, 3.7958, 2.0993, 3.8277, 3.7943, 2.2054, 2.2128],\n",
            "        [1.3467, 1.9231, 1.1818, 1.9288, 1.8538, 1.2592, 1.2098],\n",
            "        [2.9130, 3.7636, 2.0830, 3.7943, 3.7617, 2.1830, 2.1932]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "176\n",
            "tensor([[1.9025, 2.6039, 1.5189, 2.6149, 2.5498, 1.6173, 1.5687],\n",
            "        [3.0692, 3.9303, 2.1695, 3.9651, 3.9324, 2.2847, 2.2944],\n",
            "        [2.4376, 3.2317, 1.8262, 3.2516, 3.2034, 1.9325, 1.9035],\n",
            "        [0.9550, 1.4238, 0.9289, 1.4328, 1.3522, 0.9821, 0.9469],\n",
            "        [1.5079, 2.1241, 1.2833, 2.1321, 2.0605, 1.3705, 1.3162]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "177\n",
            "tensor([[1.8957, 2.5971, 1.5184, 2.6079, 2.5447, 1.6127, 1.5662],\n",
            "        [3.1091, 3.9679, 2.1917, 4.0046, 3.9767, 2.3106, 2.3157],\n",
            "        [1.0549, 1.5531, 0.9970, 1.5622, 1.4841, 1.0602, 1.0163],\n",
            "        [3.0288, 3.8811, 2.1462, 3.9170, 3.8890, 2.2487, 2.2631],\n",
            "        [2.7518, 3.5900, 2.0028, 3.6176, 3.5817, 2.1001, 2.0968]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "178\n",
            "tensor([[2.9404, 3.7893, 2.1047, 3.8243, 3.7908, 2.2130, 2.2126],\n",
            "        [1.4262, 2.0225, 1.2377, 2.0323, 1.9570, 1.3231, 1.2658],\n",
            "        [2.6360, 3.4578, 1.9400, 3.4849, 3.4421, 2.0408, 2.0270],\n",
            "        [1.7071, 2.3691, 1.4070, 2.3777, 2.3095, 1.5042, 1.4459],\n",
            "        [3.2102, 4.0760, 2.2475, 4.1112, 4.0730, 2.3856, 2.3846]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "179\n",
            "tensor([[1.2753, 1.8313, 1.1432, 1.8405, 1.7649, 1.2184, 1.1639],\n",
            "        [1.6270, 2.2681, 1.3591, 2.2784, 2.2089, 1.4556, 1.3942],\n",
            "        [3.2215, 4.0850, 2.2533, 4.1214, 4.0842, 2.3986, 2.3928],\n",
            "        [1.1887, 1.7218, 1.0856, 1.7302, 1.6542, 1.1579, 1.1057],\n",
            "        [2.9783, 3.8272, 2.1244, 3.8624, 3.8289, 2.2491, 2.2379]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "180\n",
            "tensor([[1.9479, 2.6565, 1.5524, 2.6725, 2.6106, 1.6554, 1.6004],\n",
            "        [1.7030, 2.3603, 1.4053, 2.3720, 2.3046, 1.5069, 1.4444],\n",
            "        [1.0776, 1.5788, 1.0142, 1.5912, 1.5122, 1.0825, 1.0331],\n",
            "        [2.0617, 2.7921, 1.6168, 2.8071, 2.7519, 1.7225, 1.6715],\n",
            "        [2.5335, 3.3382, 1.8849, 3.3661, 3.3202, 1.9937, 1.9660]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "181\n",
            "tensor([[3.1056, 3.9601, 2.1911, 3.9998, 3.9709, 2.3286, 2.3170],\n",
            "        [2.1545, 2.8995, 1.6707, 2.9164, 2.8624, 1.7822, 1.7296],\n",
            "        [1.2963, 1.8559, 1.1561, 1.8654, 1.7915, 1.2379, 1.1783],\n",
            "        [1.1024, 1.6108, 1.0292, 1.6219, 1.5439, 1.1002, 1.0486],\n",
            "        [1.0831, 1.5856, 1.0162, 1.5974, 1.5190, 1.0885, 1.0371]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "182\n",
            "tensor([[3.1872, 4.0493, 2.2345, 4.0871, 4.0533, 2.3876, 2.3743],\n",
            "        [0.9471, 1.4127, 0.9281, 1.4248, 1.3456, 0.9885, 0.9444],\n",
            "        [3.0088, 3.8565, 2.1396, 3.8930, 3.8677, 2.2703, 2.2548],\n",
            "        [2.0162, 2.7372, 1.5904, 2.7530, 2.6940, 1.7013, 1.6444],\n",
            "        [3.1741, 4.0314, 2.2270, 4.0714, 4.0404, 2.3735, 2.3632]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "183\n",
            "tensor([[2.5443, 3.3512, 1.8889, 3.3766, 3.3379, 2.0047, 1.9731],\n",
            "        [2.3396, 3.1198, 1.7748, 3.1410, 3.0908, 1.8960, 1.8497],\n",
            "        [1.0902, 1.5958, 1.0220, 1.6080, 1.5286, 1.0980, 1.0432],\n",
            "        [3.1973, 4.0591, 2.2401, 4.0956, 4.0654, 2.3987, 2.3794],\n",
            "        [3.1684, 4.0258, 2.2234, 4.0667, 4.0357, 2.3694, 2.3605]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "184\n",
            "tensor([[1.7761, 2.4500, 1.4474, 2.4617, 2.3978, 1.5596, 1.4940],\n",
            "        [1.0267, 1.5182, 0.9809, 1.5278, 1.4497, 1.0515, 1.0008],\n",
            "        [1.5257, 2.1460, 1.2953, 2.1549, 2.0849, 1.3977, 1.3327],\n",
            "        [2.6563, 3.4774, 1.9494, 3.5055, 3.4674, 2.0768, 2.0436],\n",
            "        [2.3167, 3.0911, 1.7603, 3.1108, 3.0592, 1.8836, 1.8344]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "185\n",
            "tensor([[3.2203, 4.0818, 2.2461, 4.1196, 4.0852, 2.4111, 2.3979],\n",
            "        [2.2336, 2.9962, 1.7128, 3.0150, 2.9626, 1.8355, 1.7845],\n",
            "        [1.4695, 2.0760, 1.2584, 2.0820, 2.0115, 1.3580, 1.2940],\n",
            "        [0.9982, 1.4793, 0.9596, 1.4912, 1.4110, 1.0297, 0.9814],\n",
            "        [2.8101, 3.6486, 2.0297, 3.6784, 3.6477, 2.1561, 2.1379]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "186\n",
            "tensor([[1.5592, 2.1884, 1.3168, 2.1987, 2.1288, 1.4245, 1.3572],\n",
            "        [1.9369, 2.6470, 1.5422, 2.6622, 2.5996, 1.6612, 1.6003],\n",
            "        [3.1831, 4.0454, 2.2233, 4.0848, 4.0517, 2.3871, 2.3740],\n",
            "        [1.1928, 1.7304, 1.0880, 1.7421, 1.6629, 1.1794, 1.1156],\n",
            "        [2.4024, 3.1949, 1.8064, 3.2173, 3.1697, 1.9336, 1.8917]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "187\n",
            "tensor([[2.9794, 3.8345, 2.1172, 3.8714, 3.8379, 2.2726, 2.2502],\n",
            "        [2.7366, 3.5737, 1.9870, 3.6054, 3.5658, 2.1264, 2.1016],\n",
            "        [3.0738, 3.9322, 2.1663, 3.9702, 3.9419, 2.3164, 2.3062],\n",
            "        [2.4987, 3.3042, 1.8572, 3.3298, 3.2821, 1.9899, 1.9521],\n",
            "        [3.1010, 3.9601, 2.1810, 3.9995, 3.9677, 2.3294, 2.3237]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "188\n",
            "tensor([[3.1642, 4.0292, 2.2129, 4.0678, 4.0345, 2.3893, 2.3688],\n",
            "        [1.3293, 1.9029, 1.1722, 1.9139, 1.8369, 1.2736, 1.2073],\n",
            "        [3.1959, 4.0609, 2.2294, 4.1026, 4.0671, 2.4054, 2.3884],\n",
            "        [1.9970, 2.7211, 1.5747, 2.7386, 2.6770, 1.7012, 1.6431],\n",
            "        [2.9872, 3.8433, 2.1197, 3.8807, 3.8506, 2.2673, 2.2534]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "189\n",
            "tensor([[3.0101, 3.8662, 2.1305, 3.9067, 3.8734, 2.2911, 2.2718],\n",
            "        [2.9901, 3.8417, 2.1173, 3.8843, 3.8523, 2.2704, 2.2583],\n",
            "        [2.9117, 3.7610, 2.0775, 3.8003, 3.7658, 2.2309, 2.2121],\n",
            "        [1.3712, 1.9560, 1.1980, 1.9666, 1.8911, 1.3032, 1.2372],\n",
            "        [3.2187, 4.0869, 2.2382, 4.1259, 4.0844, 2.4232, 2.4089]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "190\n",
            "tensor([[2.8153, 3.6574, 2.0216, 3.6938, 3.6573, 2.1724, 2.1547],\n",
            "        [3.1987, 4.0622, 2.2246, 4.1056, 4.0713, 2.4046, 2.3945],\n",
            "        [1.4184, 2.0179, 1.2261, 2.0309, 1.9550, 1.3379, 1.2734],\n",
            "        [2.7802, 3.6212, 2.0036, 3.6563, 3.6208, 2.1425, 2.1322],\n",
            "        [1.0617, 1.5631, 0.9994, 1.5777, 1.4968, 1.0850, 1.0310]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "191\n",
            "tensor([[2.7250, 3.5589, 1.9719, 3.5926, 3.5508, 2.1206, 2.0997],\n",
            "        [3.1846, 4.0498, 2.2150, 4.0943, 4.0602, 2.3955, 2.3882],\n",
            "        [2.1269, 2.8755, 1.6434, 2.8981, 2.8395, 1.7798, 1.7291],\n",
            "        [1.7645, 2.4432, 1.4327, 2.4588, 2.3911, 1.5605, 1.4984],\n",
            "        [3.1222, 3.9843, 2.1819, 4.0282, 3.9973, 2.3504, 2.3459]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "192\n",
            "tensor([[3.0502, 3.9107, 2.1428, 3.9560, 3.9229, 2.3057, 2.3048],\n",
            "        [3.1193, 3.9822, 2.1804, 4.0265, 3.9950, 2.3545, 2.3470],\n",
            "        [3.1967, 4.0646, 2.2187, 4.1095, 4.0750, 2.4052, 2.3995],\n",
            "        [1.9282, 2.6427, 1.5282, 2.6585, 2.5982, 1.6571, 1.6029],\n",
            "        [3.2014, 4.0700, 2.2202, 4.1095, 4.0677, 2.4132, 2.4058]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "193\n",
            "tensor([[1.3429, 1.9243, 1.1774, 1.9380, 1.8600, 1.2837, 1.2250],\n",
            "        [1.8604, 2.5616, 1.4850, 2.5774, 2.5115, 1.6188, 1.5618],\n",
            "        [0.9235, 1.3867, 0.9068, 1.4027, 1.3210, 0.9803, 0.9375],\n",
            "        [2.5183, 3.3321, 1.8573, 3.3634, 3.3149, 2.0041, 1.9781],\n",
            "        [3.0362, 3.8953, 2.1349, 3.9380, 3.9068, 2.3036, 2.2968]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "194\n",
            "tensor([[2.7467, 3.5832, 1.9769, 3.6186, 3.5783, 2.1310, 2.1195],\n",
            "        [2.8292, 3.6778, 2.0228, 3.7149, 3.6805, 2.1678, 2.1686],\n",
            "        [1.2541, 1.8111, 1.1200, 1.8249, 1.7453, 1.2226, 1.1654],\n",
            "        [0.7399, 1.1463, 0.7789, 1.1620, 1.0812, 0.8327, 0.8058],\n",
            "        [1.1005, 1.6171, 1.0201, 1.6294, 1.5497, 1.1127, 1.0614]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "195\n",
            "tensor([[1.7382, 2.4144, 1.4125, 2.4297, 2.3629, 1.5387, 1.4845],\n",
            "        [2.3756, 3.1689, 1.7764, 3.1968, 3.1441, 1.9216, 1.8912],\n",
            "        [3.0262, 3.8882, 2.1240, 3.9300, 3.8983, 2.2855, 2.2929],\n",
            "        [0.8894, 1.3429, 0.8810, 1.3589, 1.2772, 0.9535, 0.9137],\n",
            "        [3.2162, 4.0849, 2.2223, 4.1313, 4.0918, 2.4178, 2.4178]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "196\n",
            "tensor([[0.8591, 1.3051, 0.8598, 1.3215, 1.2399, 0.9291, 0.8951],\n",
            "        [2.8666, 3.7160, 2.0394, 3.7547, 3.7175, 2.1880, 2.1944],\n",
            "        [2.4152, 3.2152, 1.7972, 3.2434, 3.1961, 1.9359, 1.9152],\n",
            "        [1.1932, 1.7356, 1.0799, 1.7500, 1.6694, 1.1793, 1.1254],\n",
            "        [1.0548, 1.5583, 0.9909, 1.5737, 1.4924, 1.0798, 1.0315]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "197\n",
            "tensor([[1.6126, 2.2605, 1.3365, 2.2756, 2.2053, 1.4623, 1.4060],\n",
            "        [2.3767, 3.1695, 1.7745, 3.1968, 3.1484, 1.9212, 1.8931],\n",
            "        [2.4118, 3.2110, 1.7928, 3.2385, 3.1906, 1.9343, 1.9146],\n",
            "        [2.9268, 3.7848, 2.0702, 3.8258, 3.7926, 2.2224, 2.2348],\n",
            "        [2.6547, 3.4879, 1.9256, 3.5215, 3.4807, 2.0716, 2.0676]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "198\n",
            "tensor([[1.0828, 1.5952, 1.0060, 1.6094, 1.5300, 1.0991, 1.0514],\n",
            "        [2.1168, 2.8706, 1.6265, 2.8935, 2.8363, 1.7682, 1.7336],\n",
            "        [2.1610, 2.9238, 1.6549, 2.9463, 2.8917, 1.7911, 1.7600],\n",
            "        [3.1623, 4.0332, 2.1890, 4.0732, 4.0429, 2.3659, 2.3840],\n",
            "        [2.6067, 3.4322, 1.8976, 3.4691, 3.4256, 2.0509, 2.0411]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "199\n",
            "tensor([[2.9253, 3.7894, 2.0661, 3.8302, 3.8004, 2.2212, 2.2379],\n",
            "        [1.3679, 1.9628, 1.1880, 1.9756, 1.9016, 1.2970, 1.2475],\n",
            "        [3.1809, 4.0566, 2.1963, 4.0994, 4.0683, 2.3767, 2.4002],\n",
            "        [2.8309, 3.6851, 2.0139, 3.7202, 3.6861, 2.1715, 2.1828],\n",
            "        [1.4956, 2.1224, 1.2652, 2.1343, 2.0636, 1.3814, 1.3311]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "200\n",
            "tensor([[1.2302, 1.7893, 1.0989, 1.8021, 1.7258, 1.2036, 1.1557],\n",
            "        [1.2750, 1.8463, 1.1267, 1.8581, 1.7822, 1.2306, 1.1855],\n",
            "        [3.0803, 3.9551, 2.1437, 4.0005, 3.9717, 2.3080, 2.3396],\n",
            "        [3.1810, 4.0622, 2.1965, 4.1062, 4.0731, 2.3802, 2.4052],\n",
            "        [3.1928, 4.0723, 2.2018, 4.1148, 4.0815, 2.3907, 2.4137]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "201\n",
            "tensor([[3.1562, 4.0373, 2.1811, 4.0818, 4.0513, 2.3544, 2.3885],\n",
            "        [2.1708, 2.9441, 1.6541, 2.9664, 2.9129, 1.7927, 1.7729],\n",
            "        [3.1880, 4.0707, 2.1984, 4.1138, 4.0840, 2.3845, 2.4098],\n",
            "        [2.9117, 3.7820, 2.0538, 3.8205, 3.7933, 2.1998, 2.2325],\n",
            "        [1.0947, 1.6188, 1.0127, 1.6299, 1.5531, 1.1022, 1.0627]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "202\n",
            "tensor([[1.0225, 1.5251, 0.9675, 1.5395, 1.4605, 1.0520, 1.0148],\n",
            "        [2.7735, 3.6344, 1.9815, 3.6684, 3.6375, 2.1291, 2.1485],\n",
            "        [1.5700, 2.2184, 1.3064, 2.2307, 2.1622, 1.4238, 1.3851],\n",
            "        [3.1972, 4.0871, 2.1989, 4.1219, 4.0855, 2.3942, 2.4236],\n",
            "        [2.4360, 3.2563, 1.7999, 3.2839, 3.2389, 1.9416, 1.9415]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "203\n",
            "tensor([[3.1861, 4.0774, 2.1958, 4.1183, 4.0866, 2.3779, 2.4159],\n",
            "        [0.9088, 1.3813, 0.8914, 1.3959, 1.3164, 0.9661, 0.9366],\n",
            "        [3.2039, 4.0941, 2.2041, 4.1361, 4.1046, 2.3889, 2.4256],\n",
            "        [1.1221, 1.6573, 1.0306, 1.6705, 1.5930, 1.1277, 1.0856],\n",
            "        [3.0144, 3.8950, 2.1060, 3.9355, 3.9072, 2.2657, 2.3035]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "204\n",
            "tensor([[3.2022, 4.0973, 2.2017, 4.1360, 4.1024, 2.3918, 2.4285],\n",
            "        [1.0697, 1.5907, 0.9955, 1.6031, 1.5263, 1.0861, 1.0482],\n",
            "        [2.9719, 3.8561, 2.0820, 3.8947, 3.8719, 2.2336, 2.2758],\n",
            "        [1.8368, 2.5538, 1.4621, 2.5688, 2.5073, 1.5934, 1.5617],\n",
            "        [2.7832, 3.6582, 1.9845, 3.6911, 3.6618, 2.1261, 2.1595]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "205\n",
            "tensor([[0.8925, 1.3613, 0.8796, 1.3745, 1.2957, 0.9519, 0.9248],\n",
            "        [1.0872, 1.6168, 1.0069, 1.6274, 1.5500, 1.0957, 1.0611],\n",
            "        [1.4281, 2.0524, 1.2200, 2.0643, 1.9927, 1.3366, 1.2952],\n",
            "        [3.1821, 4.0787, 2.1879, 4.1177, 4.0869, 2.3724, 2.4145],\n",
            "        [0.7842, 1.2194, 0.8059, 1.2327, 1.1551, 0.8651, 0.8464]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "206\n",
            "tensor([[1.3138, 1.9088, 1.1486, 1.9192, 1.8456, 1.2556, 1.2180],\n",
            "        [2.9708, 3.8583, 2.0767, 3.8955, 3.8684, 2.2425, 2.2800],\n",
            "        [0.8966, 1.3682, 0.8820, 1.3817, 1.3025, 0.9554, 0.9286],\n",
            "        [2.1398, 2.9215, 1.6296, 2.9395, 2.8890, 1.7682, 1.7581],\n",
            "        [2.4461, 3.2784, 1.7981, 3.3013, 3.2602, 1.9435, 1.9517]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "207\n",
            "tensor([[2.9408, 3.8328, 2.0591, 3.8653, 3.8383, 2.2201, 2.2614],\n",
            "        [0.9101, 1.3889, 0.8897, 1.3997, 1.3214, 0.9654, 0.9378],\n",
            "        [2.6794, 3.5497, 1.9232, 3.5782, 3.5457, 2.0689, 2.0992],\n",
            "        [1.7468, 2.4516, 1.4051, 2.4629, 2.3995, 1.5395, 1.5070],\n",
            "        [2.5360, 3.3847, 1.8423, 3.4092, 3.3689, 1.9856, 2.0076]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "208\n",
            "tensor([[1.3864, 2.0027, 1.1904, 2.0125, 1.9401, 1.3052, 1.2678],\n",
            "        [1.0257, 1.5391, 0.9640, 1.5516, 1.4710, 1.0523, 1.0202],\n",
            "        [1.7947, 2.5125, 1.4298, 2.5236, 2.4621, 1.5661, 1.5378],\n",
            "        [1.8389, 2.5649, 1.4564, 2.5775, 2.5175, 1.5923, 1.5670],\n",
            "        [3.0177, 3.9143, 2.0953, 3.9532, 3.9245, 2.2619, 2.3123]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "209\n",
            "tensor([[3.1771, 4.0836, 2.1750, 4.1223, 4.0932, 2.3616, 2.4142],\n",
            "        [1.2144, 1.7848, 1.0827, 1.7963, 1.7189, 1.1891, 1.1523],\n",
            "        [1.8234, 2.5486, 1.4449, 2.5587, 2.4986, 1.5759, 1.5540],\n",
            "        [2.2111, 3.0117, 1.6622, 3.0297, 2.9784, 1.8117, 1.8044],\n",
            "        [2.3832, 3.2121, 1.7567, 3.2348, 3.1889, 1.9099, 1.9146]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "210\n",
            "tensor([[1.6018, 2.2767, 1.3155, 2.2870, 2.2198, 1.4409, 1.4104],\n",
            "        [3.0692, 3.9704, 2.1179, 4.0098, 3.9858, 2.2852, 2.3419],\n",
            "        [3.1858, 4.0958, 2.1772, 4.1342, 4.1010, 2.3721, 2.4235],\n",
            "        [1.2498, 1.8324, 1.1030, 1.8441, 1.7681, 1.2111, 1.1760],\n",
            "        [2.0144, 2.7808, 1.5543, 2.7979, 2.7407, 1.6921, 1.6808]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "211\n",
            "tensor([[2.0293, 2.7994, 1.5598, 2.8140, 2.7602, 1.6977, 1.6884],\n",
            "        [1.6270, 2.3081, 1.3303, 2.3221, 2.2538, 1.4608, 1.4281],\n",
            "        [2.4767, 3.3270, 1.8063, 3.3517, 3.3103, 1.9574, 1.9751],\n",
            "        [1.8032, 2.5256, 1.4326, 2.5404, 2.4760, 1.5676, 1.5432],\n",
            "        [1.1069, 1.6498, 1.0125, 1.6615, 1.5825, 1.1113, 1.0779]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "212\n",
            "tensor([[2.9921, 3.8943, 2.0734, 3.9323, 3.9085, 2.2355, 2.2945],\n",
            "        [3.0779, 3.9859, 2.1191, 4.0271, 3.9960, 2.2932, 2.3517],\n",
            "        [2.7772, 3.6641, 1.9624, 3.6989, 3.6673, 2.1106, 2.1611],\n",
            "        [3.1253, 4.0342, 2.1442, 4.0749, 4.0491, 2.3332, 2.3806],\n",
            "        [2.6039, 3.4683, 1.8703, 3.4986, 3.4591, 2.0200, 2.0537]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "213\n",
            "tensor([[1.4969, 2.1494, 1.2520, 2.1626, 2.0915, 1.3793, 1.3429],\n",
            "        [1.1734, 1.7357, 1.0526, 1.7480, 1.6709, 1.1562, 1.1224],\n",
            "        [1.5103, 2.1638, 1.2578, 2.1753, 2.1040, 1.3855, 1.3496],\n",
            "        [2.9750, 3.8755, 2.0648, 3.9150, 3.8876, 2.2331, 2.2832],\n",
            "        [3.1599, 4.0705, 2.1593, 4.1136, 4.0830, 2.3476, 2.4020]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "214\n",
            "tensor([[3.1903, 4.1029, 2.1713, 4.1424, 4.1117, 2.3753, 2.4234],\n",
            "        [0.9661, 1.4664, 0.9222, 1.4820, 1.4017, 1.0113, 0.9800],\n",
            "        [0.7476, 1.1779, 0.7755, 1.1927, 1.1141, 0.8378, 0.8220],\n",
            "        [1.2448, 1.8267, 1.0985, 1.8413, 1.7650, 1.2089, 1.1714],\n",
            "        [3.0521, 3.9582, 2.1015, 4.0013, 3.9796, 2.2832, 2.3325]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "215\n",
            "tensor([[1.5657, 2.2368, 1.2921, 2.2520, 2.1832, 1.4272, 1.3892],\n",
            "        [1.8559, 2.5927, 1.4588, 2.6102, 2.5487, 1.6061, 1.5786],\n",
            "        [2.1940, 2.9972, 1.6469, 3.0204, 2.9709, 1.8015, 1.7935],\n",
            "        [1.6826, 2.3817, 1.3587, 2.3978, 2.3307, 1.4953, 1.4659],\n",
            "        [1.0358, 1.5579, 0.9658, 1.5723, 1.4942, 1.0614, 1.0285]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "216\n",
            "tensor([[2.5904, 3.4583, 1.8619, 3.4908, 3.4528, 2.0227, 2.0440],\n",
            "        [2.5537, 3.4196, 1.8439, 3.4516, 3.4170, 1.9968, 2.0208],\n",
            "        [3.1689, 4.0839, 2.1604, 4.1257, 4.0947, 2.3634, 2.4118],\n",
            "        [2.7854, 3.6795, 1.9659, 3.7167, 3.6883, 2.1332, 2.1666],\n",
            "        [3.1617, 4.0748, 2.1534, 4.1123, 4.0776, 2.3675, 2.4120]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "217\n",
            "tensor([[2.1357, 2.9342, 1.6195, 2.9589, 2.9057, 1.7727, 1.7612],\n",
            "        [1.0072, 1.5240, 0.9484, 1.5405, 1.4604, 1.0460, 1.0099],\n",
            "        [0.9944, 1.5058, 0.9365, 1.5211, 1.4440, 1.0339, 1.0001],\n",
            "        [2.6368, 3.5166, 1.8900, 3.5518, 3.5166, 2.0478, 2.0756],\n",
            "        [2.1640, 2.9661, 1.6329, 2.9901, 2.9390, 1.7906, 1.7785]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "218\n",
            "tensor([[2.0589, 2.8403, 1.5765, 2.8631, 2.8104, 1.7302, 1.7106],\n",
            "        [2.5546, 3.4223, 1.8462, 3.4560, 3.4182, 2.0066, 2.0274],\n",
            "        [2.7380, 3.6264, 1.9457, 3.6655, 3.6371, 2.1084, 2.1415],\n",
            "        [2.1838, 2.9891, 1.6470, 3.0161, 2.9655, 1.8054, 1.7928],\n",
            "        [1.0597, 1.5918, 0.9844, 1.6077, 1.5284, 1.0820, 1.0480]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "219\n",
            "tensor([[1.3464, 1.9616, 1.1645, 1.9792, 1.9052, 1.2871, 1.2464],\n",
            "        [1.5073, 2.1646, 1.2610, 2.1826, 2.1122, 1.3944, 1.3540],\n",
            "        [2.7406, 3.6319, 1.9483, 3.6724, 3.6453, 2.1056, 2.1423],\n",
            "        [1.0970, 1.6404, 1.0103, 1.6595, 1.5801, 1.1134, 1.0762],\n",
            "        [2.6101, 3.4820, 1.8773, 3.5210, 3.4839, 2.0472, 2.0646]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "220\n",
            "tensor([[1.6849, 2.3874, 1.3659, 2.4058, 2.3422, 1.5054, 1.4712],\n",
            "        [2.9490, 3.8572, 2.0559, 3.9029, 3.8834, 2.2199, 2.2744],\n",
            "        [2.4295, 3.2753, 1.7821, 3.3081, 3.2675, 1.9455, 1.9500],\n",
            "        [1.5261, 2.1911, 1.2732, 2.2083, 2.1385, 1.4046, 1.3685],\n",
            "        [3.0998, 4.0152, 2.1354, 4.0671, 4.0443, 2.3265, 2.3724]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "221\n",
            "tensor([[1.2313, 1.8158, 1.0956, 1.8328, 1.7586, 1.2105, 1.1698],\n",
            "        [1.0353, 1.5617, 0.9718, 1.5789, 1.5015, 1.0676, 1.0342],\n",
            "        [1.7153, 2.4276, 1.3859, 2.4466, 2.3837, 1.5258, 1.4949],\n",
            "        [0.9926, 1.5061, 0.9451, 1.5253, 1.4454, 1.0395, 1.0057],\n",
            "        [2.9977, 3.9086, 2.0831, 3.9591, 3.9379, 2.2612, 2.3110]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "222\n",
            "tensor([[2.5589, 3.4333, 1.8545, 3.4698, 3.4360, 2.0070, 2.0387],\n",
            "        [1.4086, 2.0443, 1.2045, 2.0630, 1.9917, 1.3326, 1.2943],\n",
            "        [1.8499, 2.5914, 1.4612, 2.6128, 2.5545, 1.6128, 1.5840],\n",
            "        [2.7225, 3.6190, 1.9444, 3.6589, 3.6328, 2.1024, 2.1398],\n",
            "        [3.1116, 4.0326, 2.1429, 4.0812, 4.0562, 2.3364, 2.3891]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "223\n",
            "tensor([[1.0971, 1.6454, 1.0118, 1.6635, 1.5861, 1.1168, 1.0809],\n",
            "        [1.1469, 1.7100, 1.0434, 1.7278, 1.6506, 1.1518, 1.1159],\n",
            "        [2.5733, 3.4488, 1.8641, 3.4861, 3.4518, 2.0257, 2.0491],\n",
            "        [2.7496, 3.6457, 1.9555, 3.6861, 3.6586, 2.1237, 2.1612],\n",
            "        [0.9559, 1.4599, 0.9206, 1.4784, 1.3988, 1.0096, 0.9810]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "224\n",
            "tensor([[1.0157, 1.5390, 0.9607, 1.5573, 1.4787, 1.0571, 1.0250],\n",
            "        [3.1408, 4.0645, 2.1568, 4.1121, 4.0883, 2.3551, 2.4094],\n",
            "        [2.4786, 3.3379, 1.8133, 3.3741, 3.3370, 1.9751, 1.9905],\n",
            "        [2.1736, 2.9865, 1.6464, 3.0148, 2.9665, 1.8018, 1.7995],\n",
            "        [3.0987, 4.0182, 2.1379, 4.0671, 4.0427, 2.3333, 2.3816]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "225\n",
            "tensor([[1.9286, 2.6910, 1.5080, 2.7142, 2.6603, 1.6531, 1.6408],\n",
            "        [2.8396, 3.7491, 2.0020, 3.7936, 3.7734, 2.1649, 2.2193],\n",
            "        [1.1686, 1.7390, 1.0576, 1.7553, 1.6794, 1.1661, 1.1320],\n",
            "        [2.5975, 3.4802, 1.8772, 3.5188, 3.4895, 2.0300, 2.0669],\n",
            "        [3.1770, 4.1012, 2.1757, 4.1491, 4.1253, 2.3808, 2.4376]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "226\n",
            "tensor([[1.5073, 2.1736, 1.2653, 2.1919, 2.1240, 1.3944, 1.3662],\n",
            "        [0.9889, 1.5032, 0.9425, 1.5231, 1.4439, 1.0383, 1.0073],\n",
            "        [2.5422, 3.4152, 1.8454, 3.4533, 3.4224, 2.0054, 2.0343],\n",
            "        [3.1738, 4.0996, 2.1727, 4.1498, 4.1255, 2.3842, 2.4365],\n",
            "        [3.1609, 4.0872, 2.1670, 4.1357, 4.1111, 2.3696, 2.4279]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "227\n",
            "tensor([[0.7485, 1.1856, 0.7818, 1.2060, 1.1266, 0.8519, 0.8343],\n",
            "        [0.8734, 1.3513, 0.8665, 1.3713, 1.2922, 0.9505, 0.9249],\n",
            "        [2.0918, 2.8910, 1.6040, 2.9182, 2.8727, 1.7532, 1.7495],\n",
            "        [2.4447, 3.3029, 1.7938, 3.3387, 3.3015, 1.9578, 1.9754],\n",
            "        [1.8123, 2.5506, 1.4437, 2.5734, 2.5174, 1.5847, 1.5669]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "228\n",
            "tensor([[2.5618, 3.4332, 1.8580, 3.4726, 3.4416, 2.0200, 2.0474],\n",
            "        [0.9134, 1.4032, 0.8858, 1.4213, 1.3454, 0.9742, 0.9499],\n",
            "        [1.1960, 1.7733, 1.0752, 1.7934, 1.7191, 1.1899, 1.1542],\n",
            "        [2.6321, 3.5141, 1.8951, 3.5566, 3.5293, 2.0585, 2.0925],\n",
            "        [2.5127, 3.3809, 1.8322, 3.4190, 3.3878, 1.9904, 2.0170]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "229\n",
            "tensor([[1.5357, 2.2057, 1.2840, 2.2263, 2.1605, 1.4198, 1.3844],\n",
            "        [0.8758, 1.3543, 0.8696, 1.3750, 1.2959, 0.9533, 0.9272],\n",
            "        [3.0569, 3.9738, 2.1196, 4.0279, 4.0109, 2.2987, 2.3589],\n",
            "        [2.1859, 3.0002, 1.6557, 3.0307, 2.9852, 1.8105, 1.8105],\n",
            "        [1.7535, 2.4769, 1.4113, 2.4987, 2.4401, 1.5555, 1.5283]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "230\n",
            "tensor([[1.7263, 2.4410, 1.3963, 2.4631, 2.4029, 1.5363, 1.5085],\n",
            "        [1.2010, 1.7797, 1.0828, 1.7986, 1.7245, 1.1928, 1.1557],\n",
            "        [2.9004, 3.8085, 2.0375, 3.8576, 3.8393, 2.1981, 2.2560],\n",
            "        [2.7593, 3.6498, 1.9635, 3.6971, 3.6711, 2.1345, 2.1707],\n",
            "        [0.8387, 1.3033, 0.8459, 1.3250, 1.2461, 0.9225, 0.8996]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "231\n",
            "tensor([[3.1669, 4.0898, 2.1733, 4.1400, 4.1162, 2.3686, 2.4322],\n",
            "        [0.9701, 1.4773, 0.9349, 1.4988, 1.4197, 1.0231, 0.9948],\n",
            "        [2.6925, 3.5835, 1.9307, 3.6258, 3.6000, 2.0885, 2.1302],\n",
            "        [2.5966, 3.4748, 1.8773, 3.5151, 3.4868, 2.0330, 2.0695],\n",
            "        [2.9962, 3.9118, 2.0874, 3.9631, 3.9481, 2.2585, 2.3181]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "232\n",
            "tensor([[2.8730, 3.7771, 2.0246, 3.8209, 3.8006, 2.1843, 2.2382],\n",
            "        [2.2230, 3.0431, 1.6798, 3.0739, 3.0309, 1.8236, 1.8318],\n",
            "        [3.0973, 4.0104, 2.1397, 4.0631, 4.0474, 2.3117, 2.3790],\n",
            "        [2.6214, 3.5045, 1.8927, 3.5426, 3.5169, 2.0410, 2.0827],\n",
            "        [2.4493, 3.3042, 1.8006, 3.3412, 3.3069, 1.9534, 1.9749]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "233\n",
            "tensor([[1.5237, 2.1895, 1.2775, 2.2074, 2.1430, 1.4016, 1.3723],\n",
            "        [3.0857, 4.0007, 2.1332, 4.0497, 4.0365, 2.3067, 2.3698],\n",
            "        [1.6224, 2.3110, 1.3352, 2.3318, 2.2698, 1.4676, 1.4392],\n",
            "        [0.9906, 1.5010, 0.9461, 1.5215, 1.4455, 1.0361, 1.0057],\n",
            "        [2.9604, 3.8709, 2.0679, 3.9168, 3.9012, 2.2352, 2.2910]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "234\n",
            "tensor([[3.1863, 4.1024, 2.1816, 4.1478, 4.1287, 2.3630, 2.4333],\n",
            "        [0.9299, 1.4223, 0.9048, 1.4392, 1.3634, 0.9854, 0.9610],\n",
            "        [0.8571, 1.3235, 0.8581, 1.3449, 1.2659, 0.9338, 0.9092],\n",
            "        [2.8932, 3.7956, 2.0323, 3.8390, 3.8244, 2.1816, 2.2447],\n",
            "        [3.1937, 4.1113, 2.1859, 4.1583, 4.1365, 2.3787, 2.4410]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "235\n",
            "tensor([[0.8347, 1.2932, 0.8411, 1.3106, 1.2337, 0.9123, 0.8914],\n",
            "        [3.0783, 3.9841, 2.1278, 4.0303, 4.0199, 2.2837, 2.3563],\n",
            "        [0.7739, 1.2135, 0.8010, 1.2316, 1.1541, 0.8638, 0.8469],\n",
            "        [2.2051, 3.0117, 1.6637, 3.0382, 2.9941, 1.8064, 1.8132],\n",
            "        [1.2621, 1.8502, 1.1149, 1.8654, 1.7931, 1.2212, 1.1892]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "236\n",
            "tensor([[2.5376, 3.3946, 1.8486, 3.4298, 3.4000, 1.9845, 2.0209],\n",
            "        [2.0239, 2.7917, 1.5645, 2.8158, 2.7681, 1.6976, 1.6934],\n",
            "        [2.9140, 3.8064, 2.0425, 3.8502, 3.8380, 2.1840, 2.2516],\n",
            "        [2.7177, 3.5913, 1.9409, 3.6296, 3.6081, 2.0815, 2.1306],\n",
            "        [2.0891, 2.8659, 1.6011, 2.8913, 2.8450, 1.7354, 1.7340]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "237\n",
            "tensor([[2.3514, 3.1712, 1.7475, 3.2036, 3.1689, 1.8746, 1.9002],\n",
            "        [1.7730, 2.4822, 1.4233, 2.5032, 2.4458, 1.5466, 1.5291],\n",
            "        [1.5664, 2.2269, 1.3013, 2.2455, 2.1822, 1.4170, 1.3931],\n",
            "        [2.2018, 2.9968, 1.6654, 3.0262, 2.9827, 1.7943, 1.8067],\n",
            "        [3.1668, 4.0682, 2.1768, 4.1169, 4.1039, 2.3345, 2.4115]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "238\n",
            "tensor([[3.2035, 4.1004, 2.1987, 4.1542, 4.1377, 2.3693, 2.4405],\n",
            "        [2.7151, 3.5796, 1.9441, 3.6235, 3.6018, 2.0667, 2.1283],\n",
            "        [1.0361, 1.5516, 0.9763, 1.5721, 1.4972, 1.0618, 1.0349],\n",
            "        [1.2546, 1.8342, 1.1160, 1.8538, 1.7816, 1.2182, 1.1862],\n",
            "        [1.2004, 1.7617, 1.0810, 1.7811, 1.7077, 1.1750, 1.1477]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "239\n",
            "tensor([[3.2183, 4.1111, 2.2060, 4.1646, 4.1425, 2.3768, 2.4505],\n",
            "        [0.8163, 1.2610, 0.8298, 1.2833, 1.2051, 0.8935, 0.8784],\n",
            "        [1.7409, 2.4360, 1.4113, 2.4636, 2.4046, 1.5260, 1.5109],\n",
            "        [0.9637, 1.4530, 0.9315, 1.4766, 1.3980, 1.0082, 0.9842],\n",
            "        [3.2118, 4.1025, 2.2047, 4.1580, 4.1391, 2.3655, 2.4465]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "240\n",
            "tensor([[0.9766, 1.4676, 0.9398, 1.4925, 1.4146, 1.0167, 0.9932],\n",
            "        [1.9757, 2.7164, 1.5435, 2.7477, 2.6974, 1.6606, 1.6625],\n",
            "        [3.0911, 3.9721, 2.1449, 4.0334, 4.0204, 2.2890, 2.3663],\n",
            "        [2.2043, 2.9861, 1.6705, 3.0246, 2.9807, 1.7943, 1.8105],\n",
            "        [3.0856, 3.9679, 2.1429, 4.0280, 4.0139, 2.2844, 2.3638]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "241\n",
            "tensor([[2.6697, 3.5151, 1.9263, 3.5656, 3.5410, 2.0475, 2.1001],\n",
            "        [1.7704, 2.4631, 1.4273, 2.4937, 2.4364, 1.5403, 1.5294],\n",
            "        [2.1160, 2.8793, 1.6264, 2.9161, 2.8713, 1.7430, 1.7528],\n",
            "        [2.8982, 3.7670, 2.0457, 3.8234, 3.8085, 2.1662, 2.2436],\n",
            "        [2.7226, 3.5761, 1.9538, 3.6288, 3.6081, 2.0759, 2.1344]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "242\n",
            "tensor([[0.8843, 1.3450, 0.8800, 1.3715, 1.2917, 0.9484, 0.9272],\n",
            "        [3.2201, 4.0999, 2.2137, 4.1620, 4.1456, 2.3787, 2.4491],\n",
            "        [3.1456, 4.0210, 2.1744, 4.0870, 4.0742, 2.3187, 2.3964],\n",
            "        [1.9408, 2.6686, 1.5265, 2.7025, 2.6491, 1.6481, 1.6396],\n",
            "        [2.7281, 3.5807, 1.9587, 3.6348, 3.6151, 2.0750, 2.1362]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "243\n",
            "tensor([[1.2434, 1.8059, 1.1111, 1.8329, 1.7609, 1.2079, 1.1755],\n",
            "        [1.7977, 2.4951, 1.4476, 2.5290, 2.4721, 1.5620, 1.5474],\n",
            "        [2.8754, 3.7377, 2.0356, 3.7963, 3.7833, 2.1523, 2.2255],\n",
            "        [1.7863, 2.4802, 1.4388, 2.5134, 2.4551, 1.5578, 1.5390],\n",
            "        [0.9123, 1.3801, 0.8994, 1.4066, 1.3290, 0.9713, 0.9464]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "244\n",
            "tensor([[3.2159, 4.0898, 2.2110, 4.1535, 4.1371, 2.3754, 2.4433],\n",
            "        [1.5425, 2.1792, 1.2935, 2.2088, 2.1449, 1.4048, 1.3770],\n",
            "        [2.3160, 3.1018, 1.7361, 3.1472, 3.1083, 1.8641, 1.8753],\n",
            "        [3.2140, 4.0882, 2.2117, 4.1511, 4.1323, 2.3770, 2.4453],\n",
            "        [3.0894, 3.9587, 2.1468, 4.0227, 4.0138, 2.2826, 2.3578]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "245\n",
            "tensor([[0.7328, 1.1424, 0.7781, 1.1695, 1.0915, 0.8324, 0.8157],\n",
            "        [1.3181, 1.8992, 1.1629, 1.9280, 1.8571, 1.2619, 1.2278],\n",
            "        [1.5421, 2.1790, 1.2920, 2.2073, 2.1436, 1.4141, 1.3782],\n",
            "        [2.4580, 3.2653, 1.8162, 3.3145, 3.2815, 1.9446, 1.9642],\n",
            "        [0.7467, 1.1616, 0.7890, 1.1888, 1.1103, 0.8441, 0.8270]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "246\n",
            "tensor([[2.2869, 3.0697, 1.7272, 3.1169, 3.0772, 1.8486, 1.8589],\n",
            "        [1.2995, 1.8740, 1.1512, 1.9035, 1.8322, 1.2526, 1.2157],\n",
            "        [1.0903, 1.6091, 1.0199, 1.6383, 1.5623, 1.1070, 1.0727],\n",
            "        [2.8477, 3.7024, 2.0301, 3.7626, 3.7468, 2.1526, 2.2075],\n",
            "        [1.5538, 2.1915, 1.3048, 2.2227, 2.1587, 1.4163, 1.3856]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "247\n",
            "tensor([[0.9748, 1.4587, 0.9458, 1.4884, 1.4115, 1.0246, 0.9926],\n",
            "        [3.1273, 3.9885, 2.1758, 4.0570, 4.0445, 2.3112, 2.3835],\n",
            "        [0.9441, 1.4207, 0.9259, 1.4491, 1.3721, 1.0004, 0.9703],\n",
            "        [0.8303, 1.2708, 0.8481, 1.2985, 1.2221, 0.9109, 0.8872],\n",
            "        [2.4067, 3.2082, 1.7970, 3.2587, 3.2245, 1.9200, 1.9357]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "248\n",
            "tensor([[2.1071, 2.8560, 1.6310, 2.8970, 2.8530, 1.7548, 1.7440],\n",
            "        [2.7280, 3.5676, 1.9703, 3.6237, 3.6047, 2.0891, 2.1323],\n",
            "        [1.5519, 2.1886, 1.3121, 2.2206, 2.1594, 1.4194, 1.3849],\n",
            "        [2.3782, 3.1732, 1.7828, 3.2214, 3.1902, 1.9045, 1.9156],\n",
            "        [2.9708, 3.8309, 2.1006, 3.8927, 3.8848, 2.2271, 2.2833]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "249\n",
            "tensor([[1.5606, 2.1991, 1.3163, 2.2298, 2.1700, 1.4239, 1.3888],\n",
            "        [2.9149, 3.7670, 2.0715, 3.8303, 3.8201, 2.1969, 2.2481],\n",
            "        [3.2225, 4.0856, 2.2288, 4.1511, 4.1400, 2.3916, 2.4457],\n",
            "        [2.7244, 3.5624, 1.9718, 3.6204, 3.6057, 2.0891, 2.1302],\n",
            "        [2.4022, 3.2001, 1.7965, 3.2475, 3.2193, 1.9110, 1.9291]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "250\n",
            "tensor([[3.0468, 3.9032, 2.1406, 3.9695, 3.9645, 2.2825, 2.3310],\n",
            "        [1.9401, 2.6596, 1.5375, 2.6966, 2.6505, 1.6571, 1.6382],\n",
            "        [1.5093, 2.1323, 1.2831, 2.1619, 2.1012, 1.3910, 1.3540],\n",
            "        [1.4447, 2.0544, 1.2472, 2.0843, 2.0209, 1.3516, 1.3129],\n",
            "        [0.8462, 1.2896, 0.8612, 1.3169, 1.2421, 0.9267, 0.8991]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "251\n",
            "tensor([[2.1032, 2.8516, 1.6328, 2.8919, 2.8562, 1.7501, 1.7421],\n",
            "        [2.5131, 3.3213, 1.8584, 3.3723, 3.3508, 1.9827, 2.0006],\n",
            "        [3.1897, 4.0502, 2.2152, 4.1196, 4.1165, 2.3712, 2.4223],\n",
            "        [3.2289, 4.0902, 2.2337, 4.1555, 4.1500, 2.3988, 2.4485],\n",
            "        [2.9019, 3.7533, 2.0656, 3.8155, 3.8103, 2.1909, 2.2415]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "252\n",
            "tensor([[1.7384, 2.4155, 1.4215, 2.4479, 2.3978, 1.5420, 1.5080],\n",
            "        [3.0344, 3.8898, 2.1326, 3.9556, 3.9557, 2.2659, 2.3241],\n",
            "        [0.8624, 1.3098, 0.8735, 1.3384, 1.2647, 0.9416, 0.9116],\n",
            "        [1.7219, 2.3940, 1.4128, 2.4268, 2.3769, 1.5260, 1.4961],\n",
            "        [3.2247, 4.0888, 2.2301, 4.1513, 4.1479, 2.4004, 2.4486]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "253\n",
            "tensor([[2.3077, 3.0875, 1.7446, 3.1335, 3.1071, 1.8731, 1.8723],\n",
            "        [3.1514, 4.0095, 2.1923, 4.0767, 4.0796, 2.3446, 2.3988],\n",
            "        [2.4027, 3.1966, 1.7983, 3.2447, 3.2252, 1.9235, 1.9303],\n",
            "        [0.9770, 1.4595, 0.9509, 1.4883, 1.4168, 1.0325, 0.9950],\n",
            "        [0.9152, 1.3787, 0.9091, 1.4077, 1.3351, 0.9839, 0.9506]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "254\n",
            "tensor([[3.2269, 4.0865, 2.2314, 4.1549, 4.1549, 2.4046, 2.4488],\n",
            "        [1.0087, 1.5003, 0.9710, 1.5291, 1.4590, 1.0537, 1.0176],\n",
            "        [0.7224, 1.1261, 0.7764, 1.1547, 1.0805, 0.8322, 0.8114],\n",
            "        [1.8237, 2.5168, 1.4717, 2.5535, 2.5079, 1.5928, 1.5648],\n",
            "        [3.1991, 4.0571, 2.2177, 4.1264, 4.1264, 2.3849, 2.4301]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "255\n",
            "tensor([[3.1209, 3.9737, 2.1779, 4.0423, 4.0446, 2.3402, 2.3787],\n",
            "        [1.9960, 2.7214, 1.5716, 2.7645, 2.7247, 1.6966, 1.6774],\n",
            "        [3.1817, 4.0393, 2.2084, 4.1058, 4.1105, 2.3669, 2.4166],\n",
            "        [3.2248, 4.0816, 2.2297, 4.1480, 4.1491, 2.4008, 2.4455],\n",
            "        [1.3113, 1.8851, 1.1656, 1.9165, 1.8526, 1.2709, 1.2268]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "256\n",
            "tensor([[1.7817, 2.4604, 1.4468, 2.4976, 2.4510, 1.5704, 1.5369],\n",
            "        [3.0090, 3.8559, 2.1201, 3.9240, 3.9281, 2.2616, 2.3075],\n",
            "        [2.3549, 3.1355, 1.7717, 3.1867, 3.1642, 1.9028, 1.9025],\n",
            "        [1.2058, 1.7492, 1.0990, 1.7794, 1.7129, 1.1959, 1.1535],\n",
            "        [1.3967, 1.9887, 1.2158, 2.0205, 1.9615, 1.3281, 1.2828]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "257\n",
            "tensor([[1.0884, 1.5980, 1.0241, 1.6295, 1.5597, 1.1166, 1.0735],\n",
            "        [0.7375, 1.1436, 0.7864, 1.1728, 1.1001, 0.8452, 0.8227],\n",
            "        [3.2314, 4.0818, 2.2332, 4.1495, 4.1496, 2.4164, 2.4521],\n",
            "        [2.9565, 3.7979, 2.0934, 3.8663, 3.8708, 2.2334, 2.2756],\n",
            "        [2.5056, 3.3040, 1.8546, 3.3617, 3.3466, 1.9830, 1.9968]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "258\n",
            "tensor([[2.9551, 3.7959, 2.0931, 3.8658, 3.8692, 2.2386, 2.2753],\n",
            "        [2.4640, 3.2570, 1.8327, 3.3125, 3.2944, 1.9699, 1.9702],\n",
            "        [3.2042, 4.0497, 2.2217, 4.1254, 4.1321, 2.3951, 2.4307],\n",
            "        [0.7437, 1.1524, 0.7936, 1.1844, 1.1098, 0.8565, 0.8293],\n",
            "        [1.6353, 2.2801, 1.3611, 2.3207, 2.2668, 1.4885, 1.4445]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "259\n",
            "tensor([[2.2107, 2.9655, 1.6930, 3.0167, 2.9875, 1.8252, 1.8125],\n",
            "        [1.2893, 1.8523, 1.1440, 1.8808, 1.8208, 1.2592, 1.2078],\n",
            "        [3.1530, 3.9963, 2.1954, 4.0742, 4.0820, 2.3597, 2.3988],\n",
            "        [3.2093, 4.0541, 2.2228, 4.1298, 4.1312, 2.4016, 2.4383],\n",
            "        [3.2373, 4.0825, 2.2379, 4.1585, 4.1599, 2.4238, 2.4556]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "260\n",
            "tensor([[3.1075, 3.9437, 2.1697, 4.0210, 4.0239, 2.3490, 2.3714],\n",
            "        [3.1942, 4.0349, 2.2173, 4.1157, 4.1235, 2.3935, 2.4250],\n",
            "        [3.0336, 3.8688, 2.1330, 3.9452, 3.9543, 2.2889, 2.3210],\n",
            "        [1.4113, 2.0045, 1.2277, 2.0411, 1.9827, 1.3456, 1.2950],\n",
            "        [1.7953, 2.4731, 1.4577, 2.5178, 2.4713, 1.5886, 1.5483]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "261\n",
            "tensor([[1.0281, 1.5172, 0.9838, 1.5534, 1.4820, 1.0775, 1.0328],\n",
            "        [1.0002, 1.4834, 0.9672, 1.5188, 1.4470, 1.0596, 1.0147],\n",
            "        [3.2368, 4.0747, 2.2367, 4.1545, 4.1562, 2.4226, 2.4538],\n",
            "        [3.2326, 4.0706, 2.2318, 4.1500, 4.1477, 2.4247, 2.4539],\n",
            "        [2.5900, 3.3889, 1.8985, 3.4552, 3.4422, 2.0440, 2.0472]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "262\n",
            "tensor([[3.1945, 4.0255, 2.2151, 4.1112, 4.1191, 2.3949, 2.4237],\n",
            "        [2.0256, 2.7392, 1.5880, 2.7901, 2.7528, 1.7243, 1.6936],\n",
            "        [1.5793, 2.2062, 1.3271, 2.2464, 2.1926, 1.4567, 1.4058],\n",
            "        [3.2058, 4.0404, 2.2201, 4.1254, 4.1280, 2.3986, 2.4329],\n",
            "        [2.5590, 3.3561, 1.8831, 3.4224, 3.4097, 2.0263, 2.0308]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "263\n",
            "tensor([[3.2339, 4.0666, 2.2382, 4.1492, 4.1521, 2.4293, 2.4504],\n",
            "        [2.1541, 2.8876, 1.6619, 2.9429, 2.9111, 1.8064, 1.7762],\n",
            "        [2.9422, 3.7671, 2.0874, 3.8472, 3.8520, 2.2332, 2.2647],\n",
            "        [0.8562, 1.2952, 0.8707, 1.3309, 1.2571, 0.9485, 0.9123],\n",
            "        [2.5317, 3.3198, 1.8695, 3.3877, 3.3719, 2.0212, 2.0154]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "264\n",
            "tensor([[3.1897, 4.0196, 2.2191, 4.1059, 4.1106, 2.3962, 2.4216],\n",
            "        [1.1495, 1.6706, 1.0653, 1.7088, 1.6400, 1.1704, 1.1185],\n",
            "        [1.1594, 1.6830, 1.0718, 1.7210, 1.6519, 1.1771, 1.1255],\n",
            "        [2.2540, 3.0005, 1.7199, 3.0617, 3.0333, 1.8651, 1.8396],\n",
            "        [3.2376, 4.0675, 2.2396, 4.1507, 4.1477, 2.4338, 2.4563]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "265\n",
            "tensor([[2.0892, 2.8120, 1.6293, 2.8676, 2.8340, 1.7694, 1.7374],\n",
            "        [2.2044, 2.9461, 1.6960, 3.0053, 2.9754, 1.8315, 1.8110],\n",
            "        [1.7441, 2.4044, 1.4304, 2.4524, 2.4032, 1.5603, 1.5166],\n",
            "        [3.2369, 4.0623, 2.2418, 4.1489, 4.1528, 2.4268, 2.4527],\n",
            "        [3.1832, 4.0057, 2.2143, 4.0962, 4.1046, 2.3911, 2.4170]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "266\n",
            "tensor([[1.6396, 2.2769, 1.3714, 2.3230, 2.2688, 1.5002, 1.4507],\n",
            "        [1.0951, 1.5975, 1.0353, 1.6367, 1.5676, 1.1312, 1.0811],\n",
            "        [3.2218, 4.0450, 2.2358, 4.1311, 4.1322, 2.4269, 2.4458],\n",
            "        [2.6028, 3.3924, 1.9132, 3.4657, 3.4551, 2.0556, 2.0591],\n",
            "        [1.4599, 2.0580, 1.2637, 2.1024, 2.0424, 1.3850, 1.3328]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "267\n",
            "tensor([[1.5989, 2.2230, 1.3461, 2.2693, 2.2146, 1.4775, 1.4232],\n",
            "        [3.2315, 4.0498, 2.2450, 4.1396, 4.1393, 2.4256, 2.4516],\n",
            "        [2.3259, 3.0796, 1.7654, 3.1455, 3.1186, 1.9087, 1.8910],\n",
            "        [1.2796, 1.8303, 1.1491, 1.8696, 1.8047, 1.2590, 1.2062],\n",
            "        [1.6862, 2.3310, 1.3999, 2.3790, 2.3280, 1.5356, 1.4811]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "268\n",
            "tensor([[2.9011, 3.7124, 2.0778, 3.7982, 3.7989, 2.2268, 2.2482],\n",
            "        [2.9338, 3.7472, 2.0956, 3.8343, 3.8358, 2.2429, 2.2666],\n",
            "        [2.8776, 3.6873, 2.0655, 3.7716, 3.7730, 2.2035, 2.2307],\n",
            "        [2.0983, 2.8138, 1.6411, 2.8732, 2.8389, 1.7795, 1.7455],\n",
            "        [3.2345, 4.0533, 2.2489, 4.1444, 4.1449, 2.4289, 2.4587]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "269\n",
            "tensor([[2.9398, 3.7541, 2.1013, 3.8403, 3.8359, 2.2503, 2.2798],\n",
            "        [2.5886, 3.3711, 1.9148, 3.4469, 3.4328, 2.0549, 2.0572],\n",
            "        [1.3386, 1.9017, 1.1936, 1.9440, 1.8808, 1.3045, 1.2529],\n",
            "        [1.3933, 1.9714, 1.2274, 2.0138, 1.9524, 1.3430, 1.2893],\n",
            "        [0.9599, 1.4257, 0.9486, 1.4631, 1.3908, 1.0318, 0.9896]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "270\n",
            "tensor([[0.9184, 1.3723, 0.9220, 1.4114, 1.3374, 1.0028, 0.9638],\n",
            "        [3.1899, 4.0051, 2.2320, 4.0997, 4.1022, 2.3988, 2.4339],\n",
            "        [3.2207, 4.0393, 2.2503, 4.1329, 4.1306, 2.4261, 2.4571],\n",
            "        [1.4728, 2.0696, 1.2787, 2.1147, 2.0554, 1.3961, 1.3458],\n",
            "        [2.7668, 3.5680, 2.0131, 3.6488, 3.6417, 2.1608, 2.1733]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "271\n",
            "tensor([[3.1029, 3.9178, 2.1924, 4.0108, 4.0167, 2.3416, 2.3812],\n",
            "        [2.5757, 3.3602, 1.9157, 3.4372, 3.4217, 2.0512, 2.0586],\n",
            "        [1.1748, 1.7005, 1.0937, 1.7424, 1.6722, 1.1963, 1.1465],\n",
            "        [2.6471, 3.4387, 1.9525, 3.5164, 3.5030, 2.0970, 2.1030],\n",
            "        [2.1961, 2.9320, 1.7055, 2.9950, 2.9624, 1.8393, 1.8203]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "272\n",
            "tensor([[1.2592, 1.8064, 1.1495, 1.8493, 1.7828, 1.2590, 1.2070],\n",
            "        [2.3927, 3.1517, 1.8157, 3.2226, 3.1993, 1.9551, 1.9447],\n",
            "        [3.1880, 4.0018, 2.2394, 4.0991, 4.1045, 2.4107, 2.4406],\n",
            "        [0.8062, 1.2292, 0.8477, 1.2667, 1.1930, 0.9179, 0.8854],\n",
            "        [3.2120, 4.0278, 2.2516, 4.1218, 4.1226, 2.4223, 2.4578]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "273\n",
            "tensor([[2.8187, 3.6239, 2.0509, 3.7108, 3.7071, 2.1950, 2.2157],\n",
            "        [1.6815, 2.3252, 1.4122, 2.3752, 2.3223, 1.5369, 1.4929],\n",
            "        [3.0153, 3.8275, 2.1531, 3.9214, 3.9244, 2.3091, 2.3391],\n",
            "        [2.5847, 3.3732, 1.9280, 3.4513, 3.4380, 2.0664, 2.0727],\n",
            "        [3.2354, 4.0495, 2.2663, 4.1468, 4.1464, 2.4467, 2.4797]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "274\n",
            "tensor([[1.5024, 2.1080, 1.3072, 2.1564, 2.0965, 1.4261, 1.3774],\n",
            "        [1.2209, 1.7591, 1.1265, 1.8010, 1.7331, 1.2359, 1.1844],\n",
            "        [2.9204, 3.7300, 2.1060, 3.8211, 3.8184, 2.2524, 2.2830],\n",
            "        [2.9878, 3.7975, 2.1408, 3.8925, 3.8912, 2.2944, 2.3262],\n",
            "        [2.8797, 3.6940, 2.0883, 3.7834, 3.7820, 2.2266, 2.2597]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "275\n",
            "tensor([[1.9916, 2.6908, 1.5962, 2.7500, 2.7087, 1.7294, 1.7006],\n",
            "        [2.9591, 3.7707, 2.1272, 3.8625, 3.8630, 2.2772, 2.3101],\n",
            "        [3.0111, 3.8217, 2.1542, 3.9171, 3.9188, 2.3087, 2.3405],\n",
            "        [3.2152, 4.0282, 2.2600, 4.1263, 4.1259, 2.4358, 2.4710],\n",
            "        [2.7823, 3.5901, 2.0364, 3.6754, 3.6705, 2.1703, 2.2012]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "276\n",
            "tensor([[1.5426, 2.1550, 1.3314, 2.2024, 2.1454, 1.4488, 1.4049],\n",
            "        [1.8198, 2.4871, 1.4964, 2.5427, 2.4942, 1.6269, 1.5891],\n",
            "        [1.0626, 1.5562, 1.0263, 1.5976, 1.5249, 1.1171, 1.0752],\n",
            "        [3.2403, 4.0511, 2.2759, 4.1480, 4.1450, 2.4518, 2.4913],\n",
            "        [1.7960, 2.4596, 1.4822, 2.5130, 2.4628, 1.6128, 1.5738]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "277\n",
            "tensor([[1.0946, 1.5970, 1.0506, 1.6375, 1.5665, 1.1388, 1.0988],\n",
            "        [2.0464, 2.7528, 1.6302, 2.8133, 2.7734, 1.7575, 1.7381],\n",
            "        [1.5810, 2.2022, 1.3561, 2.2493, 2.1928, 1.4743, 1.4322],\n",
            "        [1.4104, 1.9928, 1.2533, 2.0367, 1.9742, 1.3628, 1.3170],\n",
            "        [1.2408, 1.7809, 1.1448, 1.8234, 1.7562, 1.2479, 1.2019]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "278\n",
            "tensor([[2.0616, 2.7686, 1.6443, 2.8282, 2.7888, 1.7698, 1.7488],\n",
            "        [1.8643, 2.5379, 1.5294, 2.5905, 2.5453, 1.6490, 1.6195],\n",
            "        [1.0399, 1.5282, 1.0147, 1.5678, 1.4962, 1.1008, 1.0613],\n",
            "        [2.6954, 3.4846, 1.9972, 3.5667, 3.5577, 2.1194, 2.1503],\n",
            "        [2.9943, 3.7977, 2.1528, 3.8890, 3.8877, 2.2891, 2.3371]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "279\n",
            "tensor([[3.1904, 3.9944, 2.2607, 4.0915, 4.0948, 2.4025, 2.4618],\n",
            "        [0.8661, 1.3067, 0.8971, 1.3416, 1.2696, 0.9627, 0.9355],\n",
            "        [1.2860, 1.8369, 1.1753, 1.8771, 1.8122, 1.2756, 1.2341],\n",
            "        [0.9155, 1.3694, 0.9324, 1.4061, 1.3329, 1.0022, 0.9717],\n",
            "        [1.6679, 2.3027, 1.4152, 2.3547, 2.3002, 1.5296, 1.4936]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "280\n",
            "tensor([[1.3081, 1.8651, 1.1930, 1.9072, 1.8417, 1.2902, 1.2515],\n",
            "        [0.8796, 1.3232, 0.9078, 1.3597, 1.2870, 0.9737, 0.9467],\n",
            "        [2.1446, 2.8645, 1.6975, 2.9243, 2.8905, 1.8069, 1.8041],\n",
            "        [1.2721, 1.8197, 1.1714, 1.8630, 1.7968, 1.2669, 1.2269],\n",
            "        [1.1975, 1.7271, 1.1231, 1.7673, 1.6996, 1.2118, 1.1747]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "281\n",
            "tensor([[2.4485, 3.2129, 1.8706, 3.2816, 3.2651, 1.9794, 2.0001],\n",
            "        [2.0066, 2.7064, 1.6178, 2.7619, 2.7239, 1.7283, 1.7179],\n",
            "        [2.3047, 3.0486, 1.7905, 3.1142, 3.0887, 1.9085, 1.9099],\n",
            "        [2.6622, 3.4483, 1.9885, 3.5260, 3.5182, 2.1011, 2.1361],\n",
            "        [0.9620, 1.4272, 0.9651, 1.4632, 1.3917, 1.0372, 1.0062]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "282\n",
            "tensor([[1.2557, 1.7984, 1.1568, 1.8361, 1.7721, 1.2446, 1.2127],\n",
            "        [3.0346, 3.8364, 2.1870, 3.9284, 3.9339, 2.2987, 2.3684],\n",
            "        [1.1541, 1.6719, 1.0949, 1.7083, 1.6414, 1.1749, 1.1428],\n",
            "        [1.6399, 2.2717, 1.4049, 2.3193, 2.2659, 1.5085, 1.4784],\n",
            "        [1.9574, 2.6502, 1.5936, 2.7050, 2.6637, 1.6970, 1.6891]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "283\n",
            "tensor([[3.0078, 3.8115, 2.1756, 3.8967, 3.9002, 2.2927, 2.3560],\n",
            "        [1.3341, 1.8983, 1.2152, 1.9393, 1.8761, 1.3070, 1.2716],\n",
            "        [1.0205, 1.5048, 1.0097, 1.5417, 1.4699, 1.0826, 1.0510],\n",
            "        [1.4381, 2.0283, 1.2829, 2.0687, 2.0089, 1.3738, 1.3431],\n",
            "        [1.3661, 1.9376, 1.2345, 1.9781, 1.9163, 1.3271, 1.2934]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "Loss at epoch 6: 121.2255\n",
            "Pearson correlation for aspect 1: 0.6190\n",
            "Pearson correlation for aspect 2: 0.6828\n",
            "Pearson correlation for aspect 3: 0.2389\n",
            "Pearson correlation for aspect 4: 0.7010\n",
            "Pearson correlation for aspect 5: 0.7052\n",
            "Pearson correlation for aspect 6: 0.3154\n",
            "Pearson correlation for aspect 7: 0.4072\n",
            "Mean Pearson correlation: 0.5242\n",
            "0\n",
            "tensor([[2.6780, 3.4686, 2.0050, 3.5457, 3.5342, 2.0980, 2.1536],\n",
            "        [3.0525, 3.8589, 2.2061, 3.9510, 3.9556, 2.3043, 2.3842],\n",
            "        [1.0183, 1.5020, 1.0110, 1.5393, 1.4678, 1.0797, 1.0508],\n",
            "        [0.7061, 1.0995, 0.7886, 1.1316, 1.0592, 0.8299, 0.8198],\n",
            "        [1.9062, 2.5890, 1.5669, 2.6407, 2.5979, 1.6637, 1.6554]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "1\n",
            "tensor([[2.1933, 2.9241, 1.7372, 2.9856, 2.9540, 1.8321, 1.8464],\n",
            "        [0.8394, 1.2721, 0.8872, 1.3079, 1.2328, 0.9394, 0.9208],\n",
            "        [1.0504, 1.5432, 1.0334, 1.5813, 1.5091, 1.1022, 1.0749],\n",
            "        [1.2152, 1.7499, 1.1450, 1.7906, 1.7232, 1.2209, 1.1919],\n",
            "        [2.8585, 3.6577, 2.1054, 3.7420, 3.7402, 2.1959, 2.2657]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "2\n",
            "tensor([[3.2558, 4.0617, 2.3142, 4.1500, 4.1480, 2.4404, 2.5192],\n",
            "        [3.2433, 4.0479, 2.3112, 4.1447, 4.1463, 2.4255, 2.5090],\n",
            "        [1.4282, 2.0136, 1.2813, 2.0576, 1.9969, 1.3649, 1.3396],\n",
            "        [1.9988, 2.6947, 1.6270, 2.7508, 2.7119, 1.7146, 1.7167],\n",
            "        [0.8524, 1.2882, 0.8979, 1.3238, 1.2494, 0.9468, 0.9310]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "3\n",
            "tensor([[2.2780, 3.0147, 1.7919, 3.0821, 3.0563, 1.8712, 1.8990],\n",
            "        [1.9147, 2.5960, 1.5771, 2.6481, 2.6033, 1.6653, 1.6632],\n",
            "        [2.5518, 3.3227, 1.9448, 3.3977, 3.3820, 2.0245, 2.0724],\n",
            "        [1.4589, 2.0496, 1.3033, 2.0941, 2.0346, 1.3849, 1.3602],\n",
            "        [1.4364, 2.0214, 1.2898, 2.0678, 2.0059, 1.3692, 1.3450]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "4\n",
            "tensor([[3.2502, 4.0531, 2.3213, 4.1478, 4.1478, 2.4224, 2.5147],\n",
            "        [3.1177, 3.9184, 2.2532, 4.0138, 4.0212, 2.3353, 2.4275],\n",
            "        [1.1744, 1.6955, 1.1211, 1.7378, 1.6697, 1.1867, 1.1627],\n",
            "        [1.0462, 1.5334, 1.0360, 1.5745, 1.5043, 1.0956, 1.0718],\n",
            "        [1.3453, 1.9096, 1.2336, 1.9521, 1.8897, 1.3047, 1.2823]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "5\n",
            "tensor([[2.7432, 3.5255, 2.0532, 3.6087, 3.5987, 2.1364, 2.1934],\n",
            "        [3.0459, 3.8488, 2.2188, 3.9440, 3.9475, 2.2961, 2.3857],\n",
            "        [3.2591, 4.0617, 2.3288, 4.1552, 4.1535, 2.4291, 2.5236],\n",
            "        [2.1333, 2.8466, 1.7130, 2.9093, 2.8765, 1.7905, 1.8051],\n",
            "        [3.1960, 3.9991, 2.2970, 4.0957, 4.1021, 2.3817, 2.4779]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "6\n",
            "tensor([[3.2496, 4.0537, 2.3244, 4.1505, 4.1495, 2.4215, 2.5179],\n",
            "        [0.8829, 1.3282, 0.9242, 1.3658, 1.2925, 0.9728, 0.9560],\n",
            "        [2.9775, 3.7759, 2.1820, 3.8696, 3.8713, 2.2600, 2.3426],\n",
            "        [1.9513, 2.6413, 1.6062, 2.6975, 2.6561, 1.6866, 1.6912],\n",
            "        [1.2198, 1.7546, 1.1541, 1.7979, 1.7312, 1.2211, 1.1972]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "7\n",
            "tensor([[3.2645, 4.0716, 2.3339, 4.1665, 4.1665, 2.4410, 2.5299],\n",
            "        [1.1674, 1.6899, 1.1212, 1.7306, 1.6633, 1.1851, 1.1598],\n",
            "        [3.2706, 4.0762, 2.3397, 4.1715, 4.1688, 2.4483, 2.5339],\n",
            "        [1.6457, 2.2778, 1.4234, 2.3255, 2.2725, 1.5032, 1.4882],\n",
            "        [1.8958, 2.5758, 1.5796, 2.6314, 2.5896, 1.6501, 1.6536]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "8\n",
            "tensor([[2.0164, 2.7185, 1.6515, 2.7774, 2.7411, 1.7268, 1.7336],\n",
            "        [2.5812, 3.3633, 1.9750, 3.4431, 3.4277, 2.0419, 2.0996],\n",
            "        [1.0119, 1.4947, 1.0148, 1.5339, 1.4619, 1.0730, 1.0510],\n",
            "        [1.5698, 2.1886, 1.3817, 2.2348, 2.1804, 1.4577, 1.4372],\n",
            "        [2.5099, 3.2824, 1.9361, 3.3594, 3.3426, 2.0026, 2.0518]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "9\n",
            "tensor([[3.2538, 4.0597, 2.3336, 4.1591, 4.1584, 2.4303, 2.5197],\n",
            "        [2.6074, 3.3941, 1.9903, 3.4728, 3.4595, 2.0628, 2.1147],\n",
            "        [1.4201, 2.0069, 1.2899, 2.0531, 1.9918, 1.3644, 1.3376],\n",
            "        [2.5392, 3.3157, 1.9525, 3.3923, 3.3777, 2.0293, 2.0700],\n",
            "        [2.1860, 2.9178, 1.7515, 2.9822, 2.9501, 1.8272, 1.8449]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "10\n",
            "tensor([[3.2292, 4.0436, 2.3255, 4.1385, 4.1412, 2.4203, 2.5050],\n",
            "        [3.2530, 4.0635, 2.3373, 4.1600, 4.1649, 2.4375, 2.5174],\n",
            "        [3.1514, 3.9636, 2.2860, 4.0601, 4.0638, 2.3845, 2.4570],\n",
            "        [3.1321, 3.9429, 2.2744, 4.0392, 4.0469, 2.3522, 2.4407],\n",
            "        [1.2776, 1.8334, 1.1975, 1.8742, 1.8088, 1.2652, 1.2383]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "11\n",
            "tensor([[3.2531, 4.0664, 2.3383, 4.1636, 4.1650, 2.4458, 2.5195],\n",
            "        [2.3110, 3.0650, 1.8276, 3.1322, 3.1058, 1.9001, 1.9243],\n",
            "        [3.1753, 3.9870, 2.2975, 4.0845, 4.0863, 2.3983, 2.4697],\n",
            "        [2.2524, 2.9996, 1.7939, 3.0654, 3.0351, 1.8674, 1.8881],\n",
            "        [1.8644, 2.5478, 1.5656, 2.6009, 2.5584, 1.6385, 1.6343]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "12\n",
            "tensor([[2.4745, 3.2508, 1.9206, 3.3237, 3.3064, 1.9874, 2.0278],\n",
            "        [1.6763, 2.3221, 1.4522, 2.3722, 2.3202, 1.5290, 1.5090],\n",
            "        [2.2133, 2.9572, 1.7722, 3.0218, 2.9898, 1.8418, 1.8628],\n",
            "        [2.9567, 3.7709, 2.1841, 3.8619, 3.8646, 2.2500, 2.3280],\n",
            "        [3.2582, 4.0725, 2.3393, 4.1638, 4.1596, 2.4532, 2.5243]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "13\n",
            "tensor([[2.7877, 3.5924, 2.0941, 3.6748, 3.6713, 2.1547, 2.2200],\n",
            "        [1.7610, 2.4241, 1.5065, 2.4762, 2.4265, 1.5813, 1.5649],\n",
            "        [1.9476, 2.6458, 1.6161, 2.7008, 2.6582, 1.6943, 1.6861],\n",
            "        [1.2256, 1.7702, 1.1648, 1.8118, 1.7438, 1.2307, 1.2006],\n",
            "        [3.2441, 4.0552, 2.3335, 4.1488, 4.1472, 2.4301, 2.5084]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "14\n",
            "tensor([[1.0081, 1.4979, 1.0199, 1.5354, 1.4618, 1.0741, 1.0459],\n",
            "        [0.9357, 1.4031, 0.9630, 1.4387, 1.3669, 1.0182, 0.9916],\n",
            "        [1.7204, 2.3771, 1.4813, 2.4268, 2.3755, 1.5580, 1.5351],\n",
            "        [3.2685, 4.0837, 2.3511, 4.1775, 4.1749, 2.4540, 2.5224],\n",
            "        [1.4926, 2.1013, 1.3382, 2.1447, 2.0867, 1.4076, 1.3809]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "15\n",
            "tensor([[3.1697, 3.9788, 2.2971, 4.0696, 4.0704, 2.3714, 2.4533],\n",
            "        [3.2610, 4.0738, 2.3495, 4.1692, 4.1654, 2.4499, 2.5147],\n",
            "        [2.3715, 3.1335, 1.8672, 3.2037, 3.1759, 1.9384, 1.9559],\n",
            "        [1.6057, 2.2378, 1.4108, 2.2881, 2.2289, 1.4868, 1.4593],\n",
            "        [1.7341, 2.3921, 1.4920, 2.4434, 2.3895, 1.5652, 1.5426]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "16\n",
            "tensor([[2.6476, 3.4371, 2.0235, 3.5155, 3.4977, 2.0814, 2.1261],\n",
            "        [2.5920, 3.3818, 1.9960, 3.4586, 3.4390, 2.0566, 2.0941],\n",
            "        [3.2104, 4.0233, 2.3288, 4.1189, 4.1183, 2.4148, 2.4786],\n",
            "        [2.5264, 3.3053, 1.9577, 3.3791, 3.3568, 2.0232, 2.0504],\n",
            "        [1.5025, 2.1133, 1.3495, 2.1570, 2.0957, 1.4198, 1.3866]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "17\n",
            "tensor([[3.2655, 4.0818, 2.3609, 4.1749, 4.1673, 2.4525, 2.5153],\n",
            "        [1.8556, 2.5417, 1.5715, 2.5942, 2.5433, 1.6406, 1.6220],\n",
            "        [2.5835, 3.3735, 1.9949, 3.4489, 3.4284, 2.0567, 2.0874],\n",
            "        [3.2661, 4.0798, 2.3605, 4.1736, 4.1687, 2.4483, 2.5145],\n",
            "        [2.0364, 2.7488, 1.6754, 2.8042, 2.7613, 1.7531, 1.7372]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "18\n",
            "tensor([[1.5117, 2.1289, 1.3584, 2.1709, 2.1079, 1.4297, 1.3927],\n",
            "        [1.7640, 2.4353, 1.5181, 2.4835, 2.4292, 1.5881, 1.5620],\n",
            "        [1.0212, 1.5159, 1.0335, 1.5507, 1.4750, 1.0857, 1.0512],\n",
            "        [1.7300, 2.3934, 1.4965, 2.4401, 2.3840, 1.5680, 1.5384],\n",
            "        [1.4082, 2.0020, 1.2930, 2.0435, 1.9772, 1.3590, 1.3229]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "19\n",
            "tensor([[1.4063, 2.0012, 1.2938, 2.0405, 1.9730, 1.3633, 1.3215],\n",
            "        [3.1405, 3.9623, 2.3054, 4.0537, 4.0506, 2.3834, 2.4339],\n",
            "        [2.7675, 3.5795, 2.1040, 3.6588, 3.6439, 2.1711, 2.2049],\n",
            "        [0.8254, 1.2658, 0.8955, 1.2991, 1.2213, 0.9394, 0.9113],\n",
            "        [3.0130, 3.8361, 2.2373, 3.9220, 3.9175, 2.3049, 2.3558]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "20\n",
            "tensor([[1.4588, 2.0681, 1.3312, 2.1068, 2.0423, 1.3998, 1.3590],\n",
            "        [3.2698, 4.0984, 2.3790, 4.1871, 4.1747, 2.4805, 2.5237],\n",
            "        [0.7614, 1.1848, 0.8527, 1.2178, 1.1395, 0.8897, 0.8655],\n",
            "        [3.2410, 4.0666, 2.3637, 4.1587, 4.1500, 2.4553, 2.5047],\n",
            "        [1.0353, 1.5389, 1.0509, 1.5753, 1.4982, 1.1075, 1.0665]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "21\n",
            "tensor([[2.7595, 3.5776, 2.1074, 3.6537, 3.6404, 2.1669, 2.2009],\n",
            "        [2.5696, 3.3719, 2.0039, 3.4425, 3.4208, 2.0635, 2.0834],\n",
            "        [3.2637, 4.0917, 2.3800, 4.1787, 4.1663, 2.4803, 2.5221],\n",
            "        [1.8275, 2.5185, 1.5662, 2.5667, 2.5112, 1.6430, 1.6091],\n",
            "        [2.1973, 2.9504, 1.7879, 3.0069, 2.9665, 1.8592, 1.8464]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "22\n",
            "tensor([[1.2409, 1.8053, 1.1941, 1.8405, 1.7667, 1.2628, 1.2130],\n",
            "        [1.6187, 2.2696, 1.4375, 2.3097, 2.2478, 1.5154, 1.4688],\n",
            "        [2.7699, 3.5919, 2.1195, 3.6681, 3.6521, 2.1824, 2.2107],\n",
            "        [3.2398, 4.0735, 2.3745, 4.1596, 4.1503, 2.4682, 2.5075],\n",
            "        [2.6639, 3.4764, 2.0611, 3.5492, 3.5272, 2.1312, 2.1444]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "23\n",
            "tensor([[1.6991, 2.3693, 1.4929, 2.4131, 2.3535, 1.5709, 1.5257],\n",
            "        [2.6437, 3.4610, 2.0552, 3.5307, 3.5109, 2.1109, 2.1318],\n",
            "        [1.7882, 2.4768, 1.5493, 2.5221, 2.4647, 1.6252, 1.5838],\n",
            "        [0.8038, 1.2457, 0.8887, 1.2757, 1.1969, 0.9290, 0.8989],\n",
            "        [2.3941, 3.1808, 1.9086, 3.2417, 3.2080, 1.9830, 1.9769]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "24\n",
            "tensor([[1.1020, 1.6295, 1.1028, 1.6622, 1.5859, 1.1624, 1.1133],\n",
            "        [1.1886, 1.7427, 1.1639, 1.7739, 1.7009, 1.2251, 1.1757],\n",
            "        [3.1621, 4.0006, 2.3416, 4.0852, 4.0772, 2.4244, 2.4594],\n",
            "        [2.9490, 3.7855, 2.2272, 3.8641, 3.8551, 2.2917, 2.3225],\n",
            "        [1.6221, 2.2810, 1.4491, 2.3199, 2.2587, 1.5211, 1.4741]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "25\n",
            "tensor([[3.2633, 4.1019, 2.3979, 4.1850, 4.1725, 2.4947, 2.5249],\n",
            "        [1.0834, 1.6095, 1.0924, 1.6408, 1.5638, 1.1534, 1.1030],\n",
            "        [1.0350, 1.5466, 1.0592, 1.5787, 1.5002, 1.1167, 1.0686],\n",
            "        [3.2434, 4.0841, 2.3916, 4.1680, 4.1595, 2.4855, 2.5111],\n",
            "        [1.2565, 1.8295, 1.2127, 1.8616, 1.7898, 1.2769, 1.2236]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "26\n",
            "tensor([[3.1786, 4.0203, 2.3599, 4.1029, 4.0932, 2.4412, 2.4707],\n",
            "        [1.7950, 2.4886, 1.5586, 2.5262, 2.4724, 1.6298, 1.5846],\n",
            "        [2.1539, 2.9143, 1.7842, 2.9650, 2.9235, 1.8494, 1.8233],\n",
            "        [1.0349, 1.5487, 1.0639, 1.5808, 1.5030, 1.1206, 1.0701],\n",
            "        [1.7610, 2.4503, 1.5401, 2.4897, 2.4323, 1.6157, 1.5670]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "27\n",
            "tensor([[3.2287, 4.0732, 2.3935, 4.1544, 4.1422, 2.4811, 2.5025],\n",
            "        [2.0544, 2.7999, 1.7255, 2.8469, 2.8026, 1.7963, 1.7591],\n",
            "        [3.2608, 4.1034, 2.4093, 4.1826, 4.1713, 2.5056, 2.5222],\n",
            "        [3.1242, 3.9664, 2.3364, 4.0483, 4.0421, 2.4135, 2.4338],\n",
            "        [1.6611, 2.3275, 1.4808, 2.3663, 2.3058, 1.5539, 1.4994]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "28\n",
            "tensor([[1.0850, 1.6140, 1.1007, 1.6418, 1.5669, 1.1557, 1.1027],\n",
            "        [0.9525, 1.4433, 1.0079, 1.4724, 1.3950, 1.0563, 1.0092],\n",
            "        [1.5560, 2.2019, 1.4163, 2.2362, 2.1745, 1.4893, 1.4282],\n",
            "        [1.8504, 2.5568, 1.6023, 2.5968, 2.5448, 1.6735, 1.6254],\n",
            "        [3.2487, 4.0883, 2.4049, 4.1661, 4.1574, 2.4963, 2.5144]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "29\n",
            "tensor([[3.2503, 4.0917, 2.4090, 4.1654, 4.1617, 2.4969, 2.5123],\n",
            "        [0.9991, 1.5042, 1.0419, 1.5320, 1.4559, 1.0948, 1.0425],\n",
            "        [1.2544, 1.8275, 1.2197, 1.8567, 1.7877, 1.2840, 1.2228],\n",
            "        [1.4938, 2.1263, 1.3801, 2.1602, 2.0957, 1.4500, 1.3881],\n",
            "        [1.5828, 2.2361, 1.4362, 2.2682, 2.2083, 1.5045, 1.4463]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "30\n",
            "tensor([[3.2488, 4.0927, 2.4118, 4.1620, 4.1569, 2.5006, 2.5136],\n",
            "        [2.4305, 3.2195, 1.9491, 3.2698, 3.2443, 2.0258, 1.9949],\n",
            "        [1.4248, 2.0416, 1.3337, 2.0717, 2.0071, 1.4007, 1.3408],\n",
            "        [1.0142, 1.5252, 1.0550, 1.5506, 1.4767, 1.1073, 1.0539],\n",
            "        [3.0110, 3.8521, 2.2824, 3.9198, 3.9185, 2.3329, 2.3581]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "31\n",
            "tensor([[3.0362, 3.8765, 2.2963, 3.9441, 3.9476, 2.3579, 2.3745],\n",
            "        [1.5776, 2.2276, 1.4332, 2.2556, 2.1999, 1.5037, 1.4423],\n",
            "        [3.2137, 4.0552, 2.3943, 4.1273, 4.1267, 2.4836, 2.4910],\n",
            "        [3.2183, 4.0589, 2.3972, 4.1305, 4.1313, 2.4792, 2.4928],\n",
            "        [2.3689, 3.1581, 1.9201, 3.2072, 3.1793, 1.9853, 1.9595]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "32\n",
            "tensor([[3.2642, 4.1013, 2.4198, 4.1693, 4.1647, 2.5138, 2.5260],\n",
            "        [0.9285, 1.4106, 0.9944, 1.4372, 1.3627, 1.0431, 0.9919],\n",
            "        [2.9924, 3.8311, 2.2740, 3.8946, 3.8979, 2.3292, 2.3476],\n",
            "        [0.9831, 1.4810, 1.0326, 1.5067, 1.4330, 1.0842, 1.0309],\n",
            "        [0.9046, 1.3796, 0.9744, 1.4048, 1.3298, 1.0222, 0.9730]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "33\n",
            "tensor([[3.2133, 4.0501, 2.3975, 4.1187, 4.1196, 2.4766, 2.4906],\n",
            "        [2.8061, 3.6361, 2.1756, 3.6954, 3.6897, 2.2306, 2.2341],\n",
            "        [2.7108, 3.5314, 2.1208, 3.5879, 3.5796, 2.1785, 2.1735],\n",
            "        [1.5365, 2.1751, 1.4079, 2.2024, 2.1449, 1.4831, 1.4159],\n",
            "        [3.2663, 4.1033, 2.4263, 4.1714, 4.1708, 2.5190, 2.5250]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "34\n",
            "tensor([[1.0571, 1.5759, 1.0878, 1.6012, 1.5287, 1.1449, 1.0855],\n",
            "        [0.7474, 1.1744, 0.8609, 1.1986, 1.1244, 0.8968, 0.8579],\n",
            "        [1.9764, 2.7033, 1.6912, 2.7372, 2.6963, 1.7541, 1.7062],\n",
            "        [3.1690, 4.0056, 2.3779, 4.0703, 4.0699, 2.4534, 2.4596],\n",
            "        [3.2670, 4.1008, 2.4288, 4.1663, 4.1631, 2.5209, 2.5247]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "35\n",
            "tensor([[2.7298, 3.5462, 2.1374, 3.6010, 3.5934, 2.1934, 2.1839],\n",
            "        [3.2726, 4.1028, 2.4372, 4.1696, 4.1684, 2.5210, 2.5270],\n",
            "        [2.8721, 3.6972, 2.2167, 3.7548, 3.7530, 2.2707, 2.2717],\n",
            "        [1.2770, 1.8519, 1.2421, 1.8781, 1.8121, 1.3051, 1.2381],\n",
            "        [1.0514, 1.5693, 1.0851, 1.5930, 1.5209, 1.1406, 1.0810]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "36\n",
            "tensor([[3.2677, 4.0995, 2.4368, 4.1634, 4.1629, 2.5215, 2.5241],\n",
            "        [2.4982, 3.2940, 2.0088, 3.3404, 3.3232, 2.0626, 2.0376],\n",
            "        [0.9645, 1.4551, 1.0263, 1.4800, 1.4062, 1.0749, 1.0177],\n",
            "        [1.1797, 1.7305, 1.1788, 1.7535, 1.6862, 1.2317, 1.1697],\n",
            "        [2.7131, 3.5327, 2.1311, 3.5835, 3.5773, 2.1721, 2.1727]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "37\n",
            "tensor([[2.7925, 3.6157, 2.1770, 3.6685, 3.6652, 2.2156, 2.2217],\n",
            "        [1.6736, 2.3390, 1.5048, 2.3640, 2.3121, 1.5709, 1.5058],\n",
            "        [1.2978, 1.8784, 1.2594, 1.9008, 1.8365, 1.3171, 1.2517],\n",
            "        [1.7460, 2.4268, 1.5510, 2.4534, 2.4049, 1.6162, 1.5544],\n",
            "        [1.6651, 2.3276, 1.4988, 2.3534, 2.3018, 1.5639, 1.5006]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "38\n",
            "tensor([[0.9165, 1.3925, 0.9906, 1.4162, 1.3424, 1.0343, 0.9832],\n",
            "        [2.8828, 3.7101, 2.2278, 3.7651, 3.7622, 2.2764, 2.2798],\n",
            "        [2.7621, 3.5820, 2.1592, 3.6319, 3.6298, 2.1992, 2.2013],\n",
            "        [1.8377, 2.5348, 1.6101, 2.5634, 2.5182, 1.6723, 1.6148],\n",
            "        [1.5745, 2.2190, 1.4420, 2.2418, 2.1891, 1.5016, 1.4391]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "39\n",
            "tensor([[2.0189, 2.7477, 1.7217, 2.7779, 2.7413, 1.7725, 1.7326],\n",
            "        [1.0692, 1.5892, 1.1016, 1.6103, 1.5406, 1.1511, 1.0927],\n",
            "        [3.1211, 3.9499, 2.3566, 4.0091, 4.0119, 2.4179, 2.4275],\n",
            "        [2.3621, 3.1403, 1.9274, 3.1795, 3.1564, 1.9734, 1.9513],\n",
            "        [2.3287, 3.1010, 1.9080, 3.1406, 3.1139, 1.9591, 1.9320]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "40\n",
            "tensor([[0.8225, 1.2720, 0.9222, 1.2932, 1.2197, 0.9561, 0.9139],\n",
            "        [3.0097, 3.8374, 2.2977, 3.8939, 3.8996, 2.3363, 2.3547],\n",
            "        [3.1589, 3.9860, 2.3781, 4.0460, 4.0539, 2.4172, 2.4439],\n",
            "        [3.1713, 3.9989, 2.3855, 4.0581, 4.0631, 2.4275, 2.4566],\n",
            "        [1.2016, 1.7573, 1.1933, 1.7791, 1.7117, 1.2482, 1.1863]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "41\n",
            "tensor([[3.0411, 3.8741, 2.3131, 3.9261, 3.9360, 2.3497, 2.3752],\n",
            "        [2.4439, 3.2358, 1.9776, 3.2741, 3.2560, 2.0183, 2.0041],\n",
            "        [1.1348, 1.6756, 1.1447, 1.6928, 1.6261, 1.1956, 1.1396],\n",
            "        [1.1803, 1.7323, 1.1774, 1.7510, 1.6844, 1.2281, 1.1707],\n",
            "        [1.6093, 2.2628, 1.4645, 2.2850, 2.2315, 1.5214, 1.4644]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "42\n",
            "tensor([[2.5901, 3.4002, 2.0609, 3.4392, 3.4286, 2.0913, 2.0967],\n",
            "        [2.1239, 2.8672, 1.7834, 2.8987, 2.8653, 1.8360, 1.8008],\n",
            "        [1.1173, 1.6545, 1.1330, 1.6710, 1.6045, 1.1786, 1.1267],\n",
            "        [0.9875, 1.4866, 1.0426, 1.5066, 1.4344, 1.0844, 1.0357],\n",
            "        [3.2778, 4.1038, 2.4381, 4.1580, 4.1593, 2.5017, 2.5291]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "43\n",
            "tensor([[1.8152, 2.5103, 1.5922, 2.5296, 2.4889, 1.6398, 1.5987],\n",
            "        [3.2815, 4.1089, 2.4389, 4.1610, 4.1650, 2.5027, 2.5315],\n",
            "        [2.3342, 3.1122, 1.9090, 3.1442, 3.1218, 1.9491, 1.9354],\n",
            "        [2.1129, 2.8562, 1.7736, 2.8838, 2.8520, 1.8234, 1.7931],\n",
            "        [1.1934, 1.7503, 1.1865, 1.7671, 1.7013, 1.2318, 1.1813]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "44\n",
            "tensor([[2.8574, 3.6840, 2.2093, 3.7295, 3.7295, 2.2329, 2.2625],\n",
            "        [0.9743, 1.4711, 1.0309, 1.4882, 1.4196, 1.0701, 1.0261],\n",
            "        [2.0073, 2.7386, 1.7139, 2.7647, 2.7312, 1.7599, 1.7283],\n",
            "        [2.2658, 3.0351, 1.8675, 3.0651, 3.0414, 1.9069, 1.8926],\n",
            "        [1.1323, 1.6710, 1.1438, 1.6889, 1.6220, 1.1903, 1.1385]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "45\n",
            "tensor([[2.7457, 3.5627, 2.1434, 3.6052, 3.6040, 2.1686, 2.1947],\n",
            "        [1.4211, 2.0314, 1.3373, 2.0485, 1.9923, 1.3875, 1.3374],\n",
            "        [2.7332, 3.5485, 2.1376, 3.5901, 3.5904, 2.1620, 2.1852],\n",
            "        [3.2275, 4.0528, 2.4096, 4.1071, 4.1224, 2.4508, 2.4911],\n",
            "        [2.6394, 3.4517, 2.0843, 3.4916, 3.4855, 2.1112, 2.1303]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "46\n",
            "tensor([[1.8150, 2.5076, 1.5902, 2.5283, 2.4890, 1.6341, 1.6018],\n",
            "        [3.1406, 3.9713, 2.3616, 4.0208, 4.0343, 2.3912, 2.4382],\n",
            "        [0.9661, 1.4588, 1.0252, 1.4765, 1.4084, 1.0629, 1.0208],\n",
            "        [0.8688, 1.3328, 0.9538, 1.3519, 1.2818, 0.9858, 0.9502],\n",
            "        [3.0109, 3.8368, 2.2907, 3.8862, 3.8966, 2.3204, 2.3589]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "47\n",
            "tensor([[2.7557, 3.5687, 2.1467, 3.6093, 3.6131, 2.1650, 2.1971],\n",
            "        [2.4922, 3.2853, 1.9981, 3.3197, 3.3116, 2.0187, 2.0342],\n",
            "        [1.3692, 1.9663, 1.3023, 1.9818, 1.9261, 1.3448, 1.3012],\n",
            "        [2.0182, 2.7448, 1.7137, 2.7682, 2.7366, 1.7514, 1.7328],\n",
            "        [1.4399, 2.0524, 1.3453, 2.0690, 2.0134, 1.3927, 1.3505]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "48\n",
            "tensor([[1.7562, 2.4334, 1.5497, 2.4524, 2.4123, 1.5937, 1.5592],\n",
            "        [2.8212, 3.6399, 2.1802, 3.6814, 3.6884, 2.1937, 2.2362],\n",
            "        [2.0027, 2.7276, 1.7042, 2.7496, 2.7203, 1.7438, 1.7210],\n",
            "        [2.5849, 3.3827, 2.0467, 3.4181, 3.4132, 2.0699, 2.0902],\n",
            "        [0.7403, 1.1640, 0.8568, 1.1835, 1.1118, 0.8809, 0.8545]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "49\n",
            "tensor([[2.9902, 3.8140, 2.2714, 3.8590, 3.8718, 2.2911, 2.3391],\n",
            "        [0.9076, 1.3800, 0.9775, 1.3973, 1.3287, 1.0096, 0.9761],\n",
            "        [3.1472, 3.9659, 2.3575, 4.0165, 4.0317, 2.3827, 2.4368],\n",
            "        [2.8515, 3.6660, 2.1935, 3.7072, 3.7145, 2.2109, 2.2526],\n",
            "        [0.9947, 1.4915, 1.0381, 1.5086, 1.4429, 1.0745, 1.0385]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "50\n",
            "tensor([[1.5464, 2.1795, 1.4092, 2.1949, 2.1459, 1.4548, 1.4173],\n",
            "        [1.5184, 2.1471, 1.3906, 2.1606, 2.1130, 1.4351, 1.4000],\n",
            "        [2.3986, 3.1786, 1.9333, 3.2079, 3.1941, 1.9552, 1.9727],\n",
            "        [1.6219, 2.2727, 1.4605, 2.2900, 2.2445, 1.5037, 1.4712],\n",
            "        [0.8208, 1.2670, 0.9111, 1.2851, 1.2144, 0.9397, 0.9122]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "51\n",
            "tensor([[3.1313, 3.9478, 2.3392, 4.0014, 4.0155, 2.3660, 2.4275],\n",
            "        [1.1512, 1.6905, 1.1454, 1.7058, 1.6434, 1.1878, 1.1487],\n",
            "        [2.8975, 3.7127, 2.2114, 3.7551, 3.7632, 2.2280, 2.2800],\n",
            "        [1.7568, 2.4302, 1.5405, 2.4497, 2.4084, 1.5895, 1.5591],\n",
            "        [3.2458, 4.0615, 2.4015, 4.1167, 4.1317, 2.4330, 2.4979]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "52\n",
            "tensor([[1.5477, 2.1785, 1.4067, 2.1952, 2.1468, 1.4540, 1.4194],\n",
            "        [2.8647, 3.6803, 2.1895, 3.7248, 3.7347, 2.2024, 2.2597],\n",
            "        [2.3220, 3.0885, 1.8803, 3.1174, 3.1017, 1.9072, 1.9229],\n",
            "        [1.4727, 2.0871, 1.3507, 2.1023, 2.0513, 1.4108, 1.3695],\n",
            "        [1.5838, 2.2239, 1.4298, 2.2418, 2.1950, 1.4785, 1.4446]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "53\n",
            "tensor([[2.4599, 3.2396, 1.9574, 3.2744, 3.2656, 1.9872, 2.0081],\n",
            "        [1.1449, 1.6806, 1.1383, 1.6971, 1.6354, 1.1823, 1.1450],\n",
            "        [2.4395, 3.2158, 1.9447, 3.2492, 3.2371, 1.9700, 1.9951],\n",
            "        [2.9248, 3.7409, 2.2176, 3.7859, 3.7998, 2.2315, 2.2962],\n",
            "        [2.7729, 3.5797, 2.1352, 3.6234, 3.6274, 2.1564, 2.2048]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "54\n",
            "tensor([[3.2562, 4.0691, 2.3940, 4.1251, 4.1416, 2.4367, 2.5034],\n",
            "        [1.7757, 2.4542, 1.5489, 2.4748, 2.4360, 1.5913, 1.5712],\n",
            "        [0.8617, 1.3173, 0.9357, 1.3378, 1.2681, 0.9707, 0.9430],\n",
            "        [1.0110, 1.5100, 1.0405, 1.5275, 1.4613, 1.0838, 1.0502],\n",
            "        [2.9024, 3.7217, 2.2042, 3.7680, 3.7818, 2.2152, 2.2827]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "55\n",
            "tensor([[3.2948, 4.1040, 2.4118, 4.1619, 4.1726, 2.4664, 2.5306],\n",
            "        [3.2925, 4.1008, 2.4119, 4.1600, 4.1734, 2.4626, 2.5287],\n",
            "        [2.4156, 3.1863, 1.9253, 3.2224, 3.2098, 1.9576, 1.9803],\n",
            "        [1.4460, 2.0536, 1.3372, 2.0731, 2.0216, 1.3859, 1.3517],\n",
            "        [3.2938, 4.1047, 2.4128, 4.1642, 4.1791, 2.4635, 2.5290]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "56\n",
            "tensor([[1.9881, 2.6998, 1.6734, 2.7295, 2.6974, 1.7211, 1.7113],\n",
            "        [3.2682, 4.0796, 2.3997, 4.1406, 4.1553, 2.4496, 2.5134],\n",
            "        [1.5798, 2.2160, 1.4201, 2.2371, 2.1897, 1.4716, 1.4421],\n",
            "        [3.2597, 4.0709, 2.3936, 4.1324, 4.1479, 2.4414, 2.5067],\n",
            "        [2.3968, 3.1667, 1.9158, 3.2033, 3.1913, 1.9493, 1.9679]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "57\n",
            "tensor([[3.2418, 4.0531, 2.3829, 4.1156, 4.1328, 2.4370, 2.4968],\n",
            "        [3.0104, 3.8221, 2.2582, 3.8804, 3.8940, 2.2906, 2.3515],\n",
            "        [0.7761, 1.2068, 0.8727, 1.2266, 1.1574, 0.9000, 0.8784],\n",
            "        [0.7747, 1.2022, 0.8702, 1.2230, 1.1532, 0.8986, 0.8763],\n",
            "        [1.4885, 2.1073, 1.3628, 2.1275, 2.0780, 1.4136, 1.3810]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "58\n",
            "tensor([[1.7671, 2.4426, 1.5376, 2.4681, 2.4292, 1.5931, 1.5678],\n",
            "        [2.8408, 3.6535, 2.1665, 3.7040, 3.7146, 2.1923, 2.2475],\n",
            "        [2.0810, 2.8100, 1.7292, 2.8393, 2.8172, 1.7735, 1.7688],\n",
            "        [3.2913, 4.1013, 2.4089, 4.1627, 4.1793, 2.4668, 2.5289],\n",
            "        [2.9280, 3.7434, 2.2134, 3.7970, 3.8103, 2.2458, 2.3013]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "59\n",
            "tensor([[0.8701, 1.3287, 0.9407, 1.3485, 1.2815, 0.9794, 0.9485],\n",
            "        [1.0657, 1.5792, 1.0807, 1.6002, 1.5358, 1.1287, 1.0895],\n",
            "        [3.2272, 4.0395, 2.3748, 4.1036, 4.1212, 2.4273, 2.4866],\n",
            "        [1.9011, 2.6017, 1.6204, 2.6298, 2.5966, 1.6784, 1.6553],\n",
            "        [1.8733, 2.5698, 1.6041, 2.5961, 2.5641, 1.6580, 1.6365]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "60\n",
            "tensor([[3.1645, 3.9795, 2.3438, 4.0412, 4.0622, 2.3924, 2.4463],\n",
            "        [0.7788, 1.2124, 0.8726, 1.2330, 1.1646, 0.9079, 0.8821],\n",
            "        [2.5427, 3.3343, 1.9999, 3.3780, 3.3747, 2.0480, 2.0638],\n",
            "        [2.7555, 3.5666, 2.1213, 3.6144, 3.6219, 2.1564, 2.1943],\n",
            "        [3.3056, 4.1187, 2.4177, 4.1790, 4.1920, 2.4972, 2.5424]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "61\n",
            "tensor([[2.7109, 3.5178, 2.0971, 3.5665, 3.5697, 2.1449, 2.1693],\n",
            "        [2.5620, 3.3581, 2.0169, 3.4007, 3.3989, 2.0559, 2.0734],\n",
            "        [1.3464, 1.9358, 1.2723, 1.9579, 1.9039, 1.3341, 1.2867],\n",
            "        [1.5561, 2.1912, 1.4080, 2.2143, 2.1680, 1.4723, 1.4280],\n",
            "        [1.2371, 1.7970, 1.1988, 1.8189, 1.7615, 1.2558, 1.2094]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "62\n",
            "tensor([[3.3004, 4.1189, 2.4216, 4.1822, 4.1979, 2.4961, 2.5360],\n",
            "        [0.8753, 1.3371, 0.9447, 1.3585, 1.2921, 0.9889, 0.9530],\n",
            "        [2.2424, 3.0025, 1.8326, 3.0402, 3.0231, 1.8835, 1.8748],\n",
            "        [1.5861, 2.2304, 1.4282, 2.2523, 2.2094, 1.4877, 1.4457],\n",
            "        [2.7514, 3.5596, 2.1223, 3.6105, 3.6166, 2.1719, 2.1918]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "63\n",
            "tensor([[3.2327, 4.0542, 2.3881, 4.1171, 4.1370, 2.4553, 2.4909],\n",
            "        [2.5736, 3.3700, 2.0214, 3.4136, 3.4141, 2.0607, 2.0798],\n",
            "        [0.8658, 1.3270, 0.9422, 1.3482, 1.2821, 0.9810, 0.9453],\n",
            "        [2.8682, 3.6885, 2.1883, 3.7397, 3.7540, 2.2241, 2.2624],\n",
            "        [0.9696, 1.4590, 1.0140, 1.4791, 1.4159, 1.0586, 1.0196]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "64\n",
            "tensor([[3.1363, 3.9609, 2.3364, 4.0219, 4.0436, 2.3877, 2.4290],\n",
            "        [2.5366, 3.3334, 2.0018, 3.3734, 3.3735, 2.0447, 2.0571],\n",
            "        [2.0339, 2.7620, 1.7079, 2.7911, 2.7694, 1.7628, 1.7372],\n",
            "        [0.8821, 1.3471, 0.9527, 1.3691, 1.3022, 0.9957, 0.9573],\n",
            "        [3.2649, 4.0885, 2.4054, 4.1483, 4.1687, 2.4715, 2.5097]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "65\n",
            "tensor([[2.7145, 3.5290, 2.1042, 3.5740, 3.5805, 2.1463, 2.1687],\n",
            "        [2.2156, 2.9725, 1.8157, 3.0060, 2.9899, 1.8709, 1.8555],\n",
            "        [1.3879, 1.9907, 1.3020, 2.0084, 1.9585, 1.3567, 1.3118],\n",
            "        [2.7665, 3.5831, 2.1331, 3.6297, 3.6418, 2.1705, 2.1970],\n",
            "        [1.0545, 1.5711, 1.0766, 1.5909, 1.5289, 1.1260, 1.0809]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "66\n",
            "tensor([[1.4012, 2.0088, 1.3102, 2.0269, 1.9778, 1.3682, 1.3216],\n",
            "        [1.8370, 2.5335, 1.5862, 2.5572, 2.5248, 1.6427, 1.6099],\n",
            "        [2.2086, 2.9645, 1.8089, 2.9957, 2.9781, 1.8628, 1.8497],\n",
            "        [2.8593, 3.6818, 2.1824, 3.7311, 3.7456, 2.2207, 2.2553],\n",
            "        [0.7365, 1.1591, 0.8454, 1.1794, 1.1124, 0.8762, 0.8492]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "67\n",
            "tensor([[3.0078, 3.8348, 2.2632, 3.8856, 3.9075, 2.3043, 2.3432],\n",
            "        [2.9202, 3.7486, 2.2131, 3.7970, 3.8134, 2.2545, 2.2933],\n",
            "        [0.8356, 1.2895, 0.9193, 1.3091, 1.2423, 0.9564, 0.9220],\n",
            "        [1.0611, 1.5793, 1.0787, 1.5975, 1.5356, 1.1294, 1.0837],\n",
            "        [1.2427, 1.8116, 1.2028, 1.8282, 1.7747, 1.2566, 1.2104]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "68\n",
            "tensor([[1.5662, 2.2124, 1.4130, 2.2272, 2.1852, 1.4736, 1.4301],\n",
            "        [3.2537, 4.0837, 2.3946, 4.1341, 4.1531, 2.4542, 2.5000],\n",
            "        [3.0541, 3.8844, 2.2875, 3.9323, 3.9572, 2.3321, 2.3700],\n",
            "        [2.9053, 3.7349, 2.2057, 3.7780, 3.7984, 2.2406, 2.2781],\n",
            "        [2.7277, 3.5477, 2.1074, 3.5859, 3.5991, 2.1370, 2.1689]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "69\n",
            "tensor([[2.9931, 3.8275, 2.2516, 3.8697, 3.8903, 2.2951, 2.3340],\n",
            "        [3.2554, 4.0858, 2.3948, 4.1339, 4.1589, 2.4491, 2.4956],\n",
            "        [2.5003, 3.3010, 1.9749, 3.3305, 3.3307, 2.0102, 2.0281],\n",
            "        [1.2824, 1.8643, 1.2300, 1.8779, 1.8253, 1.2835, 1.2379],\n",
            "        [0.8810, 1.3496, 0.9497, 1.3666, 1.3012, 0.9902, 0.9537]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "70\n",
            "tensor([[1.3727, 1.9798, 1.2892, 1.9904, 1.9427, 1.3424, 1.2979],\n",
            "        [1.9224, 2.6417, 1.6335, 2.6559, 2.6316, 1.6867, 1.6588],\n",
            "        [2.1125, 2.8643, 1.7485, 2.8845, 2.8665, 1.8011, 1.7838],\n",
            "        [2.2502, 3.0233, 1.8309, 3.0450, 3.0365, 1.8796, 1.8701],\n",
            "        [1.3100, 1.9009, 1.2462, 1.9125, 1.8612, 1.3012, 1.2559]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "71\n",
            "tensor([[2.9697, 3.8098, 2.2359, 3.8416, 3.8688, 2.2699, 2.3109],\n",
            "        [1.3070, 1.8988, 1.2456, 1.9087, 1.8591, 1.2978, 1.2517],\n",
            "        [2.8318, 3.6692, 2.1620, 3.6999, 3.7188, 2.1991, 2.2287],\n",
            "        [1.3040, 1.8960, 1.2432, 1.9055, 1.8559, 1.2968, 1.2507],\n",
            "        [2.4986, 3.3095, 1.9740, 3.3318, 3.3358, 2.0119, 2.0240]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "72\n",
            "tensor([[0.8992, 1.3820, 0.9633, 1.3925, 1.3310, 1.0021, 0.9655],\n",
            "        [2.3594, 3.1536, 1.8921, 3.1701, 3.1695, 1.9355, 1.9334],\n",
            "        [3.2205, 4.0643, 2.3690, 4.1004, 4.1221, 2.4402, 2.4706],\n",
            "        [3.1448, 3.9892, 2.3289, 4.0226, 4.0455, 2.3843, 2.4230],\n",
            "        [3.2316, 4.0756, 2.3780, 4.1132, 4.1437, 2.4327, 2.4732]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "73\n",
            "tensor([[0.7143, 1.1409, 0.8256, 1.1509, 1.0871, 0.8527, 0.8291],\n",
            "        [0.8504, 1.3197, 0.9265, 1.3282, 1.2680, 0.9612, 0.9281],\n",
            "        [1.1462, 1.7009, 1.1334, 1.7089, 1.6558, 1.1819, 1.1396],\n",
            "        [1.7977, 2.5054, 1.5494, 2.5080, 2.4789, 1.6101, 1.5736],\n",
            "        [1.8174, 2.5286, 1.5658, 2.5348, 2.5070, 1.6212, 1.5899]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "74\n",
            "tensor([[3.2651, 4.1123, 2.3856, 4.1426, 4.1634, 2.4486, 2.4951],\n",
            "        [0.8797, 1.3598, 0.9480, 1.3680, 1.3064, 0.9845, 0.9513],\n",
            "        [2.9948, 3.8464, 2.2409, 3.8720, 3.8988, 2.2716, 2.3229],\n",
            "        [2.3587, 3.1620, 1.8882, 3.1742, 3.1735, 1.9311, 1.9323],\n",
            "        [2.4294, 3.2429, 1.9267, 3.2547, 3.2575, 1.9611, 1.9759]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "75\n",
            "tensor([[2.2609, 3.0507, 1.8264, 3.0562, 3.0515, 1.8663, 1.8652],\n",
            "        [1.9007, 2.6312, 1.6140, 2.6345, 2.6122, 1.6641, 1.6397],\n",
            "        [1.1466, 1.7062, 1.1367, 1.7110, 1.6564, 1.1839, 1.1390],\n",
            "        [1.7248, 2.4211, 1.5062, 2.4226, 2.3940, 1.5581, 1.5247],\n",
            "        [1.2462, 1.8293, 1.2003, 1.8343, 1.7836, 1.2498, 1.2069]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "76\n",
            "tensor([[0.8137, 1.2730, 0.8983, 1.2802, 1.2172, 0.9265, 0.9006],\n",
            "        [1.5545, 2.2161, 1.3976, 2.2158, 2.1807, 1.4494, 1.4129],\n",
            "        [1.7945, 2.5082, 1.5484, 2.5073, 2.4831, 1.5934, 1.5683],\n",
            "        [2.1532, 2.9294, 1.7654, 2.9334, 2.9262, 1.8030, 1.7980],\n",
            "        [3.1140, 3.9726, 2.3031, 3.9960, 4.0266, 2.3333, 2.3952]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "77\n",
            "tensor([[2.4449, 3.2634, 1.9340, 3.2705, 3.2780, 1.9546, 1.9794],\n",
            "        [2.9057, 3.7639, 2.1889, 3.7809, 3.8084, 2.2094, 2.2657],\n",
            "        [3.1109, 3.9657, 2.2974, 3.9854, 4.0186, 2.3214, 2.3872],\n",
            "        [0.7457, 1.1845, 0.8481, 1.1918, 1.1297, 0.8693, 0.8497],\n",
            "        [1.0831, 1.6225, 1.0876, 1.6258, 1.5709, 1.1277, 1.0920]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "78\n",
            "tensor([[1.3453, 1.9595, 1.2651, 1.9586, 1.9141, 1.3042, 1.2726],\n",
            "        [1.0447, 1.5750, 1.0613, 1.5797, 1.5231, 1.1001, 1.0667],\n",
            "        [0.8262, 1.2900, 0.9093, 1.2982, 1.2356, 0.9345, 0.9104],\n",
            "        [2.7018, 3.5458, 2.0758, 3.5583, 3.5784, 2.0937, 2.1360],\n",
            "        [2.4889, 3.3136, 1.9589, 3.3212, 3.3320, 1.9788, 2.0052]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "79\n",
            "tensor([[1.9525, 2.7032, 1.6459, 2.7020, 2.6861, 1.6805, 1.6712],\n",
            "        [3.1187, 3.9806, 2.3031, 4.0019, 4.0297, 2.3386, 2.3954],\n",
            "        [1.0328, 1.5608, 1.0547, 1.5656, 1.5092, 1.0901, 1.0570],\n",
            "        [3.1432, 4.0049, 2.3168, 4.0280, 4.0615, 2.3377, 2.4087],\n",
            "        [3.1641, 4.0240, 2.3275, 4.0472, 4.0812, 2.3535, 2.4210]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "80\n",
            "tensor([[0.7918, 1.2476, 0.8812, 1.2545, 1.1932, 0.9035, 0.8830],\n",
            "        [1.5852, 2.2559, 1.4135, 2.2550, 2.2195, 1.4602, 1.4310],\n",
            "        [2.6742, 3.5227, 2.0579, 3.5317, 3.5509, 2.0694, 2.1196],\n",
            "        [3.2262, 4.0885, 2.3583, 4.1119, 4.1442, 2.3925, 2.4590],\n",
            "        [2.1236, 2.9042, 1.7435, 2.9046, 2.8955, 1.7728, 1.7788]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "81\n",
            "tensor([[1.5001, 2.1553, 1.3603, 2.1543, 2.1136, 1.4039, 1.3753],\n",
            "        [1.4697, 2.1166, 1.3424, 2.1157, 2.0748, 1.3846, 1.3530],\n",
            "        [2.4467, 3.2700, 1.9266, 3.2756, 3.2813, 1.9570, 1.9784],\n",
            "        [2.5668, 3.4057, 1.9953, 3.4143, 3.4273, 2.0090, 2.0513],\n",
            "        [0.9302, 1.4296, 0.9803, 1.4349, 1.3759, 1.0119, 0.9843]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "82\n",
            "tensor([[1.9397, 2.6882, 1.6275, 2.6859, 2.6683, 1.6638, 1.6577],\n",
            "        [1.9794, 2.7372, 1.6509, 2.7368, 2.7184, 1.6898, 1.6867],\n",
            "        [2.9928, 3.8586, 2.2256, 3.8762, 3.9031, 2.2557, 2.3128],\n",
            "        [2.3089, 3.1192, 1.8457, 3.1237, 3.1198, 1.8751, 1.8944],\n",
            "        [0.9216, 1.4187, 0.9754, 1.4258, 1.3639, 1.0099, 0.9783]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "83\n",
            "tensor([[3.2663, 4.1317, 2.3655, 4.1526, 4.1791, 2.4105, 2.4819],\n",
            "        [1.3650, 1.9904, 1.2701, 1.9879, 1.9432, 1.3124, 1.2845],\n",
            "        [2.2764, 3.0816, 1.8211, 3.0833, 3.0795, 1.8508, 1.8717],\n",
            "        [1.9435, 2.6938, 1.6278, 2.6942, 2.6733, 1.6681, 1.6627],\n",
            "        [2.8450, 3.7074, 2.1400, 3.7230, 3.7436, 2.1635, 2.2222]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "84\n",
            "tensor([[2.3185, 3.1332, 1.8436, 3.1381, 3.1336, 1.8737, 1.9007],\n",
            "        [1.1655, 1.7373, 1.1359, 1.7389, 1.6859, 1.1847, 1.1500],\n",
            "        [2.6280, 3.4818, 2.0178, 3.4901, 3.5016, 2.0377, 2.0915],\n",
            "        [2.1076, 2.8848, 1.7194, 2.8851, 2.8707, 1.7605, 1.7647],\n",
            "        [1.9870, 2.7485, 1.6511, 2.7491, 2.7297, 1.6917, 1.6908]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "85\n",
            "tensor([[1.4540, 2.1066, 1.3258, 2.1059, 2.0598, 1.3727, 1.3478],\n",
            "        [1.4720, 2.1279, 1.3344, 2.1263, 2.0842, 1.3783, 1.3579],\n",
            "        [3.1040, 3.9791, 2.2723, 3.9998, 4.0281, 2.3067, 2.3846],\n",
            "        [0.8541, 1.3332, 0.9205, 1.3411, 1.2759, 0.9515, 0.9315],\n",
            "        [3.1335, 4.0051, 2.2887, 4.0253, 4.0433, 2.3400, 2.4048]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "86\n",
            "tensor([[1.5110, 2.1777, 1.3569, 2.1756, 2.1315, 1.4053, 1.3843],\n",
            "        [3.2819, 4.1585, 2.3670, 4.1789, 4.1980, 2.4271, 2.5005],\n",
            "        [1.0348, 1.5717, 1.0465, 1.5763, 1.5131, 1.0875, 1.0602],\n",
            "        [2.4642, 3.3054, 1.9210, 3.3110, 3.3099, 1.9531, 1.9953],\n",
            "        [0.9812, 1.5037, 1.0104, 1.5082, 1.4445, 1.0493, 1.0241]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "87\n",
            "tensor([[0.9375, 1.4483, 0.9788, 1.4541, 1.3898, 1.0183, 0.9936],\n",
            "        [2.9543, 3.8360, 2.1902, 3.8546, 3.8731, 2.2229, 2.2985],\n",
            "        [3.0103, 3.8911, 2.2190, 3.9098, 3.9273, 2.2611, 2.3362],\n",
            "        [3.0694, 3.9533, 2.2535, 3.9740, 3.9932, 2.2871, 2.3699],\n",
            "        [2.1950, 2.9999, 1.7670, 3.0024, 2.9875, 1.8062, 1.8277]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "88\n",
            "tensor([[3.2082, 4.0904, 2.3250, 4.1157, 4.1347, 2.3753, 2.4599],\n",
            "        [1.0920, 1.6509, 1.0865, 1.6573, 1.5952, 1.1324, 1.1060],\n",
            "        [2.8313, 3.7105, 2.1220, 3.7274, 3.7412, 2.1534, 2.2270],\n",
            "        [2.6491, 3.5165, 2.0239, 3.5292, 3.5335, 2.0542, 2.1168],\n",
            "        [2.8048, 3.6858, 2.1091, 3.6999, 3.7122, 2.1370, 2.2116]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "89\n",
            "tensor([[2.8596, 3.7420, 2.1365, 3.7591, 3.7746, 2.1665, 2.2455],\n",
            "        [2.3915, 3.2344, 1.8772, 3.2416, 3.2338, 1.9096, 1.9585],\n",
            "        [1.5372, 2.2151, 1.3752, 2.2185, 2.1733, 1.4270, 1.4111],\n",
            "        [1.5135, 2.1872, 1.3602, 2.1886, 2.1440, 1.4112, 1.3920],\n",
            "        [0.9484, 1.4640, 0.9869, 1.4715, 1.4057, 1.0262, 1.0041]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "90\n",
            "tensor([[2.8590, 3.7514, 2.1391, 3.7685, 3.7853, 2.1550, 2.2475],\n",
            "        [2.1096, 2.9041, 1.7177, 2.9102, 2.8886, 1.7643, 1.7812],\n",
            "        [1.2413, 1.8438, 1.1843, 1.8488, 1.7912, 1.2336, 1.2108],\n",
            "        [2.8401, 3.7231, 2.1273, 3.7424, 3.7536, 2.1540, 2.2360],\n",
            "        [3.0742, 3.9626, 2.2515, 3.9872, 4.0072, 2.2874, 2.3799]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "91\n",
            "tensor([[2.6317, 3.5014, 2.0121, 3.5164, 3.5180, 2.0386, 2.1079],\n",
            "        [2.9620, 3.8476, 2.1910, 3.8701, 3.8869, 2.2163, 2.3090],\n",
            "        [1.4625, 2.1229, 1.3254, 2.1249, 2.0771, 1.3757, 1.3587],\n",
            "        [3.2475, 4.1294, 2.3438, 4.1590, 4.1747, 2.3969, 2.4878],\n",
            "        [3.2665, 4.1496, 2.3537, 4.1771, 4.1917, 2.4167, 2.5015]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "92\n",
            "tensor([[3.2518, 4.1331, 2.3437, 4.1614, 4.1751, 2.3957, 2.4908],\n",
            "        [1.0307, 1.5702, 1.0425, 1.5792, 1.5138, 1.0855, 1.0631],\n",
            "        [3.1514, 4.0338, 2.2900, 4.0664, 4.0838, 2.3232, 2.4255],\n",
            "        [3.2764, 4.1583, 2.3559, 4.1877, 4.2007, 2.4211, 2.5070],\n",
            "        [0.9848, 1.5096, 1.0076, 1.5178, 1.4532, 1.0486, 1.0282]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "93\n",
            "tensor([[1.4958, 2.1571, 1.3394, 2.1618, 2.1122, 1.3907, 1.3798],\n",
            "        [2.9763, 3.8590, 2.1972, 3.8855, 3.9001, 2.2256, 2.3173],\n",
            "        [2.1193, 2.9123, 1.7206, 2.9212, 2.9000, 1.7568, 1.7852],\n",
            "        [3.1251, 4.0027, 2.2751, 4.0346, 4.0513, 2.3120, 2.4091],\n",
            "        [1.5913, 2.2776, 1.4036, 2.2826, 2.2371, 1.4584, 1.4450]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "94\n",
            "tensor([[2.4967, 3.3445, 1.9333, 3.3596, 3.3557, 1.9553, 2.0218],\n",
            "        [2.9668, 3.8466, 2.1908, 3.8742, 3.8883, 2.2199, 2.3112],\n",
            "        [1.7819, 2.5091, 1.5206, 2.5163, 2.4781, 1.5727, 1.5688],\n",
            "        [2.6983, 3.5617, 2.0436, 3.5820, 3.5845, 2.0771, 2.1463],\n",
            "        [3.0383, 3.9186, 2.2287, 3.9461, 3.9623, 2.2627, 2.3541]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "95\n",
            "tensor([[2.7552, 3.6256, 2.0733, 3.6483, 3.6524, 2.0977, 2.1808],\n",
            "        [1.2291, 1.8258, 1.1740, 1.8327, 1.7724, 1.2247, 1.2004],\n",
            "        [3.1164, 3.9898, 2.2649, 4.0202, 4.0309, 2.3140, 2.4002],\n",
            "        [1.9946, 2.7624, 1.6454, 2.7704, 2.7421, 1.6858, 1.7038],\n",
            "        [0.9726, 1.4910, 0.9996, 1.5021, 1.4334, 1.0398, 1.0202]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "96\n",
            "tensor([[2.7080, 3.5710, 2.0445, 3.5932, 3.5942, 2.0791, 2.1495],\n",
            "        [1.6672, 2.3703, 1.4485, 2.3775, 2.3325, 1.5002, 1.4923],\n",
            "        [2.5501, 3.4002, 1.9599, 3.4169, 3.4149, 1.9871, 2.0497],\n",
            "        [1.7810, 2.5089, 1.5154, 2.5156, 2.4763, 1.5619, 1.5658],\n",
            "        [3.1025, 3.9804, 2.2563, 4.0135, 4.0259, 2.2947, 2.3924]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "97\n",
            "tensor([[1.3260, 1.9457, 1.2320, 1.9512, 1.8936, 1.2837, 1.2632],\n",
            "        [0.9254, 1.4298, 0.9654, 1.4404, 1.3704, 1.0011, 0.9852],\n",
            "        [2.4125, 3.2462, 1.8794, 3.2604, 3.2493, 1.9168, 1.9664],\n",
            "        [3.2620, 4.1353, 2.3357, 4.1687, 4.1804, 2.3860, 2.4878],\n",
            "        [0.9193, 1.4225, 0.9605, 1.4340, 1.3645, 0.9978, 0.9812]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "98\n",
            "tensor([[2.6137, 3.4704, 1.9879, 3.4888, 3.4862, 2.0173, 2.0892],\n",
            "        [2.3660, 3.1912, 1.8506, 3.2081, 3.1915, 1.8903, 1.9371],\n",
            "        [2.7046, 3.5670, 2.0341, 3.5887, 3.5896, 2.0685, 2.1448],\n",
            "        [1.3743, 2.0064, 1.2603, 2.0118, 1.9570, 1.3093, 1.2942],\n",
            "        [2.7389, 3.6048, 2.0551, 3.6267, 3.6282, 2.0864, 2.1644]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "99\n",
            "tensor([[3.2266, 4.1010, 2.3093, 4.1351, 4.1460, 2.3645, 2.4651],\n",
            "        [3.2589, 4.1317, 2.3272, 4.1675, 4.1783, 2.3884, 2.4882],\n",
            "        [3.1397, 4.0165, 2.2633, 4.0506, 4.0636, 2.3140, 2.4112],\n",
            "        [1.2797, 1.8875, 1.1968, 1.8941, 1.8338, 1.2520, 1.2325],\n",
            "        [2.3695, 3.1949, 1.8465, 3.2114, 3.1945, 1.8964, 1.9403]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "100\n",
            "tensor([[1.5357, 2.2076, 1.3583, 2.2188, 2.1637, 1.4199, 1.4070],\n",
            "        [3.2632, 4.1379, 2.3241, 4.1744, 4.1765, 2.3997, 2.4955],\n",
            "        [2.8048, 3.6817, 2.0819, 3.7065, 3.7101, 2.1136, 2.2090],\n",
            "        [2.8061, 3.6814, 2.0833, 3.7067, 3.7091, 2.1193, 2.2107],\n",
            "        [3.1890, 4.0633, 2.2844, 4.1002, 4.1122, 2.3398, 2.4452]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "101\n",
            "tensor([[2.7935, 3.6734, 2.0721, 3.6996, 3.7015, 2.1103, 2.2064],\n",
            "        [2.8220, 3.6994, 2.0875, 3.7257, 3.7281, 2.1277, 2.2217],\n",
            "        [3.2806, 4.1527, 2.3268, 4.1881, 4.1888, 2.4153, 2.5112],\n",
            "        [2.1149, 2.9020, 1.6953, 2.9162, 2.8857, 1.7550, 1.7818],\n",
            "        [1.4331, 2.0814, 1.2922, 2.0916, 2.0333, 1.3539, 1.3390]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "102\n",
            "tensor([[1.6235, 2.3215, 1.4064, 2.3296, 2.2781, 1.4726, 1.4686],\n",
            "        [0.7059, 1.1403, 0.8010, 1.1552, 1.0811, 0.8319, 0.8260],\n",
            "        [2.9871, 3.8693, 2.1691, 3.9020, 3.9065, 2.2208, 2.3261],\n",
            "        [3.1836, 4.0594, 2.2728, 4.0992, 4.1059, 2.3455, 2.4480],\n",
            "        [1.1203, 1.6845, 1.0895, 1.6951, 1.6265, 1.1457, 1.1257]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "103\n",
            "tensor([[0.7708, 1.2278, 0.8472, 1.2433, 1.1683, 0.8860, 0.8763],\n",
            "        [2.4880, 3.3326, 1.8991, 3.3533, 3.3372, 1.9565, 2.0186],\n",
            "        [2.2090, 3.0173, 1.7439, 3.0313, 3.0025, 1.8033, 1.8446],\n",
            "        [2.6423, 3.5058, 1.9835, 3.5294, 3.5190, 2.0369, 2.1149],\n",
            "        [2.7333, 3.6045, 2.0311, 3.6301, 3.6285, 2.0749, 2.1677]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "104\n",
            "tensor([[2.6319, 3.4948, 1.9743, 3.5172, 3.5119, 2.0242, 2.1061],\n",
            "        [0.8125, 1.2815, 0.8766, 1.2966, 1.2212, 0.9165, 0.9062],\n",
            "        [0.8614, 1.3491, 0.9116, 1.3634, 1.2886, 0.9535, 0.9418],\n",
            "        [3.2468, 4.1226, 2.2992, 4.1590, 4.1612, 2.3961, 2.4891],\n",
            "        [3.2505, 4.1263, 2.3019, 4.1641, 4.1680, 2.3846, 2.4901]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "105\n",
            "tensor([[2.7899, 3.6603, 2.0548, 3.6859, 3.6841, 2.1078, 2.2002],\n",
            "        [1.0601, 1.6072, 1.0434, 1.6191, 1.5496, 1.1021, 1.0832],\n",
            "        [1.7214, 2.4375, 1.4584, 2.4476, 2.3987, 1.5316, 1.5306],\n",
            "        [1.8342, 2.5740, 1.5237, 2.5837, 2.5413, 1.5935, 1.6030],\n",
            "        [1.0309, 1.5685, 1.0228, 1.5779, 1.5083, 1.0736, 1.0594]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "106\n",
            "tensor([[1.7862, 2.5164, 1.4930, 2.5242, 2.4799, 1.5642, 1.5699],\n",
            "        [0.9087, 1.4102, 0.9424, 1.4234, 1.3508, 0.9892, 0.9744],\n",
            "        [1.3932, 2.0313, 1.2549, 2.0392, 1.9799, 1.3215, 1.3102],\n",
            "        [2.1680, 2.9676, 1.7136, 2.9812, 2.9506, 1.7847, 1.8164],\n",
            "        [3.1955, 4.0707, 2.2698, 4.1113, 4.1169, 2.3469, 2.4513]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "107\n",
            "tensor([[0.8945, 1.3906, 0.9323, 1.4034, 1.3313, 0.9763, 0.9637],\n",
            "        [2.3375, 3.1618, 1.8103, 3.1793, 3.1577, 1.8745, 1.9209],\n",
            "        [2.3502, 3.1754, 1.8169, 3.1932, 3.1730, 1.8724, 1.9280],\n",
            "        [0.7449, 1.1909, 0.8251, 1.2056, 1.1318, 0.8584, 0.8531],\n",
            "        [1.2520, 1.8533, 1.1683, 1.8635, 1.7981, 1.2294, 1.2158]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "108\n",
            "tensor([[3.1895, 4.0645, 2.2658, 4.1020, 4.1087, 2.3445, 2.4440],\n",
            "        [1.4682, 2.1285, 1.3053, 2.1357, 2.0782, 1.3686, 1.3603],\n",
            "        [1.4373, 2.0907, 1.2857, 2.1001, 2.0423, 1.3513, 1.3421],\n",
            "        [1.7375, 2.4580, 1.4673, 2.4652, 2.4192, 1.5305, 1.5368],\n",
            "        [2.8116, 3.6862, 2.0669, 3.7111, 3.7146, 2.1114, 2.2094]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "109\n",
            "tensor([[1.6345, 2.3320, 1.4047, 2.3412, 2.2903, 1.4704, 1.4708],\n",
            "        [1.0584, 1.6048, 1.0425, 1.6167, 1.5456, 1.0958, 1.0792],\n",
            "        [1.3216, 1.9428, 1.2126, 1.9517, 1.8891, 1.2741, 1.2622],\n",
            "        [2.4995, 3.3428, 1.8955, 3.3629, 3.3481, 1.9499, 2.0199],\n",
            "        [3.1196, 3.9930, 2.2288, 4.0292, 4.0315, 2.3068, 2.4031]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "110\n",
            "tensor([[2.9568, 3.8345, 2.1418, 3.8661, 3.8694, 2.1915, 2.2985],\n",
            "        [3.1284, 4.0005, 2.2334, 4.0392, 4.0442, 2.3035, 2.4052],\n",
            "        [2.8513, 3.7230, 2.0870, 3.7526, 3.7540, 2.1372, 2.2335],\n",
            "        [2.3185, 3.1371, 1.7980, 3.1552, 3.1308, 1.8547, 1.9060],\n",
            "        [2.7132, 3.5759, 2.0139, 3.6032, 3.5975, 2.0620, 2.1502]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "111\n",
            "tensor([[2.4266, 3.2541, 1.8568, 3.2770, 3.2596, 1.9154, 1.9725],\n",
            "        [0.9894, 1.5133, 0.9951, 1.5282, 1.4562, 1.0451, 1.0319],\n",
            "        [1.4295, 2.0731, 1.2780, 2.0860, 2.0264, 1.3427, 1.3342],\n",
            "        [3.1716, 4.0428, 2.2540, 4.0838, 4.0941, 2.3188, 2.4301],\n",
            "        [3.1934, 4.0654, 2.2632, 4.1051, 4.1112, 2.3338, 2.4451]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "112\n",
            "tensor([[2.5631, 3.4069, 1.9321, 3.4345, 3.4242, 1.9813, 2.0577],\n",
            "        [3.2513, 4.1177, 2.2952, 4.1615, 4.1678, 2.3722, 2.4829],\n",
            "        [3.2385, 4.1078, 2.2891, 4.1534, 4.1595, 2.3659, 2.4756],\n",
            "        [2.7862, 3.6537, 2.0513, 3.6847, 3.6838, 2.0955, 2.1957],\n",
            "        [0.7333, 1.1744, 0.8169, 1.1926, 1.1166, 0.8513, 0.8465]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "113\n",
            "tensor([[2.9591, 3.8257, 2.1412, 3.8656, 3.8690, 2.1975, 2.3011],\n",
            "        [0.6734, 1.0925, 0.7741, 1.1116, 1.0364, 0.8016, 0.8005],\n",
            "        [1.3527, 1.9773, 1.2298, 1.9905, 1.9296, 1.2925, 1.2840],\n",
            "        [0.8947, 1.3860, 0.9296, 1.4037, 1.3314, 0.9727, 0.9650],\n",
            "        [3.1408, 4.0088, 2.2376, 4.0519, 4.0597, 2.3083, 2.4169]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "114\n",
            "tensor([[0.8701, 1.3551, 0.9140, 1.3739, 1.2994, 0.9582, 0.9472],\n",
            "        [0.9187, 1.4182, 0.9499, 1.4373, 1.3635, 0.9943, 0.9829],\n",
            "        [2.9835, 3.8498, 2.1570, 3.8927, 3.8982, 2.2153, 2.3184],\n",
            "        [2.3226, 3.1357, 1.8002, 3.1603, 3.1414, 1.8503, 1.9098],\n",
            "        [3.1466, 4.0143, 2.2406, 4.0613, 4.0697, 2.2994, 2.4187]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "115\n",
            "tensor([[2.4475, 3.2770, 1.8718, 3.3067, 3.2928, 1.9226, 1.9912],\n",
            "        [0.7281, 1.1653, 0.8156, 1.1853, 1.1107, 0.8452, 0.8425],\n",
            "        [1.8205, 2.5492, 1.5183, 2.5712, 2.5281, 1.5793, 1.5957],\n",
            "        [1.9794, 2.7340, 1.6059, 2.7533, 2.7190, 1.6699, 1.6937],\n",
            "        [1.8061, 2.5294, 1.5083, 2.5465, 2.5047, 1.5680, 1.5821]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "116\n",
            "tensor([[0.8238, 1.2923, 0.8838, 1.3123, 1.2391, 0.9195, 0.9128],\n",
            "        [2.5063, 3.3406, 1.9060, 3.3747, 3.3637, 1.9524, 2.0278],\n",
            "        [2.1191, 2.8990, 1.6885, 2.9223, 2.8977, 1.7454, 1.7839],\n",
            "        [1.7457, 2.4599, 1.4777, 2.4799, 2.4359, 1.5352, 1.5471],\n",
            "        [3.2535, 4.1155, 2.3025, 4.1676, 4.1775, 2.3769, 2.4873]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "117\n",
            "tensor([[0.8692, 1.3497, 0.9191, 1.3743, 1.3003, 0.9595, 0.9484],\n",
            "        [3.2655, 4.1226, 2.3100, 4.1767, 4.1880, 2.3875, 2.4960],\n",
            "        [1.4861, 2.1400, 1.3180, 2.1578, 2.1055, 1.3761, 1.3744],\n",
            "        [3.2631, 4.1199, 2.3086, 4.1769, 4.1902, 2.3829, 2.4925],\n",
            "        [2.3250, 3.1299, 1.8037, 3.1603, 3.1422, 1.8596, 1.9110]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "118\n",
            "tensor([[0.9886, 1.5079, 0.9999, 1.5303, 1.4618, 1.0485, 1.0354],\n",
            "        [3.2314, 4.0881, 2.2918, 4.1457, 4.1590, 2.3641, 2.4726],\n",
            "        [1.1526, 1.7177, 1.1079, 1.7384, 1.6740, 1.1603, 1.1482],\n",
            "        [2.1088, 2.8834, 1.6869, 2.9111, 2.8858, 1.7446, 1.7778],\n",
            "        [1.1693, 1.7400, 1.1181, 1.7598, 1.6948, 1.1713, 1.1605]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "119\n",
            "tensor([[2.7524, 3.6017, 2.0413, 3.6490, 3.6505, 2.0893, 2.1796],\n",
            "        [1.0400, 1.5711, 1.0349, 1.5936, 1.5263, 1.0823, 1.0691],\n",
            "        [2.6496, 3.4913, 1.9847, 3.5338, 3.5333, 2.0356, 2.1157],\n",
            "        [2.7756, 3.6236, 2.0541, 3.6715, 3.6751, 2.1049, 2.1932],\n",
            "        [2.7871, 3.6362, 2.0602, 3.6830, 3.6871, 2.1040, 2.1982]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "120\n",
            "tensor([[2.2904, 3.0953, 1.7923, 3.1312, 3.1121, 1.8438, 1.8963],\n",
            "        [2.3379, 3.1436, 1.8169, 3.1805, 3.1643, 1.8735, 1.9241],\n",
            "        [1.1236, 1.6817, 1.0917, 1.7057, 1.6387, 1.1427, 1.1311],\n",
            "        [1.8551, 2.5873, 1.5429, 2.6138, 2.5782, 1.6046, 1.6198],\n",
            "        [2.7607, 3.6068, 2.0452, 3.6565, 3.6606, 2.0921, 2.1842]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "121\n",
            "tensor([[3.2280, 4.0859, 2.2952, 4.1476, 4.1619, 2.3747, 2.4764],\n",
            "        [2.1006, 2.8748, 1.6843, 2.9092, 2.8824, 1.7463, 1.7782],\n",
            "        [0.8157, 1.2818, 0.8842, 1.3073, 1.2350, 0.9217, 0.9127],\n",
            "        [3.2953, 4.1467, 2.3255, 4.2071, 4.2140, 2.4200, 2.5217],\n",
            "        [1.5226, 2.1838, 1.3467, 2.2101, 2.1604, 1.4085, 1.4038]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "122\n",
            "tensor([[3.0638, 3.9263, 2.2089, 3.9877, 4.0012, 2.2727, 2.3781],\n",
            "        [2.1913, 2.9807, 1.7362, 3.0148, 2.9976, 1.7919, 1.8359],\n",
            "        [1.7736, 2.4908, 1.4967, 2.5197, 2.4797, 1.5589, 1.5693],\n",
            "        [0.9207, 1.4213, 0.9571, 1.4449, 1.3755, 1.0020, 0.9887],\n",
            "        [3.2264, 4.0840, 2.2939, 4.1483, 4.1636, 2.3745, 2.4794]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "123\n",
            "tensor([[2.6700, 3.5204, 2.0002, 3.5678, 3.5722, 2.0465, 2.1370],\n",
            "        [0.9780, 1.4968, 0.9958, 1.5227, 1.4534, 1.0468, 1.0327],\n",
            "        [0.8104, 1.2765, 0.8802, 1.3017, 1.2306, 0.9192, 0.9095],\n",
            "        [3.2688, 4.1262, 2.3162, 4.1893, 4.2054, 2.3928, 2.5039],\n",
            "        [2.3641, 3.1838, 1.8331, 3.2238, 3.2123, 1.8878, 1.9492]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "124\n",
            "tensor([[0.8249, 1.2955, 0.8926, 1.3244, 1.2512, 0.9345, 0.9239],\n",
            "        [1.9290, 2.6834, 1.5930, 2.7142, 2.6844, 1.6513, 1.6742],\n",
            "        [0.9251, 1.4284, 0.9626, 1.4559, 1.3841, 1.0086, 0.9966],\n",
            "        [1.3004, 1.9119, 1.2093, 1.9385, 1.8799, 1.2722, 1.2597],\n",
            "        [1.0226, 1.5548, 1.0280, 1.5818, 1.5138, 1.0802, 1.0656]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "125\n",
            "tensor([[1.1101, 1.6691, 1.0864, 1.6962, 1.6307, 1.1447, 1.1282],\n",
            "        [3.2060, 4.0695, 2.2856, 4.1383, 4.1550, 2.3582, 2.4712],\n",
            "        [2.6131, 3.4618, 1.9724, 3.5101, 3.5110, 2.0258, 2.1059],\n",
            "        [3.0527, 3.9198, 2.2062, 3.9806, 3.9939, 2.2783, 2.3772],\n",
            "        [1.1998, 1.7827, 1.1434, 1.8091, 1.7474, 1.2053, 1.1898]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "126\n",
            "tensor([[2.0254, 2.7956, 1.6457, 2.8306, 2.8044, 1.7076, 1.7374],\n",
            "        [2.0235, 2.7898, 1.6428, 2.8251, 2.7971, 1.7121, 1.7363],\n",
            "        [1.1240, 1.6882, 1.0977, 1.7171, 1.6521, 1.1556, 1.1390],\n",
            "        [2.5946, 3.4446, 1.9633, 3.4935, 3.4943, 2.0203, 2.0964],\n",
            "        [0.9033, 1.3999, 0.9466, 1.4279, 1.3573, 0.9950, 0.9808]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "127\n",
            "tensor([[2.2827, 3.0915, 1.7889, 3.1340, 3.1184, 1.8570, 1.9033],\n",
            "        [0.9606, 1.4765, 0.9877, 1.5071, 1.4359, 1.0431, 1.0265],\n",
            "        [3.2585, 4.1208, 2.3119, 4.1906, 4.2056, 2.4032, 2.5098],\n",
            "        [0.8380, 1.3163, 0.9028, 1.3463, 1.2729, 0.9465, 0.9368],\n",
            "        [1.6764, 2.3800, 1.4437, 2.4125, 2.3684, 1.5130, 1.5153]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "128\n",
            "tensor([[3.2107, 4.0767, 2.2862, 4.1473, 4.1627, 2.3854, 2.4834],\n",
            "        [0.9257, 1.4320, 0.9630, 1.4622, 1.3902, 1.0186, 1.0014],\n",
            "        [2.1062, 2.8936, 1.6919, 2.9346, 2.9086, 1.7655, 1.7971],\n",
            "        [2.9989, 3.8707, 2.1751, 3.9360, 3.9486, 2.2454, 2.3519],\n",
            "        [1.2194, 1.8137, 1.1607, 1.8443, 1.7803, 1.2289, 1.2112]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "129\n",
            "tensor([[1.8700, 2.6148, 1.5529, 2.6502, 2.6143, 1.6417, 1.6475],\n",
            "        [3.2635, 4.1244, 2.3103, 4.1964, 4.2034, 2.4266, 2.5233],\n",
            "        [1.5394, 2.2144, 1.3574, 2.2465, 2.1980, 1.4367, 1.4280],\n",
            "        [2.6504, 3.5037, 1.9910, 3.5604, 3.5602, 2.0669, 2.1389],\n",
            "        [2.9293, 3.7997, 2.1392, 3.8657, 3.8768, 2.2177, 2.3117]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "130\n",
            "tensor([[1.9343, 2.6886, 1.5906, 2.7279, 2.6934, 1.6795, 1.6904],\n",
            "        [3.1119, 3.9809, 2.2318, 4.0538, 4.0667, 2.3323, 2.4296],\n",
            "        [1.5156, 2.1857, 1.3468, 2.2202, 2.1687, 1.4257, 1.4158],\n",
            "        [1.4188, 2.0633, 1.2823, 2.0953, 2.0378, 1.3654, 1.3488],\n",
            "        [3.2741, 4.1340, 2.3154, 4.2082, 4.2159, 2.4386, 2.5330]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "131\n",
            "tensor([[3.1120, 3.9733, 2.2258, 4.0467, 4.0426, 2.3630, 2.4400],\n",
            "        [0.8182, 1.2919, 0.8896, 1.3265, 1.2495, 0.9446, 0.9283],\n",
            "        [3.2794, 4.1411, 2.3152, 4.2178, 4.2203, 2.4511, 2.5433],\n",
            "        [3.2201, 4.0866, 2.2887, 4.1637, 4.1727, 2.4093, 2.5032],\n",
            "        [0.9297, 1.4389, 0.9666, 1.4724, 1.3980, 1.0281, 1.0093]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "132\n",
            "tensor([[1.5574, 2.2396, 1.3684, 2.2774, 2.2244, 1.4596, 1.4499],\n",
            "        [2.7564, 3.6271, 2.0436, 3.6920, 3.6952, 2.1307, 2.2181],\n",
            "        [1.0388, 1.5807, 1.0358, 1.6128, 1.5422, 1.1072, 1.0881],\n",
            "        [3.0138, 3.8783, 2.1749, 3.9542, 3.9591, 2.2887, 2.3794],\n",
            "        [3.2316, 4.0974, 2.2898, 4.1789, 4.1843, 2.4158, 2.5140]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "133\n",
            "tensor([[2.7130, 3.5684, 2.0159, 3.6342, 3.6304, 2.1099, 2.1916],\n",
            "        [2.7257, 3.5862, 2.0237, 3.6542, 3.6497, 2.1293, 2.2029],\n",
            "        [2.8303, 3.7037, 2.0805, 3.7748, 3.7766, 2.1762, 2.2688],\n",
            "        [1.1756, 1.7598, 1.1283, 1.7938, 1.7268, 1.2107, 1.1896],\n",
            "        [2.2424, 3.0563, 1.7652, 3.1103, 3.0855, 1.8615, 1.9026]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "134\n",
            "tensor([[2.2937, 3.1113, 1.7900, 3.1689, 3.1434, 1.8982, 1.9360],\n",
            "        [1.5337, 2.2080, 1.3507, 2.2484, 2.1926, 1.4545, 1.4392],\n",
            "        [2.5337, 3.3785, 1.9212, 3.4422, 3.4301, 2.0264, 2.0869],\n",
            "        [2.8002, 3.6714, 2.0634, 3.7432, 3.7415, 2.1677, 2.2541],\n",
            "        [1.1541, 1.7308, 1.1153, 1.7692, 1.6988, 1.1990, 1.1787]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "135\n",
            "tensor([[0.8213, 1.2948, 0.8870, 1.3309, 1.2528, 0.9516, 0.9347],\n",
            "        [1.6525, 2.3522, 1.4204, 2.3955, 2.3424, 1.5251, 1.5200],\n",
            "        [0.9408, 1.4536, 0.9704, 1.4905, 1.4149, 1.0458, 1.0240],\n",
            "        [2.6043, 3.4534, 1.9545, 3.5216, 3.5075, 2.0730, 2.1351],\n",
            "        [1.8320, 2.5702, 1.5242, 2.6168, 2.5709, 1.6348, 1.6394]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "136\n",
            "tensor([[3.2307, 4.0960, 2.2810, 4.1853, 4.1792, 2.4466, 2.5335],\n",
            "        [2.0612, 2.8441, 1.6570, 2.8989, 2.8599, 1.7716, 1.7915],\n",
            "        [0.9689, 1.4907, 0.9899, 1.5308, 1.4526, 1.0712, 1.0474],\n",
            "        [1.4785, 2.1408, 1.3147, 2.1837, 2.1217, 1.4239, 1.4053],\n",
            "        [1.0416, 1.5859, 1.0378, 1.6239, 1.5499, 1.1205, 1.0981]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "137\n",
            "tensor([[2.9850, 3.8508, 2.1496, 3.9375, 3.9266, 2.2930, 2.3775],\n",
            "        [1.8902, 2.6429, 1.5588, 2.6941, 2.6499, 1.6721, 1.6821],\n",
            "        [0.9380, 1.4484, 0.9655, 1.4884, 1.4103, 1.0471, 1.0233],\n",
            "        [1.0967, 1.6577, 1.0745, 1.7006, 1.6231, 1.1673, 1.1415],\n",
            "        [1.6818, 2.3888, 1.4338, 2.4370, 2.3827, 1.5503, 1.5433]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "138\n",
            "tensor([[1.8454, 2.5874, 1.5294, 2.6385, 2.5907, 1.6463, 1.6534],\n",
            "        [2.5050, 3.3481, 1.8965, 3.4207, 3.3964, 2.0150, 2.0791],\n",
            "        [2.5845, 3.4363, 1.9385, 3.5087, 3.4941, 2.0565, 2.1280],\n",
            "        [0.9415, 1.4534, 0.9684, 1.4950, 1.4140, 1.0506, 1.0288],\n",
            "        [2.5146, 3.3527, 1.9006, 3.4251, 3.4016, 2.0274, 2.0838]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "139\n",
            "tensor([[2.3968, 3.2282, 1.8361, 3.2966, 3.2666, 1.9614, 2.0127],\n",
            "        [2.5182, 3.3563, 1.8991, 3.4296, 3.4034, 2.0295, 2.0880],\n",
            "        [3.2753, 4.1334, 2.2956, 4.2278, 4.2206, 2.4733, 2.5625],\n",
            "        [3.1053, 3.9737, 2.2067, 4.0636, 4.0612, 2.3498, 2.4528],\n",
            "        [2.1664, 2.9649, 1.7094, 3.0261, 2.9891, 1.8306, 1.8649]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "140\n",
            "tensor([[2.8258, 3.6888, 2.0606, 3.7704, 3.7579, 2.1948, 2.2789],\n",
            "        [1.8378, 2.5756, 1.5216, 2.6288, 2.5730, 1.6422, 1.6486],\n",
            "        [1.1377, 1.7084, 1.0978, 1.7512, 1.6723, 1.1942, 1.1717],\n",
            "        [0.8368, 1.3169, 0.8952, 1.3582, 1.2747, 0.9706, 0.9522],\n",
            "        [2.2683, 3.0816, 1.7644, 3.1459, 3.1116, 1.8849, 1.9291]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "141\n",
            "tensor([[1.7112, 2.4261, 1.4456, 2.4756, 2.4167, 1.5628, 1.5645],\n",
            "        [1.6481, 2.3469, 1.4087, 2.3969, 2.3337, 1.5288, 1.5226],\n",
            "        [1.0564, 1.6054, 1.0444, 1.6483, 1.5675, 1.1360, 1.1139],\n",
            "        [1.7828, 2.5104, 1.4873, 2.5628, 2.5050, 1.6111, 1.6128],\n",
            "        [0.9107, 1.4125, 0.9451, 1.4555, 1.3719, 1.0271, 1.0064]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "142\n",
            "tensor([[1.6990, 2.4123, 1.4376, 2.4621, 2.4008, 1.5622, 1.5573],\n",
            "        [3.1835, 4.0460, 2.2395, 4.1407, 4.1299, 2.4087, 2.5039],\n",
            "        [0.8750, 1.3663, 0.9215, 1.4078, 1.3240, 0.9966, 0.9793],\n",
            "        [2.2478, 3.0568, 1.7469, 3.1211, 3.0803, 1.8734, 1.9147],\n",
            "        [2.0115, 2.7812, 1.6136, 2.8374, 2.7871, 1.7497, 1.7614]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "143\n",
            "tensor([[2.7643, 3.6309, 2.0210, 3.7080, 3.6910, 2.1488, 2.2398],\n",
            "        [1.7963, 2.5300, 1.4935, 2.5821, 2.5225, 1.6185, 1.6223],\n",
            "        [0.7273, 1.1722, 0.8167, 1.2109, 1.1259, 0.8787, 0.8674],\n",
            "        [2.1298, 2.9202, 1.6802, 2.9788, 2.9340, 1.8141, 1.8372],\n",
            "        [2.2567, 3.0693, 1.7496, 3.1313, 3.0900, 1.8799, 1.9206]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "144\n",
            "tensor([[0.8365, 1.3187, 0.8918, 1.3577, 1.2735, 0.9672, 0.9503],\n",
            "        [0.8038, 1.2741, 0.8721, 1.3153, 1.2290, 0.9427, 0.9264],\n",
            "        [1.0478, 1.5948, 1.0330, 1.6338, 1.5510, 1.1249, 1.1027],\n",
            "        [3.0569, 3.9306, 2.1706, 4.0172, 4.0035, 2.3255, 2.4234],\n",
            "        [1.0473, 1.5947, 1.0341, 1.6365, 1.5533, 1.1329, 1.1061]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "145\n",
            "tensor([[3.2648, 4.1302, 2.2742, 4.2163, 4.2012, 2.4486, 2.5514],\n",
            "        [2.7720, 3.6409, 2.0187, 3.7145, 3.6947, 2.1502, 2.2407],\n",
            "        [1.5495, 2.2321, 1.3464, 2.2767, 2.2086, 1.4659, 1.4559],\n",
            "        [1.6280, 2.3300, 1.3911, 2.3738, 2.3095, 1.5153, 1.5085],\n",
            "        [1.6959, 2.4125, 1.4317, 2.4576, 2.3956, 1.5555, 1.5532]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "146\n",
            "tensor([[1.4927, 2.1630, 1.3080, 2.2042, 2.1344, 1.4290, 1.4149],\n",
            "        [1.9791, 2.7519, 1.5905, 2.8018, 2.7482, 1.7234, 1.7393],\n",
            "        [2.6454, 3.5125, 1.9529, 3.5806, 3.5558, 2.0841, 2.1632],\n",
            "        [0.9928, 1.5268, 0.9958, 1.5656, 1.4812, 1.0868, 1.0652],\n",
            "        [1.9263, 2.6872, 1.5591, 2.7366, 2.6796, 1.6930, 1.7036]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "147\n",
            "tensor([[3.2497, 4.1161, 2.2584, 4.1982, 4.1806, 2.4432, 2.5420],\n",
            "        [2.7806, 3.6470, 2.0186, 3.7179, 3.6944, 2.1693, 2.2458],\n",
            "        [2.2733, 3.0880, 1.7457, 3.1412, 3.1001, 1.8847, 1.9264],\n",
            "        [2.1354, 2.9341, 1.6742, 2.9836, 2.9358, 1.8091, 1.8394],\n",
            "        [3.2045, 4.0766, 2.2373, 4.1607, 4.1503, 2.4042, 2.5086]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "148\n",
            "tensor([[0.8504, 1.3387, 0.8991, 1.3743, 1.2877, 0.9765, 0.9582],\n",
            "        [3.0671, 3.9412, 2.1652, 4.0188, 4.0029, 2.3234, 2.4221],\n",
            "        [2.0778, 2.8680, 1.6411, 2.9156, 2.8665, 1.7728, 1.7975],\n",
            "        [3.2229, 4.0882, 2.2420, 4.1654, 4.1459, 2.4325, 2.5232],\n",
            "        [2.1483, 2.9526, 1.6809, 3.0009, 2.9557, 1.8098, 1.8440]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "149\n",
            "tensor([[2.5144, 3.3682, 1.8782, 3.4261, 3.3942, 2.0090, 2.0757],\n",
            "        [2.8495, 3.7234, 2.0496, 3.7916, 3.7726, 2.1811, 2.2816],\n",
            "        [2.6893, 3.5574, 1.9689, 3.6201, 3.5967, 2.1037, 2.1820],\n",
            "        [1.5192, 2.1991, 1.3219, 2.2368, 2.1660, 1.4436, 1.4295],\n",
            "        [1.2915, 1.9126, 1.1841, 1.9482, 1.8704, 1.2937, 1.2740]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "150\n",
            "tensor([[3.2009, 4.0805, 2.2322, 4.1558, 4.1389, 2.4129, 2.5039],\n",
            "        [2.3744, 3.2189, 1.8031, 3.2687, 3.2340, 1.9240, 1.9828],\n",
            "        [2.2924, 3.1190, 1.7578, 3.1699, 3.1291, 1.8922, 1.9330],\n",
            "        [2.1028, 2.9004, 1.6542, 2.9469, 2.8973, 1.7851, 1.8117],\n",
            "        [3.2398, 4.1163, 2.2516, 4.1917, 4.1735, 2.4256, 2.5248]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "151\n",
            "tensor([[3.2263, 4.1043, 2.2438, 4.1783, 4.1606, 2.4175, 2.5154],\n",
            "        [3.2341, 4.1134, 2.2496, 4.1884, 4.1719, 2.4248, 2.5190],\n",
            "        [1.5322, 2.2226, 1.3296, 2.2538, 2.1847, 1.4478, 1.4353],\n",
            "        [1.0618, 1.6216, 1.0370, 1.6554, 1.5708, 1.1307, 1.1104],\n",
            "        [3.2318, 4.1077, 2.2495, 4.1828, 4.1647, 2.4270, 2.5186]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "152\n",
            "tensor([[2.9892, 3.8709, 2.1195, 3.9363, 3.9180, 2.2679, 2.3632],\n",
            "        [1.3973, 2.0546, 1.2485, 2.0881, 2.0115, 1.3603, 1.3451],\n",
            "        [3.2774, 4.1523, 2.2673, 4.2242, 4.2023, 2.4490, 2.5471],\n",
            "        [0.9151, 1.4301, 0.9404, 1.4625, 1.3754, 1.0197, 1.0025],\n",
            "        [1.3348, 1.9741, 1.2099, 2.0056, 1.9278, 1.3146, 1.2989]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "153\n",
            "tensor([[2.6948, 3.5728, 1.9648, 3.6271, 3.6022, 2.0902, 2.1776],\n",
            "        [1.0624, 1.6243, 1.0348, 1.6549, 1.5706, 1.1293, 1.1087],\n",
            "        [0.8637, 1.3643, 0.9058, 1.3966, 1.3074, 0.9850, 0.9664],\n",
            "        [2.5213, 3.3864, 1.8746, 3.4357, 3.4027, 2.0014, 2.0730],\n",
            "        [2.7514, 3.6339, 1.9950, 3.6915, 3.6668, 2.1237, 2.2149]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "154\n",
            "tensor([[3.0152, 3.8985, 2.1281, 3.9616, 3.9420, 2.2726, 2.3742],\n",
            "        [2.8652, 3.7490, 2.0504, 3.8082, 3.7842, 2.1920, 2.2845],\n",
            "        [1.5057, 2.1926, 1.3101, 2.2218, 2.1493, 1.4214, 1.4136],\n",
            "        [3.2664, 4.1462, 2.2548, 4.2138, 4.1888, 2.4387, 2.5402],\n",
            "        [2.8346, 3.7231, 2.0365, 3.7799, 3.7588, 2.1590, 2.2614]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "155\n",
            "tensor([[1.5481, 2.2423, 1.3344, 2.2728, 2.1993, 1.4491, 1.4415],\n",
            "        [0.7610, 1.2263, 0.8351, 1.2577, 1.1670, 0.8998, 0.8870],\n",
            "        [1.9542, 2.7341, 1.5675, 2.7703, 2.7112, 1.6880, 1.7072],\n",
            "        [3.2269, 4.1022, 2.2315, 4.1679, 4.1413, 2.4064, 2.5107],\n",
            "        [3.2661, 4.1479, 2.2578, 4.2158, 4.1940, 2.4226, 2.5307]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "156\n",
            "tensor([[2.7002, 3.5803, 1.9680, 3.6283, 3.5982, 2.0963, 2.1764],\n",
            "        [3.2264, 4.1095, 2.2388, 4.1686, 4.1458, 2.4129, 2.5061],\n",
            "        [1.9945, 2.7828, 1.5896, 2.8157, 2.7602, 1.7063, 1.7298],\n",
            "        [1.2585, 1.8802, 1.1605, 1.9070, 1.8247, 1.2573, 1.2424],\n",
            "        [2.8472, 3.7463, 2.0481, 3.7976, 3.7791, 2.1611, 2.2664]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "157\n",
            "tensor([[1.1878, 1.7896, 1.1168, 1.8152, 1.7311, 1.2103, 1.1921],\n",
            "        [3.2743, 4.1541, 2.2625, 4.2128, 4.1890, 2.4347, 2.5324],\n",
            "        [1.0424, 1.6026, 1.0274, 1.6292, 1.5413, 1.1107, 1.0901],\n",
            "        [3.0556, 3.9444, 2.1537, 3.9976, 3.9771, 2.2945, 2.3909],\n",
            "        [2.0531, 2.8503, 1.6208, 2.8798, 2.8267, 1.7369, 1.7634]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "158\n",
            "tensor([[2.6223, 3.5027, 1.9309, 3.5414, 3.5136, 2.0376, 2.1210],\n",
            "        [2.4739, 3.3329, 1.8515, 3.3682, 3.3335, 1.9633, 2.0280],\n",
            "        [0.8990, 1.4122, 0.9316, 1.4373, 1.3498, 1.0025, 0.9842],\n",
            "        [1.8261, 2.5878, 1.4986, 2.6103, 2.5519, 1.6056, 1.6170],\n",
            "        [2.1982, 3.0228, 1.7043, 3.0525, 3.0084, 1.8187, 1.8559]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "159\n",
            "tensor([[1.5169, 2.2076, 1.3220, 2.2296, 2.1579, 1.4237, 1.4123],\n",
            "        [1.2361, 1.8535, 1.1493, 1.8759, 1.7951, 1.2449, 1.2231],\n",
            "        [1.2973, 1.9315, 1.1860, 1.9528, 1.8724, 1.2819, 1.2646],\n",
            "        [2.6233, 3.4928, 1.9299, 3.5309, 3.5027, 2.0485, 2.1152],\n",
            "        [0.9695, 1.5059, 0.9795, 1.5307, 1.4423, 1.0541, 1.0356]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "160\n",
            "tensor([[3.2423, 4.1269, 2.2515, 4.1745, 4.1612, 2.4087, 2.4953],\n",
            "        [1.6779, 2.4067, 1.4124, 2.4239, 2.3599, 1.5216, 1.5157],\n",
            "        [0.9646, 1.4976, 0.9742, 1.5212, 1.4344, 1.0513, 1.0295],\n",
            "        [1.9402, 2.7202, 1.5615, 2.7419, 2.6874, 1.6766, 1.6862],\n",
            "        [2.0855, 2.8871, 1.6406, 2.9100, 2.8612, 1.7548, 1.7755]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "161\n",
            "tensor([[0.7996, 1.2810, 0.8634, 1.3051, 1.2177, 0.9264, 0.9086],\n",
            "        [1.4685, 2.1474, 1.2925, 2.1649, 2.0922, 1.3934, 1.3762],\n",
            "        [2.2985, 3.1407, 1.7608, 3.1662, 3.1281, 1.8725, 1.9126],\n",
            "        [3.2856, 4.1665, 2.2731, 4.2110, 4.1983, 2.4303, 2.5220],\n",
            "        [1.2957, 1.9295, 1.1879, 1.9453, 1.8692, 1.2797, 1.2590]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "162\n",
            "tensor([[3.0090, 3.9041, 2.1322, 3.9434, 3.9397, 2.2435, 2.3426],\n",
            "        [0.9995, 1.5473, 0.9984, 1.5659, 1.4823, 1.0731, 1.0509],\n",
            "        [3.1951, 4.0873, 2.2281, 4.1318, 4.1262, 2.3674, 2.4619],\n",
            "        [0.8673, 1.3728, 0.9088, 1.3920, 1.3075, 0.9741, 0.9566],\n",
            "        [1.9831, 2.7723, 1.5855, 2.7909, 2.7398, 1.6963, 1.7094]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "163\n",
            "tensor([[0.8835, 1.3946, 0.9235, 1.4162, 1.3289, 0.9924, 0.9698],\n",
            "        [1.2853, 1.9191, 1.1805, 1.9331, 1.8569, 1.2712, 1.2507],\n",
            "        [0.9121, 1.4300, 0.9393, 1.4510, 1.3657, 1.0124, 0.9890],\n",
            "        [1.2334, 1.8522, 1.1501, 1.8678, 1.7903, 1.2400, 1.2151],\n",
            "        [0.7826, 1.2575, 0.8508, 1.2796, 1.1943, 0.9102, 0.8945]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "164\n",
            "tensor([[2.9737, 3.8644, 2.1142, 3.9000, 3.8931, 2.2446, 2.3208],\n",
            "        [1.6204, 2.3372, 1.3803, 2.3511, 2.2877, 1.4859, 1.4732],\n",
            "        [2.2619, 3.1004, 1.7416, 3.1199, 3.0861, 1.8427, 1.8826],\n",
            "        [0.8206, 1.3094, 0.8794, 1.3316, 1.2450, 0.9438, 0.9225],\n",
            "        [2.4835, 3.3566, 1.8607, 3.3795, 3.3554, 1.9621, 2.0223]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "165\n",
            "tensor([[0.8335, 1.3259, 0.8871, 1.3472, 1.2607, 0.9530, 0.9318],\n",
            "        [1.0421, 1.6059, 1.0257, 1.6226, 1.5415, 1.1059, 1.0813],\n",
            "        [0.9761, 1.5158, 0.9819, 1.5353, 1.4515, 1.0604, 1.0351],\n",
            "        [3.0682, 3.9601, 2.1600, 3.9988, 3.9976, 2.2914, 2.3759],\n",
            "        [2.0698, 2.8769, 1.6347, 2.8928, 2.8496, 1.7450, 1.7620]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "166\n",
            "tensor([[0.7854, 1.2642, 0.8550, 1.2843, 1.1984, 0.9158, 0.8964],\n",
            "        [1.1865, 1.7931, 1.1200, 1.8105, 1.7316, 1.2111, 1.1834],\n",
            "        [2.6882, 3.5768, 1.9676, 3.6015, 3.5879, 2.0737, 2.1431],\n",
            "        [2.7004, 3.5859, 1.9728, 3.6129, 3.5978, 2.0909, 2.1531],\n",
            "        [2.0455, 2.8522, 1.6226, 2.8657, 2.8245, 1.7310, 1.7458]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "167\n",
            "tensor([[1.1615, 1.7641, 1.1034, 1.7774, 1.7001, 1.1925, 1.1661],\n",
            "        [2.6098, 3.4936, 1.9265, 3.5161, 3.4971, 2.0327, 2.0992],\n",
            "        [1.3460, 1.9997, 1.2208, 2.0125, 1.9416, 1.3143, 1.2910],\n",
            "        [2.1694, 3.0028, 1.6959, 3.0167, 2.9817, 1.7991, 1.8257],\n",
            "        [1.0045, 1.5584, 1.0022, 1.5746, 1.4924, 1.0799, 1.0558]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "168\n",
            "tensor([[2.0007, 2.8013, 1.6010, 2.8138, 2.7683, 1.7121, 1.7199],\n",
            "        [2.8416, 3.7403, 2.0472, 3.7675, 3.7617, 2.1623, 2.2403],\n",
            "        [3.2067, 4.0973, 2.2364, 4.1312, 4.1263, 2.4005, 2.4701],\n",
            "        [2.9842, 3.8876, 2.1238, 3.9178, 3.9127, 2.2418, 2.3285],\n",
            "        [2.4642, 3.3432, 1.8520, 3.3603, 3.3394, 1.9591, 2.0123]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "169\n",
            "tensor([[3.2163, 4.1095, 2.2421, 4.1432, 4.1383, 2.4074, 2.4786],\n",
            "        [0.9660, 1.5096, 0.9789, 1.5250, 1.4431, 1.0559, 1.0302],\n",
            "        [2.5561, 3.4395, 1.9016, 3.4601, 3.4421, 2.0137, 2.0682],\n",
            "        [1.6445, 2.3751, 1.3986, 2.3877, 2.3261, 1.5094, 1.4941],\n",
            "        [0.9382, 1.4723, 0.9486, 1.4812, 1.4061, 1.0269, 1.0041]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "170\n",
            "tensor([[1.0650, 1.6404, 1.0438, 1.6575, 1.5743, 1.1319, 1.1031],\n",
            "        [3.1219, 4.0242, 2.1940, 4.0593, 4.0491, 2.3471, 2.4235],\n",
            "        [2.7026, 3.6061, 1.9779, 3.6285, 3.6171, 2.0902, 2.1631],\n",
            "        [2.9476, 3.8574, 2.1045, 3.8874, 3.8859, 2.2231, 2.3088],\n",
            "        [1.7804, 2.5457, 1.4770, 2.5557, 2.5011, 1.5878, 1.5832]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "171\n",
            "tensor([[2.2885, 3.1455, 1.7570, 3.1623, 3.1278, 1.8742, 1.9102],\n",
            "        [1.9920, 2.7988, 1.5947, 2.8112, 2.7634, 1.7131, 1.7215],\n",
            "        [1.0429, 1.6157, 1.0301, 1.6313, 1.5485, 1.1175, 1.0897],\n",
            "        [1.7778, 2.5446, 1.4746, 2.5536, 2.4992, 1.5869, 1.5828],\n",
            "        [1.1601, 1.7678, 1.1046, 1.7808, 1.7010, 1.1977, 1.1700]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "172\n",
            "tensor([[3.0328, 3.9495, 2.1469, 3.9803, 3.9785, 2.2764, 2.3685],\n",
            "        [2.2583, 3.1099, 1.7404, 3.1249, 3.0889, 1.8624, 1.8918],\n",
            "        [1.5073, 2.2122, 1.3185, 2.2227, 2.1542, 1.4291, 1.4095],\n",
            "        [3.2471, 4.1473, 2.2573, 4.1846, 4.1792, 2.4094, 2.4998],\n",
            "        [2.1841, 3.0278, 1.7025, 3.0421, 3.0044, 1.8144, 1.8442]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "173\n",
            "tensor([[1.1978, 1.8206, 1.1276, 1.8337, 1.7533, 1.2274, 1.2006],\n",
            "        [1.4486, 2.1400, 1.2820, 2.1502, 2.0808, 1.3927, 1.3704],\n",
            "        [2.9393, 3.8552, 2.0953, 3.8836, 3.8757, 2.2220, 2.3122],\n",
            "        [1.0809, 1.6687, 1.0571, 1.6805, 1.6000, 1.1469, 1.1166],\n",
            "        [1.4211, 2.1060, 1.2640, 2.1149, 2.0448, 1.3743, 1.3515]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "174\n",
            "tensor([[2.6479, 3.5515, 1.9442, 3.5688, 3.5547, 2.0588, 2.1331],\n",
            "        [1.6206, 2.3557, 1.3817, 2.3626, 2.2990, 1.4988, 1.4844],\n",
            "        [0.9550, 1.5025, 0.9704, 1.5184, 1.4326, 1.0557, 1.0296],\n",
            "        [1.5261, 2.2379, 1.3263, 2.2471, 2.1787, 1.4420, 1.4226],\n",
            "        [3.2411, 4.1488, 2.2512, 4.1827, 4.1762, 2.4202, 2.5026]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "175\n",
            "tensor([[1.5454, 2.2672, 1.3381, 2.2749, 2.2081, 1.4522, 1.4378],\n",
            "        [0.7960, 1.2884, 0.8610, 1.3054, 1.2177, 0.9316, 0.9119],\n",
            "        [3.2374, 4.1401, 2.2390, 4.1619, 4.1501, 2.4246, 2.5034],\n",
            "        [2.9223, 3.8441, 2.0844, 3.8680, 3.8618, 2.2165, 2.3034],\n",
            "        [2.4767, 3.3634, 1.8517, 3.3777, 3.3515, 1.9756, 2.0303]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "176\n",
            "tensor([[2.6394, 3.5404, 1.9327, 3.5554, 3.5352, 2.0695, 2.1331],\n",
            "        [1.2596, 1.9014, 1.1621, 1.9086, 1.8321, 1.2655, 1.2411],\n",
            "        [3.2014, 4.1111, 2.2215, 4.1375, 4.1398, 2.3745, 2.4698],\n",
            "        [1.5242, 2.2396, 1.3226, 2.2451, 2.1778, 1.4380, 1.4226],\n",
            "        [1.6247, 2.3644, 1.3809, 2.3677, 2.3060, 1.4985, 1.4882]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "177\n",
            "tensor([[2.8606, 3.7811, 2.0479, 3.7987, 3.7914, 2.1808, 2.2651],\n",
            "        [2.6781, 3.5963, 1.9556, 3.6090, 3.5996, 2.0682, 2.1525],\n",
            "        [3.1203, 4.0398, 2.1814, 4.0648, 4.0661, 2.3253, 2.4219],\n",
            "        [2.3407, 3.2187, 1.7786, 3.2275, 3.1976, 1.8986, 1.9456],\n",
            "        [2.5993, 3.5051, 1.9153, 3.5184, 3.5007, 2.0442, 2.1070]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "178\n",
            "tensor([[2.1921, 3.0469, 1.6955, 3.0508, 3.0167, 1.8182, 1.8508],\n",
            "        [2.6767, 3.5941, 1.9515, 3.6039, 3.5943, 2.0709, 2.1500],\n",
            "        [3.2631, 4.1713, 2.2494, 4.1922, 4.1824, 2.4334, 2.5175],\n",
            "        [1.3163, 1.9778, 1.1958, 1.9837, 1.9097, 1.3060, 1.2822],\n",
            "        [1.7848, 2.5623, 1.4709, 2.5660, 2.5094, 1.5923, 1.5920]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "179\n",
            "tensor([[3.1036, 4.0257, 2.1691, 4.0450, 4.0457, 2.3210, 2.4109],\n",
            "        [2.3435, 3.2243, 1.7747, 3.2277, 3.1998, 1.8962, 1.9437],\n",
            "        [3.1264, 4.0432, 2.1793, 4.0616, 4.0587, 2.3448, 2.4257],\n",
            "        [1.8946, 2.6914, 1.5277, 2.6932, 2.6437, 1.6557, 1.6579],\n",
            "        [0.8641, 1.3862, 0.9082, 1.3992, 1.3124, 0.9845, 0.9625]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "180\n",
            "tensor([[3.1195, 4.0409, 2.1713, 4.0543, 4.0618, 2.3131, 2.4137],\n",
            "        [1.9231, 2.7363, 1.5443, 2.7337, 2.6892, 1.6630, 1.6757],\n",
            "        [2.9006, 3.8345, 2.0628, 3.8437, 3.8462, 2.1899, 2.2806],\n",
            "        [1.6796, 2.4380, 1.4072, 2.4353, 2.3780, 1.5315, 1.5188],\n",
            "        [1.6484, 2.3979, 1.3881, 2.3943, 2.3392, 1.5066, 1.4953]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "181\n",
            "tensor([[3.1969, 4.1208, 2.2134, 4.1362, 4.1426, 2.3784, 2.4631],\n",
            "        [1.4535, 2.1561, 1.2764, 2.1530, 2.0891, 1.3882, 1.3657],\n",
            "        [3.2481, 4.1687, 2.2378, 4.1800, 4.1856, 2.4074, 2.4938],\n",
            "        [1.1762, 1.8025, 1.1072, 1.8051, 1.7285, 1.2095, 1.1805],\n",
            "        [0.7918, 1.2882, 0.8554, 1.2998, 1.2147, 0.9278, 0.9044]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "182\n",
            "tensor([[2.5744, 3.4814, 1.8897, 3.4782, 3.4681, 2.0226, 2.0759],\n",
            "        [3.2499, 4.1683, 2.2331, 4.1740, 4.1772, 2.4128, 2.4923],\n",
            "        [2.0934, 2.9386, 1.6363, 2.9298, 2.8976, 1.7588, 1.7759],\n",
            "        [1.3342, 2.0070, 1.2021, 2.0044, 1.9358, 1.3131, 1.2846],\n",
            "        [1.9022, 2.7137, 1.5309, 2.7061, 2.6627, 1.6535, 1.6581]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "183\n",
            "tensor([[3.0667, 3.9973, 2.1400, 4.0002, 4.0131, 2.2987, 2.3707],\n",
            "        [1.6126, 2.3583, 1.3645, 2.3476, 2.2942, 1.4804, 1.4641],\n",
            "        [1.4691, 2.1789, 1.2828, 2.1723, 2.1118, 1.3947, 1.3717],\n",
            "        [2.1123, 2.9638, 1.6436, 2.9530, 2.9238, 1.7657, 1.7846],\n",
            "        [2.0090, 2.8440, 1.5864, 2.8312, 2.7968, 1.7048, 1.7200]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "184\n",
            "tensor([[1.0887, 1.6907, 1.0494, 1.6899, 1.6129, 1.1471, 1.1129],\n",
            "        [3.0135, 3.9465, 2.1085, 3.9432, 3.9563, 2.2391, 2.3295],\n",
            "        [1.8520, 2.6542, 1.4985, 2.6389, 2.5986, 1.6150, 1.6165],\n",
            "        [1.0795, 1.6759, 1.0402, 1.6738, 1.5976, 1.1380, 1.1049],\n",
            "        [3.2628, 4.1862, 2.2353, 4.1841, 4.1973, 2.4050, 2.4845]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "185\n",
            "tensor([[0.9338, 1.4826, 0.9475, 1.4848, 1.4066, 1.0310, 1.0017],\n",
            "        [2.8632, 3.7964, 2.0296, 3.7857, 3.7958, 2.1620, 2.2390],\n",
            "        [0.7470, 1.2308, 0.8209, 1.2359, 1.1540, 0.8848, 0.8643],\n",
            "        [3.2425, 4.1616, 2.2175, 4.1522, 4.1613, 2.3998, 2.4729],\n",
            "        [1.9838, 2.8159, 1.5724, 2.7988, 2.7662, 1.6881, 1.7010]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "186\n",
            "tensor([[1.4882, 2.2046, 1.2881, 2.1920, 2.1330, 1.4046, 1.3787],\n",
            "        [1.3478, 2.0249, 1.2043, 2.0135, 1.9501, 1.3125, 1.2846],\n",
            "        [2.9038, 3.8434, 2.0469, 3.8316, 3.8448, 2.1782, 2.2609],\n",
            "        [1.9802, 2.8049, 1.5637, 2.7873, 2.7547, 1.6914, 1.6938],\n",
            "        [1.2501, 1.8992, 1.1467, 1.8911, 1.8240, 1.2493, 1.2188]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "187\n",
            "tensor([[2.1100, 2.9572, 1.6298, 2.9355, 2.9120, 1.7603, 1.7710],\n",
            "        [1.8735, 2.6791, 1.5043, 2.6603, 2.6206, 1.6289, 1.6256],\n",
            "        [1.3447, 2.0233, 1.2024, 2.0092, 1.9463, 1.3073, 1.2807],\n",
            "        [0.9711, 1.5330, 0.9697, 1.5305, 1.4540, 1.0552, 1.0243],\n",
            "        [2.8861, 3.8201, 2.0356, 3.8056, 3.8212, 2.1686, 2.2470]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "188\n",
            "tensor([[3.2603, 4.1826, 2.2191, 4.1684, 4.1851, 2.4013, 2.4768],\n",
            "        [3.2549, 4.1764, 2.2183, 4.1635, 4.1844, 2.3950, 2.4699],\n",
            "        [2.5481, 3.4657, 1.8611, 3.4427, 3.4474, 1.9754, 2.0389],\n",
            "        [2.8498, 3.7843, 2.0140, 3.7662, 3.7831, 2.1443, 2.2228],\n",
            "        [2.3075, 3.1892, 1.7339, 3.1663, 3.1556, 1.8502, 1.8905]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "189\n",
            "tensor([[2.1565, 3.0137, 1.6551, 2.9888, 2.9700, 1.7771, 1.7976],\n",
            "        [1.8635, 2.6675, 1.4956, 2.6449, 2.6108, 1.6159, 1.6157],\n",
            "        [2.6977, 3.6251, 1.9365, 3.6030, 3.6150, 2.0637, 2.1292],\n",
            "        [3.2662, 4.1875, 2.2200, 4.1710, 4.1893, 2.4038, 2.4768],\n",
            "        [1.7068, 2.4762, 1.4061, 2.4514, 2.4137, 1.5252, 1.5136]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "190\n",
            "tensor([[2.8507, 3.7842, 2.0103, 3.7621, 3.7816, 2.1335, 2.2149],\n",
            "        [3.2058, 4.1342, 2.1910, 4.1208, 4.1504, 2.3518, 2.4322],\n",
            "        [2.0476, 2.8871, 1.5963, 2.8634, 2.8405, 1.7178, 1.7277],\n",
            "        [0.9451, 1.4990, 0.9513, 1.4955, 1.4194, 1.0318, 1.0047],\n",
            "        [2.3800, 3.2715, 1.7712, 3.2472, 3.2412, 1.8971, 1.9350]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "191\n",
            "tensor([[1.5353, 2.2614, 1.3083, 2.2409, 2.1923, 1.4224, 1.3998],\n",
            "        [3.1132, 4.0424, 2.1417, 4.0284, 4.0567, 2.2946, 2.3744],\n",
            "        [3.0960, 4.0255, 2.1335, 4.0094, 4.0400, 2.2829, 2.3631],\n",
            "        [3.1616, 4.0848, 2.1657, 4.0704, 4.0978, 2.3336, 2.4044],\n",
            "        [1.9441, 2.7620, 1.5365, 2.7371, 2.7092, 1.6599, 1.6612]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "192\n",
            "tensor([[2.8404, 3.7757, 2.0020, 3.7538, 3.7796, 2.1159, 2.2030],\n",
            "        [3.0425, 3.9743, 2.1035, 3.9590, 3.9873, 2.2499, 2.3284],\n",
            "        [1.8453, 2.6431, 1.4822, 2.6197, 2.5872, 1.6046, 1.5982],\n",
            "        [2.9834, 3.9169, 2.0729, 3.8978, 3.9314, 2.2035, 2.2881],\n",
            "        [3.1417, 4.0688, 2.1551, 4.0557, 4.0870, 2.3159, 2.3898]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "193\n",
            "tensor([[2.4829, 3.3871, 1.8199, 3.3605, 3.3656, 1.9444, 1.9878],\n",
            "        [0.8291, 1.3382, 0.8708, 1.3395, 1.2619, 0.9482, 0.9193],\n",
            "        [1.4326, 2.1331, 1.2489, 2.1140, 2.0609, 1.3609, 1.3305],\n",
            "        [1.0205, 1.5971, 0.9951, 1.5899, 1.5193, 1.0878, 1.0538],\n",
            "        [3.2593, 4.1777, 2.2106, 4.1627, 4.1947, 2.3886, 2.4584]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "194\n",
            "tensor([[0.9080, 1.4437, 0.9210, 1.4410, 1.3668, 1.0059, 0.9731],\n",
            "        [1.3481, 2.0207, 1.1961, 2.0050, 1.9482, 1.3093, 1.2735],\n",
            "        [2.2335, 3.1023, 1.6892, 3.0753, 3.0671, 1.8062, 1.8330],\n",
            "        [1.7530, 2.5283, 1.4273, 2.5041, 2.4681, 1.5438, 1.5341],\n",
            "        [1.4035, 2.0905, 1.2267, 2.0727, 2.0183, 1.3390, 1.3083]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "195\n",
            "tensor([[2.1687, 3.0247, 1.6559, 2.9981, 2.9876, 1.7714, 1.7907],\n",
            "        [2.0449, 2.8680, 1.5830, 2.8427, 2.8230, 1.7123, 1.7131],\n",
            "        [3.0136, 3.9346, 2.0857, 3.9180, 3.9467, 2.2367, 2.3008],\n",
            "        [2.2619, 3.1311, 1.7023, 3.1035, 3.0983, 1.8260, 1.8478],\n",
            "        [0.9109, 1.4489, 0.9251, 1.4456, 1.3727, 1.0090, 0.9749]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "196\n",
            "tensor([[2.4430, 3.3414, 1.7989, 3.3132, 3.3212, 1.9190, 1.9567],\n",
            "        [2.1434, 2.9946, 1.6401, 2.9672, 2.9565, 1.7598, 1.7739],\n",
            "        [1.0531, 1.6366, 1.0166, 1.6290, 1.5607, 1.1093, 1.0712],\n",
            "        [1.6966, 2.4583, 1.3955, 2.4341, 2.3974, 1.5125, 1.4947],\n",
            "        [1.8590, 2.6519, 1.4852, 2.6261, 2.5981, 1.6098, 1.5967]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "197\n",
            "tensor([[3.2397, 4.1463, 2.1971, 4.1271, 4.1548, 2.3784, 2.4391],\n",
            "        [2.9163, 3.8448, 2.0373, 3.8214, 3.8559, 2.1604, 2.2328],\n",
            "        [2.7987, 3.7250, 1.9776, 3.7006, 3.7296, 2.1004, 2.1645],\n",
            "        [3.2078, 4.1223, 2.1827, 4.1070, 4.1422, 2.3532, 2.4122],\n",
            "        [2.4889, 3.3826, 1.8197, 3.3558, 3.3644, 1.9441, 1.9789]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "198\n",
            "tensor([[0.8119, 1.3158, 0.8608, 1.3179, 1.2401, 0.9342, 0.9031],\n",
            "        [2.3390, 3.2225, 1.7429, 3.1946, 3.1941, 1.8628, 1.8913],\n",
            "        [2.6517, 3.5662, 1.9048, 3.5401, 3.5587, 2.0359, 2.0785],\n",
            "        [2.2966, 3.1772, 1.7248, 3.1477, 3.1471, 1.8364, 1.8642],\n",
            "        [1.1544, 1.7738, 1.0797, 1.7618, 1.6958, 1.1790, 1.1397]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "199\n",
            "tensor([[3.2524, 4.1661, 2.2055, 4.1505, 4.1804, 2.3829, 2.4445],\n",
            "        [3.2503, 4.1640, 2.2060, 4.1485, 4.1773, 2.3831, 2.4433],\n",
            "        [2.0406, 2.8768, 1.5887, 2.8472, 2.8274, 1.7004, 1.7073],\n",
            "        [2.0634, 2.9050, 1.5996, 2.8758, 2.8592, 1.7134, 1.7221],\n",
            "        [1.5675, 2.2987, 1.3235, 2.2759, 2.2310, 1.4413, 1.4106]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "200\n",
            "tensor([[3.1903, 4.1091, 2.1766, 4.0949, 4.1232, 2.3349, 2.4067],\n",
            "        [2.5146, 3.4269, 1.8383, 3.3977, 3.4094, 1.9450, 1.9973],\n",
            "        [2.6871, 3.5997, 1.9238, 3.5746, 3.5914, 2.0532, 2.1003],\n",
            "        [1.2585, 1.9110, 1.1489, 1.8980, 1.8340, 1.2505, 1.2126],\n",
            "        [1.8809, 2.6887, 1.5032, 2.6617, 2.6323, 1.6203, 1.6121]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "201\n",
            "tensor([[2.6139, 3.5378, 1.8880, 3.5071, 3.5236, 1.9995, 2.0591],\n",
            "        [1.7412, 2.5209, 1.4275, 2.4957, 2.4593, 1.5391, 1.5250],\n",
            "        [2.3998, 3.2959, 1.7783, 3.2664, 3.2708, 1.8914, 1.9288],\n",
            "        [0.8795, 1.4112, 0.9083, 1.4082, 1.3320, 0.9852, 0.9515],\n",
            "        [2.6770, 3.5977, 1.9199, 3.5684, 3.5855, 2.0400, 2.0946]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "202\n",
            "tensor([[3.1624, 4.0885, 2.1634, 4.0691, 4.1000, 2.3228, 2.3942],\n",
            "        [1.0809, 1.6812, 1.0368, 1.6721, 1.6030, 1.1315, 1.0930],\n",
            "        [1.4397, 2.1497, 1.2550, 2.1281, 2.0773, 1.3621, 1.3333],\n",
            "        [2.2731, 3.1553, 1.7126, 3.1251, 3.1160, 1.8297, 1.8575],\n",
            "        [1.2979, 1.9609, 1.1718, 1.9433, 1.8852, 1.2757, 1.2391]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "203\n",
            "tensor([[0.6888, 1.1539, 0.7748, 1.1555, 1.0754, 0.8310, 0.8141],\n",
            "        [1.3870, 2.0830, 1.2241, 2.0637, 2.0080, 1.3276, 1.3005],\n",
            "        [2.6364, 3.5602, 1.8975, 3.5313, 3.5432, 2.0093, 2.0760],\n",
            "        [2.5002, 3.4170, 1.8303, 3.3876, 3.3944, 1.9480, 1.9975],\n",
            "        [2.2150, 3.0945, 1.6833, 3.0645, 3.0544, 1.7923, 1.8243]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "204\n",
            "tensor([[1.6851, 2.4616, 1.3980, 2.4371, 2.3958, 1.5059, 1.4963],\n",
            "        [3.1881, 4.1170, 2.1777, 4.0963, 4.1218, 2.3538, 2.4194],\n",
            "        [2.1998, 3.0815, 1.6759, 3.0505, 3.0419, 1.7840, 1.8160],\n",
            "        [1.3127, 1.9930, 1.1819, 1.9768, 1.9160, 1.2868, 1.2572],\n",
            "        [0.9252, 1.4815, 0.9395, 1.4757, 1.4010, 1.0162, 0.9887]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "205\n",
            "tensor([[1.2097, 1.8602, 1.1211, 1.8476, 1.7799, 1.2207, 1.1877],\n",
            "        [2.6076, 3.5467, 1.8894, 3.5184, 3.5309, 1.9965, 2.0672],\n",
            "        [3.0676, 4.0090, 2.1166, 3.9888, 4.0130, 2.2636, 2.3494],\n",
            "        [1.3302, 2.0134, 1.1913, 1.9964, 1.9355, 1.2958, 1.2670],\n",
            "        [1.9608, 2.7975, 1.5502, 2.7694, 2.7422, 1.6654, 1.6719]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "206\n",
            "tensor([[0.9674, 1.5385, 0.9686, 1.5340, 1.4564, 1.0477, 1.0210],\n",
            "        [1.4619, 2.1861, 1.2738, 2.1660, 2.1120, 1.3749, 1.3552],\n",
            "        [3.0285, 3.9762, 2.1004, 3.9567, 3.9877, 2.2361, 2.3224],\n",
            "        [3.2177, 4.1579, 2.1970, 4.1413, 4.1680, 2.3593, 2.4406],\n",
            "        [1.3422, 2.0344, 1.1937, 2.0108, 1.9553, 1.2938, 1.2716]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "207\n",
            "tensor([[3.2409, 4.1759, 2.2068, 4.1585, 4.1754, 2.3791, 2.4606],\n",
            "        [2.7869, 3.7302, 1.9806, 3.7082, 3.7233, 2.1096, 2.1792],\n",
            "        [3.0002, 3.9494, 2.0862, 3.9329, 3.9593, 2.2177, 2.3079],\n",
            "        [1.3978, 2.1061, 1.2327, 2.0851, 2.0290, 1.3332, 1.3110],\n",
            "        [1.7309, 2.5262, 1.4240, 2.5003, 2.4600, 1.5334, 1.5297]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "208\n",
            "tensor([[1.9384, 2.7793, 1.5425, 2.7538, 2.7239, 1.6510, 1.6615],\n",
            "        [3.2238, 4.1620, 2.1997, 4.1482, 4.1701, 2.3669, 2.4479],\n",
            "        [3.2468, 4.1855, 2.2122, 4.1696, 4.1895, 2.3859, 2.4626],\n",
            "        [2.4228, 3.3463, 1.7985, 3.3191, 3.3141, 1.9141, 1.9608],\n",
            "        [0.9413, 1.5065, 0.9531, 1.5025, 1.4249, 1.0302, 1.0035]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "209\n",
            "tensor([[2.8526, 3.8110, 2.0167, 3.7917, 3.8106, 2.1372, 2.2210],\n",
            "        [0.8318, 1.3563, 0.8815, 1.3577, 1.2759, 0.9528, 0.9244],\n",
            "        [2.4424, 3.3715, 1.8095, 3.3458, 3.3456, 1.9103, 1.9700],\n",
            "        [2.6801, 3.6343, 1.9291, 3.6128, 3.6222, 2.0410, 2.1174],\n",
            "        [2.3298, 3.2329, 1.7486, 3.2096, 3.1983, 1.8676, 1.9037]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "210\n",
            "tensor([[2.3310, 3.2427, 1.7502, 3.2187, 3.2062, 1.8576, 1.9046],\n",
            "        [3.2504, 4.1887, 2.2140, 4.1758, 4.1909, 2.3894, 2.4671],\n",
            "        [0.9947, 1.5803, 0.9896, 1.5773, 1.4979, 1.0759, 1.0430],\n",
            "        [1.2125, 1.8712, 1.1233, 1.8585, 1.7885, 1.2225, 1.1913],\n",
            "        [0.7992, 1.3141, 0.8606, 1.3176, 1.2333, 0.9290, 0.9025]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "211\n",
            "tensor([[0.8335, 1.3638, 0.8839, 1.3663, 1.2805, 0.9559, 0.9285],\n",
            "        [2.8466, 3.8131, 2.0136, 3.7939, 3.8104, 2.1251, 2.2149],\n",
            "        [2.8895, 3.8525, 2.0339, 3.8354, 3.8525, 2.1585, 2.2420],\n",
            "        [1.6072, 2.3774, 1.3592, 2.3568, 2.3060, 1.4717, 1.4514],\n",
            "        [3.1079, 4.0639, 2.1469, 4.0528, 4.0734, 2.3029, 2.3782]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "212\n",
            "tensor([[3.2304, 4.1773, 2.2057, 4.1678, 4.1826, 2.3778, 2.4523],\n",
            "        [3.2065, 4.1500, 2.1919, 4.1360, 4.1500, 2.3687, 2.4426],\n",
            "        [2.5841, 3.5309, 1.8829, 3.5103, 3.5085, 1.9979, 2.0604],\n",
            "        [0.9020, 1.4565, 0.9306, 1.4559, 1.3724, 1.0065, 0.9768],\n",
            "        [0.9510, 1.5231, 0.9633, 1.5222, 1.4397, 1.0474, 1.0130]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "213\n",
            "tensor([[1.0937, 1.7125, 1.0514, 1.7066, 1.6293, 1.1435, 1.1090],\n",
            "        [2.6569, 3.6133, 1.9203, 3.5922, 3.5959, 2.0328, 2.1013],\n",
            "        [2.0980, 2.9715, 1.6292, 2.9477, 2.9187, 1.7417, 1.7595],\n",
            "        [1.6162, 2.3890, 1.3636, 2.3683, 2.3138, 1.4749, 1.4572],\n",
            "        [1.0490, 1.6536, 1.0251, 1.6511, 1.5700, 1.1154, 1.0799]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "214\n",
            "tensor([[1.0934, 1.7155, 1.0555, 1.7108, 1.6302, 1.1493, 1.1102],\n",
            "        [2.7274, 3.6890, 1.9553, 3.6666, 3.6729, 2.0708, 2.1411],\n",
            "        [1.1338, 1.7679, 1.0797, 1.7602, 1.6830, 1.1757, 1.1391],\n",
            "        [1.3798, 2.0890, 1.2257, 2.0740, 2.0068, 1.3338, 1.3034],\n",
            "        [2.2233, 3.1260, 1.6957, 3.1013, 3.0804, 1.8053, 1.8359]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "215\n",
            "tensor([[3.1204, 4.0796, 2.1497, 4.0659, 4.0779, 2.3046, 2.3812],\n",
            "        [3.1987, 4.1476, 2.1886, 4.1380, 4.1538, 2.3395, 2.4230],\n",
            "        [3.2417, 4.1870, 2.2112, 4.1759, 4.1872, 2.3825, 2.4543],\n",
            "        [1.5735, 2.3355, 1.3389, 2.3161, 2.2580, 1.4536, 1.4266],\n",
            "        [1.8937, 2.7344, 1.5198, 2.7101, 2.6704, 1.6325, 1.6311]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "216\n",
            "tensor([[3.1689, 4.1183, 2.1739, 4.0995, 4.1084, 2.3369, 2.4092],\n",
            "        [1.4432, 2.1750, 1.2673, 2.1568, 2.0920, 1.3697, 1.3423],\n",
            "        [2.0361, 2.9054, 1.5975, 2.8786, 2.8482, 1.7080, 1.7160],\n",
            "        [1.9423, 2.7908, 1.5476, 2.7639, 2.7268, 1.6600, 1.6574],\n",
            "        [1.6722, 2.4607, 1.3962, 2.4364, 2.3847, 1.5104, 1.4875]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "217\n",
            "tensor([[2.1061, 2.9855, 1.6353, 2.9587, 2.9305, 1.7461, 1.7569],\n",
            "        [1.7061, 2.5028, 1.4144, 2.4776, 2.4270, 1.5247, 1.5077],\n",
            "        [3.1436, 4.0961, 2.1605, 4.0804, 4.1006, 2.3009, 2.3809],\n",
            "        [3.2472, 4.1949, 2.2151, 4.1788, 4.1925, 2.3839, 2.4509],\n",
            "        [1.9590, 2.8112, 1.5539, 2.7820, 2.7481, 1.6624, 1.6649]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "218\n",
            "tensor([[1.6707, 2.4619, 1.3954, 2.4369, 2.3845, 1.5033, 1.4839],\n",
            "        [2.9071, 3.8748, 2.0428, 3.8518, 3.8698, 2.1653, 2.2393],\n",
            "        [3.2252, 4.1710, 2.1998, 4.1503, 4.1617, 2.3787, 2.4389],\n",
            "        [0.9130, 1.4729, 0.9360, 1.4703, 1.3873, 1.0144, 0.9796],\n",
            "        [0.8531, 1.3877, 0.8877, 1.3848, 1.3029, 0.9630, 0.9325]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "219\n",
            "tensor([[0.5675, 0.9972, 0.6988, 1.0036, 0.9177, 0.7406, 0.7270],\n",
            "        [1.1437, 1.7851, 1.0839, 1.7736, 1.6968, 1.1798, 1.1413],\n",
            "        [1.1462, 1.7859, 1.0857, 1.7732, 1.6973, 1.1785, 1.1406],\n",
            "        [1.0083, 1.6034, 0.9993, 1.5972, 1.5146, 1.0840, 1.0463],\n",
            "        [2.7447, 3.7157, 1.9609, 3.6846, 3.6958, 2.0676, 2.1410]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "220\n",
            "tensor([[2.4459, 3.3761, 1.8083, 3.3463, 3.3354, 1.9291, 1.9610],\n",
            "        [1.5369, 2.2940, 1.3159, 2.2685, 2.2112, 1.4280, 1.3965],\n",
            "        [3.2110, 4.1625, 2.1938, 4.1422, 4.1562, 2.3579, 2.4241],\n",
            "        [0.9104, 1.4719, 0.9367, 1.4687, 1.3831, 1.0136, 0.9782],\n",
            "        [2.7321, 3.6971, 1.9530, 3.6673, 3.6719, 2.0700, 2.1339]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "221\n",
            "tensor([[2.9864, 3.9486, 2.0790, 3.9232, 3.9276, 2.2216, 2.2900],\n",
            "        [2.4186, 3.3525, 1.7962, 3.3204, 3.3073, 1.9084, 1.9438],\n",
            "        [0.8530, 1.3938, 0.8993, 1.3919, 1.3046, 0.9733, 0.9371],\n",
            "        [1.9841, 2.8486, 1.5682, 2.8162, 2.7801, 1.6768, 1.6773],\n",
            "        [3.2211, 4.1691, 2.1941, 4.1449, 4.1541, 2.3646, 2.4309]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "222\n",
            "tensor([[2.2287, 3.1312, 1.6915, 3.0985, 3.0744, 1.8131, 1.8286],\n",
            "        [3.2337, 4.1813, 2.2018, 4.1569, 4.1694, 2.3719, 2.4354],\n",
            "        [1.4707, 2.2128, 1.2794, 2.1873, 2.1240, 1.3818, 1.3545],\n",
            "        [2.7046, 3.6603, 1.9392, 3.6304, 3.6320, 2.0655, 2.1128],\n",
            "        [1.5049, 2.2534, 1.2993, 2.2278, 2.1685, 1.4051, 1.3742]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "223\n",
            "tensor([[3.2273, 4.1688, 2.1951, 4.1471, 4.1506, 2.3783, 2.4372],\n",
            "        [1.0154, 1.6150, 1.0017, 1.6069, 1.5231, 1.0887, 1.0495],\n",
            "        [0.8267, 1.3563, 0.8784, 1.3550, 1.2674, 0.9531, 0.9166],\n",
            "        [3.1162, 4.0684, 2.1420, 4.0467, 4.0644, 2.2787, 2.3580],\n",
            "        [3.0370, 3.9956, 2.1014, 3.9751, 3.9896, 2.2501, 2.3131]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "224\n",
            "tensor([[0.8344, 1.3677, 0.8850, 1.3663, 1.2785, 0.9611, 0.9227],\n",
            "        [3.1146, 4.0683, 2.1421, 4.0495, 4.0645, 2.3053, 2.3600],\n",
            "        [2.6949, 3.6544, 1.9316, 3.6245, 3.6277, 2.0513, 2.1076],\n",
            "        [1.9170, 2.7612, 1.5278, 2.7325, 2.6901, 1.6506, 1.6364],\n",
            "        [2.0231, 2.8872, 1.5849, 2.8574, 2.8205, 1.7055, 1.7015]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "225\n",
            "tensor([[2.9115, 3.8739, 2.0390, 3.8472, 3.8566, 2.1706, 2.2351],\n",
            "        [2.6490, 3.6056, 1.9060, 3.5746, 3.5755, 2.0219, 2.0797],\n",
            "        [3.2058, 4.1541, 2.1844, 4.1365, 4.1451, 2.3638, 2.4200],\n",
            "        [2.1650, 3.0554, 1.6599, 3.0243, 2.9962, 1.7797, 1.7885],\n",
            "        [2.1222, 3.0047, 1.6365, 2.9747, 2.9442, 1.7584, 1.7629]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "226\n",
            "tensor([[2.3470, 3.2671, 1.7514, 3.2362, 3.2181, 1.8712, 1.8982],\n",
            "        [2.8117, 3.7754, 1.9867, 3.7485, 3.7550, 2.1190, 2.1777],\n",
            "        [2.4467, 3.3706, 1.8024, 3.3426, 3.3276, 1.9326, 1.9591],\n",
            "        [3.1430, 4.0924, 2.1515, 4.0754, 4.0851, 2.3262, 2.3800],\n",
            "        [3.2132, 4.1528, 2.1824, 4.1333, 4.1388, 2.3679, 2.4257]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "227\n",
            "tensor([[2.7227, 3.6726, 1.9393, 3.6482, 3.6454, 2.0770, 2.1274],\n",
            "        [2.3253, 3.2409, 1.7397, 3.2131, 3.1909, 1.8687, 1.8892],\n",
            "        [3.1296, 4.0769, 2.1424, 4.0622, 4.0735, 2.3117, 2.3703],\n",
            "        [2.9630, 3.9170, 2.0584, 3.8984, 3.9045, 2.2154, 2.2729],\n",
            "        [1.1509, 1.7905, 1.0856, 1.7813, 1.6995, 1.1880, 1.1431]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "228\n",
            "tensor([[3.1802, 4.1104, 2.1610, 4.0925, 4.1003, 2.3542, 2.4024],\n",
            "        [2.2269, 3.1266, 1.6892, 3.0982, 3.0714, 1.8127, 1.8273],\n",
            "        [0.6891, 1.1645, 0.7831, 1.1710, 1.0796, 0.8488, 0.8178],\n",
            "        [1.2235, 1.8870, 1.1295, 1.8770, 1.7975, 1.2422, 1.1946],\n",
            "        [2.4078, 3.3273, 1.7798, 3.3007, 3.2811, 1.9198, 1.9395]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "229\n",
            "tensor([[1.4152, 2.1337, 1.2429, 2.1190, 2.0466, 1.3606, 1.3205],\n",
            "        [2.4798, 3.4128, 1.8184, 3.3875, 3.3733, 1.9443, 1.9820],\n",
            "        [2.9759, 3.9325, 2.0616, 3.9164, 3.9237, 2.2092, 2.2780],\n",
            "        [2.6504, 3.5954, 1.9008, 3.5733, 3.5644, 2.0435, 2.0879],\n",
            "        [1.3852, 2.0955, 1.2275, 2.0828, 2.0075, 1.3472, 1.3011]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "230\n",
            "tensor([[2.5339, 3.4695, 1.8422, 3.4479, 3.4333, 1.9762, 2.0162],\n",
            "        [0.8509, 1.3879, 0.8936, 1.3913, 1.2993, 0.9768, 0.9371],\n",
            "        [2.5447, 3.4787, 1.8475, 3.4568, 3.4411, 1.9919, 2.0251],\n",
            "        [1.1372, 1.7714, 1.0738, 1.7644, 1.6804, 1.1843, 1.1352],\n",
            "        [2.7237, 3.6745, 1.9338, 3.6529, 3.6470, 2.0650, 2.1282]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "231\n",
            "tensor([[0.9406, 1.5101, 0.9526, 1.5108, 1.4197, 1.0444, 1.0017],\n",
            "        [2.0029, 2.8595, 1.5662, 2.8380, 2.7928, 1.7000, 1.6941],\n",
            "        [1.7194, 2.5164, 1.4137, 2.4986, 2.4375, 1.5437, 1.5178],\n",
            "        [1.2605, 1.9349, 1.1520, 1.9275, 1.8452, 1.2668, 1.2210],\n",
            "        [2.4533, 3.3798, 1.7985, 3.3583, 3.3362, 1.9347, 1.9699]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "232\n",
            "tensor([[0.8827, 1.4307, 0.9150, 1.4351, 1.3396, 1.0034, 0.9616],\n",
            "        [3.2077, 4.1364, 2.1694, 4.1279, 4.1220, 2.3659, 2.4295],\n",
            "        [1.3410, 2.0378, 1.1967, 2.0273, 1.9483, 1.3178, 1.2740],\n",
            "        [2.0345, 2.8933, 1.5810, 2.8732, 2.8270, 1.7196, 1.7147],\n",
            "        [2.0359, 2.8965, 1.5828, 2.8776, 2.8323, 1.7219, 1.7175]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "233\n",
            "tensor([[2.7484, 3.7039, 1.9458, 3.6874, 3.6808, 2.0782, 2.1468],\n",
            "        [1.9797, 2.8259, 1.5517, 2.8076, 2.7582, 1.6927, 1.6808],\n",
            "        [1.1776, 1.8251, 1.0991, 1.8171, 1.7327, 1.2084, 1.1641],\n",
            "        [1.7981, 2.6102, 1.4557, 2.5916, 2.5338, 1.5870, 1.5667],\n",
            "        [2.9732, 3.9182, 2.0545, 3.9098, 3.9076, 2.2104, 2.2817]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "234\n",
            "tensor([[1.0599, 1.6690, 1.0272, 1.6676, 1.5765, 1.1295, 1.0863],\n",
            "        [1.3292, 2.0174, 1.1866, 2.0093, 1.9280, 1.3089, 1.2658],\n",
            "        [1.7187, 2.5098, 1.4070, 2.4931, 2.4304, 1.5417, 1.5170],\n",
            "        [1.1252, 1.7503, 1.0577, 1.7412, 1.6577, 1.1714, 1.1243],\n",
            "        [1.6252, 2.3936, 1.3546, 2.3771, 2.3102, 1.4908, 1.4579]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "235\n",
            "tensor([[2.8765, 3.8250, 2.0043, 3.8140, 3.8078, 2.1566, 2.2249],\n",
            "        [3.0875, 4.0288, 2.1081, 4.0240, 4.0191, 2.2908, 2.3562],\n",
            "        [1.6316, 2.4011, 1.3618, 2.3858, 2.3179, 1.4940, 1.4610],\n",
            "        [1.9530, 2.7984, 1.5376, 2.7811, 2.7297, 1.6720, 1.6656],\n",
            "        [2.9043, 3.8624, 2.0185, 3.8496, 3.8509, 2.1600, 2.2400]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "236\n",
            "tensor([[3.2189, 4.1446, 2.1730, 4.1449, 4.1367, 2.3736, 2.4374],\n",
            "        [2.1661, 3.0473, 1.6496, 3.0315, 2.9902, 1.7883, 1.7979],\n",
            "        [0.9591, 1.5312, 0.9616, 1.5348, 1.4400, 1.0597, 1.0158],\n",
            "        [2.7158, 3.6500, 1.9248, 3.6384, 3.6249, 2.0769, 2.1314],\n",
            "        [2.5472, 3.4825, 1.8440, 3.4682, 3.4482, 1.9850, 2.0294]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "237\n",
            "tensor([[2.7744, 3.7265, 1.9549, 3.7133, 3.7049, 2.0926, 2.1613],\n",
            "        [2.7013, 3.6449, 1.9166, 3.6322, 3.6198, 2.0485, 2.1183],\n",
            "        [1.0512, 1.6542, 1.0213, 1.6549, 1.5630, 1.1229, 1.0785],\n",
            "        [2.9421, 3.8897, 2.0340, 3.8828, 3.8808, 2.1805, 2.2617],\n",
            "        [3.2022, 4.1286, 2.1621, 4.1302, 4.1249, 2.3558, 2.4256]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "238\n",
            "tensor([[3.1896, 4.1164, 2.1526, 4.1174, 4.1157, 2.3408, 2.4143],\n",
            "        [0.6998, 1.1771, 0.7909, 1.1885, 1.0904, 0.8586, 0.8293],\n",
            "        [1.8104, 2.6232, 1.4550, 2.6065, 2.5477, 1.5847, 1.5749],\n",
            "        [1.7265, 2.5173, 1.4109, 2.5047, 2.4391, 1.5438, 1.5233],\n",
            "        [2.5054, 3.4291, 1.8164, 3.4160, 3.3888, 1.9596, 2.0036]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "239\n",
            "tensor([[0.8961, 1.4459, 0.9194, 1.4524, 1.3550, 1.0106, 0.9712],\n",
            "        [2.3260, 3.2241, 1.7238, 3.2105, 3.1719, 1.8632, 1.8936],\n",
            "        [2.4597, 3.3781, 1.7899, 3.3643, 3.3370, 1.9209, 1.9746],\n",
            "        [1.1854, 1.8282, 1.0974, 1.8264, 1.7372, 1.2090, 1.1682],\n",
            "        [1.1514, 1.7869, 1.0792, 1.7847, 1.6953, 1.1874, 1.1469]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "240\n",
            "tensor([[3.2185, 4.1331, 2.1581, 4.1359, 4.1203, 2.3609, 2.4380],\n",
            "        [3.1608, 4.0883, 2.1315, 4.0887, 4.0818, 2.3147, 2.3972],\n",
            "        [1.1861, 1.8303, 1.0980, 1.8282, 1.7377, 1.2072, 1.1696],\n",
            "        [3.2190, 4.1328, 2.1572, 4.1308, 4.1145, 2.3651, 2.4396],\n",
            "        [2.4899, 3.4109, 1.8033, 3.3989, 3.3699, 1.9335, 1.9930]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "241\n",
            "tensor([[0.9479, 1.5134, 0.9502, 1.5195, 1.4223, 1.0447, 1.0066],\n",
            "        [0.9443, 1.5085, 0.9475, 1.5131, 1.4167, 1.0370, 1.0031],\n",
            "        [2.9793, 3.9172, 2.0375, 3.9163, 3.9052, 2.1828, 2.2845],\n",
            "        [2.8750, 3.8124, 1.9882, 3.8096, 3.7962, 2.1372, 2.2234],\n",
            "        [1.6467, 2.4170, 1.3620, 2.4076, 2.3349, 1.4927, 1.4743]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "242\n",
            "tensor([[3.1916, 4.1093, 2.1403, 4.1155, 4.1105, 2.3256, 2.4122],\n",
            "        [2.5726, 3.5034, 1.8390, 3.4919, 3.4697, 1.9678, 2.0394],\n",
            "        [0.9665, 1.5364, 0.9616, 1.5433, 1.4455, 1.0570, 1.0197],\n",
            "        [1.1567, 1.7869, 1.0724, 1.7856, 1.6935, 1.1769, 1.1463],\n",
            "        [2.9178, 3.8585, 2.0063, 3.8552, 3.8485, 2.1456, 2.2448]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "243\n",
            "tensor([[0.7512, 1.2426, 0.8198, 1.2555, 1.1562, 0.8927, 0.8647],\n",
            "        [0.8154, 1.3300, 0.8611, 1.3420, 1.2420, 0.9423, 0.9121],\n",
            "        [1.5691, 2.3166, 1.3141, 2.3089, 2.2343, 1.4395, 1.4194],\n",
            "        [2.1434, 3.0069, 1.6182, 2.9972, 2.9483, 1.7511, 1.7805],\n",
            "        [2.6774, 3.6027, 1.8861, 3.5954, 3.5748, 2.0263, 2.1025]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "244\n",
            "tensor([[2.7678, 3.7011, 1.9296, 3.6959, 3.6815, 2.0603, 2.1522],\n",
            "        [3.2432, 4.1482, 2.1591, 4.1540, 4.1356, 2.3590, 2.4489],\n",
            "        [0.7201, 1.2005, 0.7957, 1.2122, 1.1143, 0.8630, 0.8408],\n",
            "        [1.7351, 2.5191, 1.4035, 2.5102, 2.4422, 1.5277, 1.5231],\n",
            "        [1.6190, 2.3734, 1.3401, 2.3668, 2.2922, 1.4626, 1.4493]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "245\n",
            "tensor([[0.7619, 1.2569, 0.8254, 1.2675, 1.1691, 0.8947, 0.8716],\n",
            "        [2.1335, 2.9881, 1.6121, 2.9789, 2.9299, 1.7388, 1.7680],\n",
            "        [2.7010, 3.6287, 1.8965, 3.6249, 3.6051, 2.0241, 2.1147],\n",
            "        [2.9176, 3.8380, 2.0005, 3.8408, 3.8254, 2.1494, 2.2436],\n",
            "        [2.3721, 3.2607, 1.7346, 3.2549, 3.2190, 1.8652, 1.9150]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "246\n",
            "tensor([[2.5599, 3.4577, 1.8231, 3.4557, 3.4220, 1.9470, 2.0281],\n",
            "        [2.6789, 3.5923, 1.8851, 3.5917, 3.5694, 2.0201, 2.0999],\n",
            "        [1.5431, 2.2743, 1.2963, 2.2702, 2.1936, 1.4122, 1.4001],\n",
            "        [2.6759, 3.5923, 1.8844, 3.5899, 3.5713, 2.0116, 2.0973],\n",
            "        [1.7240, 2.4983, 1.3967, 2.4919, 2.4231, 1.5205, 1.5159]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "247\n",
            "tensor([[2.1918, 3.0486, 1.6424, 3.0441, 2.9985, 1.7637, 1.8043],\n",
            "        [1.1354, 1.7494, 1.0622, 1.7555, 1.6624, 1.1580, 1.1308],\n",
            "        [1.4422, 2.1454, 1.2420, 2.1435, 2.0631, 1.3495, 1.3339],\n",
            "        [1.2368, 1.8803, 1.1236, 1.8861, 1.7945, 1.2279, 1.2011],\n",
            "        [3.1798, 4.0770, 2.1255, 4.0891, 4.0773, 2.2995, 2.4022]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "248\n",
            "tensor([[0.7881, 1.2841, 0.8459, 1.2997, 1.1996, 0.9118, 0.8894],\n",
            "        [0.8770, 1.4048, 0.9042, 1.4207, 1.3197, 0.9811, 0.9541],\n",
            "        [1.1537, 1.7713, 1.0756, 1.7803, 1.6857, 1.1730, 1.1451],\n",
            "        [1.0835, 1.6785, 1.0287, 1.6864, 1.5932, 1.1254, 1.0955],\n",
            "        [2.7918, 3.7091, 1.9404, 3.7121, 3.6964, 2.0583, 2.1652]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "249\n",
            "tensor([[0.7085, 1.1733, 0.7882, 1.1903, 1.0918, 0.8487, 0.8304],\n",
            "        [2.6200, 3.5149, 1.8549, 3.5191, 3.4912, 1.9774, 2.0638],\n",
            "        [2.7831, 3.6940, 1.9358, 3.6983, 3.6833, 2.0533, 2.1590],\n",
            "        [2.7056, 3.6150, 1.8972, 3.6170, 3.5953, 2.0079, 2.1140],\n",
            "        [2.9727, 3.8846, 2.0255, 3.8940, 3.8892, 2.1382, 2.2687]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "250\n",
            "tensor([[1.2542, 1.8950, 1.1319, 1.9009, 1.8120, 1.2332, 1.2096],\n",
            "        [0.8327, 1.3404, 0.8715, 1.3560, 1.2566, 0.9416, 0.9201],\n",
            "        [2.3085, 3.1690, 1.6996, 3.1696, 3.1267, 1.8144, 1.8756],\n",
            "        [1.3842, 2.0626, 1.2080, 2.0645, 1.9824, 1.3101, 1.2946],\n",
            "        [3.2025, 4.0903, 2.1379, 4.1065, 4.0990, 2.2965, 2.4110]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "251\n",
            "tensor([[2.3334, 3.1986, 1.7158, 3.2001, 3.1605, 1.8198, 1.8876],\n",
            "        [1.6230, 2.3560, 1.3413, 2.3565, 2.2833, 1.4453, 1.4465],\n",
            "        [1.6271, 2.3610, 1.3442, 2.3619, 2.2885, 1.4504, 1.4510],\n",
            "        [2.4750, 3.3483, 1.7810, 3.3529, 3.3172, 1.8941, 1.9739],\n",
            "        [0.7675, 1.2487, 0.8297, 1.2673, 1.1671, 0.8936, 0.8724]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "252\n",
            "tensor([[3.2620, 4.1324, 2.1624, 4.1515, 4.1337, 2.3367, 2.4504],\n",
            "        [3.0903, 3.9723, 2.0770, 3.9952, 3.9818, 2.2102, 2.3404],\n",
            "        [1.4044, 2.0794, 1.2177, 2.0858, 2.0012, 1.3213, 1.3069],\n",
            "        [3.2093, 4.0820, 2.1349, 4.1058, 4.0944, 2.2778, 2.4112],\n",
            "        [1.0637, 1.6432, 1.0178, 1.6565, 1.5600, 1.1054, 1.0822]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "253\n",
            "tensor([[2.3387, 3.1810, 1.7066, 3.1854, 3.1412, 1.8277, 1.8903],\n",
            "        [2.4709, 3.3379, 1.7775, 3.3462, 3.3108, 1.8869, 1.9692],\n",
            "        [2.8785, 3.7682, 1.9737, 3.7838, 3.7678, 2.0883, 2.2110],\n",
            "        [3.2529, 4.1194, 2.1562, 4.1437, 4.1295, 2.3181, 2.4405],\n",
            "        [1.8704, 2.6487, 1.4748, 2.6536, 2.5883, 1.5804, 1.6026]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "254\n",
            "tensor([[3.0635, 3.9364, 2.0594, 3.9597, 3.9442, 2.1956, 2.3214],\n",
            "        [2.9252, 3.8077, 1.9933, 3.8251, 3.8092, 2.1124, 2.2369],\n",
            "        [3.1211, 3.9965, 2.0885, 4.0178, 4.0096, 2.2256, 2.3533],\n",
            "        [2.2021, 3.0355, 1.6406, 3.0389, 2.9924, 1.7448, 1.8032],\n",
            "        [3.2721, 4.1298, 2.1598, 4.1517, 4.1331, 2.3386, 2.4555]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "255\n",
            "tensor([[2.6348, 3.5065, 1.8523, 3.5180, 3.4895, 1.9681, 2.0659],\n",
            "        [2.4225, 3.2761, 1.7488, 3.2838, 3.2477, 1.8575, 1.9364],\n",
            "        [1.8328, 2.5914, 1.4467, 2.5960, 2.5293, 1.5635, 1.5756],\n",
            "        [2.1445, 2.9641, 1.6120, 2.9701, 2.9188, 1.7206, 1.7698],\n",
            "        [1.6175, 2.3345, 1.3309, 2.3398, 2.2638, 1.4399, 1.4411]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "256\n",
            "tensor([[0.8364, 1.3318, 0.8715, 1.3528, 1.2520, 0.9431, 0.9207],\n",
            "        [2.9894, 3.8675, 2.0205, 3.8869, 3.8738, 2.1360, 2.2747],\n",
            "        [2.3231, 3.1624, 1.6991, 3.1702, 3.1279, 1.8100, 1.8777],\n",
            "        [3.2236, 4.0797, 2.1354, 4.1074, 4.0934, 2.3035, 2.4205],\n",
            "        [3.2746, 4.1236, 2.1570, 4.1494, 4.1346, 2.3366, 2.4543]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "257\n",
            "tensor([[2.5104, 3.3624, 1.7936, 3.3750, 3.3432, 1.9063, 1.9890],\n",
            "        [0.9081, 1.4264, 0.9183, 1.4472, 1.3461, 0.9983, 0.9725],\n",
            "        [2.5101, 3.3686, 1.7935, 3.3783, 3.3440, 1.9078, 1.9914],\n",
            "        [2.8512, 3.7241, 1.9562, 3.7405, 3.7232, 2.0852, 2.1941],\n",
            "        [2.4543, 3.3039, 1.7646, 3.3140, 3.2763, 1.8827, 1.9582]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "258\n",
            "tensor([[1.2779, 1.9067, 1.1426, 1.9183, 1.8277, 1.2450, 1.2234],\n",
            "        [2.8846, 3.7636, 1.9721, 3.7812, 3.7693, 2.0804, 2.2106],\n",
            "        [0.9758, 1.5149, 0.9616, 1.5342, 1.4344, 1.0471, 1.0189],\n",
            "        [1.3126, 1.9493, 1.1607, 1.9603, 1.8719, 1.2645, 1.2447],\n",
            "        [2.8879, 3.7637, 1.9736, 3.7815, 3.7677, 2.0911, 2.2144]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "259\n",
            "tensor([[0.8243, 1.3126, 0.8654, 1.3351, 1.2330, 0.9386, 0.9123],\n",
            "        [1.3419, 1.9862, 1.1805, 1.9975, 1.9103, 1.2836, 1.2646],\n",
            "        [0.7924, 1.2706, 0.8430, 1.2914, 1.1909, 0.9125, 0.8884],\n",
            "        [2.0080, 2.7952, 1.5435, 2.8024, 2.7432, 1.6542, 1.6863],\n",
            "        [1.4100, 2.0707, 1.2186, 2.0820, 1.9954, 1.3271, 1.3093]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "260\n",
            "tensor([[1.4819, 2.1596, 1.2609, 2.1716, 2.0878, 1.3739, 1.3569],\n",
            "        [1.3311, 1.9671, 1.1725, 1.9784, 1.8886, 1.2780, 1.2547],\n",
            "        [1.2318, 1.8440, 1.1185, 1.8589, 1.7651, 1.2180, 1.1929],\n",
            "        [2.9834, 3.8514, 2.0217, 3.8745, 3.8588, 2.1491, 2.2727],\n",
            "        [2.9281, 3.7970, 1.9959, 3.8195, 3.8032, 2.1254, 2.2391]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "261\n",
            "tensor([[3.2615, 4.0950, 2.1516, 4.1211, 4.1005, 2.3464, 2.4495],\n",
            "        [0.8850, 1.3912, 0.9024, 1.4113, 1.3113, 0.9836, 0.9543],\n",
            "        [2.6306, 3.4881, 1.8529, 3.5067, 3.4758, 1.9727, 2.0641],\n",
            "        [3.0518, 3.9128, 2.0551, 3.9403, 3.9293, 2.1787, 2.3087],\n",
            "        [3.2653, 4.0972, 2.1531, 4.1248, 4.1025, 2.3517, 2.4514]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "262\n",
            "tensor([[2.4722, 3.3093, 1.7750, 3.3242, 3.2873, 1.8965, 1.9661],\n",
            "        [1.9260, 2.6910, 1.5018, 2.7026, 2.6372, 1.6202, 1.6356],\n",
            "        [0.7865, 1.2577, 0.8414, 1.2809, 1.1797, 0.9117, 0.8836],\n",
            "        [3.1943, 4.0408, 2.1245, 4.0739, 4.0628, 2.2795, 2.3962],\n",
            "        [1.0258, 1.5747, 0.9964, 1.5953, 1.4939, 1.0860, 1.0533]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "263\n",
            "tensor([[2.4813, 3.3229, 1.7829, 3.3398, 3.2996, 1.8985, 1.9716],\n",
            "        [3.0097, 3.8698, 2.0354, 3.8963, 3.8832, 2.1692, 2.2833],\n",
            "        [1.5464, 2.2317, 1.2953, 2.2448, 2.1623, 1.4139, 1.3974],\n",
            "        [3.2685, 4.1035, 2.1605, 4.1388, 4.1258, 2.3348, 2.4443],\n",
            "        [2.9024, 3.7566, 1.9850, 3.7811, 3.7614, 2.1225, 2.2210]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "264\n",
            "tensor([[2.8321, 3.6896, 1.9524, 3.7134, 3.6914, 2.0782, 2.1780],\n",
            "        [0.7412, 1.1959, 0.8113, 1.2202, 1.1188, 0.8783, 0.8504],\n",
            "        [0.9922, 1.5274, 0.9724, 1.5483, 1.4492, 1.0638, 1.0293],\n",
            "        [2.8719, 3.7302, 1.9728, 3.7539, 3.7345, 2.1036, 2.2046],\n",
            "        [1.7592, 2.4891, 1.4149, 2.5026, 2.4279, 1.5356, 1.5312]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "265\n",
            "tensor([[2.1929, 2.9958, 1.6430, 3.0103, 2.9576, 1.7598, 1.7974],\n",
            "        [1.1666, 1.7535, 1.0796, 1.7709, 1.6776, 1.1811, 1.1465],\n",
            "        [2.3660, 3.1823, 1.7238, 3.1983, 3.1536, 1.8610, 1.9020],\n",
            "        [2.9375, 3.7951, 2.0043, 3.8211, 3.8039, 2.1311, 2.2405],\n",
            "        [3.2610, 4.0920, 2.1584, 4.1284, 4.1122, 2.3357, 2.4385]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "266\n",
            "tensor([[1.4148, 2.0664, 1.2284, 2.0828, 1.9940, 1.3406, 1.3125],\n",
            "        [1.5654, 2.2463, 1.3097, 2.2626, 2.1787, 1.4321, 1.4073],\n",
            "        [0.7267, 1.1756, 0.8025, 1.2019, 1.0998, 0.8732, 0.8424],\n",
            "        [2.8990, 3.7603, 1.9854, 3.7856, 3.7689, 2.1089, 2.2170],\n",
            "        [1.6744, 2.3830, 1.3688, 2.3977, 2.3191, 1.4898, 1.4763]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "267\n",
            "tensor([[1.4447, 2.0998, 1.2431, 2.1169, 2.0284, 1.3632, 1.3295],\n",
            "        [1.6189, 2.3163, 1.3427, 2.3331, 2.2516, 1.4629, 1.4429],\n",
            "        [2.1896, 2.9831, 1.6384, 3.0000, 2.9446, 1.7700, 1.7936],\n",
            "        [3.1728, 4.0014, 2.1150, 4.0379, 4.0166, 2.2825, 2.3820],\n",
            "        [1.0701, 1.6275, 1.0236, 1.6492, 1.5493, 1.1236, 1.0832]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "268\n",
            "tensor([[2.4006, 3.2241, 1.7487, 3.2449, 3.1999, 1.8845, 1.9221],\n",
            "        [3.2307, 4.0585, 2.1465, 4.0996, 4.0817, 2.3279, 2.4172],\n",
            "        [1.6541, 2.3567, 1.3593, 2.3718, 2.2919, 1.4832, 1.4627],\n",
            "        [2.2982, 3.1037, 1.6945, 3.1241, 3.0739, 1.8275, 1.8597],\n",
            "        [1.2581, 1.8689, 1.1374, 1.8877, 1.7931, 1.2488, 1.2085]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "269\n",
            "tensor([[2.7520, 3.5989, 1.9166, 3.6267, 3.5959, 2.0547, 2.1319],\n",
            "        [1.4675, 2.1314, 1.2605, 2.1492, 2.0599, 1.3818, 1.3477],\n",
            "        [2.8073, 3.6605, 1.9455, 3.6882, 3.6634, 2.0846, 2.1627],\n",
            "        [2.0040, 2.7749, 1.5474, 2.7935, 2.7269, 1.6801, 1.6832],\n",
            "        [0.8221, 1.3016, 0.8681, 1.3294, 1.2252, 0.9496, 0.9116]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "270\n",
            "tensor([[2.3173, 3.1260, 1.7064, 3.1495, 3.0945, 1.8489, 1.8740],\n",
            "        [2.3579, 3.1674, 1.7270, 3.1954, 3.1425, 1.8723, 1.8987],\n",
            "        [1.8446, 2.5871, 1.4658, 2.6069, 2.5320, 1.6006, 1.5852],\n",
            "        [1.3374, 1.9655, 1.1840, 1.9865, 1.8923, 1.3049, 1.2621],\n",
            "        [1.0558, 1.6065, 1.0130, 1.6290, 1.5280, 1.1144, 1.0704]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "271\n",
            "tensor([[0.7468, 1.2023, 0.8189, 1.2321, 1.1271, 0.8934, 0.8590],\n",
            "        [1.0593, 1.6106, 1.0186, 1.6358, 1.5334, 1.1254, 1.0768],\n",
            "        [2.6733, 3.5126, 1.8816, 3.5432, 3.5060, 2.0266, 2.0869],\n",
            "        [0.9640, 1.4895, 0.9613, 1.5179, 1.4121, 1.0585, 1.0136],\n",
            "        [0.6182, 1.0294, 0.7320, 1.0591, 0.9558, 0.7909, 0.7646]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "272\n",
            "tensor([[2.7355, 3.5804, 1.9120, 3.6117, 3.5791, 2.0558, 2.1231],\n",
            "        [2.8001, 3.6520, 1.9445, 3.6840, 3.6546, 2.0904, 2.1645],\n",
            "        [0.8900, 1.3915, 0.9144, 1.4216, 1.3151, 1.0054, 0.9622],\n",
            "        [1.6053, 2.2993, 1.3380, 2.3196, 2.2347, 1.4653, 1.4370],\n",
            "        [3.1402, 3.9686, 2.1032, 4.0119, 3.9894, 2.2710, 2.3650]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "273\n",
            "tensor([[3.0109, 3.8608, 2.0436, 3.8979, 3.8787, 2.1994, 2.2849],\n",
            "        [1.5951, 2.2850, 1.3305, 2.3067, 2.2190, 1.4674, 1.4314],\n",
            "        [1.1073, 1.6754, 1.0511, 1.7025, 1.5982, 1.1599, 1.1127],\n",
            "        [3.2725, 4.0975, 2.1708, 4.1413, 4.1191, 2.3724, 2.4473],\n",
            "        [2.1177, 2.9080, 1.6090, 2.9293, 2.8676, 1.7410, 1.7563]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "274\n",
            "tensor([[2.8305, 3.6872, 1.9594, 3.7182, 3.6947, 2.0954, 2.1774],\n",
            "        [3.2915, 4.1099, 2.1774, 4.1524, 4.1247, 2.3975, 2.4635],\n",
            "        [3.2699, 4.0922, 2.1684, 4.1384, 4.1136, 2.3672, 2.4467],\n",
            "        [1.2927, 1.9128, 1.1614, 1.9353, 1.8374, 1.2823, 1.2357],\n",
            "        [1.3711, 2.0084, 1.2001, 2.0273, 1.9341, 1.3226, 1.2829]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "275\n",
            "tensor([[2.6215, 3.4533, 1.8565, 3.4817, 3.4412, 2.0114, 2.0570],\n",
            "        [2.9265, 3.7764, 2.0045, 3.8114, 3.7896, 2.1594, 2.2349],\n",
            "        [1.3569, 1.9924, 1.1994, 2.0152, 1.9185, 1.3276, 1.2792],\n",
            "        [0.9017, 1.4105, 0.9212, 1.4354, 1.3307, 1.0133, 0.9690],\n",
            "        [3.2605, 4.0862, 2.1627, 4.1286, 4.1087, 2.3604, 2.4366]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "276\n",
            "tensor([[2.7927, 3.6533, 1.9426, 3.6829, 3.6526, 2.0754, 2.1562],\n",
            "        [3.2516, 4.0821, 2.1613, 4.1251, 4.1029, 2.3581, 2.4347],\n",
            "        [2.5687, 3.4019, 1.8319, 3.4314, 3.3894, 1.9852, 2.0267],\n",
            "        [3.2894, 4.1121, 2.1801, 4.1532, 4.1302, 2.3956, 2.4580],\n",
            "        [1.9300, 2.6898, 1.5134, 2.7099, 2.6366, 1.6568, 1.6416]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "277\n",
            "tensor([[2.4020, 3.2269, 1.7534, 3.2517, 3.2013, 1.8944, 1.9259],\n",
            "        [3.1421, 3.9848, 2.1086, 4.0232, 4.0041, 2.2740, 2.3617],\n",
            "        [2.2517, 3.0585, 1.6782, 3.0806, 3.0217, 1.8242, 1.8383],\n",
            "        [1.0460, 1.5988, 1.0160, 1.6239, 1.5188, 1.1185, 1.0710],\n",
            "        [2.5944, 3.4344, 1.8478, 3.4615, 3.4224, 1.9937, 2.0396]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "278\n",
            "tensor([[0.7104, 1.1563, 0.7993, 1.1856, 1.0790, 0.8726, 0.8346],\n",
            "        [2.5465, 3.3898, 1.8263, 3.4143, 3.3714, 1.9661, 2.0119],\n",
            "        [2.0161, 2.7880, 1.5587, 2.8062, 2.7366, 1.6977, 1.6920],\n",
            "        [3.2883, 4.1100, 2.1783, 4.1486, 4.1246, 2.3985, 2.4590],\n",
            "        [2.9980, 3.8486, 2.0401, 3.8837, 3.8632, 2.1995, 2.2759]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "279\n",
            "tensor([[2.3336, 3.1564, 1.7215, 3.1773, 3.1236, 1.8621, 1.8856],\n",
            "        [3.0740, 3.9215, 2.0746, 3.9549, 3.9394, 2.2238, 2.3190],\n",
            "        [2.6091, 3.4612, 1.8554, 3.4853, 3.4477, 1.9947, 2.0490],\n",
            "        [2.9213, 3.7762, 2.0053, 3.8065, 3.7814, 2.1603, 2.2321],\n",
            "        [1.4740, 2.1416, 1.2661, 2.1589, 2.0681, 1.3961, 1.3538]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "280\n",
            "tensor([[1.0486, 1.6023, 1.0155, 1.6264, 1.5202, 1.1253, 1.0740],\n",
            "        [1.3267, 1.9603, 1.1852, 1.9799, 1.8832, 1.3057, 1.2600],\n",
            "        [3.2868, 4.1130, 2.1788, 4.1515, 4.1260, 2.3913, 2.4596],\n",
            "        [0.8013, 1.2776, 0.8590, 1.3045, 1.1974, 0.9415, 0.9001],\n",
            "        [0.8460, 1.3382, 0.8891, 1.3657, 1.2580, 0.9783, 0.9343]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "281\n",
            "tensor([[0.8403, 1.3311, 0.8869, 1.3590, 1.2512, 0.9759, 0.9306],\n",
            "        [1.0883, 1.6541, 1.0389, 1.6766, 1.5722, 1.1540, 1.1018],\n",
            "        [0.8648, 1.3625, 0.9000, 1.3891, 1.2813, 0.9920, 0.9469],\n",
            "        [2.8293, 3.6927, 1.9610, 3.7208, 3.6915, 2.0984, 2.1784],\n",
            "        [3.2582, 4.0858, 2.1614, 4.1271, 4.0951, 2.3756, 2.4482]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "282\n",
            "tensor([[1.9859, 2.7595, 1.5436, 2.7785, 2.7057, 1.6899, 1.6806],\n",
            "        [0.8264, 1.3106, 0.8756, 1.3390, 1.2293, 0.9656, 0.9207],\n",
            "        [2.8951, 3.7538, 1.9904, 3.7834, 3.7585, 2.1331, 2.2170],\n",
            "        [1.0458, 1.5987, 1.0147, 1.6239, 1.5172, 1.1223, 1.0723],\n",
            "        [2.6262, 3.4729, 1.8623, 3.4987, 3.4571, 2.0144, 2.0626]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "283\n",
            "tensor([[2.9608, 3.8200, 2.0205, 3.8526, 3.8267, 2.1890, 2.2626],\n",
            "        [0.8050, 1.2839, 0.8605, 1.3127, 1.2035, 0.9500, 0.9071],\n",
            "        [0.8794, 1.3823, 0.9085, 1.4102, 1.3019, 1.0068, 0.9598],\n",
            "        [3.2247, 4.0601, 2.1459, 4.1025, 4.0789, 2.3431, 2.4214],\n",
            "        [2.2387, 3.0541, 1.6716, 3.0726, 3.0117, 1.8149, 1.8326]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "Loss at epoch 7: 117.9212\n",
            "Pearson correlation for aspect 1: 0.6126\n",
            "Pearson correlation for aspect 2: 0.6884\n",
            "Pearson correlation for aspect 3: 0.2438\n",
            "Pearson correlation for aspect 4: 0.7153\n",
            "Pearson correlation for aspect 5: 0.7087\n",
            "Pearson correlation for aspect 6: 0.3193\n",
            "Pearson correlation for aspect 7: 0.3948\n",
            "Mean Pearson correlation: 0.5261\n"
          ]
        }
      ],
      "source": [
        "#setting up the optimizer to update the models parameters during its training where AdamW() will adepts the learing rate and preventing it overfitting by penalizing large weigth during training.\n",
        "optimizer = AdamW(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
        "train(model, model_path, train_data_loader, eval_data_loader, optimizer, loss_weights, num_epochs) # calling train function to hadle traing of the model.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "s3ZsBaQWHpd1",
        "outputId": "15cfd1e1-d34e-4455-89aa-33292a9fb3b6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#importing  matplotlib library for plotting and visualzing the values.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the loss curves\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, marker='o', label='Training Loss')\n",
        "\n",
        "plt.plot(range(1, num_epochs + 1), val_losses, marker='o', label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Avg Loss per batch')\n",
        "plt.title('Training and Validation Loss over Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "qjvG4jTmNZZl",
        "outputId": "7992e443-f5bd-4f2e-856b-b61c77ac0d08"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plotting and visualzing the loss curves.\n",
        "plt.plot(range(1, num_epochs + 1), pearson_scores, marker='o', label='Training Loss')\n",
        "\n",
        "# plt.plot(range(1, num_epochs + 1), val_losses, marker='o', label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Pearson Scores per batch')\n",
        "plt.title('Pearson Scores over Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTEe9rwjTP-e"
      },
      "source": [
        "## 4. Evaluation on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "oRoOJqC7FFX3"
      },
      "outputs": [],
      "source": [
        "#Defining function to predit the model\n",
        "def predict(model, data_loader):\n",
        "  model.eval() #model.eval() setting the model into evaluation mode to ensure stable pridiction.\n",
        "  overall_pred, overall_true = [], [] #lists will be storing the prediction and true value of for all the batches.\n",
        "  with torch.no_grad(): # temporarily desabling the graidant calculation to reduce the memory consumption.\n",
        "    val_loss_sum=0\n",
        "    for idx, (ids, att_msks, y) in enumerate(data_loader):  # iteration through the dataset where data_loader providing the data batches, ids is the inputIDs, att_mask is corrsponding which toekn should be used or ignore, and y is the true lable for the current batch.\n",
        "      ids, att_msks, y = ids.to(device), att_msks.to(device), y.to(device)  #moving the data to the device which is using for the computaion.\n",
        "      y_pred = model(ids, att_msks) #model is running and  generating the prediction\n",
        "\n",
        "\n",
        "\n",
        "      y_pred, y = torch.squeeze(y_pred).cpu().numpy().tolist(), torch.squeeze(y).cpu().numpy().tolist() # torch.seweeze () ensuring the shape of the tensor is appropriate for further process, .cpu() shifting the GPU to CPU bcs NumPy calculation cannot be done on GPU,.NumPy()converting the tensor into NumPy array and .tolist() is converting the NumPy array into Python list.\n",
        "      overall_pred.append(y_pred)\n",
        "      overall_true.append(y)\n",
        "\n",
        "  return overall_pred, overall_true\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "e_T1OBBtkIRG",
        "outputId": "33756fbb-a967-446d-e34e-27d08864e64a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-59-a59a79e2dc7f>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"BERT_Multilingual_0.25_overall_loss.pth\"), strict=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.361519694328308, 1.9247442483901978, 1.1100759506225586, 1.9309498071670532, 1.8876211643218994, 1.2195284366607666, 1.2453298568725586], [1.2718610763549805, 1.8117040395736694, 1.0497748851776123, 1.8169597387313843, 1.7744255065917969, 1.1505122184753418, 1.1824922561645508], [1.7983062267303467, 2.471595048904419, 1.3867868185043335, 2.490954875946045, 2.450662136077881, 1.526197075843811, 1.5605626106262207], [1.3124758005142212, 1.8632841110229492, 1.0769702196121216, 1.8688058853149414, 1.8244779109954834, 1.1788688898086548, 1.2112394571304321], [1.4598785638809204, 2.050065517425537, 1.1719162464141846, 2.057950258255005, 2.0160953998565674, 1.2876262664794922, 1.3176733255386353], [1.6732217073440552, 2.3167724609375, 1.3083795309066772, 2.331407308578491, 2.290336847305298, 1.436367392539978, 1.4714337587356567], [2.166170120239258, 2.9190115928649902, 1.614565134048462, 2.951693058013916, 2.9148216247558594, 1.7684720754623413, 1.8173811435699463], [2.6977972984313965, 3.5538241863250732, 1.937654972076416, 3.6061315536499023, 3.572042942047119, 2.109065294265747, 2.188833713531494], [2.9950058460235596, 3.9054832458496094, 2.1148781776428223, 3.964632034301758, 3.9236559867858887, 2.3119802474975586, 2.399148941040039], [1.8502262830734253, 2.535348653793335, 1.4191431999206543, 2.5550355911254883, 2.518632173538208, 1.5599453449249268, 1.5963897705078125], [1.009879469871521, 1.4750111103057861, 0.8792593479156494, 1.4783804416656494, 1.4308046102523804, 0.9532284736633301, 0.9900567531585693], [1.9603086709976196, 2.671872854232788, 1.4886400699615479, 2.697680950164795, 2.6593408584594727, 1.638362169265747, 1.675828456878662], [2.899719476699829, 3.782150983810425, 2.0569827556610107, 3.846644401550293, 3.8171308040618896, 2.235558271408081, 2.324709892272949], [1.4164118766784668, 1.9957462549209595, 1.1442418098449707, 2.0031163692474365, 1.9592909812927246, 1.2571548223495483, 1.2860912084579468], [2.5932984352111816, 3.4313690662384033, 1.8747045993804932, 3.48258376121521, 3.445699691772461, 2.0461132526397705, 2.1174211502075195], [2.7627158164978027, 3.6277499198913574, 1.9758527278900146, 3.686891555786133, 3.653644561767578, 2.1498522758483887, 2.232736110687256], [1.9527283906936646, 2.660719871520996, 1.4837983846664429, 2.6869521141052246, 2.6466028690338135, 1.6317651271820068, 1.6706467866897583], [1.4910979270935059, 2.089665174484253, 1.1905505657196045, 2.098345994949341, 2.056591749191284, 1.310307264328003, 1.340366005897522], [2.470320463180542, 3.2833404541015625, 1.80077064037323, 3.329761028289795, 3.2937614917755127, 1.9670250415802002, 2.030458450317383], [2.9725470542907715, 3.8750219345092773, 2.1021885871887207, 3.9360878467559814, 3.8989803791046143, 2.292600631713867, 2.379824161529541], [1.5061267614364624, 2.1069185733795166, 1.200941562652588, 2.1171796321868896, 2.0754611492156982, 1.3223447799682617, 1.351758599281311], [2.7536330223083496, 3.6175496578216553, 1.9717141389846802, 3.6762261390686035, 3.646191358566284, 2.1416921615600586, 2.2260890007019043], [1.1056945323944092, 1.5971399545669556, 0.9421499371528625, 1.6009424924850464, 1.554724097251892, 1.0249968767166138, 1.0598785877227783], [1.7572884559631348, 2.4213383197784424, 1.3597806692123413, 2.4380698204040527, 2.3966803550720215, 1.4935333728790283, 1.529803991317749], [1.357290506362915, 1.9194447994232178, 1.1054812669754028, 1.9269111156463623, 1.8826168775558472, 1.2108641862869263, 1.2437376976013184], [2.532862901687622, 3.359074592590332, 1.8384867906570435, 3.4092841148376465, 3.376244068145752, 2.004526376724243, 2.074650287628174], [2.816192626953125, 3.6915202140808105, 2.009157419204712, 3.7488362789154053, 3.7146174907684326, 2.1795568466186523, 2.268948554992676], [2.9154622554779053, 3.806396484375, 2.066678047180176, 3.86936092376709, 3.832709789276123, 2.254274845123291, 2.340268135070801], [2.764833450317383, 3.6326797008514404, 1.9787189960479736, 3.689291477203369, 3.6571366786956787, 2.1530861854553223, 2.2347159385681152], [2.5489931106567383, 3.377150774002075, 1.8483006954193115, 3.426539182662964, 3.3943095207214355, 2.0145580768585205, 2.0830883979797363], [1.6926848888397217, 2.3408308029174805, 1.3194810152053833, 2.3546009063720703, 2.312380790710449, 1.4497745037078857, 1.4848157167434692], [2.0284159183502197, 2.7543303966522217, 1.5292127132415771, 2.7809054851531982, 2.74194073677063, 1.6806913614273071, 1.7211520671844482], [1.0612057447433472, 1.5413399934768677, 0.9134318232536316, 1.5445733070373535, 1.4976928234100342, 0.99257493019104, 1.0277323722839355], [1.7839128971099854, 2.453256607055664, 1.3774827718734741, 2.470722198486328, 2.430309295654297, 1.5128326416015625, 1.5485873222351074], [2.8030223846435547, 3.6763737201690674, 2.0006353855133057, 3.7353649139404297, 3.7054343223571777, 2.179070472717285, 2.262246608734131], [1.9467815160751343, 2.6525561809539795, 1.4794940948486328, 2.6775002479553223, 2.6381258964538574, 1.6260020732879639, 1.664300799369812], [1.5306813716888428, 2.139420509338379, 1.2169469594955444, 2.1496636867523193, 2.1080164909362793, 1.3368806838989258, 1.3680903911590576], [2.3860361576080322, 3.183107376098633, 1.7496585845947266, 3.2257752418518066, 3.1926422119140625, 1.9139766693115234, 1.970219373703003], [1.5547009706497192, 2.1700599193573, 1.232778549194336, 2.1798174381256104, 2.1407227516174316, 1.3537123203277588, 1.385972023010254], [1.486040472984314, 2.0835835933685303, 1.1888989210128784, 2.0922129154205322, 2.050196647644043, 1.3051378726959229, 1.336419939994812], [2.7593841552734375, 3.622596025466919, 1.973799705505371, 3.6809067726135254, 3.6508469581604004, 2.1467337608337402, 2.2292346954345703], [2.2041802406311035, 2.9669249057769775, 1.6393771171569824, 3.002990245819092, 2.965100049972534, 1.7974088191986084, 1.847517728805542], [2.136842727661133, 2.8851263523101807, 1.5983150005340576, 2.916088581085205, 2.8813211917877197, 1.7499197721481323, 1.7981404066085815], [2.375016212463379, 3.169917583465576, 1.7425882816314697, 3.2123165130615234, 3.1766271591186523, 1.907145380973816, 1.9626126289367676], [1.455407738685608, 2.0446970462799072, 1.1677438020706177, 2.0524959564208984, 2.009906768798828, 1.2832047939300537, 1.3132685422897339], [2.7001378536224365, 3.5535340309143066, 1.938763976097107, 3.609701156616211, 3.573068141937256, 2.105731725692749, 2.1899213790893555], [2.8518218994140625, 3.728877544403076, 2.0293996334075928, 3.7916815280914307, 3.7608821392059326, 2.207576036453247, 2.2929325103759766], [1.6493819952011108, 2.288353681564331, 1.2918144464492798, 2.3004634380340576, 2.2583060264587402, 1.4211430549621582, 1.4540725946426392], [2.8337886333465576, 3.7108020782470703, 2.017909049987793, 3.7716126441955566, 3.7415757179260254, 2.1928484439849854, 2.282092571258545], [1.5063425302505493, 2.1073243618011475, 1.2015818357467651, 2.116511344909668, 2.074357271194458, 1.3216761350631714, 1.3506327867507935], [2.671605348587036, 3.5214598178863525, 1.9223456382751465, 3.57436203956604, 3.5432586669921875, 2.0958831310272217, 2.167479991912842], [2.6512646675109863, 3.499274969100952, 1.9105645418167114, 3.5535902976989746, 3.5214104652404785, 2.0801470279693604, 2.1562533378601074], [1.3555376529693604, 1.9189872741699219, 1.1047865152359009, 1.9248723983764648, 1.8805772066116333, 1.2118089199066162, 1.2413463592529297], [2.0612781047821045, 2.792454242706299, 1.5485690832138062, 2.820683002471924, 2.78255558013916, 1.7020072937011719, 1.744014024734497], [2.6178505420684814, 3.460188865661621, 1.8905372619628906, 3.5123817920684814, 3.4806554317474365, 2.0599117279052734, 2.1331610679626465], [2.6741158962249756, 3.5266544818878174, 1.9237143993377686, 3.580533027648926, 3.5478858947753906, 2.0966877937316895, 2.1735944747924805], [2.8642468452453613, 3.74462890625, 2.03791880607605, 3.8037922382354736, 3.7740302085876465, 2.2129809856414795, 2.2996954917907715], [1.1617037057876587, 1.6716766357421875, 0.9798180460929871, 1.6746736764907837, 1.6299530267715454, 1.0708842277526855, 1.1025445461273193], [0.9745666980743408, 1.4295734167099, 0.8551466464996338, 1.4309289455413818, 1.3853330612182617, 0.9253233671188354, 0.9628220796585083], [2.4372615814208984, 3.24772047996521, 1.7816904783248901, 3.2926700115203857, 3.2585582733154297, 1.9432120323181152, 2.009594440460205], [1.4785246849060059, 2.075265884399414, 1.1840990781784058, 2.0840437412261963, 2.041649580001831, 1.3032639026641846, 1.3321613073349], [2.713055372238159, 3.5703542232513428, 1.9489558935165405, 3.6271774768829346, 3.5958962440490723, 2.1175763607025146, 2.1984353065490723], [2.8156886100769043, 3.688060760498047, 2.0079152584075928, 3.747471570968628, 3.716496229171753, 2.185786247253418, 2.267329216003418], [1.754311203956604, 2.418782949447632, 1.3590729236602783, 2.433657646179199, 2.394625186920166, 1.494002342224121, 1.528161644935608], [2.2673239707946777, 3.04195499420166, 1.6771252155303955, 3.0798537731170654, 3.045215368270874, 1.8352822065353394, 1.8895028829574585], [1.9340218305587769, 2.6403696537017822, 1.4714463949203491, 2.661668300628662, 2.6229794025421143, 1.6177780628204346, 1.655591368675232], [2.6391141414642334, 3.482586145401001, 1.9034428596496582, 3.5360488891601562, 3.502690315246582, 2.068774461746216, 2.147111415863037], [2.1699330806732178, 2.9269723892211914, 1.6185333728790283, 2.9603195190429688, 2.92318058013916, 1.7753915786743164, 1.8229641914367676], [2.905508518218994, 3.7981698513031006, 2.061495304107666, 3.8574042320251465, 3.8165042400360107, 2.245573043823242, 2.3332767486572266], [1.5215907096862793, 2.1271297931671143, 1.2118208408355713, 2.1362743377685547, 2.093121290206909, 1.3292644023895264, 1.3621875047683716], [1.5443202257156372, 2.155198097229004, 1.2278131246566772, 2.167036294937134, 2.1258435249328613, 1.3487205505371094, 1.379433512687683], [1.6013351678848267, 2.226494312286377, 1.2625882625579834, 2.239520311355591, 2.19620943069458, 1.3892107009887695, 1.4197957515716553], [2.458178758621216, 3.2699170112609863, 1.7939380407333374, 3.316640853881836, 3.282602310180664, 1.9581429958343506, 2.022031307220459], [2.6053645610809326, 3.444617986679077, 1.883062720298767, 3.4965310096740723, 3.462163209915161, 2.0561091899871826, 2.1236934661865234], [1.8571463823318481, 2.5443413257598877, 1.4234172105789185, 2.564812660217285, 2.525383710861206, 1.5638530254364014, 1.6026451587677002], [3.003206253051758, 3.913543939590454, 2.1196868419647217, 3.9728713035583496, 3.931811809539795, 2.3167219161987305, 2.4034605026245117], [2.8107476234436035, 3.6821274757385254, 2.005772590637207, 3.7432191371917725, 3.7137231826782227, 2.180922031402588, 2.2638463973999023], [1.801522135734558, 2.4767634868621826, 1.3875494003295898, 2.49430251121521, 2.4531683921813965, 1.5268710851669312, 1.5636838674545288], [1.2018709182739258, 1.7214093208312988, 1.0046931505203247, 1.726421594619751, 1.6807435750961304, 1.097424864768982, 1.130089282989502], [2.683000326156616, 3.536806583404541, 1.929659128189087, 3.592418670654297, 3.5591394901275635, 2.1024012565612793, 2.177859306335449], [1.5311015844345093, 2.139893054962158, 1.216579556465149, 2.1493637561798096, 2.1075186729431152, 1.3361332416534424, 1.3676029443740845], [1.1931047439575195, 1.7092921733856201, 1.0001473426818848, 1.7139520645141602, 1.6692278385162354, 1.0931475162506104, 1.123932123184204], [2.912468433380127, 3.8054211139678955, 2.06593656539917, 3.8639028072357178, 3.8283355236053467, 2.2513415813446045, 2.338688850402832], [1.2175079584121704, 1.7416386604309082, 1.0164564847946167, 1.7465482950210571, 1.7028864622116089, 1.110859751701355, 1.1422035694122314], [1.278056025505066, 1.821017861366272, 1.054569959640503, 1.8252381086349487, 1.7812578678131104, 1.156090497970581, 1.185794711112976], [2.455497980117798, 3.2680933475494385, 1.792650580406189, 3.3132495880126953, 3.281838893890381, 1.958141803741455, 2.0204906463623047], [1.7070508003234863, 2.3583688735961914, 1.328844428062439, 2.372964859008789, 2.333104133605957, 1.4607025384902954, 1.4945651292800903], [1.035560131072998, 1.507084846496582, 0.8965265154838562, 1.5098533630371094, 1.4645745754241943, 0.9718775749206543, 1.0086779594421387], [1.7639600038528442, 2.4306936264038086, 1.363724708557129, 2.4459009170532227, 2.4057538509368896, 1.5000553131103516, 1.532881259918213], [2.6653456687927246, 3.514474391937256, 1.918441891670227, 3.5677835941314697, 3.537383794784546, 2.0862948894500732, 2.164215564727783], [1.1299084424972534, 1.6310606002807617, 0.9574834704399109, 1.632711410522461, 1.5884881019592285, 1.0460822582244873, 1.0771594047546387], [2.955010175704956, 3.8541479110717773, 2.0909595489501953, 3.9148290157318115, 3.879849672317505, 2.2761566638946533, 2.368246555328369], [1.5770689249038696, 2.195974111557007, 1.24644935131073, 2.20792818069458, 2.165334939956665, 1.369984745979309, 1.4022278785705566], [1.5735641717910767, 2.193026304244995, 1.2448197603225708, 2.205655336380005, 2.1632697582244873, 1.3706685304641724, 1.4004764556884766], [2.2545254230499268, 3.02770733833313, 1.6696592569351196, 3.0647804737091064, 3.0304291248321533, 1.8267117738723755, 1.8817178010940552], [1.4033745527267456, 1.9779413938522339, 1.134826898574829, 1.9844439029693604, 1.9425841569900513, 1.2459778785705566, 1.2749131917953491], [1.4928044080734253, 2.0927085876464844, 1.193547248840332, 2.101637840270996, 2.0584940910339355, 1.3125449419021606, 1.3426772356033325], [1.6371498107910156, 2.271862030029297, 1.284729242324829, 2.2859554290771484, 2.2434566020965576, 1.4123135805130005, 1.445152997970581], [2.1223082542419434, 2.8672280311584473, 1.5874724388122559, 2.8973751068115234, 2.8613719940185547, 1.7412601709365845, 1.7867637872695923], [1.2989143133163452, 1.8455133438110352, 1.0678751468658447, 1.850222110748291, 1.8060870170593262, 1.1714519262313843, 1.1999483108520508], [1.034471869468689, 1.5070030689239502, 0.8953542113304138, 1.5100914239883423, 1.4637961387634277, 0.972442626953125, 1.0084500312805176], [2.629425048828125, 3.472609758377075, 1.8980300426483154, 3.5261411666870117, 3.4926185607910156, 2.064983606338501, 2.140592575073242], [2.941105365753174, 3.835509777069092, 2.0819239616394043, 3.897941827774048, 3.8631346225738525, 2.2677814960479736, 2.3571038246154785], [1.3382130861282349, 1.8951371908187866, 1.0935540199279785, 1.9023005962371826, 1.859269142150879, 1.1983462572097778, 1.229103684425354], [2.684455394744873, 3.5358004570007324, 1.9295518398284912, 3.5922608375549316, 3.562512159347534, 2.0953564643859863, 2.1783647537231445], [2.4819908142089844, 3.2981226444244385, 1.8094253540039062, 3.3463480472564697, 3.313185214996338, 1.9706988334655762, 2.0382871627807617], [1.3371707201004028, 1.894879698753357, 1.094045877456665, 1.9006438255310059, 1.8561499118804932, 1.1996690034866333, 1.229667067527771], [2.935171604156494, 3.829317569732666, 2.078460693359375, 3.8899636268615723, 3.8558757305145264, 2.259094476699829, 2.3510684967041016], [2.5156850814819336, 3.336859941482544, 1.8291661739349365, 3.385319232940674, 3.3540191650390625, 1.9960403442382812, 2.0612430572509766], [1.721722960472107, 2.3770952224731445, 1.3381284475326538, 2.3924529552459717, 2.3522403240203857, 1.471627950668335, 1.5052565336227417], [1.605515956878662, 2.2308969497680664, 1.2656770944595337, 2.244002103805542, 2.2023913860321045, 1.390263319015503, 1.4225828647613525], [2.2931978702545166, 3.0729055404663086, 1.6922564506530762, 3.1108591556549072, 3.0752508640289307, 1.8541483879089355, 1.90533447265625], [2.5888288021087646, 3.4228832721710205, 1.8723028898239136, 3.473641872406006, 3.4411797523498535, 2.0368640422821045, 2.1113481521606445], [2.506355047225952, 3.328362226486206, 1.823533535003662, 3.3763699531555176, 3.341416835784912, 1.9888169765472412, 2.056612014770508], [1.4305505752563477, 2.012118339538574, 1.1536827087402344, 2.0200960636138916, 1.9772961139678955, 1.2655267715454102, 1.2959952354431152], [2.0994210243225098, 2.8423290252685547, 1.5728991031646729, 2.8707704544067383, 2.8333659172058105, 1.726896047592163, 1.7724109888076782], [1.4373732805252075, 2.0206055641174316, 1.1591631174087524, 2.0273830890655518, 1.9865432977676392, 1.2711150646209717, 1.3014270067214966], [1.732054352760315, 2.3898141384124756, 1.344567894935608, 2.4060440063476562, 2.3669989109039307, 1.4763579368591309, 1.5122793912887573], [2.3484463691711426, 3.1404731273651123, 1.726890206336975, 3.180854320526123, 3.1473701000213623, 1.8885436058044434, 1.9470961093902588], [2.9466288089752197, 3.8431663513183594, 2.085747241973877, 3.9062793254852295, 3.8698434829711914, 2.271301746368408, 2.3614907264709473], [2.3376381397247314, 3.125955820083618, 1.7196930646896362, 3.165966272354126, 3.132246255874634, 1.8813084363937378, 1.9383893013000488], [1.6894214153289795, 2.3369252681732178, 1.319746971130371, 2.352463722229004, 2.3115170001983643, 1.451696753501892, 1.4832099676132202], [2.821200132369995, 3.697571277618408, 2.012305498123169, 3.754727602005005, 3.7225098609924316, 2.1890335083007812, 2.2735629081726074], [2.1697745323181152, 2.9256534576416016, 1.6167371273040771, 2.9573769569396973, 2.921618938446045, 1.770961046218872, 1.8193575143814087], [2.724196434020996, 3.582061767578125, 1.9540642499923706, 3.6387109756469727, 3.608989953994751, 2.1258859634399414, 2.204385280609131], [1.3229271173477173, 1.8759076595306396, 1.0844571590423584, 1.882554292678833, 1.8365281820297241, 1.1899003982543945, 1.2189809083938599], [2.6514153480529785, 3.499162197113037, 1.9107940196990967, 3.551119565963745, 3.5178675651550293, 2.080573081970215, 2.155600070953369], [1.5415525436401367, 2.151245594024658, 1.224326729774475, 2.1625399589538574, 2.1185641288757324, 1.3471096754074097, 1.3767963647842407], [2.921799421310425, 3.8127541542053223, 2.070939302444458, 3.8750743865966797, 3.842137098312378, 2.2523837089538574, 2.3425064086914062], [1.1050838232040405, 1.59823477268219, 0.9418708682060242, 1.6015052795410156, 1.5550576448440552, 1.0266646146774292, 1.0600732564926147], [1.4977245330810547, 2.0957765579223633, 1.197192668914795, 2.106750249862671, 2.0646891593933105, 1.3162387609481812, 1.3458223342895508], [2.738227605819702, 3.599944829940796, 1.9623552560806274, 3.657344102859497, 3.62882399559021, 2.138428211212158, 2.21622896194458], [2.8362693786621094, 3.7125837802886963, 2.0199198722839355, 3.773252487182617, 3.7433557510375977, 2.2013497352600098, 2.2826271057128906], [2.488801956176758, 3.3078198432922363, 1.8125046491622925, 3.3546864986419678, 3.3190152645111084, 1.9775936603546143, 2.0446724891662598], [1.3832221031188965, 1.9529366493225098, 1.1224740743637085, 1.959774136543274, 1.915217638015747, 1.2320175170898438, 1.2627129554748535], [2.3322436809539795, 3.12003231048584, 1.7176859378814697, 3.1600582599639893, 3.1268839836120605, 1.8791028261184692, 1.934700608253479], [1.6904670000076294, 2.338275194168091, 1.3181655406951904, 2.3521604537963867, 2.312016010284424, 1.449298620223999, 1.4831407070159912], [2.9877736568450928, 3.8932242393493652, 2.110283136367798, 3.955490827560425, 3.917705535888672, 2.304126739501953, 2.392451763153076], [1.6950187683105469, 2.3438737392425537, 1.3201419115066528, 2.359025001525879, 2.3175292015075684, 1.4520033597946167, 1.4850075244903564], [2.182217597961426, 2.9407060146331787, 1.6243534088134766, 2.9732871055603027, 2.939718723297119, 1.7788176536560059, 1.8288027048110962], [2.0502359867095947, 2.7815539836883545, 1.5451513528823853, 2.810451030731201, 2.7725963592529297, 1.6970534324645996, 1.7392274141311646], [1.6859016418457031, 2.332556962966919, 1.3163180351257324, 2.347402572631836, 2.305185556411743, 1.4495606422424316, 1.4813300371170044], [1.916002869606018, 2.615912914276123, 1.4588334560394287, 2.638080596923828, 2.597705125808716, 1.6050045490264893, 1.643398642539978], [2.715047597885132, 3.5727713108062744, 1.9484516382217407, 3.627932071685791, 3.596406936645508, 2.121122121810913, 2.1991233825683594], [2.936595916748047, 3.8288681507110596, 2.078315258026123, 3.8886327743530273, 3.855377435684204, 2.2581381797790527, 2.352109432220459], [2.9012789726257324, 3.7907397747039795, 2.0577268600463867, 3.8515965938568115, 3.817478895187378, 2.2380852699279785, 2.3278889656066895], [2.704585313796997, 3.5624895095825195, 1.9413902759552002, 3.6163535118103027, 3.5798702239990234, 2.1222846508026123, 2.193286895751953], [1.9390112161636353, 2.644300937652588, 1.4757907390594482, 2.667909622192383, 2.6296470165252686, 1.6189459562301636, 1.6590629816055298], [1.918716549873352, 2.6192057132720947, 1.4618185758590698, 2.642240524291992, 2.6030781269073486, 1.6037890911102295, 1.6448578834533691], [2.894007921218872, 3.778804302215576, 2.0546205043792725, 3.839583396911621, 3.808356523513794, 2.2367427349090576, 2.3216090202331543], [2.4886512756347656, 3.3058199882507324, 1.8121788501739502, 3.351517915725708, 3.3184475898742676, 1.9741017818450928, 2.042712688446045], [1.1759545803070068, 1.6900577545166016, 0.9870246052742004, 1.6932271718978882, 1.6489179134368896, 1.0791943073272705, 1.1113555431365967], [2.9717390537261963, 3.8752100467681885, 2.1009700298309326, 3.9362683296203613, 3.895590305328369, 2.283524990081787, 2.3818483352661133], [1.6896878480911255, 2.3380415439605713, 1.3187650442123413, 2.353595733642578, 2.3121390342712402, 1.45140540599823, 1.4838508367538452], [2.716878890991211, 3.5729153156280518, 1.9487370252609253, 3.6298389434814453, 3.601893663406372, 2.1175713539123535, 2.198655605316162], [1.43325674533844, 2.0157053470611572, 1.1562556028366089, 2.02514386177063, 1.9818267822265625, 1.2701334953308105, 1.2997145652770996], [1.3360728025436401, 1.8947405815124512, 1.0920215845108032, 1.9003572463989258, 1.8559162616729736, 1.1976128816604614, 1.2275177240371704], [2.6307718753814697, 3.4733262062072754, 1.8983224630355835, 3.526895761489868, 3.4970321655273438, 2.066800117492676, 2.139942169189453], [2.6234567165374756, 3.466737985610962, 1.8940353393554688, 3.5190494060516357, 3.488142251968384, 2.068082332611084, 2.137091636657715], [2.707566738128662, 3.5621273517608643, 1.9435913562774658, 3.618594169616699, 3.590794563293457, 2.1173665523529053, 2.192871570587158], [2.7367119789123535, 3.5965917110443115, 1.961221694946289, 3.654517412185669, 3.625007390975952, 2.1352920532226562, 2.212618350982666], [2.9518837928771973, 3.8534915447235107, 2.089792013168335, 3.9140326976776123, 3.8737943172454834, 2.2814180850982666, 2.3674583435058594], [1.0477509498596191, 1.5258326530456543, 0.903434693813324, 1.5281404256820679, 1.4821381568908691, 0.9833114147186279, 1.0180842876434326], [2.222975730895996, 2.9890825748443604, 1.6502379179000854, 3.0238242149353027, 2.98630952835083, 1.8046663999557495, 1.8586764335632324], [1.8038004636764526, 2.478257656097412, 1.3908404111862183, 2.4966886043548584, 2.458038091659546, 1.5281500816345215, 1.5633213520050049], [1.7532289028167725, 2.414806365966797, 1.3582273721694946, 2.430812120437622, 2.391530990600586, 1.4922459125518799, 1.5262751579284668], [1.8795559406280518, 2.5715956687927246, 1.437300443649292, 2.593374729156494, 2.5543553829193115, 1.5823149681091309, 1.61681067943573], [2.4394781589508057, 3.2498362064361572, 1.7822257280349731, 3.2935056686401367, 3.261317729949951, 1.9481792449951172, 2.00958251953125], [2.489755868911743, 3.3080193996429443, 1.8117241859436035, 3.3550922870635986, 3.3194687366485596, 1.9748599529266357, 2.043177604675293], [1.625916838645935, 2.2576944828033447, 1.2785403728485107, 2.271141529083252, 2.230297803878784, 1.4052915573120117, 1.437334656715393], [1.2759677171707153, 1.8178058862686157, 1.0532498359680176, 1.8224546909332275, 1.7781063318252563, 1.1548155546188354, 1.1849128007888794], [1.2607536315917969, 1.7976542711257935, 1.0430585145950317, 1.8023557662963867, 1.7578409910202026, 1.1409294605255127, 1.1737173795700073], [2.120197296142578, 2.866168975830078, 1.5860830545425415, 2.895738363265991, 2.8569204807281494, 1.7383992671966553, 1.7876759767532349], [2.941819667816162, 3.8378512859344482, 2.083568811416626, 3.9014647006988525, 3.8652307987213135, 2.2712671756744385, 2.358924388885498], [2.716947078704834, 3.576390027999878, 1.9491386413574219, 3.633012294769287, 3.596924304962158, 2.125187635421753, 2.204254150390625], [2.1685173511505127, 2.9243810176849365, 1.616551160812378, 2.9572911262512207, 2.9197354316711426, 1.7718775272369385, 1.8224633932113647], [2.740943193435669, 3.6021792888641357, 1.964593529701233, 3.660162925720215, 3.630368232727051, 2.1386125087738037, 2.2163596153259277], [2.3024470806121826, 3.0858359336853027, 1.6993123292922974, 3.1254167556762695, 3.089690685272217, 1.857430338859558, 1.9159338474273682], [2.588953971862793, 3.425128936767578, 1.8719213008880615, 3.477585792541504, 3.4427247047424316, 2.0396931171417236, 2.113126754760742], [1.124009132385254, 1.6228688955307007, 0.9543270468711853, 1.6253238916397095, 1.5795761346817017, 1.0399317741394043, 1.0736875534057617], [1.1579926013946533, 1.6668695211410522, 0.9767774343490601, 1.6707158088684082, 1.6247202157974243, 1.0674551725387573, 1.0988515615463257], [2.3860361576080322, 3.183107376098633, 1.7496585845947266, 3.2257752418518066, 3.1926422119140625, 1.9139766693115234, 1.970219373703003], [1.9815312623977661, 2.6959962844848633, 1.5014382600784302, 2.721505641937256, 2.6838550567626953, 1.6493918895721436, 1.688513159751892], [1.4134348630905151, 1.9930555820465088, 1.1410597562789917, 1.9981722831726074, 1.9558228254318237, 1.2539421319961548, 1.2835720777511597], [1.1530029773712158, 1.659541368484497, 0.9733073115348816, 1.6633069515228271, 1.6176809072494507, 1.0640060901641846, 1.095569133758545], [2.021559953689575, 2.7449138164520264, 1.5253527164459229, 2.770723819732666, 2.7335758209228516, 1.6758167743682861, 1.7159866094589233], [1.3397020101547241, 1.8982043266296387, 1.0935730934143066, 1.9048182964324951, 1.860819697380066, 1.2008894681930542, 1.2308651208877563], [0.9316680431365967, 1.3739638328552246, 0.8264774680137634, 1.375079870223999, 1.3285973072052002, 0.8905282616615295, 0.9311692714691162], [1.0979375839233398, 1.5894520282745361, 0.9381055235862732, 1.5926254987716675, 1.5469911098480225, 1.0222632884979248, 1.0556634664535522], [2.351449728012085, 3.142070770263672, 1.728299856185913, 3.183568239212036, 3.147517204284668, 1.891167402267456, 1.9474328756332397], [1.0158090591430664, 1.4815418720245361, 0.8829323649406433, 1.4849328994750977, 1.4390685558319092, 0.9571559429168701, 0.9934254288673401], [2.138455629348755, 2.8870863914489746, 1.5985995531082153, 2.9175281524658203, 2.8823695182800293, 1.7515255212783813, 1.7993654012680054], [2.878720998764038, 3.761274814605713, 2.0456552505493164, 3.8226327896118164, 3.7917213439941406, 2.2266058921813965, 2.3108091354370117], [2.7074825763702393, 3.565916061401367, 1.9453315734863281, 3.619601011276245, 3.5895113945007324, 2.1140544414520264, 2.1949820518493652], [1.846001148223877, 2.5348947048187256, 1.412091851234436, 2.551204204559326, 2.510329008102417, 1.5530593395233154, 1.5925434827804565], [1.8504493236541748, 2.5378096103668213, 1.4188196659088135, 2.556607961654663, 2.5163516998291016, 1.5594457387924194, 1.5954676866531372], [2.508769989013672, 3.3314967155456543, 1.8243902921676636, 3.379439115524292, 3.3454809188842773, 1.9870827198028564, 2.057429790496826], [1.314955472946167, 1.8680707216262817, 1.080025315284729, 1.8716120719909668, 1.82906174659729, 1.1825549602508545, 1.2125474214553833], [1.3467159271240234, 1.906418800354004, 1.1004106998443604, 1.9120643138885498, 1.867762565612793, 1.20535147190094, 1.235480785369873], [2.218027114868164, 2.9843108654022217, 1.6461882591247559, 3.017446517944336, 2.9821386337280273, 1.8012242317199707, 1.854775071144104], [1.0587425231933594, 1.539067029953003, 0.9110262989997864, 1.541425347328186, 1.4951586723327637, 0.9896537065505981, 1.025282382965088], [2.9808435440063477, 3.8878376483917236, 2.106539249420166, 3.947526216506958, 3.9059245586395264, 2.2954752445220947, 2.387981414794922], [1.1759244203567505, 1.6893293857574463, 0.9893857836723328, 1.6925541162490845, 1.6487303972244263, 1.0801132917404175, 1.1115505695343018], [2.9820196628570557, 3.885258197784424, 2.1064491271972656, 3.946791410446167, 3.906752347946167, 2.297452211380005, 2.387235641479492], [2.0301594734191895, 2.7542927265167236, 1.530495524406433, 2.7798523902893066, 2.742213487625122, 1.6823327541351318, 1.7210334539413452], [2.0769946575164795, 2.81219220161438, 1.5600590705871582, 2.841433525085449, 2.8017725944519043, 1.7136728763580322, 1.7559823989868164], [2.7081797122955322, 3.5628693103790283, 1.945343255996704, 3.6193692684173584, 3.5889370441436768, 2.1107070446014404, 2.193718910217285], [2.5112197399139404, 3.335869312286377, 1.8254671096801758, 3.3800692558288574, 3.344027519226074, 1.9949464797973633, 2.057670831680298], [2.0265402793884277, 2.750377893447876, 1.529824137687683, 2.7779979705810547, 2.7407355308532715, 1.678657054901123, 1.7210352420806885], [2.632688283920288, 3.4763123989105225, 1.8995853662490845, 3.528925657272339, 3.497346878051758, 2.0669095516204834, 2.1423425674438477], [2.309645652770996, 3.0958967208862305, 1.7033390998840332, 3.1356358528137207, 3.099339246749878, 1.8645631074905396, 1.921195387840271], [1.9181922674179077, 2.6201179027557373, 1.461668610572815, 2.6420722007751465, 2.6026883125305176, 1.6046298742294312, 1.643340826034546], [2.8369405269622803, 3.7132325172424316, 2.021066904067993, 3.7741963863372803, 3.743239641189575, 2.1989197731018066, 2.2819361686706543], [2.852984666824341, 3.731287717819214, 2.029979705810547, 3.791691541671753, 3.761157989501953, 2.2095754146575928, 2.29213285446167], [1.8047670125961304, 2.4813904762268066, 1.3884565830230713, 2.4988012313842773, 2.457702875137329, 1.5288150310516357, 1.5634899139404297], [1.324996829032898, 1.8787767887115479, 1.0855008363723755, 1.8853936195373535, 1.8401416540145874, 1.191300392150879, 1.2213377952575684], [1.2659331560134888, 1.8038114309310913, 1.0474789142608643, 1.8103381395339966, 1.7654703855514526, 1.1474244594573975, 1.1780041456222534], [2.9124879837036133, 3.800734519958496, 2.0657520294189453, 3.8623974323272705, 3.8304169178009033, 2.2503230571746826, 2.335822582244873], [2.942634344100952, 3.836296319961548, 2.0833218097686768, 3.8994929790496826, 3.8663339614868164, 2.270521640777588, 2.357405185699463], [1.9222174882888794, 2.6222875118255615, 1.4630720615386963, 2.6462066173553467, 2.6063458919525146, 1.6083652973175049, 1.6452257633209229], [2.818218231201172, 3.69169282913208, 2.01001238822937, 3.7516963481903076, 3.720411539077759, 2.1874334812164307, 2.2700066566467285], [2.5479252338409424, 3.3762264251708984, 1.8472505807876587, 3.4257876873016357, 3.392538070678711, 2.013526678085327, 2.082258939743042], [2.902129888534546, 3.790534257888794, 2.059915065765381, 3.8519704341888428, 3.819472074508667, 2.24788761138916, 2.3291282653808594], [2.9989013671875, 3.9071643352508545, 2.1171398162841797, 3.967365026473999, 3.925116777420044, 2.3120508193969727, 2.3998866081237793], [2.795522451400757, 3.6637542247772217, 1.9956544637680054, 3.7235686779022217, 3.694347381591797, 2.163891553878784, 2.251335620880127], [1.2777031660079956, 1.8184078931808472, 1.054945707321167, 1.8240876197814941, 1.7795076370239258, 1.155652642250061, 1.1869553327560425], [1.4197325706481934, 1.9986995458602905, 1.1459999084472656, 2.0053012371063232, 1.961738109588623, 1.2585248947143555, 1.2880587577819824], [2.9405157566070557, 3.8368752002716064, 2.0825130939483643, 3.896378517150879, 3.8597025871276855, 2.263638973236084, 2.35958194732666], [2.82460355758667, 3.700162410736084, 2.0137698650360107, 3.7599668502807617, 3.729701519012451, 2.192350387573242, 2.2753615379333496], [1.891735315322876, 2.5885844230651855, 1.4455201625823975, 2.6088778972625732, 2.570223331451416, 1.5861209630966187, 1.6262811422348022], [2.8121261596679688, 3.687959909439087, 2.0062146186828613, 3.747933864593506, 3.715052604675293, 2.181863784790039, 2.269461154937744], [1.1668288707733154, 1.6754928827285767, 0.9823241829872131, 1.6797983646392822, 1.6341410875320435, 1.0725085735321045, 1.1045297384262085], [2.900526762008667, 3.7855679988861084, 2.0597965717315674, 3.847139358520508, 3.815430164337158, 2.2395899295806885, 2.3279170989990234], [2.1860196590423584, 2.9442999362945557, 1.6281249523162842, 2.9779140949249268, 2.9416730403900146, 1.7850570678710938, 1.8325235843658447], [1.0887794494628906, 1.5777478218078613, 0.9312607049942017, 1.5793795585632324, 1.5351207256317139, 1.0121573209762573, 1.0474905967712402], [1.9874523878097534, 2.704956293106079, 1.5043758153915405, 2.7308101654052734, 2.6915225982666016, 1.6506781578063965, 1.6941633224487305], [1.4316800832748413, 2.0133252143859863, 1.1536051034927368, 2.0208497047424316, 1.9773635864257812, 1.267875075340271, 1.296331763267517], [1.5805529356002808, 2.199925661087036, 1.2502371072769165, 2.214015483856201, 2.1708779335021973, 1.374786138534546, 1.4063363075256348], [1.527072548866272, 2.135869264602661, 1.214453101158142, 2.1456103324890137, 2.1018142700195312, 1.3393124341964722, 1.3672562837600708], [1.3889800310134888, 1.9613159894943237, 1.1267955303192139, 1.968018889427185, 1.9241676330566406, 1.2374699115753174, 1.2679214477539062], [1.9700604677200317, 2.6844799518585205, 1.4932959079742432, 2.707749843597412, 2.6705374717712402, 1.6408867835998535, 1.6810921430587769], [1.5562516450881958, 2.1701040267944336, 1.233460545539856, 2.1806089878082275, 2.1401779651641846, 1.3585326671600342, 1.3862911462783813], [2.056199073791504, 2.7875254154205322, 1.547637701034546, 2.815800428390503, 2.7783985137939453, 1.6971782445907593, 1.7411867380142212], [1.6409308910369873, 2.275944471359253, 1.2872909307479858, 2.2895448207855225, 2.2477126121520996, 1.4148837327957153, 1.4460670948028564], [2.926009178161621, 3.817948818206787, 2.0746960639953613, 3.8793983459472656, 3.845229148864746, 2.2626254558563232, 2.3452858924865723], [1.7622649669647217, 2.4263901710510254, 1.363410472869873, 2.4441537857055664, 2.403737783432007, 1.5000468492507935, 1.533478021621704], [2.676577568054199, 3.529519557952881, 1.9254350662231445, 3.583944320678711, 3.553377151489258, 2.094634771347046, 2.1737093925476074], [2.9592559337615967, 3.857111692428589, 2.0921454429626465, 3.9200456142425537, 3.882675886154175, 2.279468536376953, 2.3703646659851074], [1.9490448236465454, 2.655996799468994, 1.4796494245529175, 2.6799545288085938, 2.6413865089416504, 1.6266142129898071, 1.6657989025115967], [1.4493619203567505, 2.0357723236083984, 1.165753960609436, 2.0439722537994385, 2.0008320808410645, 1.2790446281433105, 1.3096412420272827], [2.7797231674194336, 3.6487529277801514, 1.9871783256530762, 3.7055275440216064, 3.6746177673339844, 2.1644134521484375, 2.245126724243164], [2.9118025302886963, 3.802992343902588, 2.065687894821167, 3.864933729171753, 3.8291542530059814, 2.249676465988159, 2.338163375854492], [1.9074100255966187, 2.604999303817749, 1.454802393913269, 2.628361225128174, 2.58998441696167, 1.5987392663955688, 1.6370428800582886], [2.2299890518188477, 2.9995882511138916, 1.656195044517517, 3.034489631652832, 2.9987759590148926, 1.8132710456848145, 1.8644758462905884], [2.2064223289489746, 2.968350887298584, 1.6395962238311768, 3.0023818016052246, 2.967528820037842, 1.7951533794403076, 1.8450491428375244], [1.825587272644043, 2.504408597946167, 1.40525221824646, 2.524179697036743, 2.4838945865631104, 1.5439587831497192, 1.5795185565948486], [2.3835668563842773, 3.18274188041687, 1.7487746477127075, 3.2250773906707764, 3.1927390098571777, 1.9120702743530273, 1.970400094985962], [2.5847907066345215, 3.4183030128479004, 1.8696506023406982, 3.4700281620025635, 3.43791127204895, 2.040125608444214, 2.1086325645446777], [1.9922746419906616, 2.710876703262329, 1.5074763298034668, 2.737647533416748, 2.6981780529022217, 1.6565555334091187, 1.6993708610534668], [2.912576198577881, 3.808840274810791, 2.0656676292419434, 3.868124485015869, 3.8262178897857666, 2.252346992492676, 2.339547634124756], [1.2069857120513916, 1.7295104265213013, 1.0091356039047241, 1.7335723638534546, 1.6872029304504395, 1.1032593250274658, 1.1338146924972534], [1.2228983640670776, 1.7484767436981201, 1.0188957452774048, 1.7535372972488403, 1.7088837623596191, 1.1136094331741333, 1.1456693410873413], [2.3998355865478516, 3.2024002075195312, 1.7594904899597168, 3.2467551231384277, 3.212388515472412, 1.9214451313018799, 1.9836432933807373], [2.207329750061035, 2.9701294898986816, 1.6396937370300293, 3.0036568641662598, 2.96848726272583, 1.794787049293518, 1.8465476036071777], [2.835420608520508, 3.7106058597564697, 2.0199127197265625, 3.7699408531188965, 3.739480972290039, 2.2020423412323, 2.281355857849121], [2.803772211074829, 3.674506902694702, 2.0017154216766357, 3.7341816425323486, 3.7054173946380615, 2.173844337463379, 2.2587485313415527], [1.3339155912399292, 1.8903695344924927, 1.090512990951538, 1.8967556953430176, 1.8516343832015991, 1.1965422630310059, 1.2288278341293335], [2.9372780323028564, 3.8324718475341797, 2.079810857772827, 3.8918824195861816, 3.855220317840576, 2.2592177391052246, 2.3543362617492676], [1.9599531888961792, 2.6702983379364014, 1.4865081310272217, 2.693800449371338, 2.657582998275757, 1.6311814785003662, 1.672644853591919], [2.8525733947753906, 3.728825330734253, 2.0297484397888184, 3.791062355041504, 3.760688543319702, 2.206099033355713, 2.292922019958496], [2.939279317855835, 3.8389203548431396, 2.082540512084961, 3.897667646408081, 3.859407901763916, 2.263193130493164, 2.357849597930908], [2.911191940307617, 3.802417516708374, 2.0633671283721924, 3.862738847732544, 3.829395055770874, 2.248026132583618, 2.3356003761291504], [2.768455743789673, 3.6352996826171875, 1.9800552129745483, 3.6937460899353027, 3.663114309310913, 2.154388904571533, 2.2369794845581055], [2.364257574081421, 3.1600282192230225, 1.736278772354126, 3.200725793838501, 3.164210557937622, 1.896067500114441, 1.9577884674072266], [1.15373957157135, 1.6607953310012817, 0.9743911027908325, 1.6652592420578003, 1.6193104982376099, 1.064851999282837, 1.0957425832748413], [2.109168529510498, 2.8505451679229736, 1.579884648323059, 2.8808741569519043, 2.843608856201172, 1.732295036315918, 1.7774125337600708], [1.8808189630508423, 2.57243013381958, 1.4374017715454102, 2.5940325260162354, 2.5539710521698, 1.580944299697876, 1.617960810661316], [2.5622777938842773, 3.398297071456909, 1.8570587635040283, 3.445237159729004, 3.4082539081573486, 2.0311198234558105, 2.0963830947875977], [1.4351227283477783, 2.0181593894958496, 1.1567227840423584, 2.0267245769500732, 1.9838497638702393, 1.270472764968872, 1.3006213903427124], [2.051011800765991, 2.781076192855835, 1.5448362827301025, 2.808486223220825, 2.7699527740478516, 1.6952736377716064, 1.7374862432479858], [2.3223254680633545, 3.1103127002716064, 1.709763526916504, 3.150050163269043, 3.112584114074707, 1.874220609664917, 1.9276354312896729], [2.9338741302490234, 3.832643508911133, 2.078972816467285, 3.8909618854522705, 3.8541719913482666, 2.265212297439575, 2.3547072410583496], [2.2784805297851562, 3.0554165840148926, 1.6845605373382568, 3.0934736728668213, 3.0585622787475586, 1.8455216884613037, 1.8968766927719116], [1.421189785003662, 2.000809669494629, 1.1476125717163086, 2.0085058212280273, 1.9643759727478027, 1.2590796947479248, 1.2895525693893433], [2.566288709640503, 3.401456117630005, 1.8602571487426758, 3.4504001140594482, 3.4195363521575928, 2.029677152633667, 2.098137378692627], [1.674268126487732, 2.317563772201538, 1.3079400062561035, 2.331644058227539, 2.290431499481201, 1.4384405612945557, 1.470580816268921], [2.937999963760376, 3.83201265335083, 2.081810235977173, 3.893263101577759, 3.8588976860046387, 2.2687456607818604, 2.3550472259521484], [2.0902867317199707, 2.8287787437438965, 1.5672900676727295, 2.8579585552215576, 2.8195393085479736, 1.7193306684494019, 1.7640936374664307], [1.7441668510437012, 2.4060959815979004, 1.3522393703460693, 2.4221861362457275, 2.380526065826416, 1.4873322248458862, 1.5228196382522583], [2.392320156097412, 3.1912455558776855, 1.7537562847137451, 3.233858108520508, 3.1992340087890625, 1.9176599979400635, 1.9743058681488037], [2.286902666091919, 3.0684735774993896, 1.6890770196914673, 3.1067051887512207, 3.0685572624206543, 1.8512682914733887, 1.9045966863632202], [1.7728320360183716, 2.4410390853881836, 1.372409701347351, 2.458120107650757, 2.419196605682373, 1.5076971054077148, 1.542114496231079], [2.861710548400879, 3.7425343990325928, 2.0360264778137207, 3.8045966625213623, 3.7718241214752197, 2.213466167449951, 2.302609443664551], [1.535822868347168, 2.146798849105835, 1.2198878526687622, 2.155801773071289, 2.1149423122406006, 1.3417656421661377, 1.3713302612304688], [1.6907154321670532, 2.337186813354492, 1.3175982236862183, 2.3527214527130127, 2.3103792667388916, 1.4516007900238037, 1.4834026098251343], [2.921140670776367, 3.813918113708496, 2.071690797805786, 3.873594284057617, 3.8381667137145996, 2.2556700706481934, 2.343081474304199], [2.657081365585327, 3.5061848163604736, 1.9141020774841309, 3.558821439743042, 3.5255117416381836, 2.088376522064209, 2.160046100616455], [2.9325060844421387, 3.8249263763427734, 2.0765254497528076, 3.8853530883789062, 3.853066921234131, 2.25545072555542, 2.3494553565979004], [2.7708938121795654, 3.637763023376465, 1.981046199798584, 3.697476863861084, 3.6656711101531982, 2.1592185497283936, 2.2378993034362793], [2.7596499919891357, 3.6245133876800537, 1.9754796028137207, 3.6836559772491455, 3.6533141136169434, 2.151825189590454, 2.2300362586975098], [2.7995550632476807, 3.6693811416625977, 1.9982225894927979, 3.728717803955078, 3.700284004211426, 2.1734724044799805, 2.256575584411621], [2.7276508808135986, 3.5933234691619873, 1.9565858840942383, 3.6452412605285645, 3.60200572013855, 2.133322238922119, 2.213470935821533], [2.4483511447906494, 3.259962558746338, 1.7888706922531128, 3.3043863773345947, 3.270691156387329, 1.9500327110290527, 2.016172170639038], [1.5743013620376587, 2.1950509548187256, 1.2457040548324585, 2.206294536590576, 2.1643218994140625, 1.3710606098175049, 1.4004892110824585], [2.4378864765167236, 3.248582363128662, 1.7819563150405884, 3.2910044193267822, 3.2573606967926025, 1.9486615657806396, 2.0067901611328125], [1.5049365758895874, 2.1053316593170166, 1.2002782821655273, 2.11542010307312, 2.07283091545105, 1.320238709449768, 1.3506428003311157], [2.6726980209350586, 3.522876262664795, 1.9237749576568604, 3.577653408050537, 3.5482676029205322, 2.0938124656677246, 2.169489860534668], [1.7500879764556885, 2.4138593673706055, 1.35418701171875, 2.4289095401763916, 2.3889448642730713, 1.4906251430511475, 1.5233651399612427], [1.8544235229492188, 2.540219306945801, 1.420997977256775, 2.5619890689849854, 2.5217199325561523, 1.5637116432189941, 1.598962664604187], [2.7245001792907715, 3.5854172706604004, 1.9536808729171753, 3.642143726348877, 3.6056106090545654, 2.1300430297851562, 2.2097277641296387], [2.8824193477630615, 3.7661502361297607, 2.0477023124694824, 3.8277523517608643, 3.797320604324341, 2.2256479263305664, 2.3147101402282715], [2.515104055404663, 3.3383662700653076, 1.8273680210113525, 3.384986639022827, 3.35237455368042, 1.9979400634765625, 2.061875820159912], [2.4014241695404053, 3.203390121459961, 1.7590482234954834, 3.2456891536712646, 3.211592674255371, 1.9234249591827393, 1.982850432395935], [2.931417942047119, 3.8233790397644043, 2.0758421421051025, 3.8848254680633545, 3.8498945236206055, 2.2540602684020996, 2.3486881256103516], [2.1886773109436035, 2.9501194953918457, 1.6309325695037842, 2.9845147132873535, 2.9487624168395996, 1.789535641670227, 1.835501790046692], [2.859079599380493, 3.737330675125122, 2.0341579914093018, 3.797417402267456, 3.765876054763794, 2.202037811279297, 2.2954936027526855], [2.421254873275757, 3.227083206176758, 1.77165687084198, 3.2705166339874268, 3.2377164363861084, 1.932464599609375, 1.9970169067382812], [2.9567630290985107, 3.8561229705810547, 2.0914106369018555, 3.9154961109161377, 3.8814053535461426, 2.2770164012908936, 2.3663101196289062], [1.1078128814697266, 1.6011536121368408, 0.9442254900932312, 1.6051381826400757, 1.558465600013733, 1.0280519723892212, 1.063209891319275], [2.9509215354919434, 3.8463947772979736, 2.0895416736602783, 3.9095654487609863, 3.8746113777160645, 2.279047966003418, 2.362914562225342], [1.9757500886917114, 2.689408779144287, 1.4982264041900635, 2.715026617050171, 2.6761932373046875, 1.6463727951049805, 1.6866282224655151], [1.5001450777053833, 2.099708080291748, 1.19725501537323, 2.1098296642303467, 2.06851863861084, 1.3172600269317627, 1.346353530883789], [2.4306561946868896, 3.237406015396118, 1.776606798171997, 3.28108549118042, 3.2469558715820312, 1.9391508102416992, 2.0024237632751465], [2.1151790618896484, 2.8590140342712402, 1.582628846168518, 2.888472557067871, 2.850511074066162, 1.736576795578003, 1.7815124988555908], [1.3076262474060059, 1.8587981462478638, 1.0728346109390259, 1.8638174533843994, 1.8197821378707886, 1.1767261028289795, 1.2075984477996826], [2.208178997039795, 2.970270872116089, 1.6405662298202515, 3.005645990371704, 2.9712893962860107, 1.798846960067749, 1.8476293087005615], [1.2611619234085083, 1.7974295616149902, 1.043894648551941, 1.802842378616333, 1.7573777437210083, 1.1435050964355469, 1.174320101737976], [1.3321888446807861, 1.887282371520996, 1.0908108949661255, 1.895150065422058, 1.849959135055542, 1.1972278356552124, 1.2264854907989502], [1.2670128345489502, 1.8050358295440674, 1.0492820739746094, 1.8096420764923096, 1.7654995918273926, 1.148337721824646, 1.1778783798217773], [2.394456624984741, 3.194110155105591, 1.7548115253448486, 3.2371666431427, 3.203737735748291, 1.9170823097229004, 1.9769572019577026], [2.134812116622925, 2.882152795791626, 1.5970664024353027, 2.914001226425171, 2.8772289752960205, 1.7486540079116821, 1.7971090078353882], [2.9729015827178955, 3.8749587535858154, 2.102494239807129, 3.936958074569702, 3.89863920211792, 2.294248342514038, 2.38067626953125], [1.2877898216247559, 1.8323843479156494, 1.0605254173278809, 1.8369767665863037, 1.793184518814087, 1.1629945039749146, 1.192321538925171], [2.6980152130126953, 3.552412509918213, 1.9382163286209106, 3.6089835166931152, 3.5776522159576416, 2.110116481781006, 2.1881446838378906], [1.941386342048645, 2.647033214569092, 1.4750244617462158, 2.671555757522583, 2.6318447589874268, 1.6207737922668457, 1.6609487533569336], [1.0056068897247314, 1.469449520111084, 0.8765043020248413, 1.471851110458374, 1.4251476526260376, 0.9504753351211548, 0.9862104654312134], [2.761486053466797, 3.625430107116699, 1.9758950471878052, 3.6841654777526855, 3.6552491188049316, 2.147524356842041, 2.2305002212524414], [2.0275940895080566, 2.7530195713043213, 1.5297797918319702, 2.7791311740875244, 2.7400529384613037, 1.6770130395889282, 1.7196409702301025], [0.9995208978652954, 1.4613112211227417, 0.8727272748947144, 1.4632422924041748, 1.4176735877990723, 0.944938063621521, 0.981608510017395], [1.4725334644317627, 2.067430257797241, 1.1809415817260742, 2.077378273010254, 2.0338313579559326, 1.2984791994094849, 1.3287111520767212], [2.022155523300171, 2.74676251411438, 1.5271427631378174, 2.7714853286743164, 2.7369186878204346, 1.6732887029647827, 1.7171043157577515], [2.9439544677734375, 3.837109327316284, 2.0840253829956055, 3.8979976177215576, 3.8654706478118896, 2.263148546218872, 2.355839252471924], [2.882458448410034, 3.7637939453125, 2.0477755069732666, 3.8275842666625977, 3.796276092529297, 2.23075008392334, 2.3152737617492676], [2.823906183242798, 3.698965072631836, 2.0137970447540283, 3.7603819370269775, 3.729418992996216, 2.1928870677948, 2.275935649871826], [1.2847583293914795, 1.8272606134414673, 1.058384656906128, 1.832773208618164, 1.789196252822876, 1.1590919494628906, 1.1902862787246704], [2.0352885723114014, 2.761240243911743, 1.5329340696334839, 2.788224697113037, 2.750058174133301, 1.6833323240280151, 1.7256044149398804], [2.9983596801757812, 3.9080917835235596, 2.117467164993286, 3.968064785003662, 3.9273791313171387, 2.313077926635742, 2.3995089530944824], [2.802241563796997, 3.6753933429718018, 2.000483274459839, 3.7352395057678223, 3.7032036781311035, 2.175903797149658, 2.2614693641662598], [2.4434974193573, 3.255045175552368, 1.7845189571380615, 3.2992851734161377, 3.2622272968292236, 1.9507031440734863, 2.01243257522583], [2.6750431060791016, 3.526198625564575, 1.925202488899231, 3.581580400466919, 3.5522961616516113, 2.09649658203125, 2.171436309814453], [1.7912369966506958, 2.464301109313965, 1.382529377937317, 2.48372745513916, 2.4425158500671387, 1.5212565660476685, 1.556681513786316], [1.0902762413024902, 1.5791782140731812, 0.9328814744949341, 1.582261323928833, 1.5356340408325195, 1.0171228647232056, 1.0489307641983032], [1.8168203830718994, 2.4939498901367188, 1.3977055549621582, 2.512550115585327, 2.4729275703430176, 1.5363235473632812, 1.57171630859375], [1.5233094692230225, 2.1292707920074463, 1.213261365890503, 2.1391663551330566, 2.0970308780670166, 1.3337467908859253, 1.3632662296295166], [1.8255529403686523, 2.504828929901123, 1.4040356874465942, 2.524362087249756, 2.484928846359253, 1.5431348085403442, 1.578794002532959], [2.9941720962524414, 3.9030425548553467, 2.114152431488037, 3.9604365825653076, 3.9197230339050293, 2.3032546043395996, 2.3971152305603027], [2.8691885471343994, 3.749490976333618, 2.0399134159088135, 3.811284303665161, 3.779404640197754, 2.218993663787842, 2.3049373626708984], [1.2606629133224487, 1.796372890472412, 1.044433832168579, 1.8016265630722046, 1.7581807374954224, 1.1437900066375732, 1.1729185581207275], [1.1778936386108398, 1.6909105777740479, 0.9897863864898682, 1.6946070194244385, 1.6499884128570557, 1.0816361904144287, 1.1119312047958374], [2.9879558086395264, 3.8992230892181396, 2.1108195781707764, 3.9557628631591797, 3.9090511798858643, 2.3017821311950684, 2.3962721824645996], [1.6892294883728027, 2.338433265686035, 1.3177947998046875, 2.352309226989746, 2.3111095428466797, 1.450060486793518, 1.4827767610549927], [1.2837014198303223, 1.825432538986206, 1.0600745677947998, 1.8319751024246216, 1.786794662475586, 1.1609036922454834, 1.1907035112380981], [2.8808469772338867, 3.7608861923217773, 2.0462563037872314, 3.824449062347412, 3.792022466659546, 2.2183878421783447, 2.3134474754333496], [2.98821759223938, 3.8972909450531006, 2.1112561225891113, 3.956660032272339, 3.916560411453247, 2.3024497032165527, 2.396069049835205], [1.2452024221420288, 1.7773641347885132, 1.033522129058838, 1.7814377546310425, 1.7364383935928345, 1.1295548677444458, 1.161411166191101], [1.9529045820236206, 2.661835193634033, 1.4843679666519165, 2.6855249404907227, 2.6493587493896484, 1.6277837753295898, 1.6693085432052612], [2.376075267791748, 3.172569513320923, 1.744120717048645, 3.2144646644592285, 3.1773269176483154, 1.9082282781600952, 1.9637516736984253], [1.8275277614593506, 2.507737874984741, 1.4044660329818726, 2.52665114402771, 2.487020969390869, 1.5429000854492188, 1.5794585943222046], [1.0210802555084229, 1.489610195159912, 0.886741042137146, 1.4916496276855469, 1.4455225467681885, 0.960077166557312, 0.9986072778701782], [2.367830753326416, 3.163449764251709, 1.7383595705032349, 3.2051761150360107, 3.169649362564087, 1.902221441268921, 1.9597221612930298], [1.2416211366653442, 1.772873044013977, 1.0318882465362549, 1.7777117490768433, 1.7325941324234009, 1.1281027793884277, 1.1586970090866089], [1.3767879009246826, 1.945326328277588, 1.1178056001663208, 1.951554775238037, 1.908004641532898, 1.2283644676208496, 1.2566810846328735], [1.6222623586654663, 2.253295421600342, 1.2770776748657227, 2.2668325901031494, 2.2249670028686523, 1.4056458473205566, 1.4342578649520874], [2.542529821395874, 3.3686745166778564, 1.8457739353179932, 3.4171810150146484, 3.384822368621826, 2.0111544132232666, 2.078941822052002], [2.9461796283721924, 3.844496965408325, 2.086442470550537, 3.9033915996551514, 3.866328239440918, 2.268606185913086, 2.3585238456726074], [2.416482448577881, 3.223104238510132, 1.769473671913147, 3.2668795585632324, 3.233699083328247, 1.9311110973358154, 1.9945262670516968], [1.100879430770874, 1.5920506715774536, 0.9397255778312683, 1.5962159633636475, 1.5503627061843872, 1.0236698389053345, 1.0570666790008545], [2.159050226211548, 2.9125592708587646, 1.6094496250152588, 2.9432566165924072, 2.9051616191864014, 1.7637741565704346, 1.812111496925354], [2.93196964263916, 3.8252804279327393, 2.078916311264038, 3.886894941329956, 3.85068416595459, 2.265308380126953, 2.3510985374450684], [2.9442145824432373, 3.8389406204223633, 2.083643913269043, 3.9007558822631836, 3.8667664527893066, 2.268012285232544, 2.359241008758545], [1.9964138269424438, 2.7149529457092285, 1.5104079246520996, 2.740841865539551, 2.703260660171509, 1.6584365367889404, 1.6984939575195312], [2.632301092147827, 3.4761693477630615, 1.8996119499206543, 3.5296084880828857, 3.497680902481079, 2.0669639110565186, 2.1425180435180664], [2.2817041873931885, 3.0606517791748047, 1.684138298034668, 3.098464012145996, 3.0616939067840576, 1.8446495532989502, 1.8997541666030884], [1.5112063884735107, 2.1142385005950928, 1.2036643028259277, 2.1235785484313965, 2.081019639968872, 1.324039101600647, 1.353716254234314], [2.200986385345459, 2.963468313217163, 1.636757731437683, 2.9975945949554443, 2.962705612182617, 1.7934083938598633, 1.8434299230575562], [1.145134687423706, 1.6496840715408325, 0.9669980406761169, 1.6525578498840332, 1.607529640197754, 1.0568642616271973, 1.087398648262024], [1.262727975845337, 1.8005775213241577, 1.0453816652297974, 1.8055006265640259, 1.7611851692199707, 1.1457934379577637, 1.1757701635360718], [2.779775857925415, 3.6479320526123047, 1.985619068145752, 3.7054896354675293, 3.677906036376953, 2.161051034927368, 2.2441139221191406], [2.1413583755493164, 2.890986442565918, 1.6004501581192017, 2.9225571155548096, 2.8857688903808594, 1.75390625, 1.8016612529754639], [2.7682738304138184, 3.6330394744873047, 1.9795551300048828, 3.6924543380737305, 3.660630464553833, 2.1573054790496826, 2.23599910736084], [1.2724859714508057, 1.8122422695159912, 1.0520260334014893, 1.8170216083526611, 1.7724543809890747, 1.1509953737258911, 1.1816614866256714], [2.8657987117767334, 3.7474067211151123, 2.0389721393585205, 3.808521032333374, 3.7749533653259277, 2.2101075649261475, 2.303534507751465], [2.813524007797241, 3.685544967651367, 2.006087064743042, 3.7470543384552, 3.7165720462799072, 2.1817173957824707, 2.2672290802001953], [2.721616268157959, 3.579185724258423, 1.951454520225525, 3.636610984802246, 3.6055126190185547, 2.1206893920898438, 2.203418731689453], [2.3447165489196777, 3.135232448577881, 1.7235054969787598, 3.1742584705352783, 3.138021469116211, 1.8830069303512573, 1.9421725273132324], [2.5348896980285645, 3.3609564304351807, 1.840712070465088, 3.4094090461730957, 3.377110242843628, 2.0063490867614746, 2.0736141204833984], [2.330260753631592, 3.1162006855010986, 1.7157455682754517, 3.1563236713409424, 3.1198227405548096, 1.8760374784469604, 1.931961178779602], [2.6227214336395264, 3.464571475982666, 1.894209861755371, 3.5181589126586914, 3.4881770610809326, 2.0621073246002197, 2.135220527648926], [1.7121977806091309, 2.3661675453186035, 1.3312270641326904, 2.3800623416900635, 2.3403477668762207, 1.466099739074707, 1.4988913536071777], [1.3739972114562988, 1.941150426864624, 1.117214560508728, 1.9498683214187622, 1.9053900241851807, 1.2270015478134155, 1.256606101989746], [2.907731533050537, 3.7973074913024902, 2.0625617504119873, 3.8599469661712646, 3.8245112895965576, 2.247537136077881, 2.333284854888916], [1.08758544921875, 1.5750207901000977, 0.9301000833511353, 1.5783793926239014, 1.5328431129455566, 1.011347770690918, 1.0467262268066406], [2.485001564025879, 3.3042657375335693, 1.8096368312835693, 3.3503212928771973, 3.312318801879883, 1.9772148132324219, 2.040281295776367], [2.6780447959899902, 3.5286130905151367, 1.9250679016113281, 3.583233118057251, 3.550567626953125, 2.099571704864502, 2.172478675842285], [2.762594699859619, 3.6262123584747314, 1.975624680519104, 3.6844491958618164, 3.656137704849243, 2.1505160331726074, 2.230654716491699], [1.9287906885147095, 2.632533311843872, 1.4695055484771729, 2.6565542221069336, 2.616572856903076, 1.6132330894470215, 1.6521331071853638], [1.9978209733963013, 2.716972827911377, 1.5108658075332642, 2.7424917221069336, 2.7062692642211914, 1.659255862236023, 1.7008774280548096], [2.939755439758301, 3.8374440670013428, 2.0826313495635986, 3.895251512527466, 3.8593802452087402, 2.260406732559204, 2.3582496643066406], [2.58048677444458, 3.4154508113861084, 1.8667945861816406, 3.4660394191741943, 3.432494640350342, 2.0420613288879395, 2.107384204864502], [2.625612258911133, 3.466356039047241, 1.8942841291427612, 3.5189261436462402, 3.486356019973755, 2.069180488586426, 2.135835647583008], [2.942260980606079, 3.838460922241211, 2.083448648452759, 3.8994240760803223, 3.862706422805786, 2.2694478034973145, 2.358372211456299], [2.6954052448272705, 3.5507447719573975, 1.9372398853302002, 3.6071488857269287, 3.576848030090332, 2.1050021648406982, 2.1857824325561523], [2.5313615798950195, 3.3553078174591064, 1.8377665281295776, 3.4047398567199707, 3.3699488639831543, 2.0092451572418213, 2.071599006652832], [2.7243611812591553, 3.585092067718506, 1.9549713134765625, 3.641799211502075, 3.609494924545288, 2.1227712631225586, 2.206538200378418], [1.2388006448745728, 1.7702239751815796, 1.0296391248703003, 1.7751078605651855, 1.72948157787323, 1.1270318031311035, 1.157281517982483], [2.6227307319641113, 3.465837240219116, 1.8927431106567383, 3.5183963775634766, 3.485093355178833, 2.0681354999542236, 2.136808395385742], [1.8973369598388672, 2.5927553176879883, 1.4471924304962158, 2.614483594894409, 2.5750601291656494, 1.5948126316070557, 1.6276211738586426], [2.9709270000457764, 3.8715672492980957, 2.1001698970794678, 3.9336044788360596, 3.8970093727111816, 2.2906436920166016, 2.377410411834717], [1.1117466688156128, 1.6057854890823364, 0.9476673007011414, 1.6083272695541382, 1.5634006261825562, 1.0323160886764526, 1.0644488334655762], [2.9683995246887207, 3.8709914684295654, 2.0994741916656494, 3.9322474002838135, 3.89389705657959, 2.287642478942871, 2.378018856048584], [2.261798858642578, 3.0365395545959473, 1.6735820770263672, 3.073758125305176, 3.035674571990967, 1.830122947692871, 1.885684847831726], [2.7115797996520996, 3.5700905323028564, 1.946905255317688, 3.6271259784698486, 3.5942223072052, 2.1221773624420166, 2.2002053260803223], [2.0332372188568115, 2.758307695388794, 1.5312551259994507, 2.785773992538452, 2.7470858097076416, 1.6827644109725952, 1.72404944896698], [2.772780418395996, 3.638760805130005, 1.983119010925293, 3.699638605117798, 3.668295383453369, 2.1580538749694824, 2.2396154403686523], [1.588955044746399, 2.210845708847046, 1.254828691482544, 2.2235021591186523, 2.1819636821746826, 1.3792719841003418, 1.4097599983215332], [1.532886028289795, 2.14163875579834, 1.2191798686981201, 2.152627944946289, 2.109618663787842, 1.3406354188919067, 1.3701997995376587], [3.0009803771972656, 3.911851406097412, 2.118739128112793, 3.9726643562316895, 3.9304022789001465, 2.3163766860961914, 2.404602527618408], [0.9926220178604126, 1.4537301063537598, 0.8674460053443909, 1.454635500907898, 1.4094345569610596, 0.9381895065307617, 0.9764808416366577], [2.8134522438049316, 3.6880502700805664, 2.0067124366760254, 3.7459909915924072, 3.711665153503418, 2.1859097480773926, 2.267005443572998], [2.9181759357452393, 3.8080151081085205, 2.068418264389038, 3.871504783630371, 3.8368592262268066, 2.2524712085723877, 2.339876651763916], [2.936410427093506, 3.8314616680145264, 2.080753803253174, 3.892487049102783, 3.8599133491516113, 2.265645742416382, 2.3534059524536133], [2.9074857234954834, 3.795226573944092, 2.062412977218628, 3.855881690979004, 3.8211264610290527, 2.240978717803955, 2.3298850059509277], [2.709554433822632, 3.5650393962860107, 1.9444465637207031, 3.6221048831939697, 3.588984966278076, 2.1213157176971436, 2.195988178253174], [1.6624302864074707, 2.3033969402313232, 1.300877332687378, 2.3178961277008057, 2.2757647037506104, 1.4288136959075928, 1.4633105993270874], [1.3755007982254028, 1.9434436559677124, 1.11860191822052, 1.9508835077285767, 1.9079926013946533, 1.2287367582321167, 1.2567245960235596], [2.4238224029541016, 3.2286832332611084, 1.772043228149414, 3.2736971378326416, 3.2366843223571777, 1.9380621910095215, 1.9969598054885864], [1.3407031297683716, 1.898850679397583, 1.0935766696929932, 1.9043338298797607, 1.8614745140075684, 1.199873685836792, 1.2307612895965576], [1.2482088804244995, 1.78229558467865, 1.0357609987258911, 1.7859829664230347, 1.742120385169983, 1.1322447061538696, 1.1647688150405884], [1.1307272911071777, 1.631426215171814, 0.9585174322128296, 1.634352684020996, 1.5880521535873413, 1.045969843864441, 1.0792927742004395], [2.941688060760498, 3.8376550674438477, 2.084688186645508, 3.898585319519043, 3.863750457763672, 2.2733092308044434, 2.357574462890625], [1.4786288738250732, 2.0741989612579346, 1.1836283206939697, 2.083914279937744, 2.04086971282959, 1.3021475076675415, 1.331507682800293], [2.10383939743042, 2.8484156131744385, 1.5760688781738281, 2.878880262374878, 2.84051775932312, 1.732378363609314, 1.7771565914154053], [1.3124985694885254, 1.8630365133285522, 1.077467441558838, 1.8692069053649902, 1.8260631561279297, 1.1814963817596436, 1.2110884189605713], [2.7140893936157227, 3.5705010890960693, 1.9474424123764038, 3.6264326572418213, 3.5942728519439697, 2.1262333393096924, 2.1974687576293945], [1.3827780485153198, 1.9542454481124878, 1.1222612857818604, 1.961108684539795, 1.9171911478042603, 1.2343862056732178, 1.2644190788269043], [1.025596022605896, 1.4953868389129639, 0.8899506330490112, 1.497302532196045, 1.4512550830841064, 0.9642133712768555, 1.0000951290130615], [1.3080174922943115, 1.8572580814361572, 1.0748673677444458, 1.8631850481033325, 1.8185805082321167, 1.1774659156799316, 1.2093532085418701], [1.124776840209961, 1.6240043640136719, 0.9546554684638977, 1.6268826723098755, 1.58122718334198, 1.0414812564849854, 1.0734766721725464], [1.1085565090179443, 1.602975845336914, 0.9446545839309692, 1.605467438697815, 1.5604667663574219, 1.0278340578079224, 1.0624970197677612], [2.8526718616485596, 3.731455087661743, 2.030123233795166, 3.7915401458740234, 3.760354518890381, 2.203853130340576, 2.293539047241211], [1.6953331232070923, 2.345350980758667, 1.3213860988616943, 2.3593997955322266, 2.319406032562256, 1.4538938999176025, 1.4874423742294312], [2.89123797416687, 3.776498317718506, 2.0537357330322266, 3.8399014472961426, 3.80717134475708, 2.2390897274017334, 2.3221435546875], [2.909543514251709, 3.7991132736206055, 2.064279794692993, 3.8600339889526367, 3.8272037506103516, 2.2490081787109375, 2.3326773643493652], [2.206169366836548, 2.9683563709259033, 1.6402766704559326, 3.0025925636291504, 2.9668922424316406, 1.796189546585083, 1.845334529876709], [2.1842007637023926, 2.9421324729919434, 1.6264023780822754, 2.9765632152557373, 2.9414710998535156, 1.7837518453598022, 1.8309434652328491], [2.1842596530914307, 2.942303419113159, 1.626326322555542, 2.9756019115448, 2.939307689666748, 1.7829114198684692, 1.8307634592056274], [2.062241315841675, 2.795830011367798, 1.5510485172271729, 2.8239665031433105, 2.7865331172943115, 1.7039121389389038, 1.745221734046936], [1.9116958379745483, 2.6117045879364014, 1.4582512378692627, 2.634157419204712, 2.595885753631592, 1.602837324142456, 1.640425205230713], [1.0571473836898804, 1.5356844663619995, 0.9101495146751404, 1.5394840240478516, 1.4925317764282227, 0.9878697395324707, 1.0244985818862915], [1.1464935541152954, 1.649291753768921, 0.9687584042549133, 1.6538619995117188, 1.6080374717712402, 1.0567303895950317, 1.0891337394714355], [1.6975566148757935, 2.347787380218506, 1.322153091430664, 2.3638811111450195, 2.322354555130005, 1.4546213150024414, 1.488100290298462], [1.98053777217865, 2.6962780952453613, 1.5010323524475098, 2.7234156131744385, 2.6845858097076416, 1.6498072147369385, 1.6902340650558472], [1.5909879207611084, 2.2137718200683594, 1.2562627792358398, 2.2264339923858643, 2.1848716735839844, 1.3822702169418335, 1.4125491380691528], [2.912071943283081, 3.801809787750244, 2.0650064945220947, 3.863602638244629, 3.832760810852051, 2.2507107257843018, 2.3358187675476074], [1.223248839378357, 1.7488240003585815, 1.0195369720458984, 1.7535979747772217, 1.7082560062408447, 1.114936113357544, 1.146360158920288], [1.0630160570144653, 1.5435643196105957, 0.9140039682388306, 1.546177625656128, 1.4994252920150757, 0.992497444152832, 1.0288543701171875], [2.476156234741211, 3.2928314208984375, 1.8039828538894653, 3.3378353118896484, 3.305697441101074, 1.9720146656036377, 2.0351474285125732], [2.41318416595459, 3.2166857719421387, 1.7661470174789429, 3.259880542755127, 3.2259421348571777, 1.933361530303955, 1.9895334243774414], [1.3933558464050293, 1.9663387537002563, 1.1286722421646118, 1.9728007316589355, 1.929274082183838, 1.237497091293335, 1.269250512123108], [2.9186861515045166, 3.8107352256774902, 2.070652961730957, 3.8730061054229736, 3.8380448818206787, 2.2550599575042725, 2.341909408569336], [2.7004952430725098, 3.5564825534820557, 1.9400428533554077, 3.6128363609313965, 3.5825393199920654, 2.1064505577087402, 2.1903443336486816], [2.95928955078125, 3.86419939994812, 2.0942349433898926, 3.921027898788452, 3.878390073776245, 2.279910087585449, 2.3744163513183594], [1.869372010231018, 2.55997371673584, 1.4316203594207764, 2.58182430267334, 2.5428285598754883, 1.5757732391357422, 1.6114201545715332], [2.7836573123931885, 3.65362286567688, 1.9891902208328247, 3.7128803730010986, 3.679882287979126, 2.162999153137207, 2.2478132247924805], [2.607530355453491, 3.4473886489868164, 1.8845865726470947, 3.4995367527008057, 3.4680917263031006, 2.0547544956207275, 2.125678062438965], [2.5672788619995117, 3.4010274410247803, 1.859262228012085, 3.4516265392303467, 3.416931629180908, 2.0276007652282715, 2.099771499633789], [2.744246244430542, 3.607537031173706, 1.9661312103271484, 3.6659045219421387, 3.6329429149627686, 2.1393861770629883, 2.2211761474609375], [2.6372931003570557, 3.4823801517486572, 1.9004950523376465, 3.534238338470459, 3.499729871749878, 2.066009998321533, 2.145735740661621], [1.5348924398422241, 2.143336772918701, 1.2206110954284668, 2.1538541316986084, 2.1114308834075928, 1.3393244743347168, 1.3717396259307861], [2.8022689819335938, 3.6740942001342773, 2.00140380859375, 3.732539176940918, 3.7032220363616943, 2.1779589653015137, 2.2588963508605957], [2.2411949634552, 3.011641263961792, 1.6608437299728394, 3.0477638244628906, 3.011448621749878, 1.8140923976898193, 1.8714121580123901], [3.000735282897949, 3.9121227264404297, 2.120011329650879, 3.9719972610473633, 3.929798126220703, 2.3150289058685303, 2.403611183166504], [2.836902618408203, 3.7177915573120117, 2.021883964538574, 3.776061773300171, 3.740602970123291, 2.2042770385742188, 2.286990165710449], [2.8330154418945312, 3.7094578742980957, 2.0185956954956055, 3.769953727722168, 3.7384908199310303, 2.197061538696289, 2.2819266319274902], [2.002249240875244, 2.721930980682373, 1.513979434967041, 2.7477314472198486, 2.7087996006011963, 1.6629295349121094, 1.7027987241744995], [2.972066879272461, 3.8726727962493896, 2.101626396179199, 3.935068130493164, 3.8966317176818848, 2.2897069454193115, 2.3801870346069336], [2.599456787109375, 3.4387905597686768, 1.8789204359054565, 3.489528179168701, 3.455127477645874, 2.0487914085388184, 2.1197896003723145], [1.1177922487258911, 1.6142773628234863, 0.9512768387794495, 1.6170669794082642, 1.5708109140396118, 1.0361119508743286, 1.0694680213928223], [1.8596551418304443, 2.5499889850616455, 1.425862193107605, 2.5701658725738525, 2.5299530029296875, 1.570347547531128, 1.6055740118026733], [1.8031284809112549, 2.478630781173706, 1.3895188570022583, 2.4972617626190186, 2.4566266536712646, 1.527777910232544, 1.5636903047561646], [2.867492437362671, 3.750286817550659, 2.0393121242523193, 3.8101887702941895, 3.780484437942505, 2.217062473297119, 2.3043832778930664], [2.965488910675049, 3.8700101375579834, 2.096585273742676, 3.930213212966919, 3.8920674324035645, 2.286911964416504, 2.3776822090148926], [1.8622033596038818, 2.5509684085845947, 1.4256576299667358, 2.5720977783203125, 2.5308563709259033, 1.5717308521270752, 1.6059374809265137], [2.9212698936462402, 3.815704584121704, 2.0701355934143066, 3.8751115798950195, 3.8382880687713623, 2.2507035732269287, 2.3424715995788574], [2.4344420433044434, 3.2447330951690674, 1.7800636291503906, 3.289935350418091, 3.254354238510132, 1.9457135200500488, 2.0088021755218506], [2.85593318939209, 3.736591339111328, 2.032670021057129, 3.7963547706604004, 3.765439987182617, 2.2105746269226074, 2.295621871948242], [1.3847445249557495, 1.9545522928237915, 1.1233952045440674, 1.9613919258117676, 1.917838454246521, 1.2345187664031982, 1.2624410390853882], [2.972175359725952, 3.874150514602661, 2.1019744873046875, 3.9361536502838135, 3.899949073791504, 2.293527603149414, 2.380992889404297], [1.5756781101226807, 2.19574236869812, 1.2471261024475098, 2.206914186477661, 2.1654789447784424, 1.368729591369629, 1.4013919830322266], [2.243255853652954, 3.0128087997436523, 1.6635209321975708, 3.0500831604003906, 3.0135550498962402, 1.820960521697998, 1.872918963432312], [2.958982229232788, 3.859816789627075, 2.094078779220581, 3.9200074672698975, 3.880152463912964, 2.2841989994049072, 2.3703713417053223], [3.003727436065674, 3.9134700298309326, 2.120896816253662, 3.974553108215332, 3.9330270290374756, 2.317220687866211, 2.4046249389648438], [1.7186425924301147, 2.3735387325286865, 1.3350144624710083, 2.3886983394622803, 2.3486835956573486, 1.4693981409072876, 1.5007392168045044], [2.047124147415161, 2.7760016918182373, 1.542884111404419, 2.803194999694824, 2.76737380027771, 1.691487193107605, 1.7342971563339233], [2.4234535694122314, 3.230903148651123, 1.77423894405365, 3.2753422260284424, 3.24120831489563, 1.9360244274139404, 1.9989453554153442], [1.283311367034912, 1.825490951538086, 1.0578566789627075, 1.8312819004058838, 1.7867794036865234, 1.1576637029647827, 1.1891521215438843], [2.847980499267578, 3.724499464035034, 2.026214838027954, 3.785935878753662, 3.756593942642212, 2.202528476715088, 2.289322853088379], [2.678140878677368, 3.5295920372009277, 1.9265069961547852, 3.5855162143707275, 3.5537166595458984, 2.0924839973449707, 2.174976348876953], [1.5430940389633179, 2.1543967723846436, 1.2263157367706299, 2.1658883094787598, 2.1241729259490967, 1.34803307056427, 1.3783949613571167], [2.6487579345703125, 3.4958810806274414, 1.9090975522994995, 3.550008773803711, 3.5190746784210205, 2.07705020904541, 2.1536264419555664], [2.7596933841705322, 3.6232593059539795, 1.974806547164917, 3.6815757751464844, 3.649966239929199, 2.144386053085327, 2.2281765937805176], [1.2210770845413208, 1.7474726438522339, 1.017557978630066, 1.751546859741211, 1.706426739692688, 1.1135540008544922, 1.144491195678711], [1.5858793258666992, 2.207141637802124, 1.2515950202941895, 2.2197892665863037, 2.178497076034546, 1.3751884698867798, 1.4076176881790161], [2.90875244140625, 3.799253225326538, 2.064387321472168, 3.8596317768096924, 3.8256895542144775, 2.2431869506835938, 2.33404541015625], [1.659302830696106, 2.299041509628296, 1.3000342845916748, 2.314657688140869, 2.2730069160461426, 1.4295423030853271, 1.461108922958374], [1.8326514959335327, 2.513568639755249, 1.4084287881851196, 2.5337038040161133, 2.493608236312866, 1.5491516590118408, 1.5840367078781128], [2.8857524394989014, 3.7692341804504395, 2.050093173980713, 3.83182954788208, 3.799478054046631, 2.2336947917938232, 2.3170928955078125], [2.9342668056488037, 3.8292133808135986, 2.07844877243042, 3.890181303024292, 3.8553452491760254, 2.258852958679199, 2.3536319732666016], [2.631885051727295, 3.474250555038452, 1.898984670639038, 3.527433395385742, 3.4984076023101807, 2.06886625289917, 2.1400680541992188], [1.6633448600769043, 2.3044583797454834, 1.3021222352981567, 2.31864333152771, 2.276606798171997, 1.431503415107727, 1.463655710220337], [2.113792896270752, 2.8566274642944336, 1.5830775499343872, 2.8875224590301514, 2.8500866889953613, 1.7360124588012695, 1.781741976737976], [2.790370464324951, 3.660214424133301, 1.9939863681793213, 3.719069004058838, 3.689342975616455, 2.1721763610839844, 2.2515087127685547], [2.656125068664551, 3.5027735233306885, 1.9128179550170898, 3.5564959049224854, 3.525580644607544, 2.083927869796753, 2.1575875282287598], [2.257192611694336, 3.03007435798645, 1.6717877388000488, 3.067610502243042, 3.0329782962799072, 1.8274047374725342, 1.8836246728897095], [2.6770472526550293, 3.528162956237793, 1.9255940914154053, 3.5836715698242188, 3.5543699264526367, 2.097024917602539, 2.1728105545043945], [3.0019707679748535, 3.913311004638672, 2.119232654571533, 3.9732861518859863, 3.931082010269165, 2.3180508613586426, 2.4045896530151367], [2.381868839263916, 3.1810765266418457, 1.7458044290542603, 3.2212436199188232, 3.1849305629730225, 1.9065672159194946, 1.9678598642349243], [2.548246383666992, 3.377202272415161, 1.847427487373352, 3.4264421463012695, 3.393399238586426, 2.0136239528656006, 2.0846426486968994], [2.826367139816284, 3.70320725440979, 2.0148422718048096, 3.7636897563934326, 3.73097562789917, 2.1917762756347656, 2.2781944274902344], [1.8119773864746094, 2.487370491027832, 1.3944876194000244, 2.506382465362549, 2.4672019481658936, 1.5358517169952393, 1.5690019130706787], [1.5769634246826172, 2.197445869445801, 1.2459392547607422, 2.2081828117370605, 2.1662235260009766, 1.370467185974121, 1.4008162021636963], [1.4551026821136475, 2.0435550212860107, 1.1678296327590942, 2.052194356918335, 2.008760690689087, 1.2833740711212158, 1.312886118888855], [2.8344624042510986, 3.7129948139190674, 2.018958568572998, 3.773982048034668, 3.7412467002868652, 2.1989316940307617, 2.284555435180664], [1.9256490468978882, 2.6297712326049805, 1.466822624206543, 2.653108835220337, 2.614441394805908, 1.6110459566116333, 1.650199055671692], [1.650477647781372, 2.288663148880005, 1.291724443435669, 2.30177640914917, 2.2597367763519287, 1.422835111618042, 1.4526209831237793], [1.1512072086334229, 1.657267451286316, 0.9734254479408264, 1.6597068309783936, 1.613232135772705, 1.0602837800979614, 1.0929539203643799], [2.692887306213379, 3.5504162311553955, 1.936414361000061, 3.602982759475708, 3.5665979385375977, 2.106151819229126, 2.1853251457214355], [2.8020706176757812, 3.6710760593414307, 2.0004003047943115, 3.7315049171447754, 3.7013399600982666, 2.1758270263671875, 2.257984161376953], [1.3993861675262451, 1.9735208749771118, 1.1335434913635254, 1.980760931968689, 1.9358855485916138, 1.243261456489563, 1.2745474576950073], [2.912163019180298, 3.80025315284729, 2.06457257270813, 3.8600213527679443, 3.829096555709839, 2.2424323558807373, 2.332313060760498], [1.1951812505722046, 1.7134464979171753, 1.0020378828048706, 1.7172231674194336, 1.6710093021392822, 1.0937068462371826, 1.1253044605255127], [1.4489721059799194, 2.0357346534729004, 1.1659735441207886, 2.0455286502838135, 2.0024704933166504, 1.2816954851150513, 1.311076045036316], [1.271383285522461, 1.810488224029541, 1.0518115758895874, 1.8159323930740356, 1.771183729171753, 1.151092529296875, 1.1813074350357056], [2.5777502059936523, 3.411979913711548, 1.8660039901733398, 3.462287664413452, 3.42869234085083, 2.0290966033935547, 2.1040759086608887], [2.347107172012329, 3.1369407176971436, 1.7265875339508057, 3.177807331085205, 3.144231081008911, 1.8874077796936035, 1.9437379837036133], [2.8074464797973633, 3.678619146347046, 2.003755807876587, 3.7376747131347656, 3.70703125, 2.180953025817871, 2.2624154090881348], [2.8266985416412354, 3.705352783203125, 2.015108823776245, 3.765458106994629, 3.730685234069824, 2.195957660675049, 2.279573917388916], [2.412365674972534, 3.2158472537994385, 1.765730381011963, 3.258319139480591, 3.224912166595459, 1.9298322200775146, 1.9894590377807617], [2.573478937149048, 3.4056894779205322, 1.8625422716140747, 3.4546549320220947, 3.425764560699463, 2.0318312644958496, 2.101449489593506], [1.921897530555725, 2.624922513961792, 1.4642834663391113, 2.6480162143707275, 2.608760356903076, 1.6106971502304077, 1.6483234167099], [2.7393972873687744, 3.600749969482422, 1.9622482061386108, 3.6570210456848145, 3.6252737045288086, 2.138424873352051, 2.2163496017456055], [2.5711700916290283, 3.4052090644836426, 1.8611257076263428, 3.4547908306121826, 3.421692132949829, 2.029266834259033, 2.1017327308654785], [2.912992000579834, 3.8058485984802246, 2.0667526721954346, 3.8658721446990967, 3.828554153442383, 2.2550010681152344, 2.3371787071228027], [2.465513229370117, 3.2790005207061768, 1.798216700553894, 3.3241562843322754, 3.2897181510925293, 1.963564395904541, 2.0260133743286133], [1.3746551275253296, 1.9415725469589233, 1.1174956560134888, 1.9489415884017944, 1.905478835105896, 1.2268611192703247, 1.256080150604248], [2.346451759338379, 3.1368765830993652, 1.7254537343978882, 3.177339792251587, 3.143649101257324, 1.8897396326065063, 1.9435808658599854], [1.4047857522964478, 1.9803130626678467, 1.1370444297790527, 1.9875611066818237, 1.9459245204925537, 1.2465832233428955, 1.2779579162597656], [1.5315489768981934, 2.138944149017334, 1.2170056104660034, 2.150223731994629, 2.1069891452789307, 1.339456558227539, 1.3683815002441406], [2.1234383583068848, 2.8680148124694824, 1.590006947517395, 2.899477958679199, 2.863440752029419, 1.743604063987732, 1.7885932922363281], [1.9773160219192505, 2.690448760986328, 1.4976835250854492, 2.7155823707580566, 2.6775035858154297, 1.6444547176361084, 1.6849279403686523], [2.395051956176758, 3.1955432891845703, 1.756054162979126, 3.2382309436798096, 3.2069907188415527, 1.9160387516021729, 1.9787191152572632], [1.5659960508346558, 2.182170867919922, 1.2403658628463745, 2.1951866149902344, 2.1524546146392822, 1.3632384538650513, 1.3953156471252441], [1.922711730003357, 2.6257450580596924, 1.4640073776245117, 2.6499054431915283, 2.609874725341797, 1.6126682758331299, 1.6499603986740112], [2.6124014854431152, 3.4528393745422363, 1.8870962858200073, 3.5044052600860596, 3.473865032196045, 2.0560719966888428, 2.1284170150756836], [2.6939892768859863, 3.5467307567596436, 1.9363576173782349, 3.601686477661133, 3.5714685916900635, 2.1113457679748535, 2.182384967803955], [1.5246225595474243, 2.1324079036712646, 1.2135523557662964, 2.1412200927734375, 2.100113868713379, 1.3359370231628418, 1.3631207942962646], [1.2733116149902344, 1.813510537147522, 1.0515438318252563, 1.8197640180587769, 1.77443528175354, 1.1538382768630981, 1.1835495233535767], [1.957229733467102, 2.664187431335449, 1.4862416982650757, 2.6893293857574463, 2.6519503593444824, 1.6322864294052124, 1.6711235046386719], [2.218510150909424, 2.9837992191314697, 1.647932767868042, 3.016613721847534, 2.9832098484039307, 1.803454875946045, 1.8545376062393188], [2.0039994716644287, 2.7244176864624023, 1.5115410089492798, 2.7473506927490234, 2.7078959941864014, 1.6625492572784424, 1.703389286994934], [2.8151352405548096, 3.6879336833953857, 2.007751226425171, 3.745523691177368, 3.7175374031066895, 2.1838009357452393, 2.265761375427246], [1.691904067993164, 2.3405001163482666, 1.3199571371078491, 2.354830026626587, 2.31592059135437, 1.4531930685043335, 1.483797311782837], [2.250602960586548, 3.024313449859619, 1.6658823490142822, 3.059476137161255, 3.0202724933624268, 1.82841157913208, 1.8779736757278442], [2.1881585121154785, 2.945589542388916, 1.6276354789733887, 2.9792191982269287, 2.9419875144958496, 1.784619927406311, 1.8314822912216187], [1.6895544528961182, 2.337358236312866, 1.3172049522399902, 2.351931095123291, 2.3116369247436523, 1.450189232826233, 1.4819270372390747], [2.3769028186798096, 3.172128915786743, 1.7437450885772705, 3.213989734649658, 3.18015456199646, 1.909398078918457, 1.9634350538253784], [2.253661870956421, 3.0271265506744385, 1.6696621179580688, 3.062283754348755, 3.0284948348999023, 1.8321267366409302, 1.878423810005188], [1.6762077808380127, 2.319418430328369, 1.309994101524353, 2.3348002433776855, 2.293473958969116, 1.4401808977127075, 1.4729015827178955], [1.102885127067566, 1.5952507257461548, 0.941979169845581, 1.5984562635421753, 1.5531647205352783, 1.0252352952957153, 1.0573878288269043], [2.843823194503784, 3.7202608585357666, 2.0243172645568848, 3.779721975326538, 3.75154447555542, 2.202606678009033, 2.2845849990844727], [1.2617636919021606, 1.7991783618927002, 1.0437153577804565, 1.804760456085205, 1.7591371536254883, 1.1423733234405518, 1.1736996173858643], [1.2803161144256592, 1.8230315446853638, 1.0568292140960693, 1.8279391527175903, 1.7830902338027954, 1.157329797744751, 1.1888911724090576], [2.2279367446899414, 2.997288703918457, 1.6528875827789307, 3.0319724082946777, 2.994248390197754, 1.8119584321975708, 1.8635002374649048], [2.8303959369659424, 3.7076728343963623, 2.0168190002441406, 3.7680246829986572, 3.7356927394866943, 2.1994736194610596, 2.2795629501342773], [1.1455618143081665, 1.65221107006073, 0.9687154293060303, 1.655022144317627, 1.60921049118042, 1.0572642087936401, 1.0908843278884888], [2.899756669998169, 3.784104824066162, 2.056375026702881, 3.846956729888916, 3.815859317779541, 2.2328639030456543, 2.3260068893432617], [1.3579946756362915, 1.9204109907150269, 1.107202410697937, 1.9284117221832275, 1.8845239877700806, 1.2158102989196777, 1.2448818683624268], [2.306187629699707, 3.088655710220337, 1.701799988746643, 3.1272666454315186, 3.0932271480560303, 1.8595616817474365, 1.9153170585632324], [2.934969902038574, 3.8277885913848877, 2.0783283710479736, 3.8903679847717285, 3.8567144870758057, 2.2600812911987305, 2.3504409790039062], [1.8371756076812744, 2.520143985748291, 1.4105428457260132, 2.5390431880950928, 2.498819589614868, 1.5493948459625244, 1.586450457572937], [1.3498252630233765, 1.9090893268585205, 1.100992202758789, 1.916353702545166, 1.871836543083191, 1.2095623016357422, 1.2378616333007812], [2.883747100830078, 3.767383098602295, 2.0494697093963623, 3.829610586166382, 3.7972657680511475, 2.2288284301757812, 2.3172507286071777], [2.1976351737976074, 2.957371473312378, 1.6335170269012451, 2.991379976272583, 2.954758405685425, 1.793269395828247, 1.8385493755340576], [2.800114631652832, 3.6742441654205322, 1.998997449874878, 3.7303802967071533, 3.696363687515259, 2.1796627044677734, 2.2586865425109863], [1.1691662073135376, 1.6806503534317017, 0.9840558171272278, 1.6841899156570435, 1.6390728950500488, 1.0743399858474731, 1.106986165046692], [2.6090188026428223, 3.4509458541870117, 1.8853826522827148, 3.500077962875366, 3.463671922683716, 2.053661823272705, 2.1259875297546387], [1.2943006753921509, 1.840522289276123, 1.063966155052185, 1.846099615097046, 1.8014202117919922, 1.1671772003173828, 1.1990619897842407], [2.100038528442383, 2.8416225910186768, 1.572211503982544, 2.8708033561706543, 2.8310539722442627, 1.7266221046447754, 1.7712275981903076], [2.920283794403076, 3.8103315830230713, 2.071265935897827, 3.8731298446655273, 3.840407133102417, 2.2567362785339355, 2.3415846824645996], [2.058908700942993, 2.78948974609375, 1.5495436191558838, 2.8179306983947754, 2.7795450687408447, 1.699122428894043, 1.7422889471054077], [1.6626906394958496, 2.305448055267334, 1.3000832796096802, 2.3191463947296143, 2.276670455932617, 1.4298595190048218, 1.4618147611618042], [1.9195038080215454, 2.620690107345581, 1.461436152458191, 2.643782377243042, 2.604306936264038, 1.6073471307754517, 1.6463148593902588], [2.264284372329712, 3.038337469100952, 1.674014925956726, 3.075208902359009, 3.040090322494507, 1.8358330726623535, 1.885428547859192], [1.9720250368118286, 2.6865923404693604, 1.493039846420288, 2.710465431213379, 2.6684155464172363, 1.643953561782837, 1.6829503774642944], [2.6100804805755615, 3.447611093521118, 1.885041356086731, 3.4992868900299072, 3.4703845977783203, 2.0473477840423584, 2.1255335807800293], [2.8258068561553955, 3.7008731365203857, 2.0142316818237305, 3.7607481479644775, 3.732089042663574, 2.1901602745056152, 2.2755980491638184], [2.3096582889556885, 3.0938773155212402, 1.7026115655899048, 3.132101535797119, 3.098118782043457, 1.8605817556381226, 1.9175556898117065], [2.945863723754883, 3.843200445175171, 2.085109233856201, 3.9037091732025146, 3.868817090988159, 2.269017219543457, 2.358933925628662], [1.2369368076324463, 1.7672244310379028, 1.0284463167190552, 1.7718629837036133, 1.7255847454071045, 1.1248434782028198, 1.1575169563293457], [1.1119381189346313, 1.605837345123291, 0.9466396570205688, 1.6087323427200317, 1.5630491971969604, 1.029948353767395, 1.0623284578323364], [2.057715892791748, 2.788390874862671, 1.5477120876312256, 2.817150115966797, 2.7775590419769287, 1.698392629623413, 1.741127371788025], [1.2653870582580566, 1.8027533292770386, 1.0468865633010864, 1.8086254596710205, 1.7642911672592163, 1.1464588642120361, 1.1771783828735352], [2.4478299617767334, 3.2620790004730225, 1.7883491516113281, 3.3052268028259277, 3.27336049079895, 1.9562697410583496, 2.0164754390716553], [1.552870750427246, 2.1672658920288086, 1.2316093444824219, 2.177753448486328, 2.134880304336548, 1.3542290925979614, 1.3853846788406372], [2.241157293319702, 3.008754253387451, 1.6601742506027222, 3.045130968093872, 3.009453535079956, 1.8191165924072266, 1.8688490390777588], [2.6675314903259277, 3.5179600715637207, 1.920423150062561, 3.573007583618164, 3.540950298309326, 2.089000940322876, 2.166806221008301], [1.6501379013061523, 2.288635492324829, 1.2941219806671143, 2.3025872707366943, 2.260690927505493, 1.4233416318893433, 1.455058217048645], [2.0045416355133057, 2.7244701385498047, 1.5152870416641235, 2.750776529312134, 2.712815523147583, 1.66611647605896, 1.7058682441711426], [2.339120864868164, 3.127934694290161, 1.722044825553894, 3.169191360473633, 3.1354238986968994, 1.8819059133529663, 1.9393181800842285], [2.63533091545105, 3.480752944946289, 1.9014884233474731, 3.53305721282959, 3.500981330871582, 2.0688393115997314, 2.1449098587036133], [2.97666597366333, 3.8802237510681152, 2.1045734882354736, 3.9416885375976562, 3.904581069946289, 2.2981133460998535, 2.3847298622131348], [1.1010385751724243, 1.593677282333374, 0.9390284419059753, 1.595826268196106, 1.5507235527038574, 1.0234031677246094, 1.0565128326416016], [1.6299904584884644, 2.2627644538879395, 1.2806051969528198, 2.275801658630371, 2.234375476837158, 1.408532738685608, 1.44057035446167], [2.0949630737304688, 2.836731195449829, 1.5716636180877686, 2.866626024246216, 2.829317092895508, 1.7241638898849487, 1.7707264423370361], [1.7312506437301636, 2.388437032699585, 1.3448972702026367, 2.405393600463867, 2.3654165267944336, 1.4797130823135376, 1.5124881267547607], [2.3773412704467773, 3.17425799369812, 1.7426941394805908, 3.214752674102783, 3.181914806365967, 1.9058154821395874, 1.9635422229766846], [1.043494462966919, 1.5176392793655396, 0.9019094109535217, 1.521664023399353, 1.4754490852355957, 0.9798257350921631, 1.015139102935791], [2.1783947944641113, 2.935997724533081, 1.6222633123397827, 2.968646287918091, 2.9328975677490234, 1.7774817943572998, 1.825286865234375], [1.0632820129394531, 1.543658971786499, 0.9142017364501953, 1.5457463264465332, 1.4998589754104614, 0.9942054748535156, 1.0276824235916138], [2.528559446334839, 3.3540382385253906, 1.8364497423171997, 3.403085947036743, 3.3689730167388916, 2.0064072608947754, 2.071389675140381], [1.6778831481933594, 2.323777198791504, 1.309158444404602, 2.336944818496704, 2.2960610389709473, 1.4428876638412476, 1.4739655256271362], [2.786456823348999, 3.6585490703582764, 1.990678310394287, 3.71608567237854, 3.6829159259796143, 2.170123815536499, 2.2507524490356445], [2.218055248260498, 2.984680652618408, 1.6481205224990845, 3.0193090438842773, 2.9846279621124268, 1.8033957481384277, 1.8552638292312622], [1.3876630067825317, 1.9590028524398804, 1.1257609128952026, 1.9658538103103638, 1.9209840297698975, 1.234682321548462, 1.2678228616714478], [2.3703696727752686, 3.165095090866089, 1.739301085472107, 3.206342935562134, 3.170146942138672, 1.903664469718933, 1.9602634906768799], [2.7404377460479736, 3.6051948070526123, 1.961162805557251, 3.6607282161712646, 3.6235718727111816, 2.1335136890411377, 2.2203760147094727], [2.8603124618530273, 3.7405385971069336, 2.035094738006592, 3.8008697032928467, 3.7685086727142334, 2.207710027694702, 2.299149513244629], [2.2896621227264404, 3.0693674087524414, 1.6900333166122437, 3.1065971851348877, 3.0709707736968994, 1.8517811298370361, 1.9040064811706543], [2.9869186878204346, 3.8935348987579346, 2.1107828617095947, 3.9545822143554688, 3.9136810302734375, 2.304389476776123, 2.3918027877807617], [1.342491865158081, 1.9013500213623047, 1.0969674587249756, 1.9066492319107056, 1.8630427122116089, 1.2020108699798584, 1.2324376106262207], [2.839634656906128, 3.7143983840942383, 2.021895408630371, 3.77593994140625, 3.7442264556884766, 2.200047016143799, 2.2834396362304688], [1.405381679534912, 1.9812419414520264, 1.1369140148162842, 1.9888815879821777, 1.9451408386230469, 1.2495605945587158, 1.2785272598266602], [2.4433910846710205, 3.2533063888549805, 1.783947467803955, 3.298079490661621, 3.263225793838501, 1.947204828262329, 2.0124168395996094], [2.4356706142425537, 3.2430660724639893, 1.7808955907821655, 3.2879292964935303, 3.2552568912506104, 1.9457073211669922, 2.006870746612549], [1.7787048816680908, 2.4492764472961426, 1.3735864162445068, 2.4671573638916016, 2.4260921478271484, 1.5098986625671387, 1.5464965105056763], [2.9893407821655273, 3.8963217735290527, 2.1122915744781494, 3.9569034576416016, 3.916895866394043, 2.30779767036438, 2.3940181732177734], [2.9056639671325684, 3.796950578689575, 2.061967611312866, 3.857945680618286, 3.82258939743042, 2.248988389968872, 2.333707809448242], [1.4521576166152954, 2.041037082672119, 1.1674591302871704, 2.048696756362915, 2.00565505027771, 1.2837104797363281, 1.3117702007293701], [1.7905930280685425, 2.466017723083496, 1.3796756267547607, 2.4822964668273926, 2.4416120052337646, 1.5167924165725708, 1.5536125898361206], [1.2219393253326416, 1.746645450592041, 1.020363450050354, 1.7504990100860596, 1.705195665359497, 1.1130690574645996, 1.1445667743682861], [2.8974061012268066, 3.785125732421875, 2.05645489692688, 3.846573829650879, 3.812267541885376, 2.2431325912475586, 2.325817584991455], [2.6359024047851562, 3.480030059814453, 1.900482177734375, 3.5335118770599365, 3.5021743774414062, 2.0719738006591797, 2.145566940307617], [1.3758248090744019, 1.9441754817962646, 1.1180557012557983, 1.9505095481872559, 1.9066364765167236, 1.2267547845840454, 1.2560789585113525], [2.484232187271118, 3.3022754192352295, 1.8084235191345215, 3.34883713722229, 3.3143668174743652, 1.9727981090545654, 2.0396318435668945], [1.6088389158248901, 2.2359817028045654, 1.2667299509048462, 2.2480878829956055, 2.2063746452331543, 1.3937386274337769, 1.4238954782485962], [2.61248779296875, 3.455070734024048, 1.8869174718856812, 3.505896806716919, 3.4688796997070312, 2.058373212814331, 2.1321096420288086], [1.126052975654602, 1.6248477697372437, 0.9563746452331543, 1.6270747184753418, 1.5818853378295898, 1.0408661365509033, 1.0741931200027466], [1.922974705696106, 2.625807285308838, 1.464167594909668, 2.648893117904663, 2.609790802001953, 1.6106114387512207, 1.6483319997787476], [2.465869665145874, 3.2798097133636475, 1.7973473072052002, 3.32555890083313, 3.289661169052124, 1.9663448333740234, 2.027164936065674], [1.336483359336853, 1.8955882787704468, 1.0936698913574219, 1.9006454944610596, 1.8572208881378174, 1.1993741989135742, 1.2287815809249878], [1.9430228471755981, 2.651125431060791, 1.4782187938690186, 2.676351547241211, 2.6355438232421875, 1.6233644485473633, 1.664156436920166], [2.2663872241973877, 3.0416650772094727, 1.6764817237854004, 3.0803372859954834, 3.04349684715271, 1.835597276687622, 1.8904805183410645], [2.9265034198760986, 3.821624279022217, 2.0740625858306885, 3.8817484378814697, 3.8471217155456543, 2.2552993297576904, 2.3473100662231445], [2.1932666301727295, 2.9545795917510986, 1.6331369876861572, 2.989602565765381, 2.9531021118164062, 1.7900402545928955, 1.8394086360931396], [2.4017577171325684, 3.2042088508605957, 1.7603179216384888, 3.246941328048706, 3.212850332260132, 1.9226694107055664, 1.9833731651306152], [2.8398356437683105, 3.7162814140319824, 2.0223021507263184, 3.7764382362365723, 3.7416481971740723, 2.1908111572265625, 2.2851338386535645], [1.5479553937911987, 2.1608030796051025, 1.228244662284851, 2.170837640762329, 2.129505157470703, 1.3503128290176392, 1.381808876991272], [1.8741685152053833, 2.569272994995117, 1.4324768781661987, 2.588533401489258, 2.5476157665252686, 1.5760632753372192, 1.613774061203003], [2.4688720703125, 3.2857706546783447, 1.8016116619110107, 3.3310625553131104, 3.2962982654571533, 1.9660494327545166, 2.0304460525512695], [2.966526985168457, 3.8688812255859375, 2.098987579345703, 3.9320831298828125, 3.8915607929229736, 2.2903339862823486, 2.3779916763305664], [1.8295423984527588, 2.5096967220306396, 1.4064538478851318, 2.530334711074829, 2.491270065307617, 1.547493577003479, 1.5821917057037354], [1.3213047981262207, 1.8737279176712036, 1.083204984664917, 1.8799045085906982, 1.8358733654022217, 1.1870694160461426, 1.2174875736236572], [1.3868210315704346, 1.9576021432876587, 1.1253606081008911, 1.9638513326644897, 1.9210983514785767, 1.2355846166610718, 1.2646270990371704], [1.6963372230529785, 2.346012830734253, 1.3216934204101562, 2.3608973026275635, 2.3200368881225586, 1.4556678533554077, 1.4878488779067993], [2.369367837905884, 3.164250373840332, 1.740126371383667, 3.2064454555511475, 3.171461820602417, 1.8993748426437378, 1.9593278169631958], [1.1874053478240967, 1.7023138999938965, 0.9956540465354919, 1.7054483890533447, 1.6617058515548706, 1.08600914478302, 1.1185029745101929], [1.0186032056808472, 1.4869438409805298, 0.8840458393096924, 1.4889156818389893, 1.442239761352539, 0.9579211473464966, 0.9956278204917908], [0.9364372491836548, 1.3804688453674316, 0.8288511633872986, 1.3806973695755005, 1.3360978364944458, 0.8935874700546265, 0.9345901012420654], [2.4084391593933105, 3.2104945182800293, 1.7638169527053833, 3.2544639110565186, 3.2212142944335938, 1.9231104850769043, 1.9876750707626343], [1.986129641532898, 2.7023425102233887, 1.503962516784668, 2.726853609085083, 2.6899678707122803, 1.6504426002502441, 1.6905494928359985], [1.907762050628662, 2.60559344291687, 1.4543412923812866, 2.6276886463165283, 2.587761402130127, 1.6002923250198364, 1.636215090751648], [2.9563536643981934, 3.8566765785217285, 2.092118263244629, 3.9166462421417236, 3.880873680114746, 2.2817909717559814, 2.369333267211914], [1.6896519660949707, 2.338930130004883, 1.3175485134124756, 2.3545453548431396, 2.3130998611450195, 1.4517873525619507, 1.4842948913574219], [2.4642467498779297, 3.2788643836975098, 1.7981681823730469, 3.3247194290161133, 3.2915520668029785, 1.9639382362365723, 2.02730655670166], [2.1295273303985596, 2.875431776046753, 1.5934988260269165, 2.9083030223846436, 2.87221622467041, 1.7459888458251953, 1.7933332920074463], [1.658992886543274, 2.299064874649048, 1.2989329099655151, 2.3122565746307373, 2.273137092590332, 1.429284691810608, 1.459769368171692], [1.957396388053894, 2.6679279804229736, 1.486818552017212, 2.690554141998291, 2.653169631958008, 1.6319106817245483, 1.6708519458770752], [2.8710179328918457, 3.752028703689575, 2.038814067840576, 3.8131299018859863, 3.780268430709839, 2.2109627723693848, 2.3055739402770996], [1.6312123537063599, 2.263766050338745, 1.2809019088745117, 2.276898145675659, 2.2362685203552246, 1.408134937286377, 1.4405760765075684], [2.582629442214966, 3.4165749549865723, 1.8697651624679565, 3.467620372772217, 3.4362285137176514, 2.0370874404907227, 2.107257843017578], [1.0445809364318848, 1.5201383829116821, 0.9013271927833557, 1.5211678743362427, 1.4763182401657104, 0.9773207902908325, 1.0143402814865112], [1.986864447593689, 2.7029573917388916, 1.5038959980010986, 2.728231906890869, 2.68865704536438, 1.651440143585205, 1.6921371221542358], [2.895728588104248, 3.7815654277801514, 2.0542407035827637, 3.8418595790863037, 3.8092639446258545, 2.2342450618743896, 2.32204008102417], [2.904025077819824, 3.7910268306732178, 2.0599842071533203, 3.853328227996826, 3.821580410003662, 2.241910219192505, 2.3313980102539062], [2.294919967651367, 3.0763680934906006, 1.6944279670715332, 3.1140053272247314, 3.0797157287597656, 1.853208065032959, 1.909454107284546], [2.6496479511260986, 3.4961745738983154, 1.909688949584961, 3.549772262573242, 3.5180418491363525, 2.081403970718384, 2.155938148498535], [1.530289888381958, 2.138448715209961, 1.2183510065078735, 2.148693561553955, 2.1064114570617676, 1.3396610021591187, 1.3688527345657349], [1.3318723440170288, 1.8878382444381714, 1.0899957418441772, 1.8936967849731445, 1.849187970161438, 1.195390224456787, 1.225372076034546], [1.762208342552185, 2.4271812438964844, 1.3637974262237549, 2.445885181427002, 2.4055514335632324, 1.5034562349319458, 1.535548210144043], [2.9194447994232178, 3.809304714202881, 2.068971633911133, 3.8693175315856934, 3.8330461978912354, 2.2424278259277344, 2.3398890495300293], [2.1356561183929443, 2.8853185176849365, 1.5958938598632812, 2.9168856143951416, 2.8766443729400635, 1.7499043941497803, 1.7972087860107422], [2.4765608310699463, 3.293884754180908, 1.8045423030853271, 3.339768648147583, 3.3085408210754395, 1.9678516387939453, 2.0357158184051514], [1.3376717567443848, 1.8957170248031616, 1.093722939491272, 1.9018487930297852, 1.8581697940826416, 1.1991418600082397, 1.230002760887146], [1.7549546957015991, 2.4197754859924316, 1.3586732149124146, 2.43558931350708, 2.394808053970337, 1.4965088367462158, 1.528185486793518], [2.933399200439453, 3.8273470401763916, 2.079449415206909, 3.8895671367645264, 3.854297399520874, 2.265380382537842, 2.352297782897949], [1.586459994316101, 2.2071027755737305, 1.2528282403945923, 2.2190229892730713, 2.177537679672241, 1.377217411994934, 1.4073362350463867], [2.2936646938323975, 3.0751266479492188, 1.6925010681152344, 3.113023519515991, 3.077110528945923, 1.8524736166000366, 1.9077733755111694], [2.8066468238830566, 3.6821844577789307, 2.002326726913452, 3.738426446914673, 3.7038071155548096, 2.178999662399292, 2.2637224197387695], [2.098951578140259, 2.840545415878296, 1.5730206966400146, 2.8701205253601074, 2.832798480987549, 1.7253073453903198, 1.7713420391082764], [2.9009437561035156, 3.7863705158233643, 2.056748390197754, 3.8470356464385986, 3.8163580894470215, 2.234635353088379, 2.324042797088623], [2.3292932510375977, 3.1154627799987793, 1.713710069656372, 3.1559982299804688, 3.122617721557617, 1.8768820762634277, 1.9316775798797607], [2.915987014770508, 3.806334972381592, 2.066908597946167, 3.8686206340789795, 3.8340890407562256, 2.253999948501587, 2.339909076690674], [2.8170533180236816, 3.690692186355591, 2.007655143737793, 3.750369071960449, 3.719783067703247, 2.181432008743286, 2.269303798675537], [2.2737414836883545, 3.0493528842926025, 1.6802911758422852, 3.0868728160858154, 3.0507030487060547, 1.842279076576233, 1.8927412033081055], [1.5459709167480469, 2.1584441661834717, 1.2277123928070068, 2.1691744327545166, 2.127690315246582, 1.3488612174987793, 1.3801144361495972], [2.959587574005127, 3.8599772453308105, 2.0930681228637695, 3.920426845550537, 3.8832414150238037, 2.278898000717163, 2.3725500106811523], [1.553689956665039, 2.1677486896514893, 1.231994390487671, 2.1778171062469482, 2.1375222206115723, 1.3543795347213745, 1.3848628997802734], [1.3432101011276245, 1.9016972780227661, 1.0979946851730347, 1.9095396995544434, 1.8643946647644043, 1.2030977010726929, 1.2345938682556152], [1.7745884656906128, 2.442028760910034, 1.370501160621643, 2.4611384868621826, 2.419987201690674, 1.5093697309494019, 1.5438662767410278], [2.402179718017578, 3.203714370727539, 1.7606323957443237, 3.246840476989746, 3.214238166809082, 1.922231912612915, 1.9826308488845825], [1.6515029668807983, 2.2898216247558594, 1.2934179306030273, 2.3035037517547607, 2.262259006500244, 1.4215946197509766, 1.4548439979553223], [1.4287770986557007, 2.0099546909332275, 1.1526844501495361, 2.0194661617279053, 1.9758927822113037, 1.2666646242141724, 1.2957704067230225], [1.1500377655029297, 1.65542733669281, 0.9710054397583008, 1.6595228910446167, 1.6137604713439941, 1.0577164888381958, 1.0935111045837402], [1.4320454597473145, 2.0156285762786865, 1.1546522378921509, 2.022624969482422, 1.978703260421753, 1.2662171125411987, 1.298417091369629], [1.7791191339492798, 2.447526454925537, 1.3752135038375854, 2.4654085636138916, 2.4267849922180176, 1.5113681554794312, 1.5461091995239258], [1.2486592531204224, 1.7824327945709229, 1.0367000102996826, 1.787384033203125, 1.7408162355422974, 1.1363129615783691, 1.1653187274932861], [1.2797956466674805, 1.822288990020752, 1.055396556854248, 1.8270193338394165, 1.7818089723587036, 1.1591664552688599, 1.1870797872543335], [2.328639507293701, 3.114795684814453, 1.7139239311218262, 3.153831720352173, 3.1180479526519775, 1.8769491910934448, 1.930478811264038], [2.5876529216766357, 3.423888921737671, 1.8714439868927002, 3.475342273712158, 3.4389488697052, 2.0388500690460205, 2.1126327514648438], [2.88265061378479, 3.7666475772857666, 2.0480613708496094, 3.8292622566223145, 3.7962422370910645, 2.2259421348571777, 2.3175315856933594], [1.54746675491333, 2.1591298580169678, 1.2281831502914429, 2.170919895172119, 2.128572463989258, 1.3510057926177979, 1.380948543548584], [2.081658124923706, 2.816879987716675, 1.5635221004486084, 2.8471264839172363, 2.8091392517089844, 1.713832974433899, 1.759405493736267], [2.9951632022857666, 3.9055123329162598, 2.114501476287842, 3.962581157684326, 3.9196722507476807, 2.304896116256714, 2.395962715148926], [2.9620652198791504, 3.8618037700653076, 2.0931942462921143, 3.920915365219116, 3.887991428375244, 2.280329704284668, 2.371067523956299], [2.672865629196167, 3.5235276222229004, 1.9232758283615112, 3.57840633392334, 3.5492265224456787, 2.092007637023926, 2.171929359436035], [1.5618054866790771, 2.177495241165161, 1.2371712923049927, 2.189171314239502, 2.1473469734191895, 1.362181305885315, 1.3916133642196655], [2.318685293197632, 3.1024155616760254, 1.7094159126281738, 3.143205404281616, 3.1056315898895264, 1.8682548999786377, 1.9241899251937866], [2.8362507820129395, 3.7116332054138184, 2.020113468170166, 3.772406816482544, 3.741508960723877, 2.1915197372436523, 2.2812857627868652], [2.1536741256713867, 2.9056944847106934, 1.6068062782287598, 2.9375550746917725, 2.900747299194336, 1.7636367082595825, 1.8084617853164673], [2.3091001510620117, 3.093327283859253, 1.7030442953109741, 3.1303534507751465, 3.095564603805542, 1.8612834215164185, 1.9162977933883667], [1.771605372428894, 2.4387378692626953, 1.368843913078308, 2.455303192138672, 2.4149508476257324, 1.5064027309417725, 1.5398008823394775], [2.7271509170532227, 3.587075710296631, 1.955936074256897, 3.642333984375, 3.6114540100097656, 2.130014657974243, 2.2064719200134277], [2.499037742614746, 3.31852388381958, 1.8193879127502441, 3.366037607192993, 3.3348381519317627, 1.9868569374084473, 2.05002498626709], [1.735999345779419, 2.3947646617889404, 1.3473637104034424, 2.4106273651123047, 2.3701558113098145, 1.4825661182403564, 1.5141032934188843], [1.3547192811965942, 1.9180688858032227, 1.1059224605560303, 1.9248181581497192, 1.8808554410934448, 1.2133896350860596, 1.2429189682006836], [2.694175958633423, 3.5475733280181885, 1.9367659091949463, 3.6028542518615723, 3.5719988346099854, 2.1078455448150635, 2.184152126312256], [2.5173375606536865, 3.340864658355713, 1.8302195072174072, 3.3894917964935303, 3.3572192192077637, 1.9960863590240479, 2.063859462738037], [1.8913452625274658, 2.586639404296875, 1.4442548751831055, 2.608423948287964, 2.5697340965270996, 1.5885151624679565, 1.625939130783081], [2.64798641204834, 3.4958205223083496, 1.908674716949463, 3.548633337020874, 3.5168585777282715, 2.0807509422302246, 2.1538033485412598], [1.8651288747787476, 2.554563045501709, 1.4296486377716064, 2.575788974761963, 2.5374011993408203, 1.568739414215088, 1.608747124671936], [2.8710994720458984, 3.752690076828003, 2.0412607192993164, 3.8127143383026123, 3.7824785709381104, 2.2207419872283936, 2.3066110610961914], [2.768734931945801, 3.636836051940918, 1.9813134670257568, 3.695612907409668, 3.66412091255188, 2.152576446533203, 2.2382450103759766], [1.9255422353744507, 2.6284282207489014, 1.4645764827728271, 2.649646282196045, 2.612175226211548, 1.6086891889572144, 1.6487613916397095], [1.5217701196670532, 2.128079414367676, 1.210762858390808, 2.1371612548828125, 2.0949547290802, 1.3296571969985962, 1.362015962600708], [1.1993927955627441, 1.718932867050171, 1.003859281539917, 1.7246977090835571, 1.6787487268447876, 1.0990517139434814, 1.1294738054275513], [2.739612340927124, 3.5980584621429443, 1.9627028703689575, 3.6562869548797607, 3.6263623237609863, 2.1348092555999756, 2.215261936187744], [1.2406892776489258, 1.7710883617401123, 1.0305653810501099, 1.7759639024734497, 1.7321587800979614, 1.1274043321609497, 1.1582742929458618], [2.148836374282837, 2.898930311203003, 1.6044987440109253, 2.930311918258667, 2.896092176437378, 1.7592524290084839, 1.8057059049606323], [2.727240800857544, 3.58821702003479, 1.9549355506896973, 3.6459779739379883, 3.617013931274414, 2.128957748413086, 2.210381031036377], [1.8769868612289429, 2.567505121231079, 1.4359194040298462, 2.589519739151001, 2.551229953765869, 1.5799858570098877, 1.614881992340088], [2.9091029167175293, 3.797806978225708, 2.0647964477539062, 3.8604888916015625, 3.828007221221924, 2.2467195987701416, 2.334066390991211], [1.9418648481369019, 2.6479592323303223, 1.4762401580810547, 2.6730563640594482, 2.6342737674713135, 1.6241952180862427, 1.6623170375823975], [1.9128762483596802, 2.6121294498443604, 1.4593316316604614, 2.6347496509552, 2.598158836364746, 1.6047227382659912, 1.641305685043335], [2.8965768814086914, 3.781059980392456, 2.054631233215332, 3.8412294387817383, 3.809966802597046, 2.2339437007904053, 2.32004976272583], [1.1988693475723267, 1.7190150022506714, 1.0036370754241943, 1.7224993705749512, 1.6772081851959229, 1.0967631340026855, 1.1281970739364624], [2.8675477504730225, 3.7472455501556396, 2.0386593341827393, 3.8084559440612793, 3.778815269470215, 2.218212127685547, 2.302380084991455], [1.776495337486267, 2.444683074951172, 1.372299313545227, 2.462672233581543, 2.421579122543335, 1.510996699333191, 1.543172836303711], [2.8951332569122314, 3.781702756881714, 2.0551834106445312, 3.842132091522217, 3.8108444213867188, 2.232578754425049, 2.323390007019043], [2.8910181522369385, 3.777113676071167, 2.0522279739379883, 3.837650775909424, 3.8060431480407715, 2.235682249069214, 2.3192076683044434], [1.7277671098709106, 2.384575605392456, 1.3420253992080688, 2.401481866836548, 2.3607330322265625, 1.4775711297988892, 1.5102146863937378], [2.0712814331054688, 2.8056273460388184, 1.5584676265716553, 2.83432936668396, 2.797495126724243, 1.7073283195495605, 1.7527129650115967], [1.3343108892440796, 1.8905787467956543, 1.090908169746399, 1.8966552019119263, 1.8522604703903198, 1.1970046758651733, 1.2267884016036987], [2.0630722045898438, 2.796116352081299, 1.5515568256378174, 2.824495553970337, 2.786181688308716, 1.702909231185913, 1.7447775602340698], [2.648477792739868, 3.4941980838775635, 1.9096561670303345, 3.5489046573638916, 3.5163142681121826, 2.0787041187286377, 2.153459072113037], [2.221529245376587, 2.985363245010376, 1.6483947038650513, 3.021188497543335, 2.9856810569763184, 1.8086614608764648, 1.8554526567459106], [1.1762059926986694, 1.6889047622680664, 0.9879418611526489, 1.6915407180786133, 1.647600531578064, 1.0797615051269531, 1.1111528873443604], [2.0487051010131836, 2.778005838394165, 1.5436654090881348, 2.80698561668396, 2.7688331604003906, 1.6939396858215332, 1.7369565963745117], [2.960036516189575, 3.860311508178711, 2.09427809715271, 3.921236515045166, 3.884221315383911, 2.2807605266571045, 2.3710951805114746], [1.809838056564331, 2.486717700958252, 1.39402437210083, 2.5054173469543457, 2.4666061401367188, 1.5341659784317017, 1.567914605140686], [1.3835859298706055, 1.9542732238769531, 1.1228834390640259, 1.9611090421676636, 1.9174810647964478, 1.2313785552978516, 1.2630947828292847], [2.6000208854675293, 3.438429832458496, 1.8798688650131226, 3.488818407058716, 3.4571077823638916, 2.048325300216675, 2.119555950164795], [1.4886772632598877, 2.086082696914673, 1.1905534267425537, 2.0953409671783447, 2.050812005996704, 1.308316707611084, 1.3390381336212158], [2.875159502029419, 3.7572648525238037, 2.0442988872528076, 3.818864107131958, 3.7876832485198975, 2.2227940559387207, 2.3101282119750977], [1.3358505964279175, 1.8931509256362915, 1.091562271118164, 1.899473786354065, 1.8550894260406494, 1.1988251209259033, 1.2274824380874634], [2.891315460205078, 3.7769405841827393, 2.0533955097198486, 3.8372702598571777, 3.8031985759735107, 2.232243776321411, 2.319492816925049], [2.769364833831787, 3.6324944496154785, 1.978461742401123, 3.692798137664795, 3.66273832321167, 2.1475300788879395, 2.2342567443847656], [2.208548069000244, 2.97163724899292, 1.6402779817581177, 3.006499767303467, 2.9690895080566406, 1.796476125717163, 1.8472394943237305], [1.6055068969726562, 2.230776071548462, 1.265684723854065, 2.2440199851989746, 2.202834129333496, 1.3922796249389648, 1.4224193096160889], [1.3011853694915771, 1.8478604555130005, 1.0707728862762451, 1.853297233581543, 1.81063711643219, 1.1732972860336304, 1.201880693435669], [1.5497575998306274, 2.1626157760620117, 1.2307064533233643, 2.1738672256469727, 2.13214111328125, 1.3519457578659058, 1.3826788663864136], [2.987276315689087, 3.8928370475769043, 2.109689712524414, 3.9524013996124268, 3.9144320487976074, 2.302304744720459, 2.3899760246276855], [2.5563199520111084, 3.3862664699554443, 1.853654384613037, 3.4359829425811768, 3.4029183387756348, 2.021364450454712, 2.088942050933838], [2.9642693996429443, 3.863651752471924, 2.0972936153411865, 3.925328254699707, 3.888845443725586, 2.2845563888549805, 2.3726840019226074], [1.9590238332748413, 2.6680264472961426, 1.4856867790222168, 2.6913139820098877, 2.6537508964538574, 1.6341813802719116, 1.670707106590271], [2.9082043170928955, 3.7971243858337402, 2.0622177124023438, 3.8587417602539062, 3.826482057571411, 2.2446682453155518, 2.3336315155029297], [2.9030940532684326, 3.7908082008361816, 2.0597126483917236, 3.85139799118042, 3.8214731216430664, 2.2396674156188965, 2.3292617797851562], [1.304408311843872, 1.8527418375015259, 1.0714929103851318, 1.8575270175933838, 1.8135510683059692, 1.1735559701919556, 1.2039378881454468], [1.381025791168213, 1.9506094455718994, 1.1220307350158691, 1.9581620693206787, 1.9152432680130005, 1.2340128421783447, 1.260949969291687], [1.3514503240585327, 1.9126368761062622, 1.1028660535812378, 1.9200475215911865, 1.8750932216644287, 1.2097561359405518, 1.2402161359786987], [2.333956480026245, 3.1242661476135254, 1.71869695186615, 3.1641476154327393, 3.1300177574157715, 1.876240611076355, 1.9362760782241821], [1.4307255744934082, 2.0125348567962646, 1.1538264751434326, 2.0224239826202393, 1.9793986082077026, 1.2679111957550049, 1.2982407808303833], [2.4856464862823486, 3.3048667907714844, 1.8103890419006348, 3.3507120609283447, 3.3185391426086426, 1.97833251953125, 2.0427145957946777], [2.9225144386291504, 3.8126635551452637, 2.071805477142334, 3.8756086826324463, 3.841848611831665, 2.259675979614258, 2.3432836532592773], [1.323706030845642, 1.8769786357879639, 1.0852068662643433, 1.8830801248550415, 1.8389540910720825, 1.1896719932556152, 1.2200566530227661], [1.6496177911758423, 2.2877376079559326, 1.2924679517745972, 2.299976348876953, 2.2586233615875244, 1.4218966960906982, 1.4525548219680786], [1.4235388040542603, 2.00483775138855, 1.1495156288146973, 2.0116729736328125, 1.9704294204711914, 1.2626612186431885, 1.2921217679977417], [2.9563381671905518, 3.853609800338745, 2.0905725955963135, 3.9146668910980225, 3.8781898021698, 2.273061990737915, 2.3663430213928223], [1.3902758359909058, 1.9619860649108887, 1.1270755529403687, 1.969417691230774, 1.9239226579666138, 1.238356351852417, 1.269166111946106], [2.4880645275115967, 3.302971124649048, 1.8112291097640991, 3.351011037826538, 3.3163344860076904, 1.976940393447876, 2.041661262512207], [2.9533884525299072, 3.851811647415161, 2.0915110111236572, 3.9137516021728516, 3.8750641345977783, 2.2777390480041504, 2.3687314987182617], [1.3218868970870972, 1.8743133544921875, 1.0842148065567017, 1.8809168338775635, 1.8365200757980347, 1.1887396574020386, 1.2178046703338623], [1.279085397720337, 1.8211023807525635, 1.0558390617370605, 1.8266669511795044, 1.782536506652832, 1.1571226119995117, 1.1871992349624634], [2.9620521068573, 3.864008903503418, 2.0951290130615234, 3.923435926437378, 3.8839073181152344, 2.28214693069458, 2.374570369720459], [2.581252336502075, 3.4191696643829346, 1.868410348892212, 3.4682939052581787, 3.4296035766601562, 2.0398595333099365, 2.1077842712402344], [2.3318028450012207, 3.1181395053863525, 1.7164109945297241, 3.158212661743164, 3.1235814094543457, 1.8789759874343872, 1.9335683584213257], [2.897726535797119, 3.782822847366333, 2.0578606128692627, 3.8460676670074463, 3.813349962234497, 2.24139142036438, 2.3264899253845215], [1.2449570894241333, 1.778550624847412, 1.0345011949539185, 1.7820788621902466, 1.7374275922775269, 1.131544828414917, 1.1625829935073853], [2.8245904445648193, 3.7005579471588135, 2.0135209560394287, 3.758416175842285, 3.7256288528442383, 2.1849451065063477, 2.2742972373962402], [2.2508463859558105, 3.0225448608398438, 1.6683719158172607, 3.0595719814300537, 3.0241572856903076, 1.8272401094436646, 1.877063274383545], [2.2406375408172607, 3.0140395164489746, 1.6607197523117065, 3.0481631755828857, 3.009634494781494, 1.8124134540557861, 1.8721224069595337], [1.7949414253234863, 2.466508626937866, 1.3842427730560303, 2.4850969314575195, 2.4453866481781006, 1.5223884582519531, 1.557665228843689], [2.289299488067627, 3.068613052368164, 1.690995454788208, 3.1065642833709717, 3.0731472969055176, 1.8501248359680176, 1.9042110443115234], [2.785057544708252, 3.6520938873291016, 1.9905009269714355, 3.7110025882720947, 3.68229079246521, 2.161207675933838, 2.24509859085083], [1.3699419498443604, 1.9374409914016724, 1.1153429746627808, 1.9427648782730103, 1.9004639387130737, 1.2234079837799072, 1.2527046203613281], [2.978776454925537, 3.883622884750366, 2.104642152786255, 3.945646047592163, 3.9049792289733887, 2.2953929901123047, 2.3880362510681152], [2.6848952770233154, 3.538809061050415, 1.9298328161239624, 3.593705177307129, 3.5593202114105225, 2.1016101837158203, 2.17897891998291], [2.246964693069458, 3.020718812942505, 1.6639662981033325, 3.0548768043518066, 3.0160186290740967, 1.8242263793945312, 1.8752038478851318], [2.3193771839141846, 3.1051652431488037, 1.708287000656128, 3.143498659133911, 3.1053783893585205, 1.8715828657150269, 1.9243383407592773], [2.824669122695923, 3.6995973587036133, 2.012995719909668, 3.7598628997802734, 3.7285828590393066, 2.195361852645874, 2.27506160736084], [2.655332326889038, 3.502199411392212, 1.913588047027588, 3.5557310581207275, 3.5231027603149414, 2.0819907188415527, 2.157029628753662], [1.7323282957077026, 2.3904502391815186, 1.3452398777008057, 2.40598201751709, 2.3653576374053955, 1.4809705018997192, 1.5127754211425781], [2.0972061157226562, 2.8396573066711426, 1.5721603631973267, 2.867766857147217, 2.8314177989959717, 1.7278170585632324, 1.771096110343933], [1.4655784368515015, 2.0564913749694824, 1.1757794618606567, 2.0653271675109863, 2.022188901901245, 1.2912490367889404, 1.3216142654418945], [2.3862597942352295, 3.1862449645996094, 1.7501888275146484, 3.228196144104004, 3.1938705444335938, 1.914395809173584, 1.9719115495681763], [1.2281707525253296, 1.75519859790802, 1.0228909254074097, 1.760695457458496, 1.7148659229278564, 1.11758291721344, 1.1498302221298218], [2.552155017852783, 3.3834354877471924, 1.8519307374954224, 3.432586193084717, 3.3982136249542236, 2.019801139831543, 2.088407278060913], [2.99467134475708, 3.9050486087799072, 2.1166257858276367, 3.960569143295288, 3.919807195663452, 2.3063206672668457, 2.398125171661377], [2.0538532733917236, 2.784466028213501, 1.5463005304336548, 2.8129422664642334, 2.77571964263916, 1.6968234777450562, 1.740407109260559], [1.571933388710022, 2.1905860900878906, 1.2442545890808105, 2.2016451358795166, 2.159874200820923, 1.367441177368164, 1.398813247680664], [2.5070362091064453, 3.3306665420532227, 1.824477195739746, 3.3783135414123535, 3.3463306427001953, 1.9907774925231934, 2.057079792022705], [2.6536507606506348, 3.502046823501587, 1.9116008281707764, 3.5552337169647217, 3.52364444732666, 2.0827627182006836, 2.158141613006592], [2.7433695793151855, 3.6080384254455566, 1.9652701616287231, 3.665018320083618, 3.632351875305176, 2.1398708820343018, 2.220653533935547], [2.263648509979248, 3.0383572578430176, 1.6748958826065063, 3.07564640045166, 3.039464235305786, 1.8329687118530273, 1.8862367868423462], [2.5510082244873047, 3.381479263305664, 1.8500146865844727, 3.4327211380004883, 3.3989856243133545, 2.020822763442993, 2.088298797607422], [1.8454378843307495, 2.529369592666626, 1.4162135124206543, 2.548771619796753, 2.5102827548980713, 1.5535893440246582, 1.5916788578033447], [2.8320062160491943, 3.713395357131958, 2.0187556743621826, 3.770082712173462, 3.7340643405914307, 2.200974702835083, 2.2833786010742188], [2.9340949058532715, 3.828200101852417, 2.0781893730163574, 3.890364408493042, 3.8567910194396973, 2.2675769329071045, 2.3518519401550293], [2.4121153354644775, 3.215869665145874, 1.7671688795089722, 3.2608413696289062, 3.2256205081939697, 1.9316153526306152, 1.9904460906982422], [2.407670259475708, 3.2088699340820312, 1.7617326974868774, 3.252182722091675, 3.2173941135406494, 1.9302983283996582, 1.9851356744766235], [1.1341769695281982, 1.635253667831421, 0.961287260055542, 1.6393764019012451, 1.5938397645950317, 1.048109531402588, 1.0817333459854126], [1.178259253501892, 1.6920907497406006, 0.9904229044914246, 1.6957001686096191, 1.650895595550537, 1.082184076309204, 1.1129565238952637], [2.8423938751220703, 3.7182836532592773, 2.0242204666137695, 3.778958559036255, 3.745575428009033, 2.1940860748291016, 2.285633087158203], [2.7196266651153564, 3.581716537475586, 1.9506502151489258, 3.6368677616119385, 3.5992021560668945, 2.1278023719787598, 2.2071218490600586], [2.763838529586792, 3.628110647201538, 1.9781190156936646, 3.686898946762085, 3.6572165489196777, 2.1491527557373047, 2.232438087463379], [1.8917330503463745, 2.587303400039673, 1.44587242603302, 2.6097240447998047, 2.569981336593628, 1.589398741722107, 1.6266342401504517], [1.0096787214279175, 1.4748940467834473, 0.8794603943824768, 1.4777159690856934, 1.4314203262329102, 0.9545813798904419, 0.9893187284469604], [2.917736053466797, 3.8088595867156982, 2.069685220718384, 3.870624303817749, 3.8377766609191895, 2.253045082092285, 2.3400325775146484], [1.742541790008545, 2.4016687870025635, 1.3511848449707031, 2.41813588142395, 2.3775763511657715, 1.4875648021697998, 1.5198297500610352], [2.4976303577423096, 3.318885087966919, 1.8181209564208984, 3.3651061058044434, 3.330613374710083, 1.9856207370758057, 2.049185276031494], [2.3547146320343018, 3.147430896759033, 1.7307498455047607, 3.188168525695801, 3.153243064880371, 1.8932127952575684, 1.9501503705978394], [1.409614086151123, 1.9864295721054077, 1.1402032375335693, 1.9954042434692383, 1.9520291090011597, 1.2541121244430542, 1.2828375101089478], [2.9013495445251465, 3.7886624336242676, 2.0599119663238525, 3.8508150577545166, 3.8170862197875977, 2.243155002593994, 2.327277660369873], [2.0535316467285156, 2.7836225032806396, 1.545355200767517, 2.8116743564605713, 2.774301052093506, 1.6978033781051636, 1.7394449710845947], [2.82315731048584, 3.6946322917938232, 2.01237154006958, 3.755153179168701, 3.724822998046875, 2.1865434646606445, 2.2724947929382324], [2.4391703605651855, 3.249976396560669, 1.781790018081665, 3.2938718795776367, 3.2586045265197754, 1.9503600597381592, 2.0088348388671875], [2.440237045288086, 3.247568368911743, 1.7837580442428589, 3.2942464351654053, 3.261021852493286, 1.9457981586456299, 2.0100526809692383], [1.7173906564712524, 2.3704581260681152, 1.3355218172073364, 2.3863253593444824, 2.3462491035461426, 1.4678001403808594, 1.5023891925811768], [2.480962038040161, 3.2972497940063477, 1.8071041107177734, 3.343679189682007, 3.310009002685547, 1.972482681274414, 2.037688732147217], [2.1528260707855225, 2.907332181930542, 1.6055331230163574, 2.9358034133911133, 2.8951683044433594, 1.7567793130874634, 1.8090336322784424], [1.624843716621399, 2.256588935852051, 1.2770087718963623, 2.269181251525879, 2.2271900177001953, 1.4041557312011719, 1.4351627826690674], [2.950152635574341, 3.847907066345215, 2.0890302658081055, 3.910370349884033, 3.8752026557922363, 2.2768187522888184, 2.3651318550109863], [2.9964871406555176, 3.904981851577759, 2.116318702697754, 3.9647793769836426, 3.9253990650177, 2.3093068599700928, 2.399311065673828], [2.1666791439056396, 2.9222161769866943, 1.6154435873031616, 2.955127239227295, 2.917248010635376, 1.7736984491348267, 1.819619059562683], [2.496199607849121, 3.3145346641540527, 1.818122386932373, 3.362111806869507, 3.331099510192871, 1.9825379848480225, 2.048074722290039], [1.124343752861023, 1.6223344802856445, 0.954269528388977, 1.6256327629089355, 1.5792232751846313, 1.040323257446289, 1.0739754438400269], [1.4490805864334106, 2.0357139110565186, 1.1646207571029663, 2.044736623764038, 2.0008199214935303, 1.2785215377807617, 1.3103742599487305], [1.2732348442077637, 1.8118401765823364, 1.051637053489685, 1.8174183368682861, 1.772334337234497, 1.150842547416687, 1.1815000772476196], [2.690335750579834, 3.542179584503174, 1.9342775344848633, 3.5967628955841064, 3.5682473182678223, 2.1004703044891357, 2.179577350616455], [2.6391665935516357, 3.4847869873046875, 1.9024747610092163, 3.5377633571624756, 3.5053746700286865, 2.077666997909546, 2.1472978591918945], [1.2362732887268066, 1.7662241458892822, 1.0275517702102661, 1.771174669265747, 1.7253214120864868, 1.1243047714233398, 1.1564267873764038], [2.567193031311035, 3.398597002029419, 1.8597644567489624, 3.4487574100494385, 3.41668701171875, 2.0279269218444824, 2.097334861755371], [1.3064262866973877, 1.855634093284607, 1.0737643241882324, 1.8599793910980225, 1.8175638914108276, 1.1779123544692993, 1.2060869932174683], [2.5158188343048096, 3.339855670928955, 1.8287017345428467, 3.3876454830169678, 3.3561348915100098, 1.9975786209106445, 2.0611743927001953], [1.674250602722168, 2.319856643676758, 1.3077056407928467, 2.333240032196045, 2.2927494049072266, 1.4393360614776611, 1.471526026725769], [2.872377872467041, 3.754756450653076, 2.0414347648620605, 3.814384937286377, 3.7853400707244873, 2.222551107406616, 2.3068580627441406], [2.3132119178771973, 3.098317861557007, 1.7056703567504883, 3.136002540588379, 3.102365493774414, 1.8642629384994507, 1.9214328527450562], [1.5382623672485352, 2.1477766036987305, 1.2210997343063354, 2.1582419872283936, 2.116785764694214, 1.3436367511749268, 1.3734767436981201], [2.323977470397949, 3.109675884246826, 1.7109453678131104, 3.148653268814087, 3.1147661209106445, 1.8676635026931763, 1.9288692474365234], [2.8278286457061768, 3.7049524784088135, 2.015728712081909, 3.7637252807617188, 3.733059883117676, 2.1884329319000244, 2.276604175567627], [2.897341251373291, 3.784695863723755, 2.0569605827331543, 3.847632884979248, 3.812654495239258, 2.2359371185302734, 2.3261260986328125], [2.2405927181243896, 3.0096304416656494, 1.6620560884475708, 3.0457022190093994, 3.013568878173828, 1.8156532049179077, 1.8709330558776855], [1.5858134031295776, 2.209641218185425, 1.2511205673217773, 2.220386028289795, 2.1792612075805664, 1.3773349523544312, 1.407615065574646], [2.8561816215515137, 3.738581418991089, 2.030919313430786, 3.7977752685546875, 3.7637417316436768, 2.207016706466675, 2.29838228225708], [1.8658193349838257, 2.5552732944488525, 1.4283479452133179, 2.575490951538086, 2.5363869667053223, 1.572776436805725, 1.6066538095474243], [1.4023693799972534, 1.9776320457458496, 1.1360424757003784, 1.9837661981582642, 1.9414461851119995, 1.2447935342788696, 1.2765494585037231], [2.6051242351531982, 3.4444034099578857, 1.8824260234832764, 3.4971835613250732, 3.46286678314209, 2.050482749938965, 2.124382972717285], [1.6766047477722168, 2.3200249671936035, 1.3098907470703125, 2.334796667098999, 2.29354190826416, 1.4405426979064941, 1.473227620124817], [1.422269582748413, 2.001955509185791, 1.148878574371338, 2.010611057281494, 1.9653600454330444, 1.262794017791748, 1.2926301956176758], [2.399538278579712, 3.2015058994293213, 1.7576744556427002, 3.2456095218658447, 3.211671829223633, 1.9223427772521973, 1.9823163747787476], [2.8051772117614746, 3.6778197288513184, 2.003019094467163, 3.735436201095581, 3.7060208320617676, 2.1759278774261475, 2.2612547874450684], [2.7006046772003174, 3.554462432861328, 1.9398432970046997, 3.6118059158325195, 3.5817692279815674, 2.1081700325012207, 2.189757823944092], [1.617537260055542, 2.246544122695923, 1.2730907201766968, 2.259578227996826, 2.218126058578491, 1.3989861011505127, 1.4308439493179321], [2.542630910873413, 3.374572515487671, 1.8472398519515991, 3.422661066055298, 3.386301040649414, 2.0172817707061768, 2.0836052894592285], [2.4678118228912354, 3.2814886569976807, 1.7990992069244385, 3.3273508548736572, 3.293600082397461, 1.9672789573669434, 2.029088020324707], [2.887188673019409, 3.7760555744171143, 2.0517191886901855, 3.8342623710632324, 3.7988452911376953, 2.231450080871582, 2.320246696472168], [1.7624831199645996, 2.4282007217407227, 1.363075852394104, 2.443962574005127, 2.4032015800476074, 1.499129056930542, 1.531973123550415], [2.658428192138672, 3.5052201747894287, 1.9138466119766235, 3.559826135635376, 3.528545379638672, 2.088818311691284, 2.1583805084228516], [2.119107961654663, 2.8642446994781494, 1.5874909162521362, 2.8961169719696045, 2.8570563793182373, 1.7429404258728027, 1.7869670391082764], [2.3045690059661865, 3.088123321533203, 1.7001140117645264, 3.1273369789123535, 3.09236478805542, 1.8571501970291138, 1.9156711101531982], [1.4355995655059814, 2.0195538997650146, 1.1559230089187622, 2.027833938598633, 1.984811782836914, 1.2698254585266113, 1.3003913164138794], [1.3827060461044312, 1.9531266689300537, 1.1231226921081543, 1.9597370624542236, 1.9152642488479614, 1.2325379848480225, 1.262486457824707], [1.4483273029327393, 2.033585786819458, 1.1644047498703003, 2.0428261756896973, 2.000589370727539, 1.280559778213501, 1.308879017829895], [2.983816623687744, 3.8907411098480225, 2.1082663536071777, 3.9523472785949707, 3.911372661590576, 2.303250312805176, 2.39093017578125], [2.2473437786102295, 3.0190622806549072, 1.6636641025543213, 3.054905652999878, 3.017056465148926, 1.8213449716567993, 1.8762894868850708], [2.00850248336792, 2.7294418811798096, 1.5171318054199219, 2.755720853805542, 2.717128276824951, 1.6676421165466309, 1.7064998149871826], [2.4309725761413574, 3.2366695404052734, 1.777228832244873, 3.2815351486206055, 3.247466802597046, 1.940185546875, 2.0029499530792236], [1.995399832725525, 2.7158455848693848, 1.5103330612182617, 2.740072011947632, 2.7022130489349365, 1.6597355604171753, 1.6980845928192139], [1.159233808517456, 1.6680140495300293, 0.976841151714325, 1.671262264251709, 1.626929521560669, 1.0674471855163574, 1.0991538763046265], [1.543988585472107, 2.1542115211486816, 1.2254326343536377, 2.1657633781433105, 2.124359130859375, 1.3473701477050781, 1.3779629468917847], [2.50537371635437, 3.327944040298462, 1.8216915130615234, 3.3747780323028564, 3.336174488067627, 1.9890727996826172, 2.056027889251709], [1.0270017385482788, 1.49736750125885, 0.8898088932037354, 1.4985394477844238, 1.453830599784851, 0.9661002159118652, 1.0014249086380005], [2.4442827701568604, 3.2515931129455566, 1.7845869064331055, 3.2961246967315674, 3.263124942779541, 1.9487509727478027, 2.0096826553344727], [1.7293274402618408, 2.3867883682250977, 1.3430486917495728, 2.40289044380188, 2.3619868755340576, 1.478690505027771, 1.5109676122665405], [2.4611592292785645, 3.275024652481079, 1.7969642877578735, 3.3213858604431152, 3.286008834838867, 1.9605255126953125, 2.0249290466308594], [1.1420143842697144, 1.6443517208099365, 0.9665892720222473, 1.648836612701416, 1.6021039485931396, 1.0519864559173584, 1.0879602432250977], [2.492323160171509, 3.3125970363616943, 1.8160653114318848, 3.3593671321868896, 3.3264007568359375, 1.9793720245361328, 2.045530319213867], [2.991361379623413, 3.9008095264434814, 2.113687753677368, 3.9613380432128906, 3.918154239654541, 2.305729866027832, 2.398176670074463], [1.6887465715408325, 2.3362159729003906, 1.3174448013305664, 2.3506593704223633, 2.3078629970550537, 1.4487378597259521, 1.480660319328308]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Loading the test data\n",
        "test_data = pd.read_csv (\"/content/drive/MyDrive/Colab Notebooks/testing_set.csv\")\n",
        "test_data = test_data[test_data['lang1']==test_data['lang2']] # Filtering rows where lang1 == lang2\n",
        "# Preprocessing the test data\n",
        "test_data = test_data.rename(columns={'text_1': 'merge1', 'text_2': 'merge2'})\n",
        "# Createing DataLoader for the test dataset\n",
        "test_data_loader = get_data_loader(test_data,False)\n",
        "# Loading the model weights\n",
        "model.load_state_dict(torch.load(\"BERT_Multilingual_0.25_overall_loss.pth\"), strict=False)\n",
        "model.to(device)\n",
        "# Get predictions on the test dataset\n",
        "test_pred_overall, test_true_overall = predict(model, test_data_loader)\n",
        "print(test_pred_overall)\n",
        "\n",
        "\n",
        "\n",
        "# Converting lists to NumPy arrays for indexing\n",
        "test_pred_overall = np.array(test_pred_overall)\n",
        "test_true_overall = np.array(test_true_overall)\n",
        "\n",
        "# Calculating Pearson correlations for each aspect\n",
        "pearson_correlations = calculate_pearson_per_aspect(test_pred_overall, test_true_overall)\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Createing scatter plot\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(test_true_overall, test_pred_overall, alpha=0.3, color='b', label='Predictions')\n",
        "\n",
        "# Plot a line for perfect predictions (y = x)\n",
        "min_val = min(test_true_overall.min(), test_pred_overall.min())\n",
        "max_val = max(test_true_overall.max(), test_pred_overall.max())\n",
        "plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='Perfect Prediction')\n",
        "\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('True Labels')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Model Evaluation: True vs Predicted')\n",
        "plt.legend()\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FoW_1ySDZ8H",
        "outputId": "7b277b6e-1373-43c0-b421-f8d851a7b11e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson correlation for aspect 1: 0.5494\n",
            "Pearson correlation for aspect 2: 0.7449\n",
            "Pearson correlation for aspect 3: 0.2245\n",
            "Pearson correlation for aspect 4: 0.7181\n",
            "Pearson correlation for aspect 5: 0.7489\n",
            "Pearson correlation for aspect 6: 0.3203\n",
            "Pearson correlation for aspect 7: 0.3828\n",
            "Mean Pearson correlation for test dataset: 0.5270\n"
          ]
        }
      ],
      "source": [
        "# Calculating Pearson correlations for each aspect\n",
        "pearson_correlations = calculate_pearson_per_aspect(test_pred_overall, test_true_overall)\n",
        "for i, r in enumerate(pearson_correlations):\n",
        "        print(f\"Pearson correlation for aspect {i+1}: {r:.4f}\")\n",
        "#np.mean() calculating the mean of the correlation of all 7 aspects and assigning to the curr_pearson object.\n",
        "curr_pearson = np.mean(pearson_correlations)\n",
        "print(f\"Mean Pearson correlation for test dataset: {curr_pearson:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh3hMbu3rkht",
        "outputId": "4f7f3858-618b-4927-cd9e-27c2b008c43d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.36151969, 1.92474425, 1.11007595, ..., 1.88762116, 1.21952844,\n",
              "        1.24532986],\n",
              "       [1.27186108, 1.81170404, 1.04977489, ..., 1.77442551, 1.15051222,\n",
              "        1.18249226],\n",
              "       [1.79830623, 2.47159505, 1.38678682, ..., 2.45066214, 1.52619708,\n",
              "        1.56056261],\n",
              "       ...,\n",
              "       [2.49232316, 3.31259704, 1.81606531, ..., 3.32640076, 1.97937202,\n",
              "        2.04553032],\n",
              "       [2.99136138, 3.90080953, 2.11368775, ..., 3.91815424, 2.30572987,\n",
              "        2.39817667],\n",
              "       [1.68874657, 2.33621597, 1.3174448 , ..., 2.307863  , 1.44873786,\n",
              "        1.48066032]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "test_pred_overall"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Fine Tuning Bert_Multilingual Model with NER enriched Dataset."
      ],
      "metadata": {
        "id": "AybBEmBnTJoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Attach your google drive if you are running this file using google colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-4j_SVNvTxgt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5869de83-d97f-4c3e-f364-8348419c9fd1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enriched_training_dataFilePath = \"/content/drive/MyDrive/Colab Notebooks/enriched_training_data.csv\"\n"
      ],
      "metadata": {
        "id": "WE5nDBXcT1Mv"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In case you are running this notebook using google colab then uncomment the below lines otherwiese make sure it is installed in your system if running using VS code.\n",
        "\n",
        "!pip install transformers #installing transformers to get pre-trained modle.\n",
        "!pip install sentencepiece #installing sentencepiece to split text into small units."
      ],
      "metadata": {
        "id": "MJAmB8jtT9s3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c2b21e-534f-4b7c-f918-f1be8def5177"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imprting all required packages and their libraries.\n",
        "## Ensuring rendom number generator is used in the PyTorch.\n",
        "## Ensuring operation used in deterministic way."
      ],
      "metadata": {
        "id": "EZ1WEsRQUGhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Imporint required packages.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import regex as re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sentencepiece\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import XLMRobertaConfig, XLMRobertaModel, XLMRobertaTokenizer\n",
        "\n",
        "torch.cuda.empty_cache() #this function is used to realesed unused memory cached by CUDA to optimize the performance\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") # checking if GPU is available and assigning to device veriable.\n",
        "\n",
        "# Seed\n",
        "seed = 123 #setting fix value for the rendom seeds to ensure rendom number generator used in Pytorch\n",
        "torch.manual_seed(seed) #to ensure any operation used in Pytorch is deterministic when same seed is used.\n",
        "torch.cuda.manual_seed(seed) #setting the seeds for Pytorch rendom number generator.\n",
        "torch.cuda.manual_seed_all(seed) #setting renodom seed for all GPU.\n",
        "np.random.seed(seed)#setting renodm seed for NumPy rendom number generator.\n",
        "random.seed(seed) #setting seeds for Python stnaderd rendom libray\n",
        "torch.backends.cudnn.benchmark = False # cunfiguring CUDA deep nural network library in Pytorch and setting false to ensure that cuDNN will determine the best algorithem.\n",
        "torch.backends.cudnn.deterministic = True #to ensure  deterministic way."
      ],
      "metadata": {
        "id": "OYhl5k6_UCpW"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using enriched_training_dataset.csv file for this task and stored in the same folder with this .ipynb file. In case you have different location , please update the path."
      ],
      "metadata": {
        "id": "65vt6pP2UOEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading csv file using pandas from gogole drive location\n",
        "training_data = pd.read_csv(enriched_training_dataFilePath) #using NER enriched traing data as csv file.\n",
        "training_data = training_data.dropna() #Removing null rows from training data frame.\n",
        "training_data"
      ],
      "metadata": {
        "id": "iIV43S5TUIhp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bc865ab7-6d20-4ffb-efd3-53505d29e490"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text1  \\\n",
              "0     ORG: Zomato Buys ORG: Uber ' s Food Delivery B...   \n",
              "1     ORG: Wiesenthal Center Calls for ORG: FBI Task...   \n",
              "2     Big cut on import duty on crude and refined pa...   \n",
              "3     The biggest business con of 2019: fleecing wor...   \n",
              "4     MISC: The Compatriots : The Brutal and Chaotic...   \n",
              "...                                                 ...   \n",
              "2485   Cena ropy WTI. Kilka słów o ogonie i jego psi...   \n",
              "2486   El jefe de ORG: Grab dice que obtuvo un reemb...   \n",
              "2487   Offenbach: Polizei findet Mann hilflos auf St...   \n",
              "2488   Oltre 13 milioni di palestinesi nel mondo ent...   \n",
              "2489  For MISC: Auld Lang Jackass\\nby PER: Turd Ferg...   \n",
              "\n",
              "                                                  text2 lang1 lang2  \\\n",
              "0     MISC: Indian Online Food Delivery Market to Hi...    en    en   \n",
              "1     ORG: Jewish Groups React to MISC: Monsey ORG: ...    en    en   \n",
              "2     LOC: Delhi weather update: Delhiites shiver at...    en    en   \n",
              "3     The left’s constant victimhood olympics is a g...    en    en   \n",
              "4     ORG: Amazon. com.Enter the characters you see ...    en    en   \n",
              "...                                                 ...   ...   ...   \n",
              "2485   Gdzie można otworzyć konto maklerskie? Rachun...    pl    pl   \n",
              "2486  I passeggeri pagheranno P10 in più per la tass...    es    it   \n",
              "2487   ORG: BMW gets smashed by train, driver surviv...    de    en   \n",
              "2488  La popolazione mondiale palestinese è di 13 mi...    it    it   \n",
              "2489  Post-Iraq war LOC: US intel report predicting ...    en    en   \n",
              "\n",
              "      Geography  Entities      Time  Narrative   Overall     Style      Tone  \n",
              "0      1.000000  2.333333  2.666667   1.666667  2.000000  1.666667  1.666667  \n",
              "1      1.250000  1.750000  1.250000   1.750000  2.000000  1.000000  1.250000  \n",
              "2      3.000000  4.000000  1.333333   4.000000  3.666667  1.333333  1.333333  \n",
              "3      2.333333  3.666667  1.333333   3.666667  3.333333  1.333333  1.333333  \n",
              "4      1.000000  4.000000  4.000000   1.000000  4.000000  1.000000  1.000000  \n",
              "...         ...       ...       ...        ...       ...       ...       ...  \n",
              "2485   1.000000  4.000000  4.000000   4.000000  4.000000  1.000000  3.000000  \n",
              "2486   1.000000  3.000000  1.333333   3.000000  3.000000  1.666667  1.333333  \n",
              "2487   4.000000  4.000000  4.000000   4.000000  4.000000  2.000000  3.000000  \n",
              "2488   1.000000  1.333333  1.333333   1.666667  1.000000  2.666667  1.000000  \n",
              "2489   1.333333  4.000000  2.666667   4.000000  4.000000  2.333333  2.000000  \n",
              "\n",
              "[2490 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49a64289-5ba9-4b42-945d-8abe87afb37b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text1</th>\n",
              "      <th>text2</th>\n",
              "      <th>lang1</th>\n",
              "      <th>lang2</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Entities</th>\n",
              "      <th>Time</th>\n",
              "      <th>Narrative</th>\n",
              "      <th>Overall</th>\n",
              "      <th>Style</th>\n",
              "      <th>Tone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ORG: Zomato Buys ORG: Uber ' s Food Delivery B...</td>\n",
              "      <td>MISC: Indian Online Food Delivery Market to Hi...</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>1.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ORG: Wiesenthal Center Calls for ORG: FBI Task...</td>\n",
              "      <td>ORG: Jewish Groups React to MISC: Monsey ORG: ...</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Big cut on import duty on crude and refined pa...</td>\n",
              "      <td>LOC: Delhi weather update: Delhiites shiver at...</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The biggest business con of 2019: fleecing wor...</td>\n",
              "      <td>The left’s constant victimhood olympics is a g...</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MISC: The Compatriots : The Brutal and Chaotic...</td>\n",
              "      <td>ORG: Amazon. com.Enter the characters you see ...</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2485</th>\n",
              "      <td>Cena ropy WTI. Kilka słów o ogonie i jego psi...</td>\n",
              "      <td>Gdzie można otworzyć konto maklerskie? Rachun...</td>\n",
              "      <td>pl</td>\n",
              "      <td>pl</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2486</th>\n",
              "      <td>El jefe de ORG: Grab dice que obtuvo un reemb...</td>\n",
              "      <td>I passeggeri pagheranno P10 in più per la tass...</td>\n",
              "      <td>es</td>\n",
              "      <td>it</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2487</th>\n",
              "      <td>Offenbach: Polizei findet Mann hilflos auf St...</td>\n",
              "      <td>ORG: BMW gets smashed by train, driver surviv...</td>\n",
              "      <td>de</td>\n",
              "      <td>en</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2488</th>\n",
              "      <td>Oltre 13 milioni di palestinesi nel mondo ent...</td>\n",
              "      <td>La popolazione mondiale palestinese è di 13 mi...</td>\n",
              "      <td>it</td>\n",
              "      <td>it</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2489</th>\n",
              "      <td>For MISC: Auld Lang Jackass\\nby PER: Turd Ferg...</td>\n",
              "      <td>Post-Iraq war LOC: US intel report predicting ...</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2490 rows × 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49a64289-5ba9-4b42-945d-8abe87afb37b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-49a64289-5ba9-4b42-945d-8abe87afb37b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-49a64289-5ba9-4b42-945d-8abe87afb37b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-34a7ff87-3e13-495b-bfa3-2820bfa2d636\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-34a7ff87-3e13-495b-bfa3-2820bfa2d636')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-34a7ff87-3e13-495b-bfa3-2820bfa2d636 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_04047133-3a4e-4ee8-aad2-3608d4ca25af\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('training_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_04047133-3a4e-4ee8-aad2-3608d4ca25af button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('training_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "training_data",
              "summary": "{\n  \"name\": \"training_data\",\n  \"rows\": 2490,\n  \"fields\": [\n    {\n      \"column\": \"text1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2440,\n        \"samples\": [\n          \"MISC: Rose Parade 2020: See the coolest floats\\n(ORG: CNN) Is it really MISC: New Year ' s Day without the MISC: Rose Parade?\\n\\nIn its 131st year, the parade unleashed a vibrant spectacle of flower-studded floats through LOC: Pasadena, LOC: California. There were horses, marching bands, live music and dancing in the streets and, of course, ornate works of art.\\n\\nHere are a few of the most colorful, festive floats of the 2020 MISC: Rose Parade. (The party's not over -- the MISC: Rose Bowl college football match-up starts at 5 p.m. on ORG: ESPN.)\\n\\nFantastic floats\\n\\nORG: Amazon, MISC: ChipORG: ##otMISC: ##le and MISC: Trader ORG: Joe's were among the 2020 parade participants. The most fantastic floats earned awards based on their design, presentation and entertainment value.\",\n          \"ORG: Curcio Law Offices Partners With ORG: Greater Chicago Food Depository to Take Hunger off MISC: the ORG: Table.CHICAGO, IL / ACCESSWIRE / January 14, 2020 / ORG: Curcio Law Offices pledges to make a monthly donation to the ORG: Greater Chicago Food Depository throughout the year 2020.  ORG: Curcio Law Offices, which focuses on personal injury law, has also vowed to organize a volunteer day where its staff will help out at the ORG: Greater Chicago Food Depository, the city of LOC: Chicago's food bank. The ORG: Greater Chicago Food Depository strives to end hunger in the LOC: Chicagoland area.  \\\"Having personally supported the ORG: Greater Chicago Food Depository on my own for many years, we felt this was a great opportunity for our firm to partner with a local charity to help so many in need. We are planning for our entire office to volunteer on site one day in the coming weeks,\\\" said PER: Tracy Robb, managing partner of ORG: Curcio Law Offices.  The ORG: Greater Chicago Food Depository, a member of ORG: Feeding America, provides food where it's needed most throughout LOC: Chicago and LOC: Cook County every day. The organization acts as a hub for a network of more than 700 food pantries, soup kitchens, shelters and other programs and also addresses the root causes of hunger.  To donate directly to or volunteer at the ORG: Greater Chicago Food Depository, please visit https://www.chicagosfoodbank.org/. Volunteers are vital to its success, and donations are put to use immediately to provide food for hungry people in the community.  Personal injury attorney PER: Tracy Robb is a dedicated professional with more than 25 years of legal experience. PER: Tracy is renowned in the legal community for her outstanding analytical skills and articulate writing style, establishing herself as a strategist for brainstorming with attorneys on many cases at the firm.  Founded by PER: Joseph ORG: R. Curcio in 1957, ORG: Curcio Law Offices has been representing the injured for over 60 years. To this day, ORG: Curcio Law Offices has established a reputation among LOC: Chicago's leading personal injury law firms through outstanding legal representation and commitment to clients.  About ORG: Curcio Law Offices Curcio Law Offices exclusively focuses on personal injury, auto accident injuries and wrongful death representation. Its attorneys have obtained millions of dollars in verdicts and settlements for clients and their families who are dealing with serious and catastrophic personal injuries and death. For more information, please call 312-321-1111, or visit https://www.curcio-law.com/. The law office is located at 161 North Clark Street, Suite 2240, Chicago, IL 60601.  For media inquiries, please call THE NALA at 805.650.6121, ext. 361.  SOURCE: Curcio Law Offices  View source version on accesswire.com:https://www.accesswire.com/572901/Curcio-Law-Offices-Partners-With-Greater-Chicago-Food-Depository-to-Take-Hunger-off-the-Table\",\n          \"Zdezynfekowano \\\"nagrzyk\\u0119 w koronach drzew: bezpieczniejsza\\\"  Zw\\u0142aszcza w weekendy Nowa atrakcja lasu w pobli\\u017cu LOC: Malta Lake cieszy si\\u0119 bez powodu unflaging.Poniewa\\u017c stra\\u017cnicy miasta informuj\\u0105, \\u015bcie\\u017cka jest bezpieczniejsza.- Dezynfekcja cz\\u0119\\u015bci spacerowej zosta\\u0142a przeprowadzona pod nadzorem le\\u015bnictwa z LOC: lasu Pozna\\u0144skiego.Ta w\\u0142a\\u015bciwo\\u015b\\u0107 nale\\u017cy do najbardziej atrakcyjnych miejsc do LOC: Poznania, kt\\u00f3ry odwiedza setki mieszka\\u0144c\\u00f3w.Oznacza to, \\u017ce dba\\u0142o\\u015b\\u0107 o higien\\u0119 w epoce rozprzestrzeniaj\\u0105cego pandemii jest tam bardzo wa\\u017cne.Stra\\u017cnicy przypominaj\\u0105 ci, \\u017ce na \\u015bcie\\u017cce jest kilka zasad.Przede wszystkim ruch w jedn\\u0105 stron\\u0119 zosta\\u0142 wprowadzony - z boku ko\\u0144ca ulicy w kierunku LOC: ulicy Czekalskie.Po drugie, nadal nie mo\\u017cesz tutaj korzysta\\u0107 z witryn spoczynkowych, a zatem \\u0142awki.- Jeste\\u015bmy odleg\\u0142o\\u015bci, sugerujemy r\\u00f3wnie\\u017c zakrycie us  zas\\u0142anianie ust i nosa. Bezwzgl\\u0119dnie korzystamy z \\u0142adunk\\u00f3w na drobne - wymieniaj\\u0105 kosztuj\\u0105 stra\\u017cnicy. Zwracaj\\u0105 uwag\\u0119, \\u017ce parkowanie samochod\\u00f3w jest tylko mo\\u017cliwe w wyznaczonych parkingach. Autor: KaT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2308,\n        \"samples\": [\n          \"ORG: MarketMISC: ##Buzz Podcast with ORG: Ekta Batra: ORG: Sensex, ORG: Nifty likely to open flat; ORG: Tata Motors, ORG: Coal India in focus\\n\\ufeff\\n\\nMISC: Indian shares are expected to open little changed on Thursday following muted trends in global markets. Asian shares were mixed, while LOC: US futures traded marginally higher in the morning trades.\\n\\nORG: SGX Nifty futures traded 0.05 percent lower as of 7.45 AM at 12,239, indicating a flat start for the ORG: Sensex and the MISC: NiORG: ##ftyMISC: ##50.\",\n          \"State expands benefits to more seniors.LOC: Alton, LOC: IL (62002)  Today  Some clouds this morning will give way to generally sunny skies for the afternoon. High 64F. Winds WSW at 10 to 20 mph..  Tonight  Clear skies. Low 41F. Winds WNW at 5 to 10 mph.\",\n          \"Internationale Nachrichten aus aller Welt.Sturz des S\\u00e4ngers vom Balkon MISC: Drei Menschen nach Tod von PER: Liam Payne angeklagt  Der Tod von PER: Liam Payne gab viele R\\u00e4tsel auf. Der fr\\u00fchere S\\u00e4nger von ORG: One Direction st\\u00fcrzte von einem Hotelbalkon in LOC: Buenos Aires. Ermittler schlie\\u00dfen nun Suizid aus und erheben Anklage gegen drei M\\u00e4nner, die ihn mit Drogen versorgt haben sollen. mehr\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lang1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"en\",\n          \"de\",\n          \"it\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lang2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"en\",\n          \"de\",\n          \"it\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Geography\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1781436605532687,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          3.333333333333333,\n          1.4,\n          1.6666666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Entities\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1397028554052493,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          2.6666666666666665,\n          3.25,\n          2.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0033708134307442,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          3.333333333333333,\n          1.714285714,\n          2.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Narrative\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1063894684668387,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          1.6666666666666667,\n          1.4,\n          3.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Overall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1416537520185221,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          1.3333333333333333,\n          3.571428571,\n          2.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Style\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8940661615264246,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          1.3333333333333333,\n          1.75,\n          2.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tone\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8560001128199259,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          2.333333333333333,\n          3.4,\n          2.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first few rows\n",
        "print(f\"this is the head of training data={training_data.head()}\")\n",
        "\n",
        "# Check the shape of the data (number of rows and columns)\n",
        "print(f\"this is the shape of traning data={training_data.shape}\")\n",
        "\n",
        "# Check data types and null values\n",
        "print(f\"this is the shape of training data={training_data.info()}\")\n",
        "\n",
        "# Summary statistics\n",
        "print(f\"summery of the training data={training_data.describe()}\")\n"
      ],
      "metadata": {
        "id": "eTMkFnriUd80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55fc5695-5760-458e-f9cb-e0428dc5bfca"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is the head of training data=                                               text1  \\\n",
            "0  ORG: Zomato Buys ORG: Uber ' s Food Delivery B...   \n",
            "1  ORG: Wiesenthal Center Calls for ORG: FBI Task...   \n",
            "2  Big cut on import duty on crude and refined pa...   \n",
            "3  The biggest business con of 2019: fleecing wor...   \n",
            "4  MISC: The Compatriots : The Brutal and Chaotic...   \n",
            "\n",
            "                                               text2 lang1 lang2  Geography  \\\n",
            "0  MISC: Indian Online Food Delivery Market to Hi...    en    en   1.000000   \n",
            "1  ORG: Jewish Groups React to MISC: Monsey ORG: ...    en    en   1.250000   \n",
            "2  LOC: Delhi weather update: Delhiites shiver at...    en    en   3.000000   \n",
            "3  The left’s constant victimhood olympics is a g...    en    en   2.333333   \n",
            "4  ORG: Amazon. com.Enter the characters you see ...    en    en   1.000000   \n",
            "\n",
            "   Entities      Time  Narrative   Overall     Style      Tone  \n",
            "0  2.333333  2.666667   1.666667  2.000000  1.666667  1.666667  \n",
            "1  1.750000  1.250000   1.750000  2.000000  1.000000  1.250000  \n",
            "2  4.000000  1.333333   4.000000  3.666667  1.333333  1.333333  \n",
            "3  3.666667  1.333333   3.666667  3.333333  1.333333  1.333333  \n",
            "4  4.000000  4.000000   1.000000  4.000000  1.000000  1.000000  \n",
            "this is the shape of traning data=(2490, 11)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2490 entries, 0 to 2489\n",
            "Data columns (total 11 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   text1      2490 non-null   object \n",
            " 1   text2      2490 non-null   object \n",
            " 2   lang1      2490 non-null   object \n",
            " 3   lang2      2490 non-null   object \n",
            " 4   Geography  2490 non-null   float64\n",
            " 5   Entities   2490 non-null   float64\n",
            " 6   Time       2490 non-null   float64\n",
            " 7   Narrative  2490 non-null   float64\n",
            " 8   Overall    2490 non-null   float64\n",
            " 9   Style      2490 non-null   float64\n",
            " 10  Tone       2490 non-null   float64\n",
            "dtypes: float64(7), object(4)\n",
            "memory usage: 214.1+ KB\n",
            "this is the shape of training data=None\n",
            "summery of the training data=         Geography     Entities         Time    Narrative      Overall  \\\n",
            "count  2490.000000  2490.000000  2490.000000  2490.000000  2490.000000   \n",
            "mean      2.075735     2.807642     1.744111     2.858173     2.809911   \n",
            "std       1.178144     1.139703     1.003371     1.106389     1.141654   \n",
            "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
            "25%       1.000000     2.000000     1.000000     2.000000     2.000000   \n",
            "50%       1.666667     3.000000     1.000000     3.000000     3.000000   \n",
            "75%       3.000000     4.000000     2.312500     4.000000     4.000000   \n",
            "max       4.000000     4.000000     4.000000     4.000000     4.000000   \n",
            "\n",
            "             Style         Tone  \n",
            "count  2490.000000  2490.000000  \n",
            "mean      1.781139     1.801523  \n",
            "std       0.894066     0.856000  \n",
            "min       1.000000     1.000000  \n",
            "25%       1.000000     1.000000  \n",
            "50%       1.500000     1.666667  \n",
            "75%       2.333333     2.333333  \n",
            "max       4.000000     4.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting the text into lowercase"
      ],
      "metadata": {
        "id": "CVGAxzF8Us4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to lowercase\n",
        "training_data['text1'] = training_data['text1'].str.lower()\n",
        "training_data['text2'] = training_data['text2'].str.lower()\n",
        "\n",
        "# Remove special characters\n",
        "training_data['text1'] = training_data['text1'].str.replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
        "training_data['text2'] = training_data['text2'].str.replace(r'[^a-zA-Z\\s]', '', regex=True)\n"
      ],
      "metadata": {
        "id": "J93su0coUj5j"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Checking the training dataset"
      ],
      "metadata": {
        "id": "4QKCXcNIU-eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique values in a column\n",
        "print(training_data['text1'].unique())\n",
        "\n",
        "# Count occurrences of each value in a column\n",
        "print(training_data['text1'].value_counts())\n"
      ],
      "metadata": {
        "id": "uBVpenWTU6g3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10dd7cd8-f1d2-4eec-bd2f-7ecb945cd3b5"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['org zomato buys org uber  s food delivery business in loc india in an misc all  stock dealorg uber has sold its online foodordering business in loc india to local rival org zomato in exchange for a  percent stake in the startup backed by loc chinas org ant financial limiting its exposure to a crowded market where it has struggled to grow the allstock deal is likely to push org zomato to the top position in loc indias food delivery market ahead of org swiggy which counts loc chinas org tencent holdings as an investor org zomato  valued at around  billion roughly rs  crores after raising money from org alibaba affiliate org ant this month  said org uber eats in loc india will discontinue operations and direct restaurants delivery partners and users to the org zomato platform from tuesday  loc india remains an exceptionally important market to org uber and we will continue to invest in growing our local org rides business said per dara khosrowshahi org ubers chief executive officer  we entered food delivery in loc india in  and today is when our journey takes a different route org zomato has acquired org uber eats in loc india and well no longer be available here with immediate effect we wish all our users more good times with great food on the road ahead pictwittercomwebjnajym  org uber eats india org ubereatsinorg d january    org uber eats in loc india accounted for  percent of the business gross bookings globally but more than a quarter of its adjusted org ebitda loss in the first three quarters of  the org u s ridehailing firm said  org uber eats india is now org zomato heres to better food for more people and new beginnings    for more details httpstcocqwpikok pictwittercomnkicyikw  org deepinder goyal deepigoyal january    org uber eats which also pulled out of loc south korea earlier this year said it will continue to operate in loc bangladesh and loc sri lanka  while this is the first large acquisition in the misc indian online food delivery market deal activity has been heating up globally  earlier this month dutch firm takeawaycom pipped investment company prosus to buy britains just eat for  billion pounds  billion in december germanys delivery hero agreed to buy south koreas top food delivery app owner woowa brothers for  billion   thomson reuters '\n",
            " 'org wiesenthal center calls for org fbi task force to deal with anti  semitismthe org simon wiesenthal center called on the loc white house to direct the org fbi to form a task force to focus exclusively on antisemiorg tism following the stabbings in per monsey org n y wiesenthal center founder and dean rabbi per marvin hier and associate dean and director of org global social action agenda said in a dec  statement enough is enough misc jews should not have to fear for their lives in loc america to go to their houses of worship the org fbi must step up and take the lead in all recent violent hate crimes targeting religious misc jews  per hier told the misc journal in a phone interview that the misc dec  misc monsey stabbings that resulted in five injured reminded him of org nazi germany in the s misc jews were beaten up on the corner misc windows were broken  thats how it started misc hier said and the population centers tolerated it nobody spoke out against it we didnt have a plan against it  he argued that the rise of antisemitism in the loc united states has become such an epidemic that more action is needed beyond statements and pledges from state and local politicians and police officers theyre all good people but theyre not  on this job per hier said they have other jobs even police they have traffic issues  there are so many issues besides the issue of antisemitism that they have to deal with  per hier added that its important to ensure that politics doesnt interfere with addressing antisemitism when you have a misc democratic mayor and a misc republican governor or vice versa its a different attitude misc hier said its just not the right way to handle an epidemic  we need the org fbi to create a special unit focusing   days a year on one subject antisemitism  per marvin hier  he also argued that people shouldnt expect antisemitism to dissipate with the election of a new president or a new misc congress when the whole world is affected by the epidemic called antisemitism  and this has happened in loc europe for the last  years  you cannot legitimately argue that the cause of it in the loc united states is due to one man misc hier said without naming president donald trump  an fbi task force that is exclusively focused on handling antisemitism is therefore necessary to address the rising antisemitism throughout the country he argued we need the fbi to create a special unit focusing   days a year on one subject antisemitism hier said thats the only way that the antisemites will wake up because basically theyre going to be targeted theyre going to be analyzed  hier gave a hypothetical of how the task force would handle an antisemitic incident lets say theres an attack here in los angeles he said first thing that happens is that everything about the attack is sent immediately to the fbi task force on antisemitism and they become the lead agency they take over immediately  hier said that the wiesenthal center has been in contact with the white house about its proposal for a task force  president trump is aware of it hier said hes been informed of it  well see what happens we are pushing very hard we need bipartisan support  hier urged for a societal unification against antisemitism as he argued that antisemitism is emboldened when societies ignore it  society didnt do the right thing he said we didnt recognize that these bigots can return early and as society we have to have a program against it and the program has to unify democrats and republicans and whatever their political persuasion in europe we have to come together to fight this'\n",
            " 'big cut on import duty on crude and refined palm oils industry says move to hurt domestic refinersthe government on wednesday slashed import duty on refined palmolein from  per cent to  per cent while that on crude palm oil cpo from  per cent to  per cent with immediate effect a move that the industry opposed saying it will hurt domestic refiners a notification in this regard has been issued by the finance ministry  the duty cut has been made under the org asean agreement and the misc india  malaysia comprehensive economic cooperation agreement org imceca the notification added opposing the move the org solvent extractors  association of india org sea said that after the reduction in import duty the tax difference between cpo and refined palmolein has reduced from  per cent to  per cent this will have serious impact on domestic palm oil refining industry and oilseeds farmers we fear import of refined palmolien would increase and capacity utilisation of our industry would be affected leading to potential loss of employment org sea executive director per b v mehta said in a statement  after a long time the domestic oilseeds had started selling their produce above the minimum support price msp lower import duty would make it difficult to defend msp and the new found enthusiasm of the oilseed farmers would be dampened he said the countrys edible oil imports are now touching  per cent of the consumption the duty cut would be counterproductive and contrary to the governments stated objective of increasing domestic oilseed production he added asserting that loc india too should protect the interest of farmers like loc malaysia and loc indonesia the org sea said loc indonesia from january  has imposed export duty of usd  on cpo and usd  on refined palmolien  also org read cigarette makers aim to record  revenue growth this fiscal on leaf tobacco exports midpremium category robust kharif prospects imports to moderate pulses prices will rborg i go for a rate cut this december economists say trouble on food inflation front can delay this further is loc india losing shine why have foreign investors sold record rs  crore in equities through october  similarly loc malaysia has imposed export duty of usd  on cpo and zero duty on refined palmolein which work out to be nearly  per cent on cpo value thus effective duty difference is hardly  per cent only we strongly appeal to the government to increase the duty differential between cpo and refined palm oil to  per cent by taking appropriate measures the industry body added'\n",
            " ...\n",
            " ' offenbach polizei findet mann hilflos auf strae  kurz darauf stirbt er in loc offenbach wird ein hilfloser mann unter einer bahnunterfhrung gefunden kurze zeit spter stirbt er jetzt liefert eine zeugin den entscheidenden hinweis polizei findet hilflose person in loc offenbach auf findet hilflose person in auf unbekannter stirbt kurz darauf in einem krankenhaus zeuge liefert entscheidenden hinweis update vom dienstag  die identitt des toten mannes aus loc offenbach ist offenbar geklrt die ffentliche fahndung der polizei hat am ende den durchbruch gebracht eine frau entdeckte den beitrag bei misc facebook und meldete sich direkt bei der polizei sie erkannte den mann wieder und wusste sogar wo er wohnt demnach ist der mann  jahre alt und wohnte in loc offenbach die kripo geht davon aus dass der mann eines natrlichen todes starb zeugen fanden ihn hilflos unter fahndung seitens der polizei war schnell erfolgreich der tatverdchtige konnte festgenommen werden aber was genau war passiert und wie kam es zu dem streit die ermittler haben jetzt neue details zum verdchtigen rubriklistenbild  polizei offenbac'\n",
            " ' oltre  milioni di palestinesi nel mondo entro la fine del   pnn pnnloc bethlehem il dottor per ola awad presidente dellorg ufficio centrale di statistica palestinese org pcbs presenta un breve resoconto sullo stato del popolo palestinese alla fine del  come segue pi di  milioni di palestinesi nel mondo entro la fine del  un aumento della popolazione di palestinesi nel mondo il numero previsto di palestinesi nel mondo  di  milioni di cui  milioni nello loc stato di palestina  milioni nel loc territorio del   milioni nei paesi arabi e circa  mila allestero pi di un terzo della popolazione risiede nella loc striscia di gaza il numero previsto di palestinesi che vivono nello loc stato di palestina alla fine del   di  milioni circa  milioni risiedono in loc cisgiordania e  milioni nella loc striscia di gaza i rifugiati palestinesi costituiscono il  dei palestinesi alla fine del  di cui la percentuale di individui di et inferiore a  anni era di circa il  per i maschi e il  per le femmine mentre la percentuale di individui di et pari o superiore a  anni era del  per i maschi e  per le femmine a fine '\n",
            " 'for misc auld lang jackass\\nby per turd ferguson misc tf metals report\\n\\nour old pal per jim willie misc the golden jackass stops by today for his annual yearinreview and look ahead if you can find some time over the holiday you should be sure to have a listen\\n\\nas usual per jim is full of valuable information over the course of this podcast just a few of the topics discussed are\\n\\nthe ongoing repoqe crisis\\n\\ncentral bank and media tricks and semantics\\n\\nmisc click here to listen\\n\\n\\n\\nthe growing alliances against the us\\n\\nhow gold will be central to the next monetary system\\n\\nthe loc us treasury bond as the new global contagion\\n\\nand as you might imagine a whole lot more\\n\\nthanks again to per jim for his time and willingness to share his insights with all of us at org tfmr it is going to be a volatile and unpredictable  listen to this podcast and begin to mentally prepare for whats ahead\\n\\nread more  misc tfmetalsreportcom']\n",
            "text1\n",
            "wyborczaplwycz misc adblockaublocka  aby czyta nasze artykuy wycz misc adblockaublocka lub dodaj wyjtek dla naszej domeny  spokojnie dodanie wyjtku nie wyczy blokowania reklam                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      5\n",
            "breaking news sports business entertainmentloc michigan believes in per trump why voters say they chose a nd term  per albom hot cocoa and safe spaces how our students deal with an election  coming soon to ballot near you per hizzoner mayor per pete and speaker per joe  tuesdays election shows loc michigans voters have shifted toward per trump                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            4\n",
            "org latin american news agencyloc caracas aug  org prensa latina misc venezuelan president per nicolas maduro thanked monday the org albatcp member states and social movements for their support to loc venezuela in the face of the siege unleashed inside and outside his country after the july th election                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      4\n",
            "przykro nam ale z adresu misc ip z ktrego si czysz odnotowalimy ogromn ilo pocze\\n\\npodejrzewamy e kto naduy adresu misc ip z ktrego korzystasz\\n\\njeli chcesz poczy si z nami zaznacz nie jestem robotem\\n\\ntwj adres misc ip                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       4\n",
            "a partir de hoy aumenta costo de pasaportes para mexicanos en el extranjeroa partir de hoy  de enero de  todos los mexicanos radicados en el extranjero tendrn que pagar ms por la emisin de pasaportes matrculas consulares y declaratorias de nacionalidad  inform la org direccin general de servicios consulares que a partir de esta fecha todos los servicios que ofrecen los loc consulados de mxico en el exterior tendrn costos ms altos  las nuevas tarifas marcan un costo de  dlares para la matrcula consular hasta la vspera costaba  dlares el pasaporte por un ao y casos de proteccin consular  dlares pasaporte por  aos  dlares y por  aos  dlares la declaratoria de nacionalidad tendr un costo de  dlares esto es dos dlares ms que en   y los connacionales que hagan un testamento pblico abierto en una oficina consular en el extranjero pagarn un  del monto  el cobro de estos documentos en dlares estadounidenses se hace desde  y se modificaron en  desde esa fecha no haban tenido cambios a pesar de los incrementos en los gastos en el sostenimiento de la red consular  de acuerdo a las disposiciones de la misc ley federal de derechos para el ejercicio  que se public en el misc diario oficial de la federacin el  de diciembre de  las cuotas de los derechos en dlares estadounidenses por la prestacin de servicios comprendidos en la misc ley federal de derechos se modificaran este                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                3\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ..\n",
            "per mikel arteta wary of org united threat to org arsenals weak defensive foundationsnew misc arsenal same old org arsenal there were  minutes on the loc emirates stadium clock last sunday the score was  against org chelsea and org arsenal had five men inside the opposing penalty area as they pushed for the winner the move broke down org chelsea countered at pace per tammy abraham scored what would be the decisive goal and for the umpteenth time everybody questioned whether org arsenal had any defensive instinct  org manchester united are the visitors to the org emirates on misc new year  s day and it will be the showpiece fixture at pm even if the misc premier league table shows it is a meeting between th and fifth per ole gunnar solskjrs team have kept their season alive by rinsing attackminded opposition on the break and the org united manager would have licked his lips as he pored over the per abraham goal do misc arsenal have to be wary of org uniteds rapierlike threat very replied per mikel arteta the clubs new manager  what per arteta wanted to make clear was that per abrahams stunning late counter was not the result of a structural breakdown in the team he is trying to reboot when per abraham received the ball out of defence from per willian  yards inside his own half he had two org arsenal players in front of him  per david luiz and per shkodran mustafi  and three in pursuit  per bukayo saka per matteo guendouzi and per lucas torreira per abraham could see per willian flicking on the afterburners to get forward on his right and per mason mount doing the same on the left  at that point org arsenal had the situation under control they had five org chelsea had three it was not a case of them overstretching in search of the winner of a peculiar naivety  that said what happened next within a reasonably solid framework was concerning per david luiz and per mustafi chose not to engage per abraham high up the pitch rather to retreat and retreat all the way into their own box after per abraham popped the ball wide to per willian per david luiz could not prevent the low cross and per mustafi was then slow to react in the middle per abraham outmanoeuvred him before shooting low past per bernd leno it was also notable that per saka seemed to be cramping up unable to move freely he could not stay with willian while guendouzi did not get back at all  so even as arteta tried to take the positives in terms of how his players had moved the structure from attack to defence he could see glaring deficiencies in the oneonone work and fitness levels  it wasnt a transition where we had a bad structure or a bad organisation when we are defending big spaces on equal numbers or are outnumbered  it wasnt the case at all arteta said we made one halfbad decision to back off and these teams when in space they punish you for sure but the other option is to defend all the time and be there in defensive areas and we dont want that  the fiver sign up and get our daily football email  arteta delivered the last line with a smile arsenal are a frontfoot team their mindset is to attack and they will remain that way under artetas charge what he wants is to put a structure in place which will provide numbers on offensive and defensive transitions allow for options on the ball and spaces between the lines the early signs in this regard have been encouraging what he needs to learn is the capacity of the players to operate at his tempo to make the right decisions and execute them  the balance of the midfield will be key and more precisely how to find a role for mesut zil artetas predecessor unai emery tried everything with zil but there was always the feeling that the offthecuff playmaker was not a natural fit for his style  arteta has given zil the central attacking midfield platform that he craves in each of his games so far  the draw at bournemouth and then chelsea  and there have been positive signs zil has created chances although his ability to do that has never been in doubt with zil it is all about creating an environment to have him switched on rather than drifting to find a consistency that has often proved elusive  mesut is putting in everything he has and his numbers physically have improved so much arteta said on his own he cant do it he needs the collective structure organisation and his teammates he needs the team to play in a certain way to facilitate his strengths more and more in the game thats what were trying to do  i put him in the team if i see every day that his attitude desire and understanding of what were trying to do is there the moment that this changes then he wont play  arteta felt a connection between his players and the emirates crowd during the chelsea game that probably for a long time hasnt been seen but will the bitter late twist have an impact on their confidence  thats my worry now arteta said i hope the result doesnt affect them too much they were all physically blown and disappointed in how the game ended because they didnt feel they deserved that but we have to move on they have to respond this is the challenge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1\n",
            "newsletter investigating loc californias worst modern boating disastera makeshift memorial for victims of the misc conception boat fire  good morning and welcome to the misc essential california newsletter  its monday dec  per julia wick is taking a misc new years break so todays edition is brought to you by org l a times deputy managing editor per shelby grad  it was the worst maritime disaster in modern loc california history on misc labor day  people died in a fire on board the misc conception during a weekend diving trip around the loc channel islands since then two questions have been asked over and over how could this have happened and how can this be prevented in the future  newsletter sign up for misc essential california the most important misc california stories and recommendations in your inbox every morning enter email address misc sign me up you may occasionally receive promotional content from the org los angeles times  org times reporters per mark puente per richard winton and per leila miller have spent months trying to answer these questions in a series of investigative stories  among their findings   org u s coast guard records over  years show the agency repeatedly rejected some recommendations by the org national transportation safety board for tougher rules describing the proposals as unnecessarily burdensome and a duplication of existing requirements   the misc conception was one of about  small passenger vessels built before  and given special exemptions from safety standards that the org coast guard imposed on new vessels some of which required larger escape hatches and illuminated exit signs  advertisement   more than  boats in loc california were grandfathered with weaker safety rules according to a searchable org times database  the reporters latest story asks whether the federal rules in place worked misc coast org guard safety rules require at least one crew member roving the vessel whenever passengers are in the bunk area but even before the misc labor day fire that killed  people aboard the misc conception some former captains said this critical rule designed to protect passengers was not followed its a regulation but it wasnt really followed one said  read the story before misc conception boat misc fire some captains say org coast guard safety rule was ignored in the org los angeles times  advertisement  where is this all going  in the aftermath of misc the org times reporting there has been a push to tighten safety regulations the org coast guard also said it is now reviewing whether some of the ntsbs earlier recommendations should be reconsidered expect action in congress in   and finally here are biographies of the victims they were united in tragedy by a love for the sea  and now heres what else is happening around california  advertisement  top stories  the plight of two friends back on the streets shows the challenges la faces not just in getting people into housing but also in keeping them there this is the final installment of the times street within series on homelessness los angeles times  plus  one rappers rise from the streets of koreatown la taco  this is one way la can be more humane los angeles times   was the year homelessness became a true crisis in la los angeles times  advertisement  malibu is trying to ban pesticides but the coastal city is expecting a big fight and there are some unexpected foes los angeles times  how new labor laws in california will change the way many people work los angeles times  la stories  los angeles police have stepped up patrols in and around jewish communities and synagogues after a man stabbed and wounded five people gathered for a hanukkah celebration at a rabbis home in new york los angeles times  la says it is ready to deal with complaints over hollywood hills tour vans but weve heard it before los angeles times  the grapevine is at the heart of the california freeway system as the last week has shown it also remains vulnerable los angeles times  advertisement  a snowstorm halted hundreds of vehicles on dec   near gorman on the ridge route a highway between los angeles and kern counties los angeles times  a christmas tree sparked a fire that killed three people in hemet los angeles times  politics and government  the story of pge an investigation examines how weak regulators poor management misguided strategies and many errors caused so much destruction wall street journal  is prison realignment money being misspent in california sacramento bee  southern california keeps turning bluer a look at why orange county register  advertisement  san joses oncestruggling airport is taking off that could mean an expansion for the silicon valley hub mercury news  california culture  another historic newspaper in california is closing this one has a connection to mark twain los angeles times  california is booming but californians are cranky at the end of  new york times  the netflix series you moved from new york to la and picked up a lot of stereotypes along the way the creators explain why los angeles times  playa del rey is having a moment and some say its affordable  if you are moving from belair new york times  advertisement  san franciscos beach blanket babylon is coming to an end and might be perfect for this moment in history san francisco chronicle  california almanac  los angeles partly cloudy  san diego cloudy  san francisco sunny  san jose sunny  sacramento sunny  more weather is here  and finally  this weeks birthdays for those who made a mark in california  dodgers legend sandy koufax dec   nobel laureate and uc berkeley cell biology professor randy schekman dec   golf pro tiger woods dec   lakers star lebron james dec   and snap chairman michael lynton jan    if you have a memory or story about the golden state share it with us  please keep your story to  words    1\n",
            "europe stock markets drop at openlondon european stock markets dropped at the open on tuesday the final trading session of a year that has seen large gains for indices  loc londons benchmark org ftse  index shed  per cent to  points compared with the close on monday  in the eurozone the org paris cac  index lost  per cent to  points  loc frankfurts dax  ended its year on monday reporting an annual gain of  per cent following a plunge of  per cent in   global stock markets have been boosted this year from record highs on loc wall street helped by receding risks of recession and easing loc chinaloc us trade tensions  org afp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               1\n",
            "protesters stay inside building of org georgian ministry for refugees for new year holidays january    two forced migrants from loc abkhazia who demand to provide them with housing stay for the second day in the locked building of the org ministry for refugees labour health and social affairs of georgia the protesters said they had no money to celebrate the misc new year  the org caucasian knot has reported that since september  internally displaced persons idps or forced migrants have been holding their protest actions in the lobby of the above ministry where they had equipped a sleeping corner for themselves they claim that the money allocated by the state for renting housing is not enough and demand to provide them with permanent housing  in the morning on december   per fridron djodjua a forced migrant and per inga rusiya another protester entered the ministry building while the staff was still at work there on december  they locked the doors and we stayed inside well only leave on january  when the ministry resumes work mr per djodjua told the misc caorg ucasian knot correspondent  according to his story on january  he and per inga rusiya will be replaced by other forced migrants who seek solution of their housing problems  protesters have stated that on the th day of their protest action the minister had never found time to meet the settlers  this article was originally published on the misc russian page of  misc internet agency misc caucasian org knot on january   at  pm msk to access the full text of the article click here                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
            "for misc auld lang jackass\\nby per turd ferguson misc tf metals report\\n\\nour old pal per jim willie misc the golden jackass stops by today for his annual yearinreview and look ahead if you can find some time over the holiday you should be sure to have a listen\\n\\nas usual per jim is full of valuable information over the course of this podcast just a few of the topics discussed are\\n\\nthe ongoing repoqe crisis\\n\\ncentral bank and media tricks and semantics\\n\\nmisc click here to listen\\n\\n\\n\\nthe growing alliances against the us\\n\\nhow gold will be central to the next monetary system\\n\\nthe loc us treasury bond as the new global contagion\\n\\nand as you might imagine a whole lot more\\n\\nthanks again to per jim for his time and willingness to share his insights with all of us at org tfmr it is going to be a volatile and unpredictable  listen to this podcast and begin to mentally prepare for whats ahead\\n\\nread more  misc tfmetalsreportcom                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1\n",
            "Name: count, Length: 2439, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exporting training_data into DataFrame."
      ],
      "metadata": {
        "id": "6bCLjelKZjNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data.to_csv('cleaned_training_data.csv', index=False)#exporting the trining_data DataFrame to csv file.\n"
      ],
      "metadata": {
        "id": "NcVpEFG_ZfgG"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merging the columns in dataframe"
      ],
      "metadata": {
        "id": "1Lz5qkJrZwXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#merge_clean_columns() merging the text1 and text2 in dataframe namee merge1 and merge2\n",
        "def merge_clean_columns(df):\n",
        "    \"\"\"\n",
        "    Merge multiple text1 and text2 columns in DataFrame\n",
        "    \"\"\"\n",
        "    df['merge1'] = df['text1'].astype(str) + ', ' + df['text2'].astype(str)\n",
        "    df['merge2'] = df['text2'].astype(str) + ', ' + df['text1'].astype(str)\n",
        "    return df\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4UJxOmbIZllO"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing train_test_split to split the data into feature and target"
      ],
      "metadata": {
        "id": "ycgBi4_2ZyXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data = merge_clean_columns(training_data) #Calling merge_clean_columns function.\n",
        "# split into train and development\n",
        "train, dev = train_test_split(processed_data, test_size=0.1, random_state = 42) #spliting processed data frame in to train (training)and dev (evaluating)using train_test_split method from sklearn.model_selection"
      ],
      "metadata": {
        "id": "vkkoJp7WZ3Wd"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_data.columns)  # Ensure 'text1' and 'text2' exist\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkAFAC6taKvm",
        "outputId": "dd32ad32-a306-4eb7-a7d7-fab359d3d9d1"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['text1', 'text2', 'lang1', 'lang2', 'Geography', 'Entities', 'Time',\n",
            "       'Narrative', 'Overall', 'Style', 'Tone', 'merge1', 'merge2'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Model on data"
      ],
      "metadata": {
        "id": "jbv-qpU0aTxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# set parameters\n",
        "max_len = 512 #aetting the maximum sequence lenght of input text\n",
        "batch_size = 5 #setting batch size for training example in each pass\n",
        "lr = 5e-6 #setting the learning rate for the optimizer to control the model's weight update after each interation.\n",
        "weight_decay = 1e-4 #setting weight decay to prevent overfitting, given value add the panlty to the loss function here which is small.\n",
        "num_epochs = 8 # setting th number of epoces\n"
      ],
      "metadata": {
        "id": "OiSzpKbDaP_E"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization\n",
        "# Processing Lables\n",
        "# Converting to PyTorch Tensors\n",
        "# Creating TensorDataset"
      ],
      "metadata": {
        "id": "xUtLHfsfabEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining function get_data_loader for modeling\n",
        "def get_data_loader(data, batch_size_flg = True): #using flag to indicate whether use or not use the bach processing, if is is true means use bach processing.\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\") #loading pre-trained BERT tokenizer.\n",
        "  input_ids, attention_masks, labels = [], [], [] #lists to hold the processed inputs\n",
        "  for idx, row in data.iterrows(): #loop iteration over the row of the data\n",
        "      text1, text2 = row['merge1'], row['merge2']\n",
        "      encode_dict = tokenizer(text1,text2,          #tokenizning text1 and text2 to create the input for the bert_mulitilingual.\n",
        "                                  max_length=max_len,\n",
        "                                  padding='max_length', #padding the sequences in max length if they are less.\n",
        "                                  truncation=True, #if max lenght is excedding then trancate.\n",
        "                                  add_special_tokens=True #by adding special tokens, fulfilling the bert_mulitlingual input format requirments.\n",
        "                                  )\n",
        "# appending \"input_ids\" and \"attention_mask\" in their respective list.\n",
        "      input_ids.append(encode_dict['input_ids'])\n",
        "      attention_masks.append(encode_dict['attention_mask'])\n",
        "      # model is used to predict all labels?? -> should we convert to only 1 label\n",
        "      labels.append([float(x) for x in [row['Geography'],row['Entities'],row['Time'],row['Narrative'],row['Overall'],row['Style'],row['Tone']]])\n",
        "#converting all the inputs in Pytorch tensors.\n",
        "  input_ids = torch.tensor(input_ids)\n",
        "  attention_masks = torch.tensor(attention_masks)\n",
        "  labels = torch.tensor(labels)\n",
        "#creating TensorDataset, wrapper of three tenosors in a format to process efficinetly by DateLoader.\n",
        "  data = TensorDataset(input_ids, attention_masks, labels)\n",
        "  if(batch_size_flg):\n",
        "      data_loader = DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "  else:\n",
        "      data_loader = DataLoader(data)\n",
        "  return data_loader\n"
      ],
      "metadata": {
        "id": "DL7R5xrqaYBt"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the Training and Evaluation DataLoader"
      ],
      "metadata": {
        "id": "lx-jyDPjajR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating DataLoader objects for both training and development dataset.\n",
        "train_data_loader = get_data_loader(train)\n",
        "eval_data_loader = get_data_loader(dev, False)"
      ],
      "metadata": {
        "id": "PGPsek4uafpa"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modifing the pre-trained bert_multilingual model for finding Multilingual News Article Similarities."
      ],
      "metadata": {
        "id": "Bf7T_t2larrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining class Custom_BERT with construction and one formward method to modify the pre-trained bert_mulilingula for multilingula news article similarities.\n",
        "class Custom_BERT(nn.Module):\n",
        "    def __init__(self, model, hidden_size):\n",
        "        super(Custom_BERT, self).__init__()\n",
        "        self.reg_model = model\n",
        "#defining four fully connected layers(linear) in costum model.\n",
        "        self.fc1 = nn.Linear(hidden_size, 512)\n",
        "        # self.dropout = nn.Dropout(0.2)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 100)\n",
        "        self.fc4 = nn.Linear(100,7) # currently processes the 7 labels that we have defined for 7 output types\n",
        "#defining activation function applying non-linear trasformaition to the data after it passes through the linear layers.\n",
        "        self.activation1 = nn.GELU()\n",
        "        self.activation2 = nn.GELU()\n",
        "        self.activation3 = nn.GELU()\n",
        "#defining forward method to tell how the data flow throught the training.\n",
        "    def forward(self, input_ids, attention_masks):\n",
        "        output1 = self.reg_model(input_ids, attention_masks)[1]\n",
        "        # output2 =\n",
        "        # x = self.dropout(x)\n",
        "        # logits1= s\n",
        "        logits1= self.fc3(self.activation2(self.fc2(self.activation1(self.fc1(output1)))))\n",
        "        logits1 = self.fc4(logits1) #pridicted value of output of the all seven layers.\n",
        "\n",
        "        return logits1"
      ],
      "metadata": {
        "id": "NWY1pt8taoOP"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pearson-Correlation Calculation"
      ],
      "metadata": {
        "id": "C7ryyJp-ayj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "#Functing to calculate pearson values.\n",
        "def calculate_pearson_per_aspect(predictions, labels):\n",
        "    \"\"\"\n",
        "    Calculates Pearson correlation for each aspect (output dimension).\n",
        "\n",
        "    Args:\n",
        "    - predictions: numpy array of shape (N, 7) containing model predictions.\n",
        "    - labels: numpy array of shape (N, 7) containing ground truth scores.\n",
        "\n",
        "    Returns:\n",
        "    - correlations: List of Pearson correlation coefficients for each aspect.\n",
        "    \"\"\"\n",
        "    correlations = []\n",
        "    predictions = np.array(predictions)\n",
        "    labels = np.array(labels)\n",
        "    for i in range(predictions.shape[1]):  # Loop through each of the 7 output scores\n",
        "        r, _ = pearsonr(predictions[:, i], labels[:, i])\n",
        "        correlations.append(r)\n",
        "    return correlations\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G9JzmSlYavmW"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tracking Losses and Pearson Scores"
      ],
      "metadata": {
        "id": "wt-CU3Rha-fI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#initializing lists to track losses and pearson scores.\n",
        "train_losses=[] #loss foe each epoch during training\n",
        "val_losses =[] #loss for each epoch during validation.\n",
        "pearson_scores = [] #pearson correlation for the model's predication on the validation set.\n",
        "#Defining function to evaluate the model on given dataset.\n",
        "def evaluate(model, data_loader,criterion):\n",
        "  model.eval()\n",
        "  overall_pred, overall_true = [], []\n",
        "  with torch.no_grad():\n",
        "    val_loss_sum=0\n",
        "    for idx, (ids, att_msks, y) in enumerate(data_loader):\n",
        "      ids, att_msks, y = ids.to(device), att_msks.to(device), y.to(device)\n",
        "      y_pred = model(ids, att_msks)\n",
        "      loss = criterion(torch.squeeze(y_pred),torch.squeeze(y))\n",
        "      val_loss_sum += loss.item()\n",
        "\n",
        "      y_pred, y = torch.squeeze(y_pred).cpu().numpy().tolist(), torch.squeeze(y).cpu().numpy().tolist()\n",
        "      overall_pred.append(y_pred)\n",
        "      overall_true.append(y)\n",
        "  val_losses.append(val_loss_sum/len(data_loader)) # after process of all batches, average validation loss is appended to the val_losses list.\n",
        "  return overall_pred, overall_true\n",
        "\n",
        "#Defining function to train the model on training dataset, evaluate on validation set after every epoch.\n",
        "def train(model, model_path, train_data_loader, eval_data_loader, optimizer, loss_weights, epochs):\n",
        "  model.train()\n",
        "  criterion = nn.MSELoss()\n",
        "  best_pearson = 0\n",
        "  for i in range(epochs):\n",
        "    train_loss_sum = 0 #to track the total loss value  for epoch.\n",
        "    for idx, (ids, att_msks, y) in enumerate(train_data_loader):\n",
        "      print(idx)\n",
        "      ids, att_msks, y = ids.to(device), att_msks.to(device), y.to(device)\n",
        "      optimizer.zero_grad() #optimizer.zero_grad() to clear the gradiant of the models's pararmeters to prevent accumlating previous value.\n",
        "      y_pred = model(ids, att_msks)\n",
        "      y_pred, y = torch.squeeze(y_pred), torch.squeeze(y) ## required because y is a vector\n",
        "      # loss = weighted_loss(y_pred, y, criterion, loss_weights)\n",
        "      print(y_pred)\n",
        "      loss = criterion(y_pred,y) #computing the lossed between the models' pridiction and true lable.\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_loss_sum += loss.item()\n",
        "\n",
        "    train_losses.append(train_loss_sum/len(train_data_loader)) #appending the average training loss in train_losses list.\n",
        "    print(f\"Loss at epoch {i}: {train_loss_sum:.4f}\")\n",
        "\n",
        "    ## Determine best epoch model using correlation coefficient for Overall in dev data\n",
        "    eval_pred_overall, eval_true_overall = evaluate(model, eval_data_loader,criterion)\n",
        "\n",
        "    pearson_correlations = calculate_pearson_per_aspect(eval_pred_overall, eval_true_overall)#calculating the perason correlationa and assigning to the pearson_correlation object.\n",
        "    for i, r in enumerate(pearson_correlations):\n",
        "        print(f\"Pearson correlation for aspect {i+1}: {r:.4f}\")\n",
        "\n",
        "    # Optionally, calculate the mean Pearson correlation\n",
        "    curr_pearson = np.mean(pearson_correlations)\n",
        "    print(f\"Mean Pearson correlation: {curr_pearson:.4f}\")\n",
        "    pearson_scores.append(curr_pearson)\n",
        "\n",
        "\n",
        "    # curr_pearson = np.corrcoef(eval_pred_overall, eval_true_overall)[0][1]\n",
        "    # print(curr_pearson)\n",
        "    if curr_pearson > best_pearson:\n",
        "      best_pearson = curr_pearson\n",
        "      torch.save(model.state_dict(), model_path) # if curr_pearson mean  is greater than best_pearson, model's parameters are saved  in the model_path.\n",
        "\n"
      ],
      "metadata": {
        "id": "hca0AL7ca25Z"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training model"
      ],
      "metadata": {
        "id": "n0LNeW2zbJKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()#using this function to free up the unused cache.\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") #checking whether GPU is available or not ant according setting the device on which PyTorch run the computation.\n",
        "\n"
      ],
      "metadata": {
        "id": "r2mg-JxubFbc"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, BertConfig, BertTokenizer\n",
        "\n",
        "# Loading pre-trained multilingual BERT model and configuration\n",
        "pre_trained_model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "config = BertConfig.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Getting the hidden size from the model configuration\n",
        "hidden_size = config.hidden_size\n",
        "\n",
        "# Defining loss weights (assume 7 output classes)\n",
        "overall_weight = 0.25\n",
        "loss_weights = [overall_weight if i == 4 else (1-overall_weight)/6 for i in range(7)]\n",
        "\n",
        "# Initializing custom model\n",
        "model = Custom_BERT(pre_trained_model, hidden_size)\n",
        "model.to(device)\n",
        "\n",
        "# Path  to save the trained model\n",
        "model_path = \"BERT_Multilingual_0.25_overall_loss.pth\"\n"
      ],
      "metadata": {
        "id": "1kB1JSiibMZT"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setting up the optimizer to update the models parameters during its training where AdamW() will adepts the learing rate and preventing it overfitting by penalizing large weigth during training.\n",
        "optimizer = AdamW(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
        "train(model, model_path, train_data_loader, eval_data_loader, optimizer, loss_weights, num_epochs) # calling train function to hadle traing of the model.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMg9CP1CbPDv",
        "outputId": "a37f75a6-5f21-4830-f335-19d7b2e9cb3d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        [1.3132, 1.9021, 1.3349, 2.0008, 1.8957, 1.4145, 1.3495],\n",
            "        [3.2578, 4.0480, 2.2341, 4.0721, 4.0961, 2.4534, 2.5177],\n",
            "        [1.3942, 2.0105, 1.3956, 2.1114, 2.0098, 1.4634, 1.4076],\n",
            "        [1.9107, 2.6537, 1.6907, 2.7456, 2.6866, 1.7365, 1.7347]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "185\n",
            "tensor([[0.9140, 1.3874, 1.0755, 1.4903, 1.3623, 1.1474, 1.0733],\n",
            "        [1.1839, 1.7396, 1.2589, 1.8406, 1.7271, 1.3329, 1.2642],\n",
            "        [1.0861, 1.6094, 1.1907, 1.7108, 1.5905, 1.2666, 1.1946],\n",
            "        [1.5257, 2.1809, 1.4782, 2.2795, 2.1888, 1.5385, 1.4949],\n",
            "        [1.8292, 2.5534, 1.6463, 2.6474, 2.5812, 1.6945, 1.6854]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "186\n",
            "tensor([[1.7192, 2.4138, 1.5851, 2.5128, 2.4354, 1.6466, 1.6197],\n",
            "        [2.3640, 3.1742, 1.9121, 3.2544, 3.2375, 1.9460, 2.0033],\n",
            "        [1.5889, 2.2522, 1.5105, 2.3531, 2.2668, 1.5734, 1.5361],\n",
            "        [1.0218, 1.5238, 1.1463, 1.6256, 1.5028, 1.2220, 1.1489],\n",
            "        [2.5136, 3.3416, 1.9785, 3.4168, 3.4144, 2.0086, 2.0869]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "187\n",
            "tensor([[3.2612, 4.0466, 2.2375, 4.0796, 4.0997, 2.4615, 2.5269],\n",
            "        [1.8581, 2.5899, 1.6704, 2.6900, 2.6242, 1.7099, 1.7085],\n",
            "        [2.2087, 2.9937, 1.8368, 3.0830, 3.0478, 1.8791, 1.9146],\n",
            "        [3.2630, 4.0465, 2.2414, 4.0792, 4.1037, 2.4654, 2.5288],\n",
            "        [1.0166, 1.5185, 1.1476, 1.6235, 1.4985, 1.2178, 1.1474]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "188\n",
            "tensor([[3.2338, 4.0145, 2.2326, 4.0546, 4.0761, 2.4353, 2.5086],\n",
            "        [3.2645, 4.0455, 2.2373, 4.0808, 4.1025, 2.4617, 2.5319],\n",
            "        [2.1287, 2.9016, 1.8003, 2.9963, 2.9523, 1.8441, 1.8714],\n",
            "        [1.4747, 2.1064, 1.4442, 2.2101, 2.1137, 1.5139, 1.4637],\n",
            "        [1.4054, 2.0208, 1.4059, 2.1272, 2.0251, 1.4735, 1.4187]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "189\n",
            "tensor([[1.2075, 1.7647, 1.2768, 1.8728, 1.7571, 1.3494, 1.2845],\n",
            "        [2.4466, 3.2663, 1.9498, 3.3500, 3.3366, 1.9791, 2.0549],\n",
            "        [2.3701, 3.1886, 1.9200, 3.2747, 3.2567, 1.9354, 2.0112],\n",
            "        [0.8382, 1.2837, 1.0197, 1.3878, 1.2557, 1.0882, 1.0184],\n",
            "        [3.2373, 4.0142, 2.2274, 4.0567, 4.0760, 2.4403, 2.5137]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "190\n",
            "tensor([[3.2683, 4.0406, 2.2314, 4.0758, 4.0977, 2.4738, 2.5371],\n",
            "        [1.8449, 2.5634, 1.6508, 2.6659, 2.5957, 1.7029, 1.7002],\n",
            "        [3.2581, 4.0411, 2.2346, 4.0797, 4.0993, 2.4668, 2.5319],\n",
            "        [2.3164, 3.1283, 1.8949, 3.2209, 3.1973, 1.9192, 1.9844],\n",
            "        [2.2661, 3.0760, 1.8758, 3.1699, 3.1405, 1.8925, 1.9566]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "191\n",
            "tensor([[2.9671, 3.7613, 2.1314, 3.8247, 3.8347, 2.2489, 2.3484],\n",
            "        [0.9249, 1.3945, 1.0760, 1.4996, 1.3701, 1.1545, 1.0822],\n",
            "        [2.1278, 2.8980, 1.7963, 2.9968, 2.9515, 1.8441, 1.8749],\n",
            "        [2.5338, 3.3462, 1.9765, 3.4303, 3.4199, 2.0323, 2.1066],\n",
            "        [2.0267, 2.7916, 1.7577, 2.8938, 2.8403, 1.7927, 1.8169]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "192\n",
            "tensor([[2.4226, 3.2563, 1.9444, 3.3448, 3.3353, 1.9530, 2.0444],\n",
            "        [1.7365, 2.4372, 1.6025, 2.5462, 2.4667, 1.6550, 1.6386],\n",
            "        [3.1206, 3.9102, 2.1840, 3.9620, 3.9787, 2.3604, 2.4426],\n",
            "        [3.2552, 4.0250, 2.2132, 4.0576, 4.0726, 2.4650, 2.5277],\n",
            "        [3.0613, 3.8536, 2.1652, 3.9124, 3.9299, 2.3277, 2.4070]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "193\n",
            "tensor([[1.5411, 2.1827, 1.4732, 2.2911, 2.1955, 1.5519, 1.5084],\n",
            "        [3.2786, 4.0517, 2.2320, 4.0942, 4.1103, 2.4757, 2.5460],\n",
            "        [3.1871, 3.9652, 2.1996, 4.0105, 4.0298, 2.4033, 2.4811],\n",
            "        [2.4097, 3.2437, 1.9399, 3.3344, 3.3225, 1.9436, 2.0390],\n",
            "        [3.2831, 4.0584, 2.2390, 4.0993, 4.1190, 2.4856, 2.5479]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "194\n",
            "tensor([[3.2279, 4.0059, 2.2234, 4.0577, 4.0764, 2.4425, 2.5134],\n",
            "        [3.2565, 4.0286, 2.2276, 4.0753, 4.0915, 2.4598, 2.5307],\n",
            "        [0.7435, 1.1541, 0.9433, 1.2572, 1.1216, 1.0121, 0.9456],\n",
            "        [0.8839, 1.3391, 1.0467, 1.4463, 1.3133, 1.1230, 1.0521],\n",
            "        [1.5929, 2.2481, 1.5073, 2.3579, 2.2664, 1.5802, 1.5426]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "195\n",
            "tensor([[1.0360, 1.5402, 1.1624, 1.6541, 1.5251, 1.2388, 1.1673],\n",
            "        [2.4635, 3.2923, 1.9571, 3.3817, 3.3742, 1.9700, 2.0673],\n",
            "        [1.7942, 2.4868, 1.6089, 2.5923, 2.5163, 1.6835, 1.6673],\n",
            "        [2.3018, 3.0969, 1.8793, 3.1976, 3.1671, 1.9253, 1.9779],\n",
            "        [2.6250, 3.4228, 2.0052, 3.5130, 3.5062, 2.0944, 2.1602]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "196\n",
            "tensor([[3.2840, 4.0511, 2.2319, 4.0989, 4.1128, 2.4871, 2.5505],\n",
            "        [1.4109, 2.0170, 1.3991, 2.1314, 2.0240, 1.4825, 1.4251],\n",
            "        [1.4227, 2.0268, 1.3984, 2.1393, 2.0345, 1.4884, 1.4303],\n",
            "        [1.3026, 1.8819, 1.3353, 1.9976, 1.8839, 1.4166, 1.3536],\n",
            "        [1.2820, 1.8573, 1.3249, 1.9741, 1.8575, 1.4014, 1.3407]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "197\n",
            "tensor([[3.0711, 3.8424, 2.1567, 3.9068, 3.9220, 2.3277, 2.4118],\n",
            "        [3.2841, 4.0447, 2.2309, 4.0942, 4.1077, 2.4899, 2.5548],\n",
            "        [2.3878, 3.1934, 1.9187, 3.2944, 3.2688, 1.9620, 2.0301],\n",
            "        [2.4175, 3.2266, 1.9317, 3.3275, 3.3064, 1.9688, 2.0462],\n",
            "        [1.6048, 2.2608, 1.5170, 2.3766, 2.2817, 1.5897, 1.5538]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "198\n",
            "tensor([[3.2327, 3.9981, 2.2202, 4.0571, 4.0683, 2.4446, 2.5183],\n",
            "        [2.8203, 3.6102, 2.0779, 3.6937, 3.7033, 2.1816, 2.2695],\n",
            "        [0.8544, 1.2964, 1.0263, 1.4067, 1.2705, 1.1053, 1.0320],\n",
            "        [0.9861, 1.4676, 1.1157, 1.5798, 1.4488, 1.2034, 1.1279],\n",
            "        [1.0706, 1.5799, 1.1810, 1.6962, 1.5681, 1.2642, 1.1916]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "199\n",
            "tensor([[1.7016, 2.3783, 1.5721, 2.4972, 2.4071, 1.6437, 1.6170],\n",
            "        [1.2719, 1.8395, 1.3161, 1.9581, 1.8402, 1.3999, 1.3326],\n",
            "        [1.2593, 1.8240, 1.3137, 1.9447, 1.8246, 1.3928, 1.3266],\n",
            "        [3.2918, 4.0529, 2.2384, 4.1112, 4.1226, 2.4931, 2.5589],\n",
            "        [1.1925, 1.7354, 1.2591, 1.8519, 1.7295, 1.3428, 1.2751]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "200\n",
            "tensor([[3.2856, 4.0406, 2.2252, 4.0912, 4.1006, 2.4996, 2.5539],\n",
            "        [1.5959, 2.2476, 1.5140, 2.3677, 2.2706, 1.5937, 1.5491],\n",
            "        [3.2662, 4.0183, 2.2186, 4.0738, 4.0836, 2.4835, 2.5390],\n",
            "        [2.8722, 3.6613, 2.1006, 3.7473, 3.7532, 2.2078, 2.3010],\n",
            "        [3.1575, 3.9260, 2.2024, 3.9989, 4.0085, 2.4226, 2.4755]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "201\n",
            "tensor([[0.8294, 1.2623, 1.0083, 1.3751, 1.2381, 1.0867, 1.0130],\n",
            "        [1.3488, 1.9389, 1.3701, 2.0624, 1.9484, 1.4505, 1.3876],\n",
            "        [3.0423, 3.8200, 2.1592, 3.9022, 3.9083, 2.3265, 2.4030],\n",
            "        [3.2523, 4.0200, 2.2359, 4.0839, 4.0938, 2.4770, 2.5352],\n",
            "        [3.1003, 3.8764, 2.1787, 3.9534, 3.9630, 2.3594, 2.4366]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "202\n",
            "tensor([[3.2333, 3.9979, 2.2309, 4.0685, 4.0795, 2.4605, 2.5209],\n",
            "        [3.2655, 4.0203, 2.2226, 4.0793, 4.0867, 2.4803, 2.5389],\n",
            "        [3.2481, 4.0047, 2.2247, 4.0739, 4.0832, 2.4705, 2.5281],\n",
            "        [1.8943, 2.6094, 1.6776, 2.7294, 2.6541, 1.7497, 1.7382],\n",
            "        [3.0491, 3.8238, 2.1617, 3.9010, 3.9074, 2.3364, 2.4083]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "203\n",
            "tensor([[3.2858, 4.0444, 2.2447, 4.1090, 4.1191, 2.5027, 2.5527],\n",
            "        [3.2929, 4.0502, 2.2410, 4.1082, 4.1172, 2.5140, 2.5596],\n",
            "        [3.1434, 3.9077, 2.1947, 3.9845, 3.9946, 2.3886, 2.4585],\n",
            "        [0.9925, 1.4740, 1.1262, 1.5922, 1.4593, 1.2129, 1.1332],\n",
            "        [0.7145, 1.1087, 0.9187, 1.2170, 1.0786, 0.9924, 0.9226]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "204\n",
            "tensor([[1.4464, 2.0544, 1.4273, 2.1793, 2.0693, 1.5108, 1.4498],\n",
            "        [2.4071, 3.2138, 1.9403, 3.3258, 3.2991, 1.9682, 2.0373],\n",
            "        [0.6995, 1.0881, 0.9084, 1.1961, 1.0572, 0.9793, 0.9107],\n",
            "        [0.9590, 1.4319, 1.1109, 1.5533, 1.4168, 1.1907, 1.1120],\n",
            "        [2.6498, 3.4489, 2.0287, 3.5499, 3.5378, 2.0938, 2.1720]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "205\n",
            "tensor([[2.6087, 3.4058, 2.0162, 3.5130, 3.5004, 2.0799, 2.1482],\n",
            "        [2.6993, 3.4974, 2.0466, 3.5970, 3.5877, 2.1233, 2.1993],\n",
            "        [2.9540, 3.7280, 2.1378, 3.8184, 3.8242, 2.2763, 2.3439],\n",
            "        [0.9010, 1.3532, 1.0668, 1.4707, 1.3332, 1.1473, 1.0663],\n",
            "        [1.6810, 2.3402, 1.5604, 2.4630, 2.3687, 1.6451, 1.5995]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "206\n",
            "tensor([[3.2841, 4.0343, 2.2481, 4.0991, 4.1024, 2.5008, 2.5488],\n",
            "        [1.4447, 2.0518, 1.4297, 2.1765, 2.0641, 1.5107, 1.4482],\n",
            "        [1.5638, 2.2002, 1.5003, 2.3242, 2.2234, 1.5789, 1.5240],\n",
            "        [0.7760, 1.1894, 0.9725, 1.3022, 1.1615, 1.0471, 0.9713],\n",
            "        [2.5510, 3.3546, 1.9969, 3.4611, 3.4417, 2.0445, 2.1170]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "207\n",
            "tensor([[3.2432, 4.0018, 2.2411, 4.0674, 4.0767, 2.4682, 2.5207],\n",
            "        [1.6337, 2.2913, 1.5463, 2.4171, 2.3183, 1.6165, 1.5720],\n",
            "        [2.2716, 3.0466, 1.8776, 3.1641, 3.1163, 1.9289, 1.9604],\n",
            "        [2.5747, 3.3646, 2.0014, 3.4714, 3.4490, 2.0816, 2.1318],\n",
            "        [1.2826, 1.8479, 1.3324, 1.9734, 1.8505, 1.4132, 1.3397]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "208\n",
            "tensor([[2.4398, 3.2315, 1.9518, 3.3416, 3.3115, 2.0115, 2.0548],\n",
            "        [3.2577, 4.0155, 2.2407, 4.0776, 4.0835, 2.4895, 2.5301],\n",
            "        [3.2008, 3.9680, 2.2290, 4.0375, 4.0426, 2.4461, 2.4954],\n",
            "        [3.2433, 4.0022, 2.2399, 4.0699, 4.0768, 2.4696, 2.5197],\n",
            "        [3.1898, 3.9515, 2.2265, 4.0255, 4.0326, 2.4324, 2.4857]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "209\n",
            "tensor([[0.8316, 1.2639, 1.0152, 1.3766, 1.2372, 1.0928, 1.0124],\n",
            "        [1.6532, 2.3112, 1.5529, 2.4330, 2.3360, 1.6294, 1.5796],\n",
            "        [0.9832, 1.4633, 1.1275, 1.5805, 1.4449, 1.2061, 1.1242],\n",
            "        [3.2285, 3.9847, 2.2360, 4.0488, 4.0597, 2.4558, 2.5045],\n",
            "        [3.1772, 3.9396, 2.2125, 4.0033, 4.0054, 2.4148, 2.4726]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "210\n",
            "tensor([[1.3284, 1.9050, 1.3565, 2.0246, 1.9065, 1.4386, 1.3646],\n",
            "        [0.8868, 1.3398, 1.0639, 1.4566, 1.3175, 1.1381, 1.0562],\n",
            "        [2.6005, 3.4050, 2.0195, 3.5048, 3.4923, 2.0719, 2.1377],\n",
            "        [3.2568, 4.0121, 2.2472, 4.0741, 4.0833, 2.4837, 2.5249],\n",
            "        [1.7401, 2.4187, 1.6041, 2.5397, 2.4492, 1.6763, 1.6347]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "211\n",
            "tensor([[2.4244, 3.2337, 1.9575, 3.3413, 3.3163, 1.9784, 2.0415],\n",
            "        [1.1509, 1.6792, 1.2459, 1.7989, 1.6723, 1.3264, 1.2433],\n",
            "        [1.2758, 1.8419, 1.3339, 1.9642, 1.8433, 1.4071, 1.3312],\n",
            "        [2.6017, 3.3943, 2.0163, 3.4942, 3.4796, 2.0838, 2.1374],\n",
            "        [1.6799, 2.3444, 1.5744, 2.4664, 2.3719, 1.6399, 1.5957]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "212\n",
            "tensor([[1.0794, 1.5851, 1.2013, 1.7049, 1.5739, 1.2772, 1.1929],\n",
            "        [2.5954, 3.4000, 2.0218, 3.4946, 3.4865, 2.0504, 2.1295],\n",
            "        [0.9224, 1.3797, 1.0831, 1.4918, 1.3561, 1.1583, 1.0766],\n",
            "        [3.2350, 3.9878, 2.2445, 4.0504, 4.0577, 2.4773, 2.5085],\n",
            "        [0.9221, 1.3789, 1.0827, 1.4922, 1.3576, 1.1567, 1.0762]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "213\n",
            "tensor([[1.5278, 2.1531, 1.4882, 2.2753, 2.1716, 1.5557, 1.4957],\n",
            "        [1.1113, 1.6263, 1.2251, 1.7463, 1.6167, 1.2944, 1.2151],\n",
            "        [1.4522, 2.0573, 1.4365, 2.1757, 2.0662, 1.5079, 1.4434],\n",
            "        [2.7985, 3.5669, 2.0859, 3.6554, 3.6534, 2.1872, 2.2405],\n",
            "        [3.2540, 4.0031, 2.2476, 4.0595, 4.0686, 2.4687, 2.5143]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "214\n",
            "tensor([[2.5701, 3.3595, 2.0106, 3.4572, 3.4428, 2.0465, 2.1124],\n",
            "        [0.9129, 1.3643, 1.0794, 1.4784, 1.3437, 1.1491, 1.0684],\n",
            "        [2.0447, 2.7685, 1.7621, 2.8795, 2.8168, 1.8201, 1.8119],\n",
            "        [0.9146, 1.3665, 1.0804, 1.4800, 1.3446, 1.1514, 1.0698],\n",
            "        [2.1834, 2.9392, 1.8437, 3.0509, 3.0025, 1.8762, 1.8961]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "215\n",
            "tensor([[0.8883, 1.3292, 1.0584, 1.4404, 1.3055, 1.1280, 1.0478],\n",
            "        [0.7572, 1.1570, 0.9559, 1.2628, 1.1255, 1.0200, 0.9473],\n",
            "        [3.2920, 4.0271, 2.2577, 4.0776, 4.0905, 2.4946, 2.5329],\n",
            "        [0.8784, 1.3187, 1.0551, 1.4306, 1.2939, 1.1226, 1.0425],\n",
            "        [1.2959, 1.8576, 1.3431, 1.9758, 1.8591, 1.4088, 1.3376]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "216\n",
            "tensor([[0.9057, 1.3531, 1.0741, 1.4647, 1.3299, 1.1431, 1.0611],\n",
            "        [2.4185, 3.1919, 1.9439, 3.2928, 3.2655, 1.9777, 2.0246],\n",
            "        [3.1120, 3.8603, 2.1998, 3.9283, 3.9392, 2.3579, 2.4188],\n",
            "        [3.2170, 3.9589, 2.2376, 4.0161, 4.0307, 2.4357, 2.4817],\n",
            "        [1.1322, 1.6456, 1.2370, 1.7627, 1.6358, 1.3044, 1.2246]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "217\n",
            "tensor([[0.8296, 1.2515, 1.0153, 1.3602, 1.2234, 1.0834, 1.0035],\n",
            "        [1.5516, 2.1767, 1.5010, 2.2937, 2.1932, 1.5546, 1.5043],\n",
            "        [1.8347, 2.5105, 1.6472, 2.6194, 2.5415, 1.7058, 1.6778],\n",
            "        [1.0091, 1.4852, 1.1461, 1.5978, 1.4658, 1.2140, 1.1350],\n",
            "        [1.5682, 2.1925, 1.5039, 2.3065, 2.2091, 1.5640, 1.5133]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "218\n",
            "tensor([[1.0119, 1.4905, 1.1564, 1.6061, 1.4728, 1.2202, 1.1396],\n",
            "        [1.1207, 1.6297, 1.2284, 1.7460, 1.6181, 1.2930, 1.2154],\n",
            "        [1.5951, 2.2254, 1.5245, 2.3405, 2.2434, 1.5790, 1.5302],\n",
            "        [1.4185, 1.9994, 1.4046, 2.1093, 2.0019, 1.4784, 1.4106],\n",
            "        [2.0901, 2.8196, 1.7886, 2.9249, 2.8687, 1.8189, 1.8320]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "219\n",
            "tensor([[2.9579, 3.7069, 2.1412, 3.7773, 3.7864, 2.2573, 2.3175],\n",
            "        [3.2540, 3.9881, 2.2468, 4.0356, 4.0529, 2.4529, 2.4970],\n",
            "        [3.0196, 3.7693, 2.1693, 3.8375, 3.8490, 2.3013, 2.3583],\n",
            "        [2.7101, 3.4869, 2.0577, 3.5649, 3.5673, 2.0963, 2.1761],\n",
            "        [2.4493, 3.2364, 1.9640, 3.3295, 3.3119, 1.9624, 2.0343]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "220\n",
            "tensor([[0.8508, 1.2775, 1.0314, 1.3837, 1.2494, 1.0971, 1.0168],\n",
            "        [1.0176, 1.4927, 1.1493, 1.6007, 1.4720, 1.2175, 1.1359],\n",
            "        [1.2537, 1.7882, 1.3001, 1.8953, 1.7809, 1.3728, 1.2963],\n",
            "        [1.4512, 2.0436, 1.4338, 2.1536, 2.0502, 1.4937, 1.4314],\n",
            "        [0.8588, 1.2886, 1.0391, 1.3967, 1.2626, 1.1029, 1.0238]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "221\n",
            "tensor([[2.3404, 3.1097, 1.9158, 3.2019, 3.1759, 1.9302, 1.9710],\n",
            "        [1.3639, 1.9335, 1.3826, 2.0429, 1.9344, 1.4465, 1.3746],\n",
            "        [0.8341, 1.2547, 1.0212, 1.3599, 1.2257, 1.0847, 1.0039],\n",
            "        [2.5763, 3.3612, 2.0124, 3.4407, 3.4395, 2.0225, 2.0977],\n",
            "        [1.3010, 1.8542, 1.3435, 1.9640, 1.8526, 1.4080, 1.3328]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "222\n",
            "tensor([[1.3928, 1.9676, 1.4003, 2.0758, 1.9721, 1.4597, 1.3911],\n",
            "        [2.2941, 3.0513, 1.8915, 3.1418, 3.1153, 1.9059, 1.9411],\n",
            "        [2.7967, 3.5569, 2.0853, 3.6227, 3.6318, 2.1311, 2.2151],\n",
            "        [3.2803, 3.9990, 2.2343, 4.0238, 4.0451, 2.4724, 2.5093],\n",
            "        [1.7428, 2.3887, 1.5934, 2.4897, 2.4117, 1.6571, 1.6105]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "223\n",
            "tensor([[1.4054, 1.9806, 1.3999, 2.0826, 1.9842, 1.4613, 1.3944],\n",
            "        [3.1941, 3.9262, 2.2277, 3.9698, 3.9969, 2.3953, 2.4496],\n",
            "        [1.1342, 1.6411, 1.2360, 1.7471, 1.6283, 1.2992, 1.2159],\n",
            "        [1.1875, 1.7100, 1.2710, 1.8156, 1.7003, 1.3292, 1.2518],\n",
            "        [1.2795, 1.8260, 1.3348, 1.9320, 1.8231, 1.3912, 1.3151]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "224\n",
            "tensor([[0.9780, 1.4390, 1.1289, 1.5450, 1.4188, 1.1882, 1.1054],\n",
            "        [3.2451, 3.9738, 2.2528, 4.0131, 4.0404, 2.4413, 2.4811],\n",
            "        [3.2654, 3.9925, 2.2517, 4.0253, 4.0520, 2.4493, 2.4921],\n",
            "        [2.5780, 3.3558, 2.0145, 3.4281, 3.4336, 2.0226, 2.0909],\n",
            "        [2.7586, 3.4958, 2.0607, 3.5586, 3.5646, 2.1696, 2.1930]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "225\n",
            "tensor([[2.9277, 3.6663, 2.1311, 3.7223, 3.7420, 2.2506, 2.2872],\n",
            "        [2.0720, 2.7904, 1.7850, 2.8831, 2.8377, 1.8019, 1.8059],\n",
            "        [3.3197, 4.0358, 2.2605, 4.0584, 4.0861, 2.4913, 2.5255],\n",
            "        [2.4488, 3.2341, 1.9668, 3.3094, 3.3061, 1.9517, 2.0199],\n",
            "        [3.1565, 3.8910, 2.2140, 3.9345, 3.9589, 2.3682, 2.4245]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "226\n",
            "tensor([[2.4819, 3.2651, 1.9808, 3.3389, 3.3383, 1.9620, 2.0342],\n",
            "        [1.6966, 2.3353, 1.5765, 2.4336, 2.3555, 1.6219, 1.5763],\n",
            "        [1.3255, 1.8780, 1.3589, 1.9807, 1.8754, 1.4129, 1.3399],\n",
            "        [3.2328, 3.9540, 2.2354, 3.9865, 4.0156, 2.4188, 2.4635],\n",
            "        [1.9363, 2.6238, 1.7070, 2.7178, 2.6601, 1.7409, 1.7230]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "227\n",
            "tensor([[3.2881, 4.0037, 2.2597, 4.0347, 4.0668, 2.4598, 2.4979],\n",
            "        [0.8650, 1.2835, 1.0320, 1.3821, 1.2547, 1.0940, 1.0144],\n",
            "        [0.8161, 1.2222, 1.0014, 1.3218, 1.1924, 1.0611, 0.9814],\n",
            "        [3.3062, 4.0244, 2.2634, 4.0479, 4.0769, 2.4672, 2.5107],\n",
            "        [3.2132, 3.9307, 2.2252, 3.9664, 3.9926, 2.3997, 2.4476]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "228\n",
            "tensor([[2.6116, 3.3813, 2.0217, 3.4476, 3.4565, 2.0273, 2.1003],\n",
            "        [1.9965, 2.6864, 1.7338, 2.7779, 2.7246, 1.7702, 1.7555],\n",
            "        [2.4656, 3.2297, 1.9629, 3.3050, 3.2989, 1.9710, 2.0242],\n",
            "        [3.3055, 4.0064, 2.2430, 4.0273, 4.0545, 2.4747, 2.5087],\n",
            "        [2.8152, 3.5636, 2.0922, 3.6247, 3.6448, 2.1457, 2.2113]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "229\n",
            "tensor([[3.1159, 3.8413, 2.1974, 3.8872, 3.9158, 2.3363, 2.3926],\n",
            "        [1.9500, 2.6378, 1.7157, 2.7331, 2.6761, 1.7449, 1.7300],\n",
            "        [1.6633, 2.2911, 1.5562, 2.3887, 2.3084, 1.6009, 1.5541],\n",
            "        [2.9948, 3.7311, 2.1464, 3.7726, 3.7993, 2.2499, 2.3177],\n",
            "        [2.9174, 3.6615, 2.1241, 3.7111, 3.7367, 2.1966, 2.2702]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "230\n",
            "tensor([[3.2635, 3.9759, 2.2401, 4.0058, 4.0386, 2.4328, 2.4798],\n",
            "        [2.8301, 3.5817, 2.0908, 3.6403, 3.6550, 2.1422, 2.2227],\n",
            "        [3.2403, 3.9568, 2.2372, 3.9905, 4.0237, 2.4182, 2.4650],\n",
            "        [3.2892, 4.0015, 2.2520, 4.0339, 4.0636, 2.4560, 2.4987],\n",
            "        [1.8846, 2.5581, 1.6736, 2.6541, 2.5910, 1.7108, 1.6897]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "231\n",
            "tensor([[0.8628, 1.2840, 1.0303, 1.3832, 1.2555, 1.0957, 1.0161],\n",
            "        [0.8666, 1.2867, 1.0300, 1.3858, 1.2589, 1.0992, 1.0176],\n",
            "        [2.3267, 3.0487, 1.8708, 3.1277, 3.1049, 1.9304, 1.9438],\n",
            "        [3.2253, 3.9513, 2.2270, 3.9855, 4.0149, 2.4076, 2.4584],\n",
            "        [1.3848, 1.9521, 1.3899, 2.0548, 1.9542, 1.4471, 1.3794]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "232\n",
            "tensor([[0.7878, 1.1898, 0.9803, 1.2911, 1.1613, 1.0420, 0.9636],\n",
            "        [1.8133, 2.4819, 1.6356, 2.5807, 2.5116, 1.6794, 1.6506],\n",
            "        [2.4847, 3.2569, 1.9647, 3.3313, 3.3301, 1.9762, 2.0359],\n",
            "        [1.1919, 1.7104, 1.2658, 1.8152, 1.7006, 1.3339, 1.2522],\n",
            "        [2.9942, 3.7348, 2.1357, 3.7852, 3.8075, 2.2503, 2.3217]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "233\n",
            "tensor([[2.3662, 3.1412, 1.9167, 3.2226, 3.2097, 1.9187, 1.9729],\n",
            "        [1.8334, 2.5005, 1.6360, 2.5963, 2.5302, 1.6948, 1.6614],\n",
            "        [2.5104, 3.2955, 1.9758, 3.3704, 3.3708, 1.9805, 2.0521],\n",
            "        [1.9060, 2.5970, 1.6867, 2.6946, 2.6328, 1.7255, 1.7087],\n",
            "        [2.2713, 3.0323, 1.8710, 3.1177, 3.0938, 1.8809, 1.9196]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "234\n",
            "tensor([[1.4619, 2.0510, 1.4239, 2.1501, 2.0558, 1.4953, 1.4280],\n",
            "        [3.2257, 3.9588, 2.2207, 3.9932, 4.0212, 2.4137, 2.4644],\n",
            "        [0.7917, 1.1995, 0.9864, 1.3030, 1.1720, 1.0502, 0.9700],\n",
            "        [1.2210, 1.7535, 1.2879, 1.8618, 1.7495, 1.3550, 1.2752],\n",
            "        [2.5944, 3.3762, 2.0032, 3.4483, 3.4543, 2.0281, 2.0989]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "235\n",
            "tensor([[2.1894, 2.9523, 1.8418, 3.0419, 3.0111, 1.8505, 1.8803],\n",
            "        [3.2376, 3.9722, 2.2259, 4.0083, 4.0376, 2.4381, 2.4766],\n",
            "        [0.9494, 1.4001, 1.0885, 1.5014, 1.3772, 1.1672, 1.0808],\n",
            "        [0.9004, 1.3436, 1.0670, 1.4492, 1.3212, 1.1353, 1.0513],\n",
            "        [1.4360, 2.0229, 1.4134, 2.1248, 2.0293, 1.4818, 1.4143]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "236\n",
            "tensor([[2.7422, 3.5219, 2.0549, 3.5897, 3.6018, 2.1156, 2.1877],\n",
            "        [0.8808, 1.3177, 1.0472, 1.4207, 1.2931, 1.1180, 1.0361],\n",
            "        [1.7156, 2.3805, 1.5903, 2.4844, 2.4091, 1.6363, 1.5987],\n",
            "        [1.5408, 2.1567, 1.4795, 2.2585, 2.1704, 1.5467, 1.4859],\n",
            "        [2.2788, 3.0429, 1.8728, 3.1312, 3.1073, 1.8985, 1.9308]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "237\n",
            "tensor([[3.2632, 4.0083, 2.2355, 4.0412, 4.0680, 2.4643, 2.4985],\n",
            "        [2.4808, 3.2823, 1.9677, 3.3598, 3.3603, 1.9735, 2.0444],\n",
            "        [0.8634, 1.3000, 1.0453, 1.4061, 1.2769, 1.1113, 1.0280],\n",
            "        [2.4833, 3.2773, 1.9646, 3.3558, 3.3537, 1.9896, 2.0471],\n",
            "        [0.7722, 1.1787, 0.9700, 1.2809, 1.1491, 1.0367, 0.9576]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "238\n",
            "tensor([[2.7573, 3.5403, 2.0575, 3.6086, 3.6216, 2.1283, 2.2002],\n",
            "        [1.5497, 2.1788, 1.4904, 2.2832, 2.1937, 1.5568, 1.4966],\n",
            "        [1.5081, 2.1339, 1.4781, 2.2431, 2.1494, 1.5342, 1.4753],\n",
            "        [1.8414, 2.5405, 1.6617, 2.6436, 2.5772, 1.7101, 1.6818],\n",
            "        [3.0961, 3.8554, 2.1834, 3.9072, 3.9330, 2.3548, 2.3998]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "239\n",
            "tensor([[1.5698, 2.1852, 1.4734, 2.2805, 2.1944, 1.5667, 1.4996],\n",
            "        [0.6905, 1.0747, 0.9099, 1.1763, 1.0433, 0.9727, 0.8979],\n",
            "        [2.3445, 3.1557, 1.9245, 3.2430, 3.2287, 1.9209, 1.9790],\n",
            "        [3.0934, 3.8569, 2.1811, 3.9073, 3.9286, 2.3466, 2.4012],\n",
            "        [2.1116, 2.8732, 1.8095, 2.9728, 2.9308, 1.8315, 1.8452]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "240\n",
            "tensor([[0.8949, 1.3468, 1.0675, 1.4550, 1.3239, 1.1388, 1.0538],\n",
            "        [3.0810, 3.8470, 2.1790, 3.9014, 3.9218, 2.3482, 2.3930],\n",
            "        [2.8788, 3.6615, 2.1058, 3.7232, 3.7414, 2.2119, 2.2705],\n",
            "        [3.0974, 3.8568, 2.1744, 3.9075, 3.9252, 2.3560, 2.3985],\n",
            "        [3.1336, 3.8982, 2.1927, 3.9444, 3.9627, 2.3788, 2.4260]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "241\n",
            "tensor([[1.6675, 2.3336, 1.5637, 2.4425, 2.3565, 1.6233, 1.5747],\n",
            "        [2.0890, 2.8395, 1.7864, 2.9401, 2.8899, 1.8344, 1.8305],\n",
            "        [0.8654, 1.3071, 1.0439, 1.4159, 1.2830, 1.1156, 1.0307],\n",
            "        [0.8333, 1.2648, 1.0183, 1.3708, 1.2382, 1.0897, 1.0061],\n",
            "        [2.1261, 2.8977, 1.8189, 2.9977, 2.9542, 1.8427, 1.8556]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "242\n",
            "tensor([[1.2024, 1.7442, 1.2757, 1.8553, 1.7374, 1.3532, 1.2680],\n",
            "        [1.6221, 2.2843, 1.5447, 2.3957, 2.3057, 1.5982, 1.5472],\n",
            "        [1.0916, 1.6008, 1.2024, 1.7128, 1.5873, 1.2812, 1.1921],\n",
            "        [3.2344, 3.9900, 2.2282, 4.0352, 4.0529, 2.4515, 2.4832],\n",
            "        [0.8548, 1.2926, 1.0328, 1.4003, 1.2670, 1.1069, 1.0214]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "243\n",
            "tensor([[2.2451, 3.0177, 1.8533, 3.1122, 3.0747, 1.9038, 1.9143],\n",
            "        [2.1970, 2.9682, 1.8355, 3.0654, 3.0222, 1.8788, 1.8890],\n",
            "        [2.8432, 3.6339, 2.0916, 3.7034, 3.7136, 2.1926, 2.2475],\n",
            "        [2.3956, 3.2096, 1.9378, 3.3019, 3.2809, 1.9511, 2.0035],\n",
            "        [2.4727, 3.2862, 1.9665, 3.3749, 3.3615, 1.9895, 2.0446]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "244\n",
            "tensor([[2.8292, 3.6188, 2.0932, 3.6921, 3.6960, 2.1964, 2.2430],\n",
            "        [1.1622, 1.6932, 1.2474, 1.8035, 1.6811, 1.3239, 1.2377],\n",
            "        [0.8665, 1.3127, 1.0506, 1.4250, 1.2885, 1.1181, 1.0322],\n",
            "        [2.4767, 3.2944, 1.9702, 3.3834, 3.3677, 1.9914, 2.0470],\n",
            "        [0.9837, 1.4642, 1.1307, 1.5773, 1.4453, 1.2037, 1.1162]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "245\n",
            "tensor([[2.2566, 3.0613, 1.8857, 3.1610, 3.1233, 1.8922, 1.9270],\n",
            "        [3.2237, 3.9886, 2.2270, 4.0358, 4.0503, 2.4418, 2.4726],\n",
            "        [2.3380, 3.1361, 1.9087, 3.2329, 3.1988, 1.9438, 1.9710],\n",
            "        [3.0421, 3.8114, 2.1531, 3.8663, 3.8815, 2.3064, 2.3607],\n",
            "        [3.1618, 3.9356, 2.2085, 3.9886, 4.0002, 2.4079, 2.4403]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "246\n",
            "tensor([[1.7842, 2.4800, 1.6272, 2.5883, 2.5038, 1.6856, 1.6434],\n",
            "        [1.8079, 2.5135, 1.6467, 2.6241, 2.5408, 1.6941, 1.6593],\n",
            "        [3.2612, 4.0299, 2.2458, 4.0778, 4.0866, 2.4740, 2.5004],\n",
            "        [0.7746, 1.1923, 0.9779, 1.3000, 1.1609, 1.0428, 0.9618],\n",
            "        [1.2704, 1.8385, 1.3261, 1.9519, 1.8324, 1.3967, 1.3141]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "247\n",
            "tensor([[1.0902, 1.6083, 1.2088, 1.7211, 1.5907, 1.2772, 1.1908],\n",
            "        [3.0978, 3.8730, 2.1897, 3.9308, 3.9373, 2.3812, 2.3982],\n",
            "        [1.7083, 2.3917, 1.5863, 2.5004, 2.4092, 1.6439, 1.5959],\n",
            "        [2.4551, 3.2824, 1.9672, 3.3731, 3.3506, 1.9755, 2.0336],\n",
            "        [3.2712, 4.0287, 2.2374, 4.0705, 4.0816, 2.4829, 2.5050]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "248\n",
            "tensor([[2.9888, 3.7848, 2.1481, 3.8466, 3.8452, 2.2758, 2.3336],\n",
            "        [1.8203, 2.5265, 1.6489, 2.6341, 2.5516, 1.7051, 1.6644],\n",
            "        [3.2411, 4.0096, 2.2313, 4.0555, 4.0610, 2.4598, 2.4869],\n",
            "        [3.2080, 3.9871, 2.2308, 4.0391, 4.0431, 2.4365, 2.4671],\n",
            "        [3.2847, 4.0513, 2.2481, 4.0899, 4.0974, 2.4929, 2.5134]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "249\n",
            "tensor([[1.2646, 1.8334, 1.3198, 1.9455, 1.8235, 1.3948, 1.3093],\n",
            "        [1.2721, 1.8400, 1.3190, 1.9511, 1.8314, 1.3937, 1.3119],\n",
            "        [2.7678, 3.5808, 2.0749, 3.6544, 3.6506, 2.1378, 2.2028],\n",
            "        [1.2238, 1.7813, 1.2927, 1.8939, 1.7702, 1.3647, 1.2810],\n",
            "        [0.7037, 1.1019, 0.9253, 1.2091, 1.0676, 0.9855, 0.9089]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "250\n",
            "tensor([[1.7388, 2.4257, 1.6023, 2.5352, 2.4454, 1.6631, 1.6133],\n",
            "        [1.9868, 2.7312, 1.7401, 2.8383, 2.7664, 1.7885, 1.7667],\n",
            "        [3.2889, 4.0549, 2.2446, 4.0973, 4.0987, 2.4986, 2.5198],\n",
            "        [3.2649, 4.0364, 2.2411, 4.0802, 4.0807, 2.4746, 2.5028],\n",
            "        [3.2377, 4.0148, 2.2399, 4.0656, 4.0664, 2.4539, 2.4859]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "251\n",
            "tensor([[3.2701, 4.0422, 2.2379, 4.0799, 4.0768, 2.4870, 2.5080],\n",
            "        [1.0256, 1.5290, 1.1668, 1.6422, 1.5071, 1.2364, 1.1464],\n",
            "        [2.9435, 3.7483, 2.1450, 3.8176, 3.8116, 2.2600, 2.3112],\n",
            "        [1.7036, 2.3955, 1.5954, 2.5069, 2.4111, 1.6447, 1.5964],\n",
            "        [3.2931, 4.0656, 2.2558, 4.1071, 4.1078, 2.5070, 2.5230]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "252\n",
            "tensor([[3.2316, 4.0160, 2.2430, 4.0667, 4.0648, 2.4509, 2.4848],\n",
            "        [3.3072, 4.0821, 2.2602, 4.1209, 4.1191, 2.5130, 2.5328],\n",
            "        [0.9736, 1.4630, 1.1306, 1.5765, 1.4381, 1.2001, 1.1101],\n",
            "        [3.2922, 4.0713, 2.2622, 4.1166, 4.1156, 2.5098, 2.5259],\n",
            "        [3.0084, 3.8090, 2.1614, 3.8722, 3.8655, 2.2937, 2.3471]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "253\n",
            "tensor([[1.1112, 1.6436, 1.2246, 1.7578, 1.6256, 1.2935, 1.2073],\n",
            "        [2.7561, 3.5747, 2.0823, 3.6529, 3.6423, 2.1582, 2.2035],\n",
            "        [3.1173, 3.9135, 2.2046, 3.9709, 3.9672, 2.3727, 2.4142],\n",
            "        [1.0850, 1.6091, 1.2065, 1.7214, 1.5873, 1.2763, 1.1885],\n",
            "        [3.2486, 4.0325, 2.2502, 4.0824, 4.0815, 2.4723, 2.4990]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "254\n",
            "tensor([[2.1446, 2.9382, 1.8360, 3.0449, 2.9843, 1.8638, 1.8676],\n",
            "        [2.1676, 2.9527, 1.8389, 3.0561, 2.9968, 1.8815, 1.8774],\n",
            "        [0.8561, 1.3064, 1.0413, 1.4143, 1.2736, 1.1102, 1.0232],\n",
            "        [1.9646, 2.7259, 1.7469, 2.8362, 2.7619, 1.7751, 1.7606],\n",
            "        [2.1564, 2.9513, 1.8444, 3.0578, 2.9996, 1.8690, 1.8741]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "255\n",
            "tensor([[1.1792, 1.7373, 1.2761, 1.8515, 1.7229, 1.3456, 1.2579],\n",
            "        [3.2885, 4.0653, 2.2546, 4.1036, 4.1039, 2.5118, 2.5279],\n",
            "        [2.1572, 2.9437, 1.8346, 3.0459, 2.9869, 1.8747, 1.8722],\n",
            "        [2.7323, 3.5619, 2.0806, 3.6424, 3.6298, 2.1317, 2.1924],\n",
            "        [2.1133, 2.8646, 1.7865, 2.9616, 2.8969, 1.8749, 1.8397]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "256\n",
            "tensor([[1.3395, 1.9470, 1.3854, 2.0594, 1.9404, 1.4474, 1.3656],\n",
            "        [1.6184, 2.3011, 1.5553, 2.4129, 2.3118, 1.6094, 1.5472],\n",
            "        [1.0062, 1.5119, 1.1582, 1.6222, 1.4869, 1.2287, 1.1352],\n",
            "        [3.2692, 4.0534, 2.2508, 4.0912, 4.0891, 2.4964, 2.5145],\n",
            "        [3.2807, 4.0668, 2.2677, 4.1123, 4.1143, 2.5079, 2.5219]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "257\n",
            "tensor([[1.3591, 1.9758, 1.4012, 2.0871, 1.9692, 1.4605, 1.3805],\n",
            "        [2.9070, 3.7269, 2.1423, 3.7939, 3.7900, 2.2448, 2.2941],\n",
            "        [2.5934, 3.4351, 2.0363, 3.5189, 3.5034, 2.0679, 2.1174],\n",
            "        [2.0608, 2.8590, 1.8155, 2.9632, 2.9016, 1.8257, 1.8222],\n",
            "        [0.7842, 1.2200, 0.9956, 1.3253, 1.1842, 1.0573, 0.9725]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "258\n",
            "tensor([[3.2598, 4.0533, 2.2633, 4.0940, 4.0984, 2.4949, 2.5101],\n",
            "        [3.2688, 4.0589, 2.2560, 4.0894, 4.0935, 2.5060, 2.5169],\n",
            "        [0.8679, 1.3350, 1.0638, 1.4451, 1.3052, 1.1271, 1.0379],\n",
            "        [3.1934, 3.9953, 2.2513, 4.0445, 4.0480, 2.4455, 2.4676],\n",
            "        [2.0732, 2.8571, 1.8022, 2.9555, 2.8945, 1.8313, 1.8218]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "259\n",
            "tensor([[3.1967, 3.9968, 2.2464, 4.0420, 4.0525, 2.4520, 2.4660],\n",
            "        [1.8408, 2.5892, 1.6907, 2.6923, 2.6127, 1.7263, 1.6872],\n",
            "        [1.8351, 2.5835, 1.6915, 2.6887, 2.6098, 1.7214, 1.6835],\n",
            "        [1.8692, 2.6242, 1.7079, 2.7285, 2.6507, 1.7408, 1.7054],\n",
            "        [2.4424, 3.2759, 1.9807, 3.3641, 3.3365, 2.0188, 2.0365]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "260\n",
            "tensor([[3.1042, 3.9174, 2.2193, 3.9671, 3.9695, 2.3774, 2.4116],\n",
            "        [2.6574, 3.5100, 2.0695, 3.5826, 3.5753, 2.1023, 2.1529],\n",
            "        [2.8252, 3.6598, 2.1286, 3.7271, 3.7279, 2.2145, 2.2464],\n",
            "        [1.7720, 2.5044, 1.6511, 2.6061, 2.5239, 1.6934, 1.6431],\n",
            "        [2.6520, 3.5062, 2.0691, 3.5797, 3.5729, 2.1047, 2.1505]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "261\n",
            "tensor([[1.9130, 2.6730, 1.7226, 2.7683, 2.7025, 1.7571, 1.7230],\n",
            "        [3.2407, 4.0459, 2.2751, 4.0849, 4.0939, 2.4836, 2.4962],\n",
            "        [2.1578, 2.9719, 1.8585, 3.0630, 3.0172, 1.8766, 1.8721],\n",
            "        [1.8293, 2.5741, 1.6838, 2.6728, 2.5956, 1.7205, 1.6768],\n",
            "        [3.0839, 3.8980, 2.2217, 3.9502, 3.9635, 2.3743, 2.3979]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "262\n",
            "tensor([[1.2089, 1.7917, 1.3091, 1.8947, 1.7752, 1.3658, 1.2755],\n",
            "        [0.7237, 1.1482, 0.9580, 1.2488, 1.1098, 1.0114, 0.9272],\n",
            "        [3.1784, 3.9943, 2.2545, 4.0362, 4.0446, 2.4342, 2.4585],\n",
            "        [1.0082, 1.5240, 1.1644, 1.6265, 1.4980, 1.2277, 1.1342],\n",
            "        [1.0173, 1.5419, 1.1816, 1.6471, 1.5171, 1.2390, 1.1446]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "263\n",
            "tensor([[3.0461, 3.8711, 2.2083, 3.9153, 3.9282, 2.3330, 2.3701],\n",
            "        [2.3280, 3.1912, 1.9564, 3.2730, 3.2507, 1.9329, 1.9677],\n",
            "        [0.7656, 1.2061, 0.9908, 1.3066, 1.1692, 1.0445, 0.9580],\n",
            "        [0.8285, 1.2942, 1.0504, 1.4001, 1.2626, 1.1003, 1.0093],\n",
            "        [3.2018, 4.0104, 2.2550, 4.0423, 4.0573, 2.4503, 2.4652]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "264\n",
            "tensor([[1.2427, 1.8414, 1.3397, 1.9453, 1.8288, 1.3876, 1.2982],\n",
            "        [2.1578, 2.9846, 1.8681, 3.0704, 3.0301, 1.8620, 1.8668],\n",
            "        [1.7688, 2.5060, 1.6529, 2.6005, 2.5229, 1.6849, 1.6342],\n",
            "        [2.3662, 3.2225, 1.9634, 3.2993, 3.2783, 1.9551, 1.9836],\n",
            "        [3.1026, 3.9236, 2.2302, 3.9657, 3.9810, 2.3735, 2.4012]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "265\n",
            "tensor([[2.4305, 3.3090, 2.0000, 3.3766, 3.3711, 1.9583, 2.0146],\n",
            "        [2.3648, 3.2160, 1.9613, 3.2910, 3.2702, 1.9600, 1.9804],\n",
            "        [3.2648, 4.0725, 2.2772, 4.0963, 4.1113, 2.4968, 2.5035],\n",
            "        [0.7681, 1.2098, 0.9924, 1.3069, 1.1727, 1.0438, 0.9566],\n",
            "        [3.1416, 3.9581, 2.2390, 3.9908, 4.0111, 2.3955, 2.4208]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "266\n",
            "tensor([[2.3173, 3.1804, 1.9465, 3.2547, 3.2344, 1.9235, 1.9525],\n",
            "        [0.8026, 1.2588, 1.0238, 1.3570, 1.2223, 1.0748, 0.9836],\n",
            "        [2.7470, 3.5998, 2.1020, 3.6548, 3.6602, 2.1308, 2.1859],\n",
            "        [1.0131, 1.5439, 1.1873, 1.6472, 1.5192, 1.2330, 1.1384],\n",
            "        [0.7844, 1.2325, 1.0066, 1.3298, 1.1951, 1.0572, 0.9683]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "267\n",
            "tensor([[0.6774, 1.0891, 0.9198, 1.1828, 1.0479, 0.9665, 0.8860],\n",
            "        [1.4633, 2.1306, 1.4795, 2.2262, 2.1285, 1.5144, 1.4380],\n",
            "        [2.5083, 3.3753, 2.0205, 3.4393, 3.4366, 2.0124, 2.0540],\n",
            "        [3.0414, 3.8692, 2.1992, 3.9078, 3.9186, 2.3126, 2.3555],\n",
            "        [1.0846, 1.6358, 1.2301, 1.7355, 1.6127, 1.2786, 1.1854]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "268\n",
            "tensor([[2.5132, 3.3912, 2.0233, 3.4532, 3.4539, 1.9961, 2.0555],\n",
            "        [0.7697, 1.2173, 1.0012, 1.3155, 1.1799, 1.0480, 0.9589],\n",
            "        [2.3958, 3.2735, 1.9800, 3.3422, 3.3318, 1.9481, 1.9927],\n",
            "        [0.9809, 1.5017, 1.1596, 1.6023, 1.4734, 1.2082, 1.1136],\n",
            "        [2.4483, 3.3234, 1.9991, 3.3906, 3.3839, 1.9737, 2.0198]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "269\n",
            "tensor([[1.8591, 2.6296, 1.7031, 2.7170, 2.6532, 1.7164, 1.6810],\n",
            "        [1.8150, 2.5691, 1.6746, 2.6567, 2.5879, 1.6974, 1.6541],\n",
            "        [1.2989, 1.9196, 1.3732, 2.0169, 1.9076, 1.4154, 1.3291],\n",
            "        [2.9410, 3.7844, 2.1621, 3.8267, 3.8419, 2.2557, 2.2950],\n",
            "        [3.2277, 4.0421, 2.2546, 4.0622, 4.0835, 2.4557, 2.4681]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "270\n",
            "tensor([[2.8086, 3.6618, 2.1168, 3.7116, 3.7233, 2.1695, 2.2171],\n",
            "        [3.2550, 4.0658, 2.2587, 4.0828, 4.1027, 2.4784, 2.4875],\n",
            "        [2.7518, 3.6064, 2.0971, 3.6587, 3.6693, 2.1485, 2.1867],\n",
            "        [3.2565, 4.0730, 2.2675, 4.0949, 4.1160, 2.4733, 2.4865],\n",
            "        [3.2652, 4.0793, 2.2651, 4.0964, 4.1169, 2.4822, 2.4907]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "271\n",
            "tensor([[2.0262, 2.8438, 1.7981, 2.9268, 2.8788, 1.7927, 1.7844],\n",
            "        [3.1612, 3.9877, 2.2296, 4.0136, 4.0349, 2.4055, 2.4284],\n",
            "        [0.9853, 1.5089, 1.1540, 1.6055, 1.4794, 1.2098, 1.1145],\n",
            "        [1.7388, 2.4861, 1.6361, 2.5761, 2.5025, 1.6563, 1.6104],\n",
            "        [1.8526, 2.6184, 1.6901, 2.7028, 2.6379, 1.7184, 1.6772]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "272\n",
            "tensor([[1.7506, 2.5052, 1.6429, 2.5966, 2.5227, 1.6665, 1.6221],\n",
            "        [3.2250, 4.0479, 2.2511, 4.0749, 4.0962, 2.4546, 2.4736],\n",
            "        [2.8759, 3.7151, 2.1296, 3.7638, 3.7781, 2.2321, 2.2619],\n",
            "        [1.0214, 1.5579, 1.1770, 1.6535, 1.5288, 1.2346, 1.1414],\n",
            "        [1.9092, 2.7025, 1.7314, 2.7872, 2.7279, 1.7434, 1.7184]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "273\n",
            "tensor([[1.8033, 2.5640, 1.6527, 2.6466, 2.5794, 1.6913, 1.6510],\n",
            "        [3.2335, 4.0544, 2.2447, 4.0766, 4.0981, 2.4594, 2.4803],\n",
            "        [2.0454, 2.8735, 1.8026, 2.9553, 2.9097, 1.8072, 1.8025],\n",
            "        [3.1920, 4.0202, 2.2342, 4.0481, 4.0698, 2.4326, 2.4545],\n",
            "        [3.2076, 4.0322, 2.2332, 4.0528, 4.0695, 2.4306, 2.4647]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "274\n",
            "tensor([[1.2094, 1.8124, 1.3083, 1.9093, 1.7954, 1.3630, 1.2758],\n",
            "        [1.3050, 1.9323, 1.3609, 2.0255, 1.9179, 1.4230, 1.3371],\n",
            "        [0.9710, 1.4917, 1.1353, 1.5873, 1.4602, 1.2001, 1.1071],\n",
            "        [2.8242, 3.6897, 2.1083, 3.7403, 3.7485, 2.1897, 2.2399],\n",
            "        [1.9501, 2.7446, 1.7344, 2.8268, 2.7690, 1.7718, 1.7442]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "275\n",
            "tensor([[1.1653, 1.7558, 1.2732, 1.8491, 1.7322, 1.3314, 1.2442],\n",
            "        [2.1732, 2.9729, 1.8101, 3.0436, 3.0020, 1.8946, 1.8675],\n",
            "        [3.2610, 4.0820, 2.2444, 4.1009, 4.1182, 2.4893, 2.5053],\n",
            "        [0.9220, 1.4274, 1.0964, 1.5214, 1.3924, 1.1590, 1.0710],\n",
            "        [1.3327, 1.9771, 1.3889, 2.0723, 1.9663, 1.4412, 1.3595]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "276\n",
            "tensor([[2.6667, 3.5461, 2.0488, 3.5991, 3.6032, 2.0915, 2.1488],\n",
            "        [1.7882, 2.5583, 1.6505, 2.6462, 2.5759, 1.6868, 1.6486],\n",
            "        [2.2286, 3.0977, 1.8813, 3.1716, 3.1433, 1.8816, 1.9089],\n",
            "        [1.5350, 2.2330, 1.5005, 2.3226, 2.2314, 1.5563, 1.4881],\n",
            "        [3.2321, 4.0647, 2.2382, 4.0859, 4.1053, 2.4579, 2.4854]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "277\n",
            "tensor([[3.1800, 4.0146, 2.2153, 4.0400, 4.0592, 2.4242, 2.4501],\n",
            "        [1.1426, 1.7082, 1.2222, 1.7931, 1.6819, 1.3014, 1.2130],\n",
            "        [3.1812, 4.0100, 2.2060, 4.0301, 4.0444, 2.4212, 2.4513],\n",
            "        [0.8997, 1.3993, 1.0821, 1.4938, 1.3636, 1.1467, 1.0565],\n",
            "        [1.4294, 2.1071, 1.4491, 2.2011, 2.1011, 1.4950, 1.4236]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "278\n",
            "tensor([[2.2994, 3.1597, 1.8941, 3.2312, 3.2030, 1.9274, 1.9473],\n",
            "        [0.8529, 1.3395, 1.0516, 1.4354, 1.3026, 1.1133, 1.0235],\n",
            "        [2.9253, 3.7848, 2.1299, 3.8283, 3.8370, 2.2474, 2.2982],\n",
            "        [3.0044, 3.8532, 2.1524, 3.8853, 3.9037, 2.2878, 2.3374],\n",
            "        [1.2615, 1.8810, 1.3281, 1.9741, 1.8634, 1.3907, 1.3075]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "279\n",
            "tensor([[1.0606, 1.6092, 1.1814, 1.7009, 1.5803, 1.2548, 1.1640],\n",
            "        [0.9122, 1.4160, 1.0855, 1.5093, 1.3795, 1.1534, 1.0629],\n",
            "        [0.7632, 1.2166, 0.9788, 1.3093, 1.1750, 1.0381, 0.9547],\n",
            "        [3.1716, 4.0088, 2.2109, 4.0361, 4.0549, 2.4167, 2.4449],\n",
            "        [2.4608, 3.3502, 1.9690, 3.4150, 3.4057, 1.9775, 2.0333]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "280\n",
            "tensor([[0.8501, 1.3352, 1.0451, 1.4305, 1.2973, 1.1076, 1.0193],\n",
            "        [2.5280, 3.4136, 1.9883, 3.4698, 3.4676, 2.0133, 2.0672],\n",
            "        [1.7332, 2.4684, 1.5782, 2.5448, 2.4661, 1.6506, 1.6009],\n",
            "        [2.3146, 3.2186, 1.9199, 3.2825, 3.2696, 1.8911, 1.9513],\n",
            "        [2.5133, 3.4026, 1.9843, 3.4611, 3.4561, 2.0036, 2.0605]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "281\n",
            "tensor([[3.2545, 4.0764, 2.2076, 4.0841, 4.0978, 2.4734, 2.4959],\n",
            "        [2.1359, 2.9919, 1.8229, 3.0659, 3.0248, 1.8322, 1.8512],\n",
            "        [2.4511, 3.3539, 1.9641, 3.4108, 3.4043, 1.9557, 2.0244],\n",
            "        [2.3643, 3.2540, 1.9243, 3.3180, 3.3009, 1.9278, 1.9790],\n",
            "        [1.8434, 2.6084, 1.6437, 2.6847, 2.6159, 1.7079, 1.6684]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "282\n",
            "tensor([[0.9494, 1.4738, 1.1189, 1.5684, 1.4373, 1.1791, 1.0929],\n",
            "        [2.6069, 3.4981, 2.0074, 3.5477, 3.5479, 2.0453, 2.1102],\n",
            "        [3.0928, 3.9388, 2.1643, 3.9652, 3.9767, 2.3411, 2.3916],\n",
            "        [3.1996, 4.0275, 2.1872, 4.0421, 4.0497, 2.4240, 2.4619],\n",
            "        [3.1848, 4.0253, 2.2024, 4.0478, 4.0619, 2.4134, 2.4509]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "283\n",
            "tensor([[3.2494, 4.0847, 2.2103, 4.0965, 4.1079, 2.4645, 2.4960],\n",
            "        [3.0549, 3.9065, 2.1490, 3.9335, 3.9431, 2.3121, 2.3715],\n",
            "        [2.2779, 3.1739, 1.8892, 3.2369, 3.2117, 1.8749, 1.9322],\n",
            "        [3.2354, 4.0778, 2.2167, 4.0894, 4.1028, 2.4499, 2.4852],\n",
            "        [2.6825, 3.5730, 2.0335, 3.6162, 3.6160, 2.0752, 2.1534]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "284\n",
            "tensor([[3.1365, 3.9893, 2.1792, 4.0084, 4.0191, 2.3656, 2.4231],\n",
            "        [1.0690, 1.6313, 1.1899, 1.7195, 1.5951, 1.2514, 1.1727],\n",
            "        [2.2067, 3.0775, 1.8438, 3.1416, 3.1044, 1.8508, 1.8915],\n",
            "        [0.8347, 1.3251, 1.0374, 1.4176, 1.2815, 1.0910, 1.0114],\n",
            "        [1.1582, 1.7535, 1.2516, 1.8403, 1.7224, 1.3117, 1.2349]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "285\n",
            "tensor([[1.1534, 1.7603, 1.2670, 1.8540, 1.7312, 1.3120, 1.2411],\n",
            "        [0.9336, 1.4570, 1.1021, 1.5468, 1.4141, 1.1591, 1.0815],\n",
            "        [2.0694, 2.9354, 1.7956, 3.0054, 2.9570, 1.7821, 1.8177],\n",
            "        [1.2799, 1.9217, 1.3334, 2.0059, 1.8937, 1.3887, 1.3197],\n",
            "        [3.0364, 3.9020, 2.1504, 3.9292, 3.9387, 2.2984, 2.3657]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "286\n",
            "tensor([[1.9332, 2.7678, 1.7216, 2.8402, 2.7780, 1.7206, 1.7380],\n",
            "        [2.7762, 3.6662, 2.0601, 3.7008, 3.7023, 2.1187, 2.2069],\n",
            "        [1.2520, 1.8858, 1.3155, 1.9713, 1.8556, 1.3642, 1.3022],\n",
            "        [2.6810, 3.5735, 2.0282, 3.6127, 3.6138, 2.0746, 2.1557],\n",
            "        [1.1625, 1.7698, 1.2631, 1.8574, 1.7369, 1.3101, 1.2429]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "287\n",
            "tensor([[2.2471, 3.1462, 1.8707, 3.2059, 3.1721, 1.8488, 1.9204],\n",
            "        [3.2245, 4.0784, 2.2039, 4.0850, 4.0907, 2.4162, 2.4832],\n",
            "        [0.9789, 1.5265, 1.1405, 1.6169, 1.4851, 1.1888, 1.1176],\n",
            "        [2.9230, 3.8045, 2.1093, 3.8356, 3.8413, 2.2123, 2.2982],\n",
            "        [2.2634, 3.1560, 1.8715, 3.2160, 3.1811, 1.8673, 1.9293]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "288\n",
            "tensor([[2.1732, 3.0588, 1.8312, 3.1213, 3.0784, 1.8178, 1.8789],\n",
            "        [1.7768, 2.5735, 1.6289, 2.6477, 2.5703, 1.6441, 1.6438],\n",
            "        [3.1004, 3.9705, 2.1656, 3.9885, 3.9914, 2.3219, 2.4100],\n",
            "        [2.8942, 3.7865, 2.0979, 3.8150, 3.8162, 2.1842, 2.2836],\n",
            "        [1.2317, 1.8683, 1.3094, 1.9544, 1.8353, 1.3525, 1.2937]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "289\n",
            "tensor([[0.7886, 1.2683, 0.9957, 1.3553, 1.2167, 1.0445, 0.9774],\n",
            "        [3.1567, 4.0235, 2.1818, 4.0352, 4.0390, 2.3509, 2.4431],\n",
            "        [1.4072, 2.1000, 1.4145, 2.1821, 2.0740, 1.4525, 1.4109],\n",
            "        [2.3794, 3.3020, 1.9212, 3.3526, 3.3273, 1.8949, 1.9964],\n",
            "        [1.5543, 2.3016, 1.5157, 2.3823, 2.2856, 1.5325, 1.5093]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "290\n",
            "tensor([[3.2083, 4.0745, 2.1988, 4.0840, 4.0877, 2.3947, 2.4810],\n",
            "        [0.8006, 1.2868, 1.0047, 1.3735, 1.2349, 1.0533, 0.9877],\n",
            "        [2.4266, 3.3489, 1.9386, 3.4002, 3.3780, 1.9190, 2.0252],\n",
            "        [0.9943, 1.5547, 1.1512, 1.6453, 1.5118, 1.1941, 1.1324],\n",
            "        [2.0278, 2.9089, 1.7758, 2.9752, 2.9202, 1.7410, 1.8012]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "291\n",
            "tensor([[1.2727, 1.9262, 1.3275, 2.0084, 1.8904, 1.3666, 1.3224],\n",
            "        [2.2421, 3.1630, 1.8718, 3.2208, 3.1833, 1.8288, 1.9269],\n",
            "        [3.0740, 3.9055, 2.0805, 3.8926, 3.8908, 2.3023, 2.3877],\n",
            "        [0.8900, 1.4121, 1.0753, 1.5010, 1.3628, 1.1172, 1.0561],\n",
            "        [1.8407, 2.6632, 1.6675, 2.7359, 2.6587, 1.6662, 1.6898]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "292\n",
            "tensor([[3.1190, 4.0009, 2.1748, 4.0188, 4.0180, 2.3195, 2.4329],\n",
            "        [0.9683, 1.5217, 1.1301, 1.6088, 1.4728, 1.1694, 1.1143],\n",
            "        [2.4808, 3.4193, 1.9632, 3.4650, 3.4472, 1.9242, 2.0592],\n",
            "        [3.1069, 3.9803, 2.1526, 3.9891, 3.9831, 2.3060, 2.4219],\n",
            "        [3.2278, 4.0917, 2.2000, 4.0987, 4.0991, 2.3931, 2.4974]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "293\n",
            "tensor([[2.3539, 3.2956, 1.9224, 3.3484, 3.3205, 1.8579, 1.9917],\n",
            "        [2.9842, 3.8780, 2.1314, 3.9060, 3.9000, 2.2284, 2.3537],\n",
            "        [2.3525, 3.2859, 1.9178, 3.3408, 3.3107, 1.8669, 1.9934],\n",
            "        [3.1338, 4.0114, 2.1757, 4.0243, 4.0227, 2.3183, 2.4388],\n",
            "        [0.7794, 1.2618, 0.9954, 1.3508, 1.2089, 1.0319, 0.9772]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "294\n",
            "tensor([[3.2119, 4.0771, 2.1926, 4.0841, 4.0768, 2.3833, 2.4957],\n",
            "        [2.4246, 3.3578, 1.9460, 3.4124, 3.3827, 1.9042, 2.0368],\n",
            "        [1.8419, 2.6679, 1.6691, 2.7430, 2.6624, 1.6607, 1.6986],\n",
            "        [2.9047, 3.8016, 2.0994, 3.8282, 3.8190, 2.1552, 2.3027],\n",
            "        [2.8677, 3.7783, 2.0979, 3.8082, 3.8007, 2.1378, 2.2846]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "295\n",
            "tensor([[2.1270, 3.0217, 1.8182, 3.0896, 3.0323, 1.7742, 1.8699],\n",
            "        [1.5917, 2.3593, 1.5415, 2.4414, 2.3415, 1.5359, 1.5445],\n",
            "        [3.2292, 4.1052, 2.2156, 4.1162, 4.1098, 2.3973, 2.5141],\n",
            "        [2.2121, 3.1253, 1.8594, 3.1895, 3.1412, 1.8137, 1.9217],\n",
            "        [2.3540, 3.3060, 1.9319, 3.3618, 3.3336, 1.8510, 1.9998]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "296\n",
            "tensor([[0.8091, 1.3069, 1.0186, 1.3960, 1.2527, 1.0513, 1.0030],\n",
            "        [0.8066, 1.3067, 1.0253, 1.3999, 1.2551, 1.0532, 1.0045],\n",
            "        [3.1740, 4.0577, 2.2032, 4.0801, 4.0708, 2.3557, 2.4829],\n",
            "        [3.1649, 4.0274, 2.1678, 4.0343, 4.0229, 2.3410, 2.4701],\n",
            "        [2.6846, 3.6161, 2.0431, 3.6596, 3.6405, 2.0230, 2.1859]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "297\n",
            "tensor([[0.8687, 1.3898, 1.0678, 1.4828, 1.3397, 1.0977, 1.0507],\n",
            "        [3.1402, 4.0349, 2.1980, 4.0586, 4.0459, 2.3249, 2.4656],\n",
            "        [2.1383, 3.0532, 1.8397, 3.1244, 3.0704, 1.7767, 1.8863],\n",
            "        [2.3293, 3.2806, 1.9284, 3.3429, 3.3060, 1.8434, 1.9952],\n",
            "        [2.4895, 3.4411, 1.9843, 3.4907, 3.4706, 1.9104, 2.0780]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "298\n",
            "tensor([[1.9215, 2.7805, 1.7307, 2.8611, 2.7845, 1.6879, 1.7593],\n",
            "        [1.0334, 1.6207, 1.1977, 1.7179, 1.5786, 1.2141, 1.1765],\n",
            "        [1.1502, 1.7699, 1.2595, 1.8615, 1.7295, 1.2837, 1.2522],\n",
            "        [1.9479, 2.8260, 1.7569, 2.9071, 2.8324, 1.6966, 1.7793],\n",
            "        [2.1071, 3.0144, 1.8298, 3.0930, 3.0324, 1.7646, 1.8737]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "299\n",
            "tensor([[0.9046, 1.4483, 1.1125, 1.5492, 1.4044, 1.1287, 1.0874],\n",
            "        [0.8331, 1.3486, 1.0583, 1.4488, 1.3014, 1.0771, 1.0334],\n",
            "        [2.2360, 3.1784, 1.8979, 3.2518, 3.2061, 1.8023, 1.9501],\n",
            "        [3.2044, 4.0702, 2.2023, 4.0842, 4.0723, 2.3798, 2.5105],\n",
            "        [2.2820, 3.2092, 1.9060, 3.2819, 3.2349, 1.8391, 1.9767]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "300\n",
            "tensor([[1.2396, 1.8974, 1.3352, 1.9956, 1.8683, 1.3429, 1.3247],\n",
            "        [3.1755, 4.0488, 2.1993, 4.0701, 4.0606, 2.3516, 2.4972],\n",
            "        [3.1480, 4.0293, 2.2034, 4.0614, 4.0532, 2.3265, 2.4780],\n",
            "        [0.9060, 1.4474, 1.1108, 1.5484, 1.4045, 1.1271, 1.0873],\n",
            "        [1.3772, 2.0885, 1.4349, 2.1865, 2.0674, 1.4229, 1.4214]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "301\n",
            "tensor([[1.3937, 2.1120, 1.4473, 2.2095, 2.0925, 1.4288, 1.4344],\n",
            "        [1.4426, 2.1701, 1.4700, 2.2676, 2.1542, 1.4567, 1.4656],\n",
            "        [2.8981, 3.7697, 2.0940, 3.8056, 3.7933, 2.1569, 2.3150],\n",
            "        [3.1049, 3.9974, 2.2029, 4.0342, 4.0256, 2.2949, 2.4580],\n",
            "        [2.1281, 3.0215, 1.8364, 3.1031, 3.0431, 1.7841, 1.8926]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "302\n",
            "tensor([[3.0925, 3.9465, 2.1493, 3.9691, 3.9576, 2.2926, 2.4429],\n",
            "        [2.2629, 3.2074, 1.9253, 3.2870, 3.2481, 1.8150, 1.9751],\n",
            "        [0.7333, 1.2066, 0.9806, 1.3052, 1.1598, 0.9971, 0.9574],\n",
            "        [1.8090, 2.6404, 1.6864, 2.7344, 2.6496, 1.6324, 1.7029],\n",
            "        [0.9857, 1.5601, 1.1812, 1.6657, 1.5245, 1.1836, 1.1525]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "303\n",
            "tensor([[2.6327, 3.5612, 2.0531, 3.6328, 3.6091, 1.9993, 2.1850],\n",
            "        [2.4802, 3.4202, 2.0046, 3.4867, 3.4690, 1.9109, 2.0921],\n",
            "        [0.9314, 1.4811, 1.1391, 1.5867, 1.4450, 1.1473, 1.1120],\n",
            "        [3.1489, 4.0317, 2.2290, 4.0751, 4.0699, 2.3275, 2.4906],\n",
            "        [0.8121, 1.3186, 1.0535, 1.4255, 1.2788, 1.0619, 1.0239]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "304\n",
            "tensor([[1.4852, 2.2292, 1.5153, 2.3362, 2.2288, 1.4782, 1.5018],\n",
            "        [3.1819, 4.0484, 2.2246, 4.0861, 4.0814, 2.3635, 2.5140],\n",
            "        [0.9646, 1.5249, 1.1627, 1.6317, 1.4926, 1.1687, 1.1367],\n",
            "        [3.1386, 4.0143, 2.2257, 4.0619, 4.0546, 2.3219, 2.4871],\n",
            "        [3.1353, 4.0015, 2.2005, 4.0390, 4.0299, 2.3246, 2.4819]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "305\n",
            "tensor([[2.8224, 3.7287, 2.1195, 3.7911, 3.7809, 2.1114, 2.2936],\n",
            "        [0.7506, 1.2306, 1.0065, 1.3386, 1.1907, 1.0178, 0.9783],\n",
            "        [1.4540, 2.1813, 1.4917, 2.2886, 2.1775, 1.4613, 1.4795],\n",
            "        [3.1749, 4.0353, 2.2303, 4.0786, 4.0724, 2.3560, 2.5132],\n",
            "        [1.2893, 1.9592, 1.3820, 2.0673, 1.9476, 1.3714, 1.3672]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "306\n",
            "tensor([[1.3348, 2.0176, 1.4120, 2.1267, 2.0083, 1.3987, 1.4001],\n",
            "        [2.2192, 3.1436, 1.9128, 3.2407, 3.1945, 1.8007, 1.9590],\n",
            "        [2.7968, 3.7036, 2.1148, 3.7732, 3.7608, 2.0971, 2.2837],\n",
            "        [3.2067, 4.0691, 2.2451, 4.1178, 4.1111, 2.3819, 2.5372],\n",
            "        [1.1567, 1.7889, 1.3086, 1.9043, 1.7731, 1.2985, 1.2829]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "307\n",
            "tensor([[2.6519, 3.5780, 2.0783, 3.6604, 3.6381, 2.0147, 2.2064],\n",
            "        [0.9548, 1.5040, 1.1550, 1.6166, 1.4760, 1.1654, 1.1310],\n",
            "        [3.0362, 3.9214, 2.2030, 3.9885, 3.9765, 2.2578, 2.4347],\n",
            "        [1.1817, 1.8157, 1.3201, 1.9301, 1.8016, 1.3133, 1.2978],\n",
            "        [3.0233, 3.9054, 2.1961, 3.9720, 3.9611, 2.2502, 2.4234]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "308\n",
            "tensor([[2.4259, 3.3553, 2.0023, 3.4477, 3.4207, 1.9010, 2.0801],\n",
            "        [1.5850, 2.3536, 1.5854, 2.4675, 2.3707, 1.5278, 1.5720],\n",
            "        [1.4711, 2.2045, 1.5197, 2.3234, 2.2138, 1.4770, 1.5000],\n",
            "        [2.3841, 3.3227, 1.9917, 3.4170, 3.3892, 1.8721, 2.0558],\n",
            "        [1.0026, 1.5759, 1.2022, 1.6935, 1.5543, 1.2029, 1.1728]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "309\n",
            "tensor([[0.8844, 1.4093, 1.1098, 1.5230, 1.3812, 1.1192, 1.0819],\n",
            "        [0.8806, 1.4040, 1.1093, 1.5188, 1.3764, 1.1185, 1.0810],\n",
            "        [3.0404, 3.9044, 2.1928, 3.9687, 3.9581, 2.2589, 2.4338],\n",
            "        [0.8999, 1.4331, 1.1281, 1.5499, 1.4077, 1.1314, 1.0964],\n",
            "        [2.5563, 3.4814, 2.0523, 3.5698, 3.5508, 1.9652, 2.1520]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "310\n",
            "tensor([[3.1212, 3.9861, 2.2339, 4.0526, 4.0439, 2.3193, 2.4910],\n",
            "        [0.8774, 1.3992, 1.1058, 1.5148, 1.3726, 1.1169, 1.0789],\n",
            "        [1.4396, 2.1594, 1.4990, 2.2809, 2.1680, 1.4684, 1.4822],\n",
            "        [1.9072, 2.7553, 1.7707, 2.8724, 2.7980, 1.6912, 1.7828],\n",
            "        [2.9912, 3.8633, 2.1800, 3.9374, 3.9260, 2.2377, 2.4105]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "311\n",
            "tensor([[1.7980, 2.6202, 1.7141, 2.7400, 2.6569, 1.6442, 1.7166],\n",
            "        [0.8465, 1.3571, 1.0869, 1.4750, 1.3313, 1.0979, 1.0586],\n",
            "        [1.7610, 2.5718, 1.6911, 2.6929, 2.6082, 1.6284, 1.6929],\n",
            "        [0.9322, 1.4750, 1.1497, 1.5922, 1.4516, 1.1561, 1.1217],\n",
            "        [1.7251, 2.5118, 1.6566, 2.6309, 2.5395, 1.6182, 1.6670]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "312\n",
            "tensor([[3.1581, 4.0048, 2.2354, 4.0698, 4.0591, 2.3641, 2.5187],\n",
            "        [3.1071, 3.9672, 2.2369, 4.0401, 4.0358, 2.3256, 2.4881],\n",
            "        [0.9704, 1.5308, 1.1870, 1.6522, 1.5124, 1.1917, 1.1556],\n",
            "        [2.7775, 3.6581, 2.1121, 3.7359, 3.7342, 2.0942, 2.2763],\n",
            "        [2.7292, 3.6305, 2.1067, 3.7225, 3.7082, 2.0746, 2.2574]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "313\n",
            "tensor([[1.6705, 2.4529, 1.6422, 2.5792, 2.4848, 1.5925, 1.6419],\n",
            "        [2.3750, 3.2949, 1.9937, 3.4061, 3.3744, 1.8988, 2.0663],\n",
            "        [2.3113, 3.2449, 1.9783, 3.3579, 3.3252, 1.8568, 2.0335],\n",
            "        [1.6704, 2.4563, 1.6420, 2.5816, 2.4876, 1.5895, 1.6414],\n",
            "        [0.7409, 1.2110, 1.0062, 1.3270, 1.1807, 1.0208, 0.9795]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "314\n",
            "tensor([[2.2905, 3.2129, 1.9707, 3.3305, 3.2937, 1.8586, 2.0258],\n",
            "        [1.7703, 2.5766, 1.6984, 2.7024, 2.6179, 1.6441, 1.7079],\n",
            "        [0.8937, 1.4208, 1.1275, 1.5433, 1.4007, 1.1411, 1.1011],\n",
            "        [1.9013, 2.7443, 1.7765, 2.8686, 2.7951, 1.7057, 1.7919],\n",
            "        [1.3618, 2.0551, 1.4605, 2.1865, 2.0688, 1.4364, 1.4412]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "315\n",
            "tensor([[2.9156, 3.7874, 2.1748, 3.8774, 3.8643, 2.1903, 2.3813],\n",
            "        [2.6799, 3.5809, 2.1044, 3.6823, 3.6709, 2.0520, 2.2436],\n",
            "        [1.6814, 2.4693, 1.6569, 2.5988, 2.5071, 1.6040, 1.6550],\n",
            "        [2.3043, 3.2378, 1.9845, 3.3538, 3.3234, 1.8564, 2.0369],\n",
            "        [2.5869, 3.4986, 2.0784, 3.6080, 3.5918, 2.0205, 2.1967]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "316\n",
            "tensor([[2.0374, 2.9082, 1.8481, 3.0338, 2.9744, 1.7736, 1.8814],\n",
            "        [1.0250, 1.6026, 1.2320, 1.7294, 1.5961, 1.2392, 1.2043],\n",
            "        [2.2247, 3.1482, 1.9526, 3.2706, 3.2338, 1.8361, 1.9953],\n",
            "        [3.1372, 3.9927, 2.2605, 4.0770, 4.0723, 2.3565, 2.5217],\n",
            "        [2.1698, 3.0090, 1.8706, 3.1266, 3.0715, 1.8610, 1.9473]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "317\n",
            "tensor([[1.8310, 2.6063, 1.6927, 2.7255, 2.6475, 1.6924, 1.7370],\n",
            "        [1.7944, 2.6075, 1.7211, 2.7371, 2.6569, 1.6677, 1.7319],\n",
            "        [0.8251, 1.3305, 1.0863, 1.4557, 1.3119, 1.0988, 1.0562],\n",
            "        [1.7178, 2.5127, 1.6805, 2.6433, 2.5571, 1.6308, 1.6834],\n",
            "        [1.3603, 2.0505, 1.4620, 2.1814, 2.0679, 1.4438, 1.4451]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "318\n",
            "tensor([[0.9107, 1.4442, 1.1441, 1.5681, 1.4291, 1.1589, 1.1193],\n",
            "        [1.6697, 2.4563, 1.6566, 2.5881, 2.4975, 1.6057, 1.6542],\n",
            "        [1.3334, 2.0157, 1.4433, 2.1442, 2.0290, 1.4286, 1.4263],\n",
            "        [0.7718, 1.2537, 1.0360, 1.3735, 1.2298, 1.0543, 1.0114],\n",
            "        [2.9100, 3.7889, 2.1824, 3.8827, 3.8765, 2.2065, 2.3838]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "319\n",
            "tensor([[0.8008, 1.2951, 1.0602, 1.4149, 1.2722, 1.0769, 1.0352],\n",
            "        [3.0277, 3.8991, 2.2302, 3.9860, 3.9837, 2.2830, 2.4579],\n",
            "        [1.1021, 1.7096, 1.2905, 1.8366, 1.7070, 1.2913, 1.2646],\n",
            "        [3.1966, 4.0453, 2.2808, 4.1189, 4.1170, 2.4116, 2.5660],\n",
            "        [0.9935, 1.5563, 1.2029, 1.6788, 1.5439, 1.2160, 1.1808]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "320\n",
            "tensor([[2.1806, 3.0899, 1.9286, 3.2091, 3.1677, 1.8293, 1.9726],\n",
            "        [3.1186, 3.9838, 2.2619, 4.0617, 4.0616, 2.3481, 2.5155],\n",
            "        [1.0774, 1.6784, 1.2778, 1.8073, 1.6750, 1.2767, 1.2492],\n",
            "        [1.0570, 1.6455, 1.2525, 1.7698, 1.6382, 1.2623, 1.2297],\n",
            "        [1.4324, 2.0976, 1.4371, 2.2071, 2.1042, 1.4759, 1.4677]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "321\n",
            "tensor([[1.8677, 2.6936, 1.7534, 2.8158, 2.7415, 1.7041, 1.7770],\n",
            "        [1.9680, 2.8265, 1.8147, 2.9497, 2.8870, 1.7461, 1.8438],\n",
            "        [1.7402, 2.5332, 1.6768, 2.6536, 2.5734, 1.6360, 1.6921],\n",
            "        [1.0364, 1.6134, 1.2311, 1.7358, 1.6034, 1.2461, 1.2123],\n",
            "        [1.1746, 1.8076, 1.3410, 1.9364, 1.8104, 1.3392, 1.3191]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "322\n",
            "tensor([[2.4284, 3.3567, 2.0287, 3.4650, 3.4475, 1.9338, 2.1123],\n",
            "        [3.1748, 4.0254, 2.2630, 4.0943, 4.0951, 2.3951, 2.5517],\n",
            "        [0.8762, 1.4012, 1.1196, 1.5217, 1.3811, 1.1393, 1.0972],\n",
            "        [1.9464, 2.8009, 1.8002, 2.9239, 2.8583, 1.7382, 1.8308],\n",
            "        [1.7700, 2.5885, 1.7143, 2.7164, 2.6364, 1.6574, 1.7234]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "323\n",
            "tensor([[2.9702, 3.8485, 2.2062, 3.9346, 3.9355, 2.2509, 2.4243],\n",
            "        [1.9778, 2.8517, 1.8276, 2.9757, 2.9155, 1.7450, 1.8532],\n",
            "        [1.2709, 1.9422, 1.4113, 2.0713, 1.9517, 1.4028, 1.3910],\n",
            "        [1.3458, 2.0250, 1.4319, 2.1455, 2.0331, 1.4376, 1.4327],\n",
            "        [2.3883, 3.3199, 2.0119, 3.4306, 3.4096, 1.9139, 2.0931]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "324\n",
            "tensor([[2.4462, 3.3794, 2.0317, 3.4832, 3.4667, 1.9330, 2.1234],\n",
            "        [3.1558, 3.9957, 2.2494, 4.0703, 4.0708, 2.3843, 2.5399],\n",
            "        [0.9624, 1.5209, 1.1857, 1.6464, 1.5081, 1.2065, 1.1651],\n",
            "        [1.6417, 2.4239, 1.6347, 2.5504, 2.4582, 1.5997, 1.6404],\n",
            "        [1.1048, 1.7146, 1.2874, 1.8410, 1.7116, 1.2994, 1.2694]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "325\n",
            "tensor([[2.3843, 3.3055, 2.0032, 3.4140, 3.3923, 1.9253, 2.0897],\n",
            "        [1.6202, 2.3956, 1.6190, 2.5238, 2.4315, 1.5892, 1.6263],\n",
            "        [2.0179, 2.8993, 1.8451, 3.0228, 2.9639, 1.7722, 1.8809],\n",
            "        [3.1174, 3.9433, 2.1997, 4.0042, 3.9982, 2.3591, 2.5111],\n",
            "        [0.7966, 1.2912, 1.0574, 1.4118, 1.2683, 1.0845, 1.0372]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "326\n",
            "tensor([[0.6982, 1.1531, 0.9719, 1.2690, 1.1241, 1.0063, 0.9570],\n",
            "        [1.4516, 2.1793, 1.5185, 2.3077, 2.1998, 1.5101, 1.5180],\n",
            "        [2.4426, 3.3708, 2.0232, 3.4804, 3.4617, 1.9389, 2.1233],\n",
            "        [2.2629, 3.1812, 1.9548, 3.2986, 3.2622, 1.8758, 2.0272],\n",
            "        [3.1321, 3.9863, 2.2473, 4.0593, 4.0581, 2.3718, 2.5287]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "327\n",
            "tensor([[1.3546, 2.0527, 1.4599, 2.1841, 2.0698, 1.4598, 1.4538],\n",
            "        [0.8252, 1.3279, 1.0702, 1.4473, 1.3065, 1.1057, 1.0581],\n",
            "        [1.8609, 2.7088, 1.7660, 2.8384, 2.7650, 1.7108, 1.7898],\n",
            "        [0.7212, 1.1866, 0.9927, 1.3030, 1.1598, 1.0276, 0.9773],\n",
            "        [3.0258, 3.8937, 2.2170, 3.9801, 3.9761, 2.2982, 2.4650]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "328\n",
            "tensor([[1.0579, 1.6500, 1.2496, 1.7766, 1.6448, 1.2782, 1.2389],\n",
            "        [1.4491, 2.1696, 1.5095, 2.2963, 2.1894, 1.5159, 1.5151],\n",
            "        [2.3821, 3.3199, 2.0101, 3.4334, 3.4095, 1.9291, 2.1001],\n",
            "        [2.0860, 2.9732, 1.8715, 3.0983, 3.0438, 1.8199, 1.9276],\n",
            "        [0.8403, 1.3551, 1.0926, 1.4790, 1.3358, 1.1280, 1.0768]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "329\n",
            "tensor([[2.2459, 3.1646, 1.9516, 3.2852, 3.2485, 1.8813, 2.0229],\n",
            "        [1.7678, 2.5838, 1.7045, 2.7130, 2.6294, 1.6818, 1.7312],\n",
            "        [0.6622, 1.1087, 0.9532, 1.2285, 1.0811, 0.9888, 0.9361],\n",
            "        [1.8054, 2.6364, 1.7306, 2.7668, 2.6863, 1.6981, 1.7568],\n",
            "        [0.9488, 1.4979, 1.1634, 1.6215, 1.4828, 1.2054, 1.1560]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "330\n",
            "tensor([[3.0495, 3.8591, 2.1436, 3.9179, 3.9052, 2.3451, 2.4743],\n",
            "        [2.9596, 3.8373, 2.1914, 3.9260, 3.9166, 2.2539, 2.4262],\n",
            "        [1.1600, 1.7926, 1.3274, 1.9235, 1.7974, 1.3492, 1.3173],\n",
            "        [2.3094, 3.2332, 1.9759, 3.3544, 3.3211, 1.9138, 2.0603],\n",
            "        [2.7317, 3.6431, 2.1271, 3.7443, 3.7343, 2.1204, 2.2971]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "331\n",
            "tensor([[1.6633, 2.4539, 1.6422, 2.5848, 2.4918, 1.6363, 1.6653],\n",
            "        [3.1416, 3.9949, 2.2467, 4.0666, 4.0640, 2.4020, 2.5388],\n",
            "        [1.6459, 2.4304, 1.6319, 2.5599, 2.4679, 1.6291, 1.6516],\n",
            "        [3.0750, 3.9420, 2.2333, 4.0254, 4.0201, 2.3407, 2.4981],\n",
            "        [0.7273, 1.1989, 1.0011, 1.3189, 1.1738, 1.0442, 0.9873]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "332\n",
            "tensor([[1.4265, 2.1455, 1.5001, 2.2777, 2.1678, 1.5153, 1.5053],\n",
            "        [3.1830, 4.0367, 2.2635, 4.1126, 4.1098, 2.4244, 2.5685],\n",
            "        [2.0761, 2.9925, 1.8900, 3.1200, 3.0698, 1.8135, 1.9292],\n",
            "        [3.1971, 4.0543, 2.2736, 4.1290, 4.1273, 2.4347, 2.5758],\n",
            "        [2.7903, 3.6812, 2.1446, 3.7823, 3.7794, 2.1893, 2.3319]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "333\n",
            "tensor([[2.4478, 3.3843, 2.0337, 3.4936, 3.4781, 1.9765, 2.1349],\n",
            "        [1.3271, 2.0118, 1.4323, 2.1405, 2.0248, 1.4619, 1.4347],\n",
            "        [2.3204, 3.2666, 1.9921, 3.3832, 3.3588, 1.9119, 2.0671],\n",
            "        [1.8395, 2.6805, 1.7477, 2.8099, 2.7358, 1.7173, 1.7772],\n",
            "        [0.8265, 1.3403, 1.0874, 1.4669, 1.3225, 1.1282, 1.0696]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "334\n",
            "tensor([[2.3142, 3.2632, 1.9905, 3.3800, 3.3565, 1.9079, 2.0630],\n",
            "        [1.0716, 1.6750, 1.2654, 1.8048, 1.6721, 1.3024, 1.2532],\n",
            "        [0.9261, 1.4743, 1.1550, 1.5986, 1.4604, 1.1993, 1.1418],\n",
            "        [0.9969, 1.5687, 1.2070, 1.6962, 1.5601, 1.2523, 1.1962],\n",
            "        [1.3195, 2.0042, 1.4314, 2.1340, 2.0185, 1.4570, 1.4298]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "335\n",
            "tensor([[2.3058, 3.2622, 1.9893, 3.3759, 3.3539, 1.8966, 2.0571],\n",
            "        [3.0195, 3.9021, 2.2212, 3.9912, 3.9890, 2.3025, 2.4664],\n",
            "        [0.7889, 1.2852, 1.0473, 1.4062, 1.2624, 1.0953, 1.0343],\n",
            "        [3.1970, 4.0466, 2.2637, 4.1207, 4.1174, 2.4362, 2.5755],\n",
            "        [2.8545, 3.7520, 2.1646, 3.8484, 3.8464, 2.2058, 2.3650]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "336\n",
            "tensor([[1.5338, 2.2964, 1.5734, 2.4273, 2.3276, 1.5805, 1.5789],\n",
            "        [3.1341, 3.9594, 2.1924, 4.0142, 4.0094, 2.3999, 2.5253],\n",
            "        [0.8958, 1.4312, 1.1288, 1.5545, 1.4139, 1.1784, 1.1174],\n",
            "        [2.8558, 3.7546, 2.1626, 3.8473, 3.8464, 2.2115, 2.3663],\n",
            "        [2.0618, 2.9663, 1.8699, 3.0903, 3.0385, 1.8126, 1.9141]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "337\n",
            "tensor([[0.7928, 1.2891, 1.0472, 1.4085, 1.2652, 1.0971, 1.0360],\n",
            "        [2.4230, 3.3625, 2.0179, 3.4632, 3.4517, 1.9481, 2.1119],\n",
            "        [1.5809, 2.3578, 1.6021, 2.4879, 2.3912, 1.6021, 1.6094],\n",
            "        [0.8592, 1.3862, 1.1073, 1.5114, 1.3678, 1.1546, 1.0924],\n",
            "        [3.1170, 3.9772, 2.2280, 4.0471, 4.0443, 2.3734, 2.5217]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "338\n",
            "tensor([[1.0204, 1.6101, 1.2301, 1.7381, 1.6012, 1.2731, 1.2162],\n",
            "        [3.0789, 3.9450, 2.2181, 4.0212, 4.0227, 2.3432, 2.4921],\n",
            "        [2.0464, 2.9421, 1.8520, 3.0620, 3.0104, 1.8083, 1.9009],\n",
            "        [1.4705, 2.2112, 1.5250, 2.3379, 2.2331, 1.5439, 1.5321],\n",
            "        [1.2976, 1.9821, 1.4115, 2.1074, 1.9909, 1.4430, 1.4124]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "339\n",
            "tensor([[1.2349, 1.9041, 1.3837, 2.0356, 1.9113, 1.4090, 1.3730],\n",
            "        [1.4638, 2.2104, 1.5308, 2.3417, 2.2359, 1.5371, 1.5307],\n",
            "        [1.6588, 2.4609, 1.6447, 2.5873, 2.4984, 1.6397, 1.6590],\n",
            "        [2.3419, 3.2900, 1.9913, 3.3987, 3.3776, 1.9257, 2.0731],\n",
            "        [2.1357, 3.0448, 1.8919, 3.1629, 3.1174, 1.8500, 1.9525]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "340\n",
            "tensor([[3.0551, 3.9344, 2.2265, 4.0133, 4.0176, 2.3362, 2.4800],\n",
            "        [3.1735, 4.0249, 2.2450, 4.0886, 4.0889, 2.4095, 2.5517],\n",
            "        [1.5589, 2.3251, 1.5786, 2.4486, 2.3536, 1.5900, 1.5883],\n",
            "        [3.1751, 4.0358, 2.2592, 4.1010, 4.1069, 2.4156, 2.5527],\n",
            "        [0.8255, 1.3416, 1.0839, 1.4646, 1.3214, 1.1281, 1.0657]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "341\n",
            "tensor([[0.8444, 1.3654, 1.0951, 1.4849, 1.3429, 1.1407, 1.0785],\n",
            "        [0.6833, 1.1418, 0.9695, 1.2586, 1.1125, 1.0139, 0.9514],\n",
            "        [0.7788, 1.2744, 1.0436, 1.3937, 1.2498, 1.0888, 1.0268],\n",
            "        [0.7675, 1.2575, 1.0340, 1.3751, 1.2316, 1.0794, 1.0171],\n",
            "        [3.1888, 4.0381, 2.2518, 4.0962, 4.1029, 2.4241, 2.5576]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "342\n",
            "tensor([[1.5086, 2.2630, 1.5570, 2.3863, 2.2879, 1.5653, 1.5562],\n",
            "        [3.1824, 4.0341, 2.2484, 4.0920, 4.0944, 2.4231, 2.5561],\n",
            "        [1.4642, 2.2084, 1.5331, 2.3332, 2.2315, 1.5353, 1.5270],\n",
            "        [0.7011, 1.1656, 0.9826, 1.2813, 1.1373, 1.0254, 0.9638],\n",
            "        [1.9003, 2.7437, 1.7645, 2.8578, 2.7969, 1.7427, 1.7992]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "343\n",
            "tensor([[3.0997, 3.9672, 2.2354, 4.0364, 4.0412, 2.3587, 2.5036],\n",
            "        [1.9547, 2.8376, 1.8166, 2.9557, 2.8988, 1.7685, 1.8445],\n",
            "        [3.1610, 4.0089, 2.2321, 4.0608, 4.0656, 2.3982, 2.5385],\n",
            "        [2.7137, 3.6340, 2.1185, 3.7210, 3.7213, 2.1173, 2.2775],\n",
            "        [2.1350, 3.0454, 1.8996, 3.1584, 3.1183, 1.8483, 1.9516]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "344\n",
            "tensor([[2.6070, 3.5387, 2.0842, 3.6282, 3.6274, 2.0489, 2.2141],\n",
            "        [3.1345, 4.0079, 2.2625, 4.0743, 4.0866, 2.3863, 2.5302],\n",
            "        [2.9883, 3.8703, 2.1973, 3.9415, 3.9512, 2.2668, 2.4340],\n",
            "        [0.9815, 1.5546, 1.2019, 1.6753, 1.5426, 1.2371, 1.1826],\n",
            "        [3.0213, 3.9047, 2.2199, 3.9750, 3.9839, 2.2977, 2.4546]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "345\n",
            "tensor([[3.0840, 3.9643, 2.2374, 4.0272, 4.0386, 2.3423, 2.4944],\n",
            "        [2.3323, 3.2934, 2.0021, 3.3907, 3.3822, 1.8998, 2.0627],\n",
            "        [2.9523, 3.8512, 2.1964, 3.9184, 3.9277, 2.2538, 2.4130],\n",
            "        [3.1639, 4.0278, 2.2619, 4.0858, 4.1023, 2.4000, 2.5386],\n",
            "        [0.9119, 1.4611, 1.1523, 1.5801, 1.4441, 1.1864, 1.1298]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "346\n",
            "tensor([[2.9714, 3.8490, 2.1822, 3.9048, 3.9168, 2.2522, 2.4150],\n",
            "        [2.9448, 3.8396, 2.1955, 3.9122, 3.9264, 2.2453, 2.4059],\n",
            "        [3.1237, 3.9596, 2.2003, 3.9986, 4.0068, 2.3650, 2.5051],\n",
            "        [1.5572, 2.3380, 1.6009, 2.4576, 2.3686, 1.5793, 1.5908],\n",
            "        [2.8459, 3.7464, 2.1579, 3.8220, 3.8334, 2.1702, 2.3422]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "347\n",
            "tensor([[3.0701, 3.9098, 2.1794, 3.9543, 3.9647, 2.3399, 2.4732],\n",
            "        [1.4932, 2.2531, 1.5621, 2.3735, 2.2808, 1.5442, 1.5476],\n",
            "        [1.6892, 2.4893, 1.6577, 2.6022, 2.5282, 1.6430, 1.6689],\n",
            "        [2.6106, 3.5486, 2.0842, 3.6267, 3.6322, 2.0368, 2.2111],\n",
            "        [2.6404, 3.5718, 2.1003, 3.6494, 3.6622, 2.0508, 2.2265]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "348\n",
            "tensor([[1.1387, 1.7778, 1.3265, 1.8962, 1.7780, 1.3369, 1.2982],\n",
            "        [2.0793, 2.9902, 1.8802, 3.0921, 3.0590, 1.8070, 1.9121],\n",
            "        [1.1198, 1.7511, 1.3117, 1.8695, 1.7508, 1.3244, 1.2835],\n",
            "        [2.0467, 2.9540, 1.8676, 3.0547, 3.0211, 1.7902, 1.8922],\n",
            "        [2.4790, 3.4306, 2.0493, 3.5098, 3.5197, 1.9582, 2.1327]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "349\n",
            "tensor([[1.9023, 2.7814, 1.7961, 2.8850, 2.8440, 1.7251, 1.8006],\n",
            "        [1.4357, 2.1788, 1.5287, 2.2938, 2.2040, 1.5071, 1.5036],\n",
            "        [1.0615, 1.6709, 1.2706, 1.7865, 1.6675, 1.2863, 1.2387],\n",
            "        [2.3273, 3.2954, 2.0040, 3.3793, 3.3844, 1.8796, 2.0491],\n",
            "        [1.5635, 2.3416, 1.5982, 2.4506, 2.3722, 1.5738, 1.5854]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "350\n",
            "tensor([[0.8904, 1.4382, 1.1470, 1.5529, 1.4237, 1.1681, 1.1119],\n",
            "        [2.5318, 3.4833, 2.0684, 3.5584, 3.5760, 1.9790, 2.1588],\n",
            "        [2.9098, 3.7954, 2.1744, 3.8447, 3.8787, 2.1932, 2.3637],\n",
            "        [2.9356, 3.8367, 2.1953, 3.8941, 3.9257, 2.2131, 2.3864],\n",
            "        [1.0251, 1.6204, 1.2385, 1.7318, 1.6131, 1.2569, 1.2087]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "351\n",
            "tensor([[2.8739, 3.7843, 2.1799, 3.8434, 3.8747, 2.1745, 2.3515],\n",
            "        [1.2346, 1.9033, 1.3858, 2.0140, 1.9118, 1.3928, 1.3579],\n",
            "        [2.5254, 3.4583, 2.0573, 3.5268, 3.5508, 1.9701, 2.1431],\n",
            "        [3.0293, 3.9133, 2.2229, 3.9612, 3.9991, 2.2716, 2.4392],\n",
            "        [1.2742, 1.9627, 1.4204, 2.0753, 1.9758, 1.4128, 1.3883]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "352\n",
            "tensor([[1.8063, 2.6588, 1.7482, 2.7633, 2.7183, 1.6801, 1.7371],\n",
            "        [0.8440, 1.3692, 1.1030, 1.4787, 1.3527, 1.1285, 1.0702],\n",
            "        [2.8147, 3.7297, 2.1668, 3.7948, 3.8282, 2.1465, 2.3157],\n",
            "        [3.0643, 3.9355, 2.2308, 3.9832, 4.0249, 2.3029, 2.4574],\n",
            "        [2.4409, 3.4004, 2.0444, 3.4789, 3.5010, 1.9271, 2.1041]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "353\n",
            "tensor([[2.9084, 3.7906, 2.1724, 3.8392, 3.8803, 2.1834, 2.3546],\n",
            "        [2.1743, 3.1152, 1.9435, 3.2077, 3.2063, 1.8192, 1.9572],\n",
            "        [0.8924, 1.4343, 1.1410, 1.5442, 1.4230, 1.1594, 1.1052],\n",
            "        [0.9632, 1.5356, 1.2021, 1.6508, 1.5316, 1.2108, 1.1619],\n",
            "        [2.2413, 3.1971, 1.9740, 3.2839, 3.2919, 1.8418, 1.9947]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "354\n",
            "tensor([[1.9947, 2.8934, 1.8528, 2.9910, 2.9719, 1.7459, 1.8471],\n",
            "        [1.9446, 2.8405, 1.8350, 2.9388, 2.9158, 1.7217, 1.8183],\n",
            "        [1.7026, 2.5308, 1.6988, 2.6386, 2.5865, 1.6213, 1.6695],\n",
            "        [3.1302, 3.9987, 2.2637, 4.0434, 4.0875, 2.3443, 2.4945],\n",
            "        [2.3719, 3.3346, 2.0268, 3.4148, 3.4365, 1.8851, 2.0619]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "355\n",
            "tensor([[0.8808, 1.4192, 1.1376, 1.5318, 1.4092, 1.1487, 1.0959],\n",
            "        [1.4627, 2.2066, 1.5403, 2.3152, 2.2407, 1.5027, 1.5053],\n",
            "        [2.7226, 3.6438, 2.1312, 3.7060, 3.7430, 2.0678, 2.2482],\n",
            "        [1.8141, 2.6568, 1.7499, 2.7591, 2.7202, 1.6729, 1.7323],\n",
            "        [1.8212, 2.6633, 1.7453, 2.7648, 2.7257, 1.6731, 1.7328]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "356\n",
            "tensor([[2.7992, 3.7055, 2.1594, 3.7675, 3.8106, 2.1162, 2.2873],\n",
            "        [2.6188, 3.5506, 2.1050, 3.6206, 3.6569, 2.0003, 2.1870],\n",
            "        [1.8576, 2.7158, 1.7775, 2.8178, 2.7864, 1.6833, 1.7564],\n",
            "        [1.0379, 1.6367, 1.2586, 1.7508, 1.6397, 1.2542, 1.2114],\n",
            "        [1.5882, 2.3746, 1.6264, 2.4831, 2.4202, 1.5633, 1.5887]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "357\n",
            "tensor([[2.7472, 3.6590, 2.1417, 3.7186, 3.7646, 2.0657, 2.2530],\n",
            "        [2.2949, 3.2573, 2.0024, 3.3384, 3.3634, 1.8281, 2.0059],\n",
            "        [1.0782, 1.6883, 1.2809, 1.8005, 1.6935, 1.2743, 1.2350],\n",
            "        [3.1559, 4.0128, 2.2724, 4.0573, 4.1009, 2.3364, 2.4976],\n",
            "        [1.3579, 2.0661, 1.4756, 2.1767, 2.0930, 1.4436, 1.4320]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "358\n",
            "tensor([[1.1839, 1.8339, 1.3597, 1.9468, 1.8481, 1.3413, 1.3109],\n",
            "        [0.8683, 1.3992, 1.1273, 1.5109, 1.3897, 1.1355, 1.0814],\n",
            "        [2.9352, 3.8189, 2.1916, 3.8740, 3.9164, 2.1765, 2.3579],\n",
            "        [1.0740, 1.6812, 1.2792, 1.7938, 1.6875, 1.2715, 1.2306],\n",
            "        [1.9436, 2.7204, 1.7256, 2.8002, 2.7678, 1.7440, 1.7685]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "359\n",
            "tensor([[1.0341, 1.6240, 1.2451, 1.7334, 1.6244, 1.2395, 1.1976],\n",
            "        [2.6815, 3.5960, 2.1214, 3.6643, 3.7080, 2.0247, 2.2101],\n",
            "        [1.0376, 1.6320, 1.2553, 1.7441, 1.6351, 1.2479, 1.2043],\n",
            "        [0.7664, 1.2556, 1.0428, 1.3655, 1.2389, 1.0546, 1.0004],\n",
            "        [3.0989, 3.9089, 2.1838, 3.9338, 3.9753, 2.3036, 2.4483]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "360\n",
            "tensor([[0.8581, 1.3844, 1.1182, 1.4959, 1.3756, 1.1221, 1.0708],\n",
            "        [2.0717, 2.9752, 1.8867, 3.0704, 3.0656, 1.7512, 1.8710],\n",
            "        [2.3871, 3.3315, 2.0268, 3.4100, 3.4389, 1.8626, 2.0449],\n",
            "        [3.1030, 3.9473, 2.2298, 3.9871, 4.0358, 2.2914, 2.4515],\n",
            "        [0.8724, 1.4016, 1.1258, 1.5120, 1.3925, 1.1318, 1.0795]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "361\n",
            "tensor([[1.7566, 2.5796, 1.7164, 2.6842, 2.6432, 1.6246, 1.6801],\n",
            "        [0.8389, 1.3574, 1.1069, 1.4694, 1.3475, 1.1093, 1.0554],\n",
            "        [3.1864, 4.0249, 2.2665, 4.0624, 4.1109, 2.3467, 2.5036],\n",
            "        [2.2856, 3.2170, 1.9836, 3.3013, 3.3234, 1.8302, 1.9892],\n",
            "        [0.9883, 1.5622, 1.2185, 1.6727, 1.5609, 1.2117, 1.1654]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "362\n",
            "tensor([[3.1351, 3.9663, 2.2372, 3.9962, 4.0475, 2.3126, 2.4676],\n",
            "        [1.4517, 2.1806, 1.5288, 2.2869, 2.2167, 1.4790, 1.4824],\n",
            "        [2.9872, 3.8530, 2.2117, 3.9092, 3.9624, 2.1898, 2.3791],\n",
            "        [1.7979, 2.6345, 1.7445, 2.7363, 2.7035, 1.6368, 1.7050],\n",
            "        [0.8017, 1.3031, 1.0716, 1.4112, 1.2888, 1.0801, 1.0249]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "363\n",
            "tensor([[3.2063, 4.0388, 2.2693, 4.0739, 4.1272, 2.3550, 2.5106],\n",
            "        [2.9834, 3.8488, 2.2046, 3.8943, 3.9481, 2.1961, 2.3686],\n",
            "        [0.7860, 1.2813, 1.0575, 1.3888, 1.2664, 1.0643, 1.0115],\n",
            "        [0.7428, 1.2180, 1.0173, 1.3237, 1.1998, 1.0304, 0.9762],\n",
            "        [1.4596, 2.1893, 1.5302, 2.2931, 2.2250, 1.4803, 1.4848]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "364\n",
            "tensor([[0.9769, 1.5445, 1.2055, 1.6524, 1.5401, 1.2006, 1.1532],\n",
            "        [3.1120, 3.9618, 2.2475, 4.0012, 4.0551, 2.2814, 2.4493],\n",
            "        [2.0161, 2.8870, 1.8436, 2.9784, 2.9680, 1.7334, 1.8292],\n",
            "        [2.2422, 3.1490, 1.9502, 3.2328, 3.2468, 1.8231, 1.9581],\n",
            "        [2.1650, 3.0813, 1.9283, 3.1670, 3.1766, 1.7773, 1.9165]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "365\n",
            "tensor([[0.9748, 1.5409, 1.2015, 1.6484, 1.5365, 1.1984, 1.1505],\n",
            "        [3.0129, 3.8750, 2.2106, 3.9169, 3.9691, 2.2125, 2.3907],\n",
            "        [0.7173, 1.1823, 0.9944, 1.2835, 1.1589, 1.0090, 0.9537],\n",
            "        [2.5436, 3.4674, 2.0691, 3.5349, 3.5762, 1.9356, 2.1215],\n",
            "        [0.7200, 1.1880, 1.0023, 1.2923, 1.1687, 1.0117, 0.9572]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "366\n",
            "tensor([[2.1425, 3.0519, 1.9144, 3.1358, 3.1425, 1.7693, 1.9005],\n",
            "        [1.7635, 2.5829, 1.7134, 2.6779, 2.6431, 1.6212, 1.6742],\n",
            "        [3.0739, 3.8796, 2.1713, 3.9055, 3.9456, 2.2564, 2.4157],\n",
            "        [1.3500, 2.0495, 1.4688, 2.1557, 2.0750, 1.4256, 1.4129],\n",
            "        [0.9083, 1.4474, 1.1492, 1.5532, 1.4365, 1.1560, 1.1001]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "367\n",
            "tensor([[0.8431, 1.3584, 1.1029, 1.4640, 1.3429, 1.1091, 1.0518],\n",
            "        [3.1892, 4.0270, 2.2678, 4.0613, 4.1124, 2.3344, 2.4911],\n",
            "        [0.9574, 1.5097, 1.1788, 1.6119, 1.4992, 1.1822, 1.1316],\n",
            "        [1.0669, 1.6622, 1.2591, 1.7655, 1.6612, 1.2540, 1.2109],\n",
            "        [1.6502, 2.3515, 1.5392, 2.4257, 2.3719, 1.5752, 1.5655]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "368\n",
            "tensor([[1.1592, 1.7852, 1.3266, 1.8879, 1.7892, 1.3144, 1.2759],\n",
            "        [3.1416, 3.9805, 2.2513, 4.0190, 4.0724, 2.2910, 2.4579],\n",
            "        [0.9769, 1.5330, 1.1900, 1.6359, 1.5244, 1.1962, 1.1439],\n",
            "        [3.1919, 4.0219, 2.2595, 4.0512, 4.1030, 2.3372, 2.4897],\n",
            "        [2.0027, 2.8804, 1.8456, 2.9694, 2.9578, 1.7143, 1.8155]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "369\n",
            "tensor([[3.0806, 3.9190, 2.2252, 3.9541, 4.0090, 2.2445, 2.4151],\n",
            "        [1.5788, 2.3304, 1.5898, 2.4248, 2.3653, 1.5364, 1.5485],\n",
            "        [0.9092, 1.4444, 1.1471, 1.5490, 1.4324, 1.1520, 1.0960],\n",
            "        [3.1107, 3.9452, 2.2411, 3.9801, 4.0387, 2.2670, 2.4337],\n",
            "        [0.7749, 1.2551, 1.0351, 1.3549, 1.2321, 1.0497, 0.9912]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "370\n",
            "tensor([[3.2096, 4.0228, 2.2471, 4.0388, 4.0919, 2.3483, 2.4906],\n",
            "        [3.0674, 3.8739, 2.1713, 3.8915, 3.9420, 2.2409, 2.3952],\n",
            "        [1.7378, 2.5347, 1.6835, 2.6231, 2.5824, 1.6073, 1.6457],\n",
            "        [1.3705, 2.0598, 1.4621, 2.1561, 2.0780, 1.4276, 1.4103],\n",
            "        [1.6677, 2.4453, 1.6471, 2.5380, 2.4881, 1.5749, 1.6040]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "371\n",
            "tensor([[1.8167, 2.6308, 1.7286, 2.7178, 2.6851, 1.6446, 1.6906],\n",
            "        [3.2172, 4.0244, 2.2474, 4.0447, 4.0970, 2.3472, 2.4926],\n",
            "        [2.1245, 3.0149, 1.8955, 3.0920, 3.0957, 1.7550, 1.8719],\n",
            "        [3.2327, 4.0502, 2.2699, 4.0719, 4.1247, 2.3587, 2.5028],\n",
            "        [3.1657, 3.9642, 2.2043, 3.9712, 4.0228, 2.3188, 2.4561]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "372\n",
            "tensor([[3.0971, 3.8803, 2.1555, 3.8846, 3.9323, 2.2635, 2.4036],\n",
            "        [2.3428, 3.2781, 1.9967, 3.3376, 3.3722, 1.8182, 1.9879],\n",
            "        [0.9563, 1.5050, 1.1732, 1.6011, 1.4903, 1.1761, 1.1204],\n",
            "        [1.7427, 2.5395, 1.6849, 2.6258, 2.5866, 1.6026, 1.6420],\n",
            "        [2.4934, 3.1791, 1.7353, 3.1440, 3.2100, 1.8258, 1.9627]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "373\n",
            "tensor([[1.8551, 2.6781, 1.7487, 2.7593, 2.7329, 1.6514, 1.7080],\n",
            "        [0.6888, 1.1340, 0.9614, 1.2275, 1.1033, 0.9789, 0.9187],\n",
            "        [0.9386, 1.4785, 1.1620, 1.5767, 1.4629, 1.1646, 1.1074],\n",
            "        [1.1532, 1.7644, 1.3049, 1.8567, 1.7628, 1.2940, 1.2533],\n",
            "        [3.2270, 4.0439, 2.2690, 4.0648, 4.1236, 2.3425, 2.4896]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "374\n",
            "tensor([[2.8007, 3.6778, 2.1386, 3.7190, 3.7757, 2.0688, 2.2315],\n",
            "        [3.0848, 3.9233, 2.2290, 3.9530, 4.0083, 2.2396, 2.3982],\n",
            "        [2.0725, 2.9453, 1.8618, 3.0170, 3.0167, 1.7331, 1.8332],\n",
            "        [2.6947, 3.5868, 2.1049, 3.6316, 3.6829, 1.9962, 2.1726],\n",
            "        [2.0404, 2.9134, 1.8513, 2.9873, 2.9828, 1.7197, 1.8159]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "375\n",
            "tensor([[2.1369, 3.0098, 1.8835, 3.0789, 3.0828, 1.7686, 1.8672],\n",
            "        [1.0328, 1.6062, 1.2282, 1.6993, 1.5951, 1.2224, 1.1707],\n",
            "        [1.1201, 1.7208, 1.2847, 1.8124, 1.7152, 1.2779, 1.2301],\n",
            "        [3.0484, 3.8954, 2.2182, 3.9198, 3.9798, 2.2170, 2.3735],\n",
            "        [3.1149, 3.9482, 2.2412, 3.9757, 4.0353, 2.2565, 2.4113]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "376\n",
            "tensor([[2.8295, 3.6952, 2.1439, 3.7349, 3.7890, 2.0819, 2.2390],\n",
            "        [2.0639, 2.9273, 1.8513, 2.9973, 2.9943, 1.7353, 1.8228],\n",
            "        [1.5973, 2.3438, 1.5902, 2.4223, 2.3736, 1.5311, 1.5378],\n",
            "        [0.9570, 1.5009, 1.1690, 1.5935, 1.4833, 1.1748, 1.1151],\n",
            "        [3.0107, 3.8611, 2.2041, 3.8869, 3.9454, 2.1797, 2.3457]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "377\n",
            "tensor([[2.1799, 3.0677, 1.9103, 3.1309, 3.1429, 1.7757, 1.8865],\n",
            "        [0.8940, 1.4148, 1.1224, 1.5066, 1.3938, 1.1297, 1.0674],\n",
            "        [2.7525, 3.6304, 2.1169, 3.6704, 3.7254, 2.0239, 2.1952],\n",
            "        [0.9628, 1.5109, 1.1758, 1.6023, 1.4938, 1.1783, 1.1182],\n",
            "        [0.8699, 1.3819, 1.1011, 1.4722, 1.3574, 1.1103, 1.0489]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "378\n",
            "tensor([[1.4316, 2.1305, 1.4883, 2.2125, 2.1469, 1.4504, 1.4316],\n",
            "        [2.3056, 3.2188, 1.9716, 3.2725, 3.3026, 1.8146, 1.9530],\n",
            "        [2.4480, 3.3655, 2.0256, 3.4116, 3.4571, 1.8706, 2.0268],\n",
            "        [1.5248, 2.2622, 1.5613, 2.3432, 2.2862, 1.4971, 1.4951],\n",
            "        [2.5915, 3.4948, 2.0694, 3.5360, 3.5862, 1.9373, 2.1040]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "379\n",
            "tensor([[2.5847, 3.4883, 2.0705, 3.5279, 3.5786, 1.9288, 2.0957],\n",
            "        [1.5263, 2.2560, 1.5534, 2.3335, 2.2759, 1.4981, 1.4915],\n",
            "        [2.7085, 3.5980, 2.1119, 3.6317, 3.6899, 2.0140, 2.1678],\n",
            "        [0.8599, 1.3675, 1.0930, 1.4551, 1.3420, 1.1028, 1.0385],\n",
            "        [3.0728, 3.9144, 2.2335, 3.9336, 4.0006, 2.2266, 2.3742]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "380\n",
            "tensor([[0.7958, 1.2802, 1.0433, 1.3655, 1.2488, 1.0559, 0.9906],\n",
            "        [2.5175, 3.3666, 2.0157, 3.4109, 3.4442, 1.9605, 2.0574],\n",
            "        [2.7350, 3.6160, 2.1209, 3.6462, 3.7063, 2.0226, 2.1747],\n",
            "        [1.5995, 2.3478, 1.5901, 2.4207, 2.3704, 1.5274, 1.5324],\n",
            "        [0.8063, 1.2925, 1.0483, 1.3775, 1.2616, 1.0621, 0.9972]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "381\n",
            "tensor([[0.8370, 1.3364, 1.0760, 1.4205, 1.3066, 1.0838, 1.0193],\n",
            "        [3.2159, 4.0329, 2.2740, 4.0404, 4.1075, 2.3183, 2.4515],\n",
            "        [2.8305, 3.7045, 2.1503, 3.7299, 3.7908, 2.0743, 2.2277],\n",
            "        [0.9403, 1.4772, 1.1539, 1.5600, 1.4540, 1.1580, 1.0935],\n",
            "        [0.8213, 1.3117, 1.0577, 1.3935, 1.2807, 1.0674, 1.0042]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "382\n",
            "tensor([[1.4436, 2.1445, 1.4956, 2.2169, 2.1527, 1.4496, 1.4305],\n",
            "        [2.8834, 3.7449, 2.1645, 3.7664, 3.8289, 2.1028, 2.2540],\n",
            "        [3.2637, 4.0731, 2.2832, 4.0729, 4.1365, 2.3531, 2.4802],\n",
            "        [2.1528, 3.0250, 1.8932, 3.0767, 3.0868, 1.7636, 1.8561],\n",
            "        [2.0708, 2.9148, 1.8413, 2.9696, 2.9680, 1.7394, 1.8080]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "383\n",
            "tensor([[0.7372, 1.1940, 0.9909, 1.2744, 1.1553, 1.0055, 0.9411],\n",
            "        [1.4389, 2.1406, 1.4967, 2.2125, 2.1456, 1.4473, 1.4285],\n",
            "        [2.5135, 3.4227, 2.0471, 3.4532, 3.5027, 1.8842, 2.0473],\n",
            "        [3.2362, 4.0480, 2.2799, 4.0499, 4.1162, 2.3333, 2.4622],\n",
            "        [0.7491, 1.2112, 1.0014, 1.2919, 1.1737, 1.0141, 0.9502]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "384\n",
            "tensor([[2.7071, 3.5901, 2.1090, 3.6129, 3.6682, 1.9959, 2.1513],\n",
            "        [1.5681, 2.3029, 1.5754, 2.3709, 2.3171, 1.5101, 1.5073],\n",
            "        [2.8487, 3.7121, 2.1562, 3.7288, 3.7892, 2.0682, 2.2291],\n",
            "        [3.2390, 4.0493, 2.2779, 4.0459, 4.1069, 2.3309, 2.4612],\n",
            "        [2.7967, 3.6660, 2.1370, 3.6874, 3.7452, 2.0410, 2.2006]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "385\n",
            "tensor([[2.3424, 3.2547, 1.9893, 3.2891, 3.3229, 1.8104, 1.9562],\n",
            "        [1.8622, 2.6712, 1.7444, 2.7280, 2.7030, 1.6411, 1.6856],\n",
            "        [2.5187, 3.4133, 2.0471, 3.4435, 3.4872, 1.8999, 2.0488],\n",
            "        [0.9094, 1.4266, 1.1237, 1.5048, 1.3935, 1.1313, 1.0668],\n",
            "        [2.7237, 3.6014, 2.1156, 3.6229, 3.6801, 2.0077, 2.1589]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "386\n",
            "tensor([[3.2344, 4.0451, 2.2869, 4.0428, 4.1042, 2.3313, 2.4554],\n",
            "        [2.3782, 3.2855, 2.0001, 3.3178, 3.3520, 1.8262, 1.9726],\n",
            "        [1.9631, 2.7971, 1.8018, 2.8502, 2.8361, 1.6762, 1.7430],\n",
            "        [2.0091, 2.8422, 1.8136, 2.8933, 2.8816, 1.6982, 1.7666],\n",
            "        [0.9815, 1.5160, 1.1670, 1.5900, 1.4841, 1.1758, 1.1128]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "387\n",
            "tensor([[2.0742, 2.9213, 1.8541, 2.9700, 2.9631, 1.7278, 1.8045],\n",
            "        [2.9595, 3.8058, 2.1920, 3.8156, 3.8710, 2.1326, 2.2833],\n",
            "        [1.3757, 2.0355, 1.4396, 2.1036, 2.0271, 1.4152, 1.3771],\n",
            "        [3.2041, 4.0105, 2.2700, 4.0102, 4.0725, 2.2953, 2.4289],\n",
            "        [1.5583, 2.2734, 1.5513, 2.3343, 2.2768, 1.5010, 1.4918]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "388\n",
            "tensor([[2.7321, 3.6061, 2.1201, 3.6248, 3.6760, 1.9965, 2.1540],\n",
            "        [2.3492, 3.2327, 1.9769, 3.2677, 3.2893, 1.8339, 1.9528],\n",
            "        [2.8273, 3.6912, 2.1511, 3.7058, 3.7590, 2.0595, 2.2089],\n",
            "        [0.7882, 1.2603, 1.0335, 1.3389, 1.2189, 1.0438, 0.9759],\n",
            "        [2.9058, 3.7558, 2.1751, 3.7680, 3.8233, 2.1025, 2.2499]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "389\n",
            "tensor([[2.5051, 3.4069, 2.0467, 3.4282, 3.4708, 1.8726, 2.0278],\n",
            "        [3.2900, 4.0897, 2.3016, 4.0795, 4.1383, 2.3619, 2.4777],\n",
            "        [0.7198, 1.1656, 0.9760, 1.2416, 1.1195, 0.9878, 0.9225],\n",
            "        [3.2653, 4.0706, 2.2957, 4.0628, 4.1217, 2.3419, 2.4624],\n",
            "        [3.2202, 4.0285, 2.2784, 4.0239, 4.0834, 2.3013, 2.4323]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "390\n",
            "tensor([[1.0597, 1.6276, 1.2383, 1.7013, 1.5980, 1.2269, 1.1663],\n",
            "        [3.2434, 4.0469, 2.2842, 4.0346, 4.0940, 2.3224, 2.4440],\n",
            "        [1.9360, 2.7442, 1.7702, 2.7911, 2.7661, 1.6712, 1.7135],\n",
            "        [2.5194, 3.4221, 2.0511, 3.4423, 3.4841, 1.8787, 2.0347],\n",
            "        [1.2223, 1.8451, 1.3521, 1.9170, 1.8247, 1.3257, 1.2770]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "391\n",
            "tensor([[2.2927, 3.1757, 1.9569, 3.2073, 3.2236, 1.8045, 1.9142],\n",
            "        [0.8604, 1.3577, 1.0876, 1.4329, 1.3150, 1.0926, 1.0246],\n",
            "        [3.0017, 3.8381, 2.2086, 3.8428, 3.8970, 2.1537, 2.2968],\n",
            "        [3.2195, 4.0271, 2.2806, 4.0207, 4.0768, 2.2950, 2.4275],\n",
            "        [2.1980, 3.0451, 1.8953, 3.0811, 3.0829, 1.7793, 1.8590]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "392\n",
            "tensor([[3.0048, 3.8472, 2.2090, 3.8454, 3.8962, 2.1546, 2.2986],\n",
            "        [0.8728, 1.3763, 1.1019, 1.4531, 1.3348, 1.1029, 1.0342],\n",
            "        [0.8759, 1.3796, 1.1017, 1.4554, 1.3380, 1.1047, 1.0353],\n",
            "        [0.9562, 1.4865, 1.1573, 1.5598, 1.4478, 1.1558, 1.0908],\n",
            "        [3.0946, 3.9237, 2.2413, 3.9188, 3.9714, 2.2117, 2.3501]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "393\n",
            "tensor([[3.0809, 3.9030, 2.2252, 3.8985, 3.9539, 2.1971, 2.3378],\n",
            "        [1.3992, 2.0671, 1.4519, 2.1275, 2.0471, 1.4220, 1.3836],\n",
            "        [1.4039, 2.0733, 1.4569, 2.1342, 2.0561, 1.4229, 1.3861],\n",
            "        [3.2449, 4.0556, 2.2869, 4.0408, 4.0904, 2.3167, 2.4397],\n",
            "        [2.5329, 3.4002, 2.0373, 3.4216, 3.4479, 1.9312, 2.0404]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "394\n",
            "tensor([[2.0157, 2.8338, 1.8036, 2.8745, 2.8511, 1.6976, 1.7504],\n",
            "        [3.2776, 4.0778, 2.2954, 4.0632, 4.1143, 2.3414, 2.4592],\n",
            "        [0.8369, 1.3263, 1.0714, 1.4020, 1.2801, 1.0780, 1.0075],\n",
            "        [0.8535, 1.3453, 1.0780, 1.4186, 1.2984, 1.0893, 1.0168],\n",
            "        [2.1818, 3.0462, 1.9020, 3.0811, 3.0781, 1.7670, 1.8510]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "395\n",
            "tensor([[2.5667, 3.4638, 2.0671, 3.4756, 3.5114, 1.9169, 2.0532],\n",
            "        [1.9190, 2.7266, 1.7610, 2.7680, 2.7385, 1.6616, 1.6982],\n",
            "        [2.2953, 3.1680, 1.9495, 3.1959, 3.2022, 1.8177, 1.9112],\n",
            "        [1.6792, 2.4256, 1.6238, 2.4771, 2.4188, 1.5644, 1.5576],\n",
            "        [2.0859, 2.9374, 1.8598, 2.9747, 2.9612, 1.7261, 1.7959]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "396\n",
            "tensor([[3.2272, 4.0417, 2.2872, 4.0273, 4.0792, 2.3232, 2.4278],\n",
            "        [0.9953, 1.5408, 1.1872, 1.6107, 1.4979, 1.1892, 1.1180],\n",
            "        [3.2796, 4.0866, 2.3021, 4.0665, 4.1159, 2.3613, 2.4617],\n",
            "        [1.5903, 2.3204, 1.5776, 2.3756, 2.3092, 1.5202, 1.5055],\n",
            "        [3.2072, 4.0250, 2.2801, 4.0118, 4.0632, 2.3090, 2.4157]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "397\n",
            "tensor([[3.0955, 3.9251, 2.2394, 3.9158, 3.9678, 2.2235, 2.3482],\n",
            "        [3.2874, 4.0874, 2.2933, 4.0650, 4.1115, 2.3626, 2.4629],\n",
            "        [0.9775, 1.5194, 1.1787, 1.5913, 1.4767, 1.1834, 1.1083],\n",
            "        [0.7571, 1.2158, 1.0030, 1.2879, 1.1632, 1.0197, 0.9464],\n",
            "        [3.1570, 3.9703, 2.2512, 3.9599, 4.0087, 2.2708, 2.3879]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "398\n",
            "tensor([[1.0962, 1.6766, 1.2676, 1.7462, 1.6383, 1.2598, 1.1893],\n",
            "        [3.2906, 4.0888, 2.3014, 4.0687, 4.1153, 2.3679, 2.4646],\n",
            "        [0.8488, 1.3432, 1.0815, 1.4180, 1.2948, 1.0944, 1.0169],\n",
            "        [3.1393, 3.9627, 2.2572, 3.9538, 3.9992, 2.2613, 2.3752],\n",
            "        [1.5383, 2.2552, 1.5537, 2.3132, 2.2418, 1.5045, 1.4752]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "399\n",
            "tensor([[3.2493, 4.0500, 2.2900, 4.0354, 4.0817, 2.3433, 2.4400],\n",
            "        [0.8073, 1.2825, 1.0452, 1.3559, 1.2310, 1.0643, 0.9847],\n",
            "        [1.6964, 2.4274, 1.6193, 2.4751, 2.4159, 1.5926, 1.5620],\n",
            "        [0.7912, 1.2613, 1.0324, 1.3345, 1.2089, 1.0531, 0.9725],\n",
            "        [2.5947, 3.4829, 2.0779, 3.4943, 3.5254, 1.9550, 2.0683]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "400\n",
            "tensor([[1.6363, 2.3631, 1.5969, 2.4147, 2.3488, 1.5599, 1.5278],\n",
            "        [2.3313, 3.1930, 1.9622, 3.2197, 3.2215, 1.8570, 1.9276],\n",
            "        [2.4825, 3.3702, 2.0350, 3.3902, 3.4097, 1.9051, 2.0092],\n",
            "        [0.6776, 1.1070, 0.9443, 1.1822, 1.0522, 0.9652, 0.8897],\n",
            "        [2.9030, 3.7475, 2.1788, 3.7504, 3.7931, 2.1300, 2.2354]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "401\n",
            "tensor([[3.3097, 4.0987, 2.3077, 4.0784, 4.1188, 2.3929, 2.4739],\n",
            "        [1.3653, 2.0282, 1.4457, 2.0912, 2.0015, 1.4223, 1.3631],\n",
            "        [0.9978, 1.5342, 1.1803, 1.6010, 1.4851, 1.1932, 1.1139],\n",
            "        [1.0279, 1.5794, 1.2091, 1.6490, 1.5349, 1.2199, 1.1386],\n",
            "        [3.2661, 4.0617, 2.3009, 4.0460, 4.0919, 2.3619, 2.4456]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "402\n",
            "tensor([[3.3003, 4.0872, 2.3062, 4.0696, 4.1063, 2.3944, 2.4672],\n",
            "        [1.4807, 2.1715, 1.5125, 2.2297, 2.1482, 1.4863, 1.4329],\n",
            "        [2.2592, 3.1148, 1.9351, 3.1453, 3.1361, 1.8341, 1.8870],\n",
            "        [1.5519, 2.2640, 1.5596, 2.3206, 2.2449, 1.5212, 1.4780],\n",
            "        [1.0515, 1.6070, 1.2248, 1.6755, 1.5606, 1.2387, 1.1536]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "403\n",
            "tensor([[0.7991, 1.2683, 1.0409, 1.3427, 1.2141, 1.0637, 0.9763],\n",
            "        [2.1375, 2.8871, 1.7954, 2.9109, 2.8788, 1.8156, 1.7978],\n",
            "        [0.8647, 1.3577, 1.0909, 1.4310, 1.3048, 1.1136, 1.0232],\n",
            "        [0.7939, 1.2626, 1.0399, 1.3382, 1.2083, 1.0624, 0.9735],\n",
            "        [1.9290, 2.7283, 1.7738, 2.7724, 2.7299, 1.6927, 1.6992]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "404\n",
            "tensor([[0.8021, 1.2704, 1.0413, 1.3441, 1.2151, 1.0661, 0.9768],\n",
            "        [0.7784, 1.2397, 1.0278, 1.3151, 1.1849, 1.0518, 0.9615],\n",
            "        [3.1917, 3.9972, 2.2931, 3.9897, 4.0316, 2.3279, 2.3959],\n",
            "        [2.7828, 3.6438, 2.1537, 3.6499, 3.6860, 2.0608, 2.1578],\n",
            "        [3.3033, 4.0668, 2.2861, 4.0365, 4.0718, 2.4162, 2.4651]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "405\n",
            "tensor([[2.4515, 3.3419, 2.0438, 3.3624, 3.3761, 1.9015, 1.9854],\n",
            "        [2.7511, 3.6122, 2.1474, 3.6203, 3.6506, 2.0568, 2.1428],\n",
            "        [0.8908, 1.3902, 1.1131, 1.4626, 1.3374, 1.1338, 1.0403],\n",
            "        [2.2496, 3.1075, 1.9469, 3.1400, 3.1283, 1.8350, 1.8786],\n",
            "        [2.2726, 3.1344, 1.9576, 3.1652, 3.1558, 1.8450, 1.8918]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "406\n",
            "tensor([[3.2854, 4.0757, 2.3252, 4.0592, 4.0955, 2.4074, 2.4538],\n",
            "        [3.3376, 4.1198, 2.3436, 4.0996, 4.1385, 2.4341, 2.4830],\n",
            "        [1.3099, 1.9287, 1.3818, 1.9851, 1.8919, 1.3871, 1.3086],\n",
            "        [3.0232, 3.8469, 2.2454, 3.8482, 3.8840, 2.2381, 2.2963],\n",
            "        [2.0951, 2.9255, 1.8765, 2.9653, 2.9360, 1.7802, 1.7931]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "407\n",
            "tensor([[2.4544, 3.3140, 2.0375, 3.3381, 3.3411, 1.9439, 1.9881],\n",
            "        [3.3371, 4.1067, 2.3292, 4.0818, 4.1139, 2.4458, 2.4863],\n",
            "        [0.8254, 1.3036, 1.0687, 1.3778, 1.2483, 1.0871, 0.9936],\n",
            "        [1.8391, 2.6179, 1.7407, 2.6654, 2.6115, 1.6738, 1.6463],\n",
            "        [1.9770, 2.7747, 1.8058, 2.8169, 2.7738, 1.7353, 1.7233]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "408\n",
            "tensor([[3.3421, 4.1189, 2.3442, 4.0991, 4.1309, 2.4535, 2.4924],\n",
            "        [3.1696, 3.9809, 2.3025, 3.9754, 4.0107, 2.3293, 2.3844],\n",
            "        [3.2273, 4.0336, 2.3233, 4.0231, 4.0579, 2.3703, 2.4208],\n",
            "        [2.4795, 3.3598, 2.0606, 3.3821, 3.3889, 1.9453, 2.0035],\n",
            "        [2.6623, 3.5420, 2.1328, 3.5551, 3.5787, 2.0170, 2.0969]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "409\n",
            "tensor([[2.8703, 3.7205, 2.2040, 3.7268, 3.7569, 2.1540, 2.2139],\n",
            "        [3.3241, 4.1082, 2.3434, 4.0864, 4.1170, 2.4364, 2.4814],\n",
            "        [3.0873, 3.9129, 2.2764, 3.9053, 3.9430, 2.2674, 2.3341],\n",
            "        [3.1776, 3.9811, 2.3006, 3.9688, 4.0094, 2.3263, 2.3858],\n",
            "        [3.2882, 4.0829, 2.3404, 4.0658, 4.1007, 2.4197, 2.4588]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "410\n",
            "tensor([[3.1958, 4.0024, 2.3136, 3.9935, 4.0317, 2.3617, 2.4034],\n",
            "        [3.1948, 4.0008, 2.3066, 3.9838, 4.0251, 2.3453, 2.3980],\n",
            "        [2.3864, 3.2824, 2.0348, 3.3032, 3.3089, 1.8937, 1.9558],\n",
            "        [2.9090, 3.7523, 2.2118, 3.7526, 3.7816, 2.1786, 2.2375],\n",
            "        [3.2936, 4.0854, 2.3406, 4.0677, 4.1035, 2.4213, 2.4631]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "411\n",
            "tensor([[3.2626, 4.0545, 2.3217, 4.0313, 4.0672, 2.4024, 2.4418],\n",
            "        [0.8158, 1.2992, 1.0735, 1.3734, 1.2419, 1.0945, 0.9934],\n",
            "        [0.8519, 1.3478, 1.1011, 1.4212, 1.2924, 1.1189, 1.0187],\n",
            "        [3.2673, 4.0722, 2.3382, 4.0516, 4.0860, 2.4106, 2.4506],\n",
            "        [1.7518, 2.5080, 1.6834, 2.5532, 2.4905, 1.6460, 1.5969]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "412\n",
            "tensor([[2.2896, 3.1850, 1.9956, 3.2082, 3.2038, 1.8616, 1.9092],\n",
            "        [3.2786, 4.0822, 2.3402, 4.0598, 4.0979, 2.4230, 2.4576],\n",
            "        [3.2894, 4.0907, 2.3441, 4.0676, 4.1045, 2.4327, 2.4665],\n",
            "        [2.3410, 3.2183, 2.0074, 3.2423, 3.2374, 1.9006, 1.9354],\n",
            "        [2.2865, 3.1810, 1.9962, 3.2056, 3.1998, 1.8598, 1.9075]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "413\n",
            "tensor([[2.1663, 3.0462, 1.9403, 3.0761, 3.0580, 1.8142, 1.8438],\n",
            "        [1.3641, 2.0279, 1.4582, 2.0861, 1.9909, 1.4504, 1.3640],\n",
            "        [1.1276, 1.7293, 1.3159, 1.7981, 1.6828, 1.3144, 1.2153],\n",
            "        [2.2158, 3.0986, 1.9614, 3.1259, 3.1120, 1.8407, 1.8720],\n",
            "        [2.1838, 3.0768, 1.9561, 3.1044, 3.0912, 1.8160, 1.8555]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "414\n",
            "tensor([[0.8574, 1.3628, 1.1115, 1.4369, 1.3067, 1.1284, 1.0272],\n",
            "        [2.9491, 3.7974, 2.2382, 3.7958, 3.8314, 2.2232, 2.2689],\n",
            "        [2.4456, 3.3603, 2.0676, 3.3715, 3.3877, 1.9247, 1.9940],\n",
            "        [3.2938, 4.0977, 2.3478, 4.0743, 4.1095, 2.4385, 2.4739],\n",
            "        [3.1556, 3.9803, 2.3057, 3.9674, 4.0039, 2.3401, 2.3891]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "415\n",
            "tensor([[3.2304, 4.0482, 2.3340, 4.0277, 4.0672, 2.3959, 2.4362],\n",
            "        [2.0631, 2.9024, 1.8720, 2.9387, 2.9084, 1.7971, 1.7871],\n",
            "        [2.1405, 2.9397, 1.8648, 2.9692, 2.9387, 1.8503, 1.8199],\n",
            "        [0.7976, 1.2829, 1.0680, 1.3585, 1.2258, 1.0859, 0.9861],\n",
            "        [3.2154, 4.0331, 2.3285, 4.0161, 4.0557, 2.3891, 2.4270]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "416\n",
            "tensor([[0.9958, 1.5508, 1.2192, 1.6235, 1.5016, 1.2290, 1.1272],\n",
            "        [3.0780, 3.9170, 2.2812, 3.9068, 3.9448, 2.2878, 2.3450],\n",
            "        [2.7667, 3.6242, 2.1685, 3.6298, 3.6604, 2.1313, 2.1691],\n",
            "        [1.8777, 2.7014, 1.7924, 2.7445, 2.6975, 1.7018, 1.6848],\n",
            "        [3.0447, 3.8884, 2.2763, 3.8809, 3.9180, 2.2838, 2.3280]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "417\n",
            "tensor([[2.9127, 3.7690, 2.2264, 3.7692, 3.8040, 2.1877, 2.2513],\n",
            "        [2.6733, 3.5549, 2.1445, 3.5649, 3.5920, 2.0683, 2.1189],\n",
            "        [3.1366, 3.9642, 2.3004, 3.9524, 3.9915, 2.3307, 2.3802],\n",
            "        [3.2442, 4.0443, 2.3187, 4.0188, 4.0571, 2.4133, 2.4452],\n",
            "        [3.2589, 4.0734, 2.3410, 4.0514, 4.0891, 2.4223, 2.4570]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "418\n",
            "tensor([[3.2928, 4.0831, 2.3377, 4.0582, 4.1016, 2.4487, 2.4746],\n",
            "        [1.2445, 1.8795, 1.3892, 1.9434, 1.8409, 1.3846, 1.2917],\n",
            "        [1.8271, 2.6340, 1.7577, 2.6779, 2.6285, 1.6780, 1.6528],\n",
            "        [1.7166, 2.4796, 1.6815, 2.5263, 2.4659, 1.6387, 1.5848],\n",
            "        [1.3192, 1.9764, 1.4396, 2.0365, 1.9409, 1.4274, 1.3389]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "419\n",
            "tensor([[1.7037, 2.4865, 1.7015, 2.5359, 2.4791, 1.6223, 1.5823],\n",
            "        [3.2805, 4.0752, 2.3326, 4.0455, 4.0878, 2.4447, 2.4663],\n",
            "        [1.7605, 2.5347, 1.7094, 2.5812, 2.5264, 1.6605, 1.6121],\n",
            "        [1.3577, 2.0384, 1.4790, 2.0988, 2.0080, 1.4502, 1.3673],\n",
            "        [2.0685, 2.9238, 1.8866, 2.9573, 2.9352, 1.7823, 1.7904]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "420\n",
            "tensor([[1.9328, 2.7625, 1.8185, 2.8020, 2.7674, 1.7248, 1.7146],\n",
            "        [2.2386, 3.1380, 1.9831, 3.1617, 3.1649, 1.8412, 1.8856],\n",
            "        [1.2227, 1.8507, 1.3747, 1.9120, 1.8119, 1.3666, 1.2744],\n",
            "        [3.2489, 4.0561, 2.3297, 4.0341, 4.0777, 2.4104, 2.4466],\n",
            "        [0.9207, 1.4514, 1.1671, 1.5254, 1.4013, 1.1772, 1.0746]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "421\n",
            "tensor([[0.7919, 1.2750, 1.0638, 1.3510, 1.2209, 1.0807, 0.9813],\n",
            "        [1.0447, 1.6117, 1.2493, 1.6811, 1.5664, 1.2601, 1.1571],\n",
            "        [3.2473, 4.0503, 2.3297, 4.0279, 4.0756, 2.4069, 2.4416],\n",
            "        [3.2357, 4.0406, 2.3288, 4.0216, 4.0695, 2.4031, 2.4352],\n",
            "        [1.8683, 2.6778, 1.7758, 2.7194, 2.6783, 1.7011, 1.6753]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "422\n",
            "tensor([[1.8021, 2.5968, 1.7386, 2.6412, 2.5936, 1.6690, 1.6374],\n",
            "        [0.8930, 1.4082, 1.1339, 1.4804, 1.3559, 1.1526, 1.0512],\n",
            "        [2.4988, 3.3892, 2.0753, 3.4014, 3.4271, 1.9668, 2.0227],\n",
            "        [3.0911, 3.9201, 2.2822, 3.9070, 3.9550, 2.3060, 2.3506],\n",
            "        [1.0023, 1.5555, 1.2183, 1.6258, 1.5078, 1.2317, 1.1290]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "423\n",
            "tensor([[0.9455, 1.4807, 1.1787, 1.5532, 1.4317, 1.1915, 1.0909],\n",
            "        [1.7050, 2.4592, 1.6590, 2.5064, 2.4481, 1.6248, 1.5742],\n",
            "        [1.1854, 1.8033, 1.3529, 1.8706, 1.7649, 1.3487, 1.2554],\n",
            "        [2.4179, 3.3206, 2.0476, 3.3372, 3.3553, 1.9220, 1.9822],\n",
            "        [0.9138, 1.4350, 1.1479, 1.5069, 1.3839, 1.1670, 1.0664]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "424\n",
            "tensor([[3.0650, 3.8958, 2.2603, 3.8819, 3.9306, 2.2742, 2.3360],\n",
            "        [2.2322, 3.1285, 1.9703, 3.1543, 3.1559, 1.8322, 1.8837],\n",
            "        [2.6323, 3.5086, 2.1146, 3.5176, 3.5493, 2.0390, 2.0959],\n",
            "        [2.4359, 3.3369, 2.0517, 3.3520, 3.3731, 1.9259, 1.9923],\n",
            "        [3.2865, 4.0826, 2.3356, 4.0579, 4.1068, 2.4384, 2.4706]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "425\n",
            "tensor([[0.8672, 1.3722, 1.1100, 1.4440, 1.3197, 1.1310, 1.0333],\n",
            "        [0.9034, 1.4249, 1.1438, 1.4989, 1.3747, 1.1611, 1.0624],\n",
            "        [2.9502, 3.7942, 2.2196, 3.7870, 3.8345, 2.2126, 2.2674],\n",
            "        [1.0295, 1.5928, 1.2334, 1.6628, 1.5473, 1.2455, 1.1485],\n",
            "        [1.0291, 1.5884, 1.2267, 1.6562, 1.5416, 1.2444, 1.1455]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "426\n",
            "tensor([[0.9295, 1.4573, 1.1555, 1.5273, 1.4066, 1.1751, 1.0775],\n",
            "        [0.8721, 1.3827, 1.1168, 1.4554, 1.3295, 1.1380, 1.0394],\n",
            "        [1.1079, 1.7002, 1.2887, 1.7666, 1.6563, 1.2975, 1.2028],\n",
            "        [2.2638, 3.1643, 1.9783, 3.1860, 3.1941, 1.8460, 1.9011],\n",
            "        [1.9504, 2.7798, 1.8132, 2.8179, 2.7871, 1.7298, 1.7261]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "427\n",
            "tensor([[1.2248, 1.8558, 1.3698, 1.9203, 1.8184, 1.3656, 1.2810],\n",
            "        [3.1510, 3.9647, 2.2801, 3.9493, 3.9993, 2.3324, 2.3881],\n",
            "        [2.7735, 3.6415, 2.1555, 3.6382, 3.6817, 2.0897, 2.1686],\n",
            "        [3.1159, 3.9384, 2.2723, 3.9244, 3.9747, 2.3066, 2.3658],\n",
            "        [1.6360, 2.3914, 1.6350, 2.4432, 2.3796, 1.5913, 1.5425]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "428\n",
            "tensor([[2.5638, 3.4599, 2.0865, 3.4692, 3.4996, 1.9799, 2.0594],\n",
            "        [0.8997, 1.4144, 1.1281, 1.4855, 1.3626, 1.1545, 1.0574],\n",
            "        [3.1392, 3.9522, 2.2716, 3.9365, 3.9843, 2.3292, 2.3803],\n",
            "        [2.2996, 3.1356, 1.9412, 3.1555, 3.1530, 1.9083, 1.9143],\n",
            "        [1.1470, 1.7431, 1.3031, 1.8075, 1.7002, 1.3213, 1.2262]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "429\n",
            "tensor([[1.1417, 1.7448, 1.3131, 1.8122, 1.7051, 1.3194, 1.2275],\n",
            "        [3.1027, 3.9243, 2.2589, 3.9115, 3.9594, 2.3109, 2.3621],\n",
            "        [2.9464, 3.7869, 2.2055, 3.7819, 3.8261, 2.2181, 2.2747],\n",
            "        [1.8185, 2.6071, 1.7216, 2.6497, 2.6035, 1.6776, 1.6484],\n",
            "        [1.2623, 1.9041, 1.3943, 1.9678, 1.8696, 1.3944, 1.3083]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "430\n",
            "tensor([[3.0276, 3.8571, 2.2274, 3.8488, 3.8913, 2.2471, 2.3171],\n",
            "        [1.9394, 2.7589, 1.7911, 2.7986, 2.7645, 1.7325, 1.7231],\n",
            "        [1.9108, 2.7438, 1.7935, 2.7841, 2.7502, 1.7056, 1.7087],\n",
            "        [3.2577, 4.0540, 2.3053, 4.0327, 4.0798, 2.4118, 2.4581],\n",
            "        [1.2006, 1.8229, 1.3474, 1.8879, 1.7842, 1.3535, 1.2673]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "431\n",
            "tensor([[1.1957, 1.8165, 1.3447, 1.8830, 1.7787, 1.3524, 1.2660],\n",
            "        [1.2571, 1.8995, 1.3876, 1.9643, 1.8648, 1.3892, 1.3060],\n",
            "        [2.5415, 3.4341, 2.0681, 3.4433, 3.4730, 1.9731, 2.0505],\n",
            "        [2.1550, 3.0236, 1.9058, 3.0538, 3.0440, 1.8139, 1.8462],\n",
            "        [2.4285, 3.3344, 2.0318, 3.3480, 3.3732, 1.9019, 1.9887]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "432\n",
            "tensor([[0.9536, 1.4940, 1.1755, 1.5688, 1.4453, 1.1937, 1.1020],\n",
            "        [2.5142, 3.4089, 2.0572, 3.4231, 3.4458, 1.9560, 2.0381],\n",
            "        [2.1587, 3.0227, 1.9028, 3.0554, 3.0438, 1.8140, 1.8460],\n",
            "        [0.8742, 1.3803, 1.1075, 1.4538, 1.3271, 1.1350, 1.0421],\n",
            "        [3.1481, 3.9600, 2.2670, 3.9490, 3.9946, 2.3334, 2.3913]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "433\n",
            "tensor([[2.7543, 3.6088, 2.1314, 3.6169, 3.6487, 2.1028, 2.1674],\n",
            "        [1.4410, 2.1191, 1.4812, 2.1759, 2.0912, 1.4841, 1.4163],\n",
            "        [2.7202, 3.5940, 2.1294, 3.6015, 3.6380, 2.0625, 2.1481],\n",
            "        [1.1539, 1.7564, 1.3090, 1.8246, 1.7156, 1.3212, 1.2358],\n",
            "        [0.9079, 1.4305, 1.1394, 1.5063, 1.3807, 1.1593, 1.0685]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "434\n",
            "tensor([[3.1123, 3.9314, 2.2550, 3.9245, 3.9703, 2.2990, 2.3688],\n",
            "        [2.2108, 3.1013, 1.9414, 3.1333, 3.1328, 1.8124, 1.8773],\n",
            "        [0.7518, 1.2126, 1.0073, 1.2876, 1.1569, 1.0369, 0.9517],\n",
            "        [2.8067, 3.6685, 2.1550, 3.6704, 3.7140, 2.0969, 2.1897],\n",
            "        [3.2780, 4.0632, 2.3046, 4.0469, 4.0933, 2.4244, 2.4724]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "435\n",
            "tensor([[2.2593, 3.1495, 1.9613, 3.1811, 3.1823, 1.8377, 1.9050],\n",
            "        [3.2037, 4.0089, 2.2893, 3.9989, 4.0426, 2.3638, 2.4263],\n",
            "        [1.9910, 2.8276, 1.8246, 2.8719, 2.8430, 1.7387, 1.7550],\n",
            "        [0.8103, 1.2922, 1.0578, 1.3694, 1.2401, 1.0847, 0.9966],\n",
            "        [1.9369, 2.7513, 1.7826, 2.7940, 2.7586, 1.7194, 1.7210]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "436\n",
            "tensor([[1.2258, 1.8569, 1.3698, 1.9290, 1.8252, 1.3630, 1.2885],\n",
            "        [3.1728, 3.9785, 2.2784, 3.9735, 4.0197, 2.3354, 2.4077],\n",
            "        [1.3193, 1.9749, 1.4267, 2.0429, 1.9479, 1.4173, 1.3474],\n",
            "        [1.7676, 2.5442, 1.6957, 2.5962, 2.5416, 1.6452, 1.6249],\n",
            "        [2.6442, 3.5277, 2.1066, 3.5434, 3.5749, 2.0083, 2.1080]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "437\n",
            "tensor([[3.2777, 4.0534, 2.2936, 4.0372, 4.0770, 2.4140, 2.4760],\n",
            "        [3.3073, 4.0903, 2.3190, 4.0745, 4.1176, 2.4302, 2.4913],\n",
            "        [3.0874, 3.8987, 2.2510, 3.8985, 3.9449, 2.2854, 2.3542],\n",
            "        [3.3111, 4.0898, 2.3146, 4.0716, 4.1133, 2.4345, 2.4954],\n",
            "        [3.2962, 4.0810, 2.3191, 4.0692, 4.1142, 2.4251, 2.4860]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "438\n",
            "tensor([[1.3753, 2.0459, 1.4638, 2.1129, 2.0209, 1.4467, 1.3863],\n",
            "        [1.0815, 1.6567, 1.2611, 1.7301, 1.6162, 1.2700, 1.1895],\n",
            "        [3.1433, 3.9537, 2.2774, 3.9534, 4.0012, 2.3173, 2.3948],\n",
            "        [3.1997, 4.0061, 2.2947, 3.9989, 4.0422, 2.3482, 2.4279],\n",
            "        [0.8656, 1.3713, 1.1126, 1.4529, 1.3249, 1.1260, 1.0426]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "439\n",
            "tensor([[1.4355, 2.1202, 1.5017, 2.1875, 2.1008, 1.4752, 1.4256],\n",
            "        [2.6292, 3.5016, 2.1076, 3.5222, 3.5497, 2.0088, 2.1064],\n",
            "        [1.3532, 2.0149, 1.4536, 2.0851, 1.9914, 1.4315, 1.3737],\n",
            "        [0.9584, 1.4911, 1.1756, 1.5702, 1.4459, 1.1883, 1.1077],\n",
            "        [2.6549, 3.5311, 2.1183, 3.5495, 3.5819, 2.0152, 2.1211]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "440\n",
            "tensor([[1.3625, 2.0207, 1.4495, 2.0889, 1.9955, 1.4321, 1.3778],\n",
            "        [1.3327, 1.9824, 1.4323, 2.0515, 1.9554, 1.4191, 1.3595],\n",
            "        [1.1165, 1.6923, 1.2779, 1.7658, 1.6527, 1.2872, 1.2130],\n",
            "        [2.8851, 3.7301, 2.1967, 3.7445, 3.7843, 2.1418, 2.2514],\n",
            "        [3.1617, 3.9622, 2.2874, 3.9671, 4.0084, 2.3393, 2.4155]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "441\n",
            "tensor([[1.2269, 1.8380, 1.3526, 1.9087, 1.8043, 1.3508, 1.2875],\n",
            "        [1.7700, 2.5418, 1.7051, 2.5996, 2.5425, 1.6328, 1.6345],\n",
            "        [0.9307, 1.4525, 1.1597, 1.5338, 1.4080, 1.1679, 1.0899],\n",
            "        [3.3196, 4.0899, 2.3293, 4.0804, 4.1179, 2.4307, 2.5109],\n",
            "        [1.6729, 2.4178, 1.6481, 2.4782, 2.4132, 1.5952, 1.5754]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "442\n",
            "tensor([[1.8292, 2.6119, 1.7366, 2.6701, 2.6163, 1.6544, 1.6697],\n",
            "        [2.4611, 3.3480, 2.0537, 3.3797, 3.3932, 1.9130, 2.0270],\n",
            "        [0.9461, 1.4659, 1.1596, 1.5445, 1.4194, 1.1724, 1.0981],\n",
            "        [3.3466, 4.1135, 2.3397, 4.1046, 4.1423, 2.4457, 2.5286],\n",
            "        [0.8245, 1.3074, 1.0773, 1.3900, 1.2575, 1.0904, 1.0144]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "443\n",
            "tensor([[0.9354, 1.4555, 1.1586, 1.5378, 1.4101, 1.1666, 1.0947],\n",
            "        [3.2055, 3.9945, 2.3015, 3.9959, 4.0301, 2.3659, 2.4488],\n",
            "        [1.4434, 2.1288, 1.5161, 2.1994, 2.1092, 1.4723, 1.4375],\n",
            "        [3.3384, 4.1035, 2.3315, 4.0897, 4.1246, 2.4452, 2.5283],\n",
            "        [2.9360, 3.7685, 2.2168, 3.7848, 3.8178, 2.1726, 2.2869]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "444\n",
            "tensor([[2.0563, 2.8738, 1.8508, 2.9248, 2.8915, 1.7579, 1.8053],\n",
            "        [2.2253, 3.0909, 1.9495, 3.1329, 3.1233, 1.8120, 1.9016],\n",
            "        [2.3528, 3.2117, 1.9935, 3.2502, 3.2486, 1.8817, 1.9710],\n",
            "        [1.0523, 1.6074, 1.2378, 1.6864, 1.5664, 1.2439, 1.1757],\n",
            "        [3.3426, 4.1124, 2.3434, 4.1082, 4.1435, 2.4367, 2.5300]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "445\n",
            "tensor([[3.0214, 3.8393, 2.2403, 3.8527, 3.8828, 2.2059, 2.3380],\n",
            "        [2.1418, 2.9751, 1.8946, 3.0236, 2.9981, 1.7913, 1.8551],\n",
            "        [1.7363, 2.4964, 1.6874, 2.5596, 2.4966, 1.6112, 1.6196],\n",
            "        [1.7986, 2.5677, 1.7173, 2.6284, 2.5692, 1.6428, 1.6564],\n",
            "        [0.8784, 1.3711, 1.1055, 1.4516, 1.3220, 1.1222, 1.0514]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "446\n",
            "tensor([[0.9840, 1.5052, 1.1727, 1.5831, 1.4586, 1.1922, 1.1236],\n",
            "        [3.1090, 3.9149, 2.2708, 3.9263, 3.9622, 2.2688, 2.3906],\n",
            "        [1.2228, 1.8358, 1.3623, 1.9146, 1.8038, 1.3460, 1.2945],\n",
            "        [1.8061, 2.5565, 1.6967, 2.6130, 2.5534, 1.6465, 1.6545],\n",
            "        [0.9334, 1.4492, 1.1547, 1.5330, 1.4046, 1.1634, 1.0947]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "447\n",
            "tensor([[2.5400, 3.4315, 2.0832, 3.4609, 3.4783, 1.9257, 2.0746],\n",
            "        [2.8690, 3.7103, 2.1903, 3.7303, 3.7569, 2.1205, 2.2556],\n",
            "        [2.3982, 3.2606, 2.0138, 3.3007, 3.2984, 1.8951, 2.0004],\n",
            "        [3.3473, 4.1119, 2.3353, 4.1077, 4.1374, 2.4329, 2.5390],\n",
            "        [2.3910, 3.2559, 2.0121, 3.2961, 3.2947, 1.8841, 1.9956]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "Loss at epoch 6: 201.0437\n",
            "Pearson correlation for aspect 1: 0.6864\n",
            "Pearson correlation for aspect 2: 0.8190\n",
            "Pearson correlation for aspect 3: 0.3201\n",
            "Pearson correlation for aspect 4: 0.7693\n",
            "Pearson correlation for aspect 5: 0.8058\n",
            "Pearson correlation for aspect 6: 0.3892\n",
            "Pearson correlation for aspect 7: 0.4372\n",
            "Mean Pearson correlation: 0.6039\n",
            "0\n",
            "tensor([[1.5771, 2.2868, 1.5794, 2.3554, 2.2745, 1.5337, 1.5233],\n",
            "        [1.6104, 2.3233, 1.5914, 2.3900, 2.3116, 1.5487, 1.5410],\n",
            "        [0.9846, 1.5186, 1.1908, 1.6026, 1.4752, 1.1956, 1.1333],\n",
            "        [1.8534, 2.6123, 1.7226, 2.6706, 2.6128, 1.6729, 1.6874],\n",
            "        [1.8699, 2.6386, 1.7374, 2.6958, 2.6412, 1.6731, 1.6979]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "1\n",
            "tensor([[3.2414, 4.0195, 2.2940, 4.0215, 4.0539, 2.3417, 2.4717],\n",
            "        [2.1980, 3.0345, 1.9107, 3.0823, 3.0606, 1.8049, 1.8905],\n",
            "        [0.8253, 1.3043, 1.0706, 1.3902, 1.2543, 1.0828, 1.0190],\n",
            "        [1.8183, 2.5274, 1.6525, 2.5790, 2.5176, 1.6509, 1.6513],\n",
            "        [1.4780, 2.1643, 1.5216, 2.2371, 2.1459, 1.4824, 1.4632]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "2\n",
            "tensor([[3.3334, 4.0996, 2.3263, 4.0973, 4.1301, 2.4191, 2.5314],\n",
            "        [0.7805, 1.2425, 1.0320, 1.3261, 1.1897, 1.0485, 0.9849],\n",
            "        [2.4904, 3.3806, 2.0560, 3.4112, 3.4256, 1.8994, 2.0510],\n",
            "        [2.5683, 3.4357, 2.0759, 3.4681, 3.4798, 1.9588, 2.0943],\n",
            "        [3.0270, 3.8418, 2.2292, 3.8564, 3.8881, 2.2060, 2.3460]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "3\n",
            "tensor([[3.3506, 4.1136, 2.3314, 4.1100, 4.1399, 2.4345, 2.5472],\n",
            "        [1.4840, 2.1646, 1.5148, 2.2339, 2.1455, 1.4847, 1.4652],\n",
            "        [2.8646, 3.7052, 2.1719, 3.7241, 3.7495, 2.0988, 2.2557],\n",
            "        [3.2970, 4.0681, 2.3125, 4.0696, 4.1006, 2.3798, 2.5096],\n",
            "        [2.5946, 3.4612, 2.0842, 3.4926, 3.5069, 1.9700, 2.1098]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "4\n",
            "tensor([[2.4339, 3.3257, 2.0355, 3.3618, 3.3722, 1.8654, 2.0235],\n",
            "        [0.7514, 1.2027, 1.0121, 1.2901, 1.1522, 1.0271, 0.9667],\n",
            "        [1.0844, 1.6465, 1.2529, 1.7271, 1.6074, 1.2546, 1.2024],\n",
            "        [1.9960, 2.8012, 1.8103, 2.8577, 2.8148, 1.7161, 1.7797],\n",
            "        [0.9706, 1.4972, 1.1774, 1.5821, 1.4541, 1.1839, 1.1262]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "5\n",
            "tensor([[3.2057, 3.9905, 2.2899, 4.0011, 4.0354, 2.3255, 2.4580],\n",
            "        [2.8629, 3.6994, 2.1746, 3.7160, 3.7509, 2.0936, 2.2520],\n",
            "        [3.2542, 4.0363, 2.3047, 4.0426, 4.0743, 2.3544, 2.4886],\n",
            "        [3.3547, 4.1049, 2.3208, 4.1033, 4.1331, 2.4282, 2.5488],\n",
            "        [2.5774, 3.4556, 2.0838, 3.4878, 3.5054, 1.9379, 2.1011]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "6\n",
            "tensor([[2.2102, 3.0468, 1.9151, 3.0963, 3.0757, 1.8099, 1.9058],\n",
            "        [3.3418, 4.0919, 2.3109, 4.0891, 4.1173, 2.4222, 2.5451],\n",
            "        [3.3510, 4.1030, 2.3202, 4.1002, 4.1322, 2.4262, 2.5489],\n",
            "        [2.7962, 3.6423, 2.1536, 3.6672, 3.6971, 2.0580, 2.2207],\n",
            "        [0.7977, 1.2654, 1.0509, 1.3526, 1.2159, 1.0643, 1.0038]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "7\n",
            "tensor([[3.2183, 3.9969, 2.2906, 4.0042, 4.0423, 2.3192, 2.4670],\n",
            "        [3.3172, 4.0741, 2.3108, 4.0748, 4.1039, 2.4019, 2.5308],\n",
            "        [3.3308, 4.0915, 2.3242, 4.0952, 4.1287, 2.4134, 2.5400],\n",
            "        [1.6338, 2.3682, 1.6244, 2.4367, 2.3643, 1.5536, 1.5704],\n",
            "        [2.4452, 3.3387, 2.0406, 3.3740, 3.3866, 1.8731, 2.0367]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "8\n",
            "tensor([[3.3475, 4.0887, 2.3089, 4.0841, 4.1137, 2.4281, 2.5518],\n",
            "        [1.9942, 2.8117, 1.8276, 2.8701, 2.8331, 1.7169, 1.7895],\n",
            "        [3.2018, 3.9876, 2.2897, 3.9970, 4.0305, 2.3213, 2.4617],\n",
            "        [3.2721, 4.0412, 2.3081, 4.0451, 4.0776, 2.3643, 2.5027],\n",
            "        [2.3121, 3.1714, 1.9729, 3.2170, 3.2101, 1.8463, 1.9677]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "9\n",
            "tensor([[1.7463, 2.4869, 1.6726, 2.5524, 2.4878, 1.6178, 1.6384],\n",
            "        [0.9445, 1.4661, 1.1684, 1.5541, 1.4245, 1.1694, 1.1172],\n",
            "        [3.1740, 3.9544, 2.2766, 3.9665, 4.0009, 2.3059, 2.4488],\n",
            "        [2.6877, 3.5428, 2.1230, 3.5740, 3.5985, 2.0163, 2.1707],\n",
            "        [1.1575, 1.7470, 1.3160, 1.8296, 1.7143, 1.3012, 1.2632]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "10\n",
            "tensor([[0.7761, 1.2352, 1.0361, 1.3241, 1.1880, 1.0480, 0.9917],\n",
            "        [0.9000, 1.4026, 1.1323, 1.4908, 1.3598, 1.1394, 1.0844],\n",
            "        [1.1106, 1.6829, 1.2826, 1.7658, 1.6490, 1.2766, 1.2320],\n",
            "        [2.6473, 3.4507, 2.0778, 3.4888, 3.4953, 2.0523, 2.1530],\n",
            "        [0.8285, 1.3030, 1.0709, 1.3882, 1.2558, 1.0837, 1.0280]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "11\n",
            "tensor([[0.8575, 1.3416, 1.0953, 1.4285, 1.2975, 1.1039, 1.0508],\n",
            "        [1.6670, 2.4007, 1.6423, 2.4725, 2.4031, 1.5721, 1.5963],\n",
            "        [1.1486, 1.7270, 1.3035, 1.8088, 1.6951, 1.2961, 1.2564],\n",
            "        [1.6533, 2.3805, 1.6313, 2.4505, 2.3798, 1.5691, 1.5862],\n",
            "        [1.1869, 1.7739, 1.3249, 1.8534, 1.7427, 1.3198, 1.2808]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "12\n",
            "tensor([[1.1159, 1.6946, 1.3010, 1.7812, 1.6653, 1.2818, 1.2414],\n",
            "        [0.8944, 1.3898, 1.1222, 1.4754, 1.3473, 1.1281, 1.0773],\n",
            "        [0.8811, 1.3766, 1.1218, 1.4660, 1.3356, 1.1252, 1.0721],\n",
            "        [1.9808, 2.7833, 1.8186, 2.8456, 2.8086, 1.7078, 1.7846],\n",
            "        [2.4258, 3.3051, 2.0385, 3.3480, 3.3612, 1.8671, 2.0341]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "13\n",
            "tensor([[1.6787, 2.4176, 1.6559, 2.4897, 2.4242, 1.5767, 1.6061],\n",
            "        [3.0838, 3.8800, 2.2584, 3.8986, 3.9371, 2.2295, 2.3984],\n",
            "        [3.3212, 4.0620, 2.3145, 4.0663, 4.1004, 2.3997, 2.5400],\n",
            "        [1.3772, 2.0273, 1.4623, 2.1048, 2.0114, 1.4256, 1.4122],\n",
            "        [3.2474, 4.0153, 2.3112, 4.0294, 4.0681, 2.3467, 2.4982]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "14\n",
            "tensor([[1.5125, 2.1986, 1.5447, 2.2723, 2.1917, 1.4958, 1.5003],\n",
            "        [3.1639, 3.9428, 2.2758, 3.9576, 3.9970, 2.2754, 2.4435],\n",
            "        [2.0237, 2.8450, 1.8499, 2.9050, 2.8771, 1.7133, 1.8132],\n",
            "        [3.2764, 4.0368, 2.3147, 4.0448, 4.0824, 2.3586, 2.5151],\n",
            "        [0.8253, 1.2963, 1.0706, 1.3829, 1.2521, 1.0770, 1.0286]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "15\n",
            "tensor([[2.5384, 3.4004, 2.0705, 3.4362, 3.4582, 1.9163, 2.0953],\n",
            "        [1.3000, 1.9251, 1.4122, 2.0069, 1.9068, 1.3808, 1.3637],\n",
            "        [3.3513, 4.0874, 2.3281, 4.0917, 4.1274, 2.4155, 2.5624],\n",
            "        [0.8918, 1.3836, 1.1173, 1.4684, 1.3418, 1.1260, 1.0771],\n",
            "        [3.0057, 3.8089, 2.2285, 3.8325, 3.8709, 2.1735, 2.3545]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "16\n",
            "tensor([[3.3119, 4.0642, 2.3257, 4.0722, 4.1156, 2.3777, 2.5376],\n",
            "        [3.2087, 3.9760, 2.2946, 3.9908, 4.0350, 2.3213, 2.4769],\n",
            "        [1.2254, 1.8332, 1.3680, 1.9155, 1.8119, 1.3379, 1.3165],\n",
            "        [3.3147, 4.0618, 2.3247, 4.0687, 4.1104, 2.3792, 2.5404],\n",
            "        [1.4024, 2.0500, 1.4657, 2.1236, 2.0352, 1.4334, 1.4269]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "17\n",
            "tensor([[2.4156, 3.3070, 2.0351, 3.3437, 3.3670, 1.8355, 2.0336],\n",
            "        [0.8191, 1.2897, 1.0677, 1.3771, 1.2463, 1.0745, 1.0290],\n",
            "        [2.3050, 3.1754, 1.9844, 3.2203, 3.2272, 1.8105, 1.9755],\n",
            "        [0.9417, 1.4490, 1.1517, 1.5328, 1.4101, 1.1571, 1.1143],\n",
            "        [1.5241, 2.2099, 1.5436, 2.2811, 2.2038, 1.4976, 1.5088]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "18\n",
            "tensor([[2.5848, 3.4505, 2.0839, 3.4838, 3.5139, 1.9175, 2.1219],\n",
            "        [2.7580, 3.5953, 2.1403, 3.6224, 3.6581, 2.0234, 2.2181],\n",
            "        [1.8063, 2.5610, 1.7073, 2.6255, 2.5734, 1.6287, 1.6872],\n",
            "        [2.3474, 3.2158, 1.9946, 3.2601, 3.2679, 1.8245, 1.9986],\n",
            "        [2.2653, 3.1168, 1.9553, 3.1664, 3.1654, 1.8083, 1.9557]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "19\n",
            "tensor([[0.7666, 1.2194, 1.0268, 1.3073, 1.1751, 1.0354, 0.9908],\n",
            "        [1.9695, 2.7710, 1.8095, 2.8318, 2.7996, 1.6904, 1.7869],\n",
            "        [3.3216, 4.0709, 2.3174, 4.0746, 4.1167, 2.3910, 2.5485],\n",
            "        [0.8053, 1.2711, 1.0563, 1.3583, 1.2275, 1.0633, 1.0196],\n",
            "        [0.8521, 1.3324, 1.0886, 1.4190, 1.2909, 1.0954, 1.0531]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "20\n",
            "tensor([[0.8866, 1.3727, 1.1046, 1.4569, 1.3308, 1.1181, 1.0756],\n",
            "        [3.2406, 4.0001, 2.2924, 4.0113, 4.0543, 2.3213, 2.4999],\n",
            "        [3.2834, 4.0391, 2.3082, 4.0468, 4.0878, 2.3597, 2.5282],\n",
            "        [2.0634, 2.8875, 1.8602, 2.9460, 2.9234, 1.7246, 1.8433],\n",
            "        [3.3639, 4.0943, 2.3195, 4.0991, 4.1369, 2.4196, 2.5797]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "21\n",
            "tensor([[1.2298, 1.8272, 1.3457, 1.9055, 1.8028, 1.3352, 1.3173],\n",
            "        [1.2008, 1.7937, 1.3373, 1.8746, 1.7690, 1.3216, 1.3014],\n",
            "        [3.3633, 4.0960, 2.3179, 4.0965, 4.1349, 2.4262, 2.5815],\n",
            "        [1.9483, 2.7384, 1.7899, 2.7996, 2.7645, 1.6856, 1.7753],\n",
            "        [0.8145, 1.2797, 1.0555, 1.3652, 1.2350, 1.0669, 1.0246]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "22\n",
            "tensor([[1.9393, 2.7200, 1.7791, 2.7821, 2.7445, 1.6931, 1.7699],\n",
            "        [2.7224, 3.5588, 2.1261, 3.5911, 3.6247, 2.0266, 2.2062],\n",
            "        [0.9817, 1.5095, 1.1905, 1.5971, 1.4760, 1.1886, 1.1514],\n",
            "        [2.7890, 3.5884, 2.1323, 3.6214, 3.6495, 2.0959, 2.2439],\n",
            "        [1.9711, 2.7743, 1.8097, 2.8349, 2.8043, 1.6944, 1.7909]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "23\n",
            "tensor([[2.9077, 3.6967, 2.1737, 3.7207, 3.7591, 2.1520, 2.3088],\n",
            "        [1.9376, 2.7296, 1.7884, 2.7920, 2.7564, 1.6807, 1.7694],\n",
            "        [0.9006, 1.3969, 1.1254, 1.4820, 1.3576, 1.1337, 1.0902],\n",
            "        [0.7197, 1.1550, 0.9871, 1.2415, 1.1087, 1.0012, 0.9555],\n",
            "        [1.7693, 2.5122, 1.6868, 2.5798, 2.5266, 1.6221, 1.6680]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "24\n",
            "tensor([[3.3413, 4.0712, 2.3077, 4.0695, 4.1114, 2.4111, 2.5645],\n",
            "        [0.7057, 1.1396, 0.9814, 1.2273, 1.0950, 0.9940, 0.9465],\n",
            "        [2.7004, 3.5457, 2.1220, 3.5739, 3.6141, 2.0040, 2.1901],\n",
            "        [1.5319, 2.2242, 1.5536, 2.2975, 2.2219, 1.5078, 1.5213],\n",
            "        [3.3324, 4.0723, 2.3134, 4.0755, 4.1176, 2.4112, 2.5601]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "25\n",
            "tensor([[2.4397, 3.3232, 2.0400, 3.3603, 3.3878, 1.8680, 2.0511],\n",
            "        [1.9110, 2.7013, 1.7757, 2.7622, 2.7276, 1.6784, 1.7535],\n",
            "        [0.9465, 1.4671, 1.1708, 1.5540, 1.4319, 1.1721, 1.1280],\n",
            "        [2.0765, 2.9146, 1.8752, 2.9706, 2.9579, 1.7341, 1.8522],\n",
            "        [2.3884, 3.2579, 2.0135, 3.3002, 3.3191, 1.8592, 2.0238]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "26\n",
            "tensor([[2.4701, 3.3510, 2.0520, 3.3863, 3.4164, 1.8894, 2.0653],\n",
            "        [3.2226, 3.9774, 2.2818, 3.9874, 4.0319, 2.3311, 2.4845],\n",
            "        [3.3223, 4.0692, 2.3227, 4.0737, 4.1208, 2.4094, 2.5527],\n",
            "        [2.0985, 2.9388, 1.8863, 2.9929, 2.9792, 1.7509, 1.8646],\n",
            "        [1.8821, 2.6542, 1.7516, 2.7162, 2.6758, 1.6728, 1.7326]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "27\n",
            "tensor([[2.0936, 2.9194, 1.8764, 2.9723, 2.9549, 1.7592, 1.8575],\n",
            "        [2.5293, 3.4078, 2.0747, 3.4383, 3.4723, 1.9159, 2.0933],\n",
            "        [1.0220, 1.5375, 1.1733, 1.6082, 1.5010, 1.1953, 1.1530],\n",
            "        [3.1336, 3.9172, 2.2725, 3.9302, 3.9775, 2.2841, 2.4366],\n",
            "        [3.3391, 4.0788, 2.3265, 4.0801, 4.1248, 2.4268, 2.5607]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "28\n",
            "tensor([[2.2753, 3.1410, 1.9732, 3.1855, 3.1905, 1.8253, 1.9587],\n",
            "        [0.8437, 1.3309, 1.0954, 1.4164, 1.2879, 1.1030, 1.0500],\n",
            "        [0.7984, 1.2706, 1.0630, 1.3579, 1.2270, 1.0715, 1.0169],\n",
            "        [2.4975, 3.3760, 2.0657, 3.4104, 3.4384, 1.9053, 2.0758],\n",
            "        [2.5617, 3.4389, 2.0868, 3.4639, 3.5023, 1.9224, 2.1064]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "29\n",
            "tensor([[2.2826, 3.1291, 1.9642, 3.1703, 3.1730, 1.8395, 1.9571],\n",
            "        [2.3802, 3.2385, 2.0122, 3.2788, 3.2941, 1.8798, 2.0121],\n",
            "        [2.1442, 3.0105, 1.9293, 3.0591, 3.0543, 1.7640, 1.8858],\n",
            "        [2.8530, 3.6790, 2.1796, 3.6982, 3.7402, 2.1145, 2.2676],\n",
            "        [1.9392, 2.7493, 1.8074, 2.8063, 2.7754, 1.6946, 1.7653]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "30\n",
            "tensor([[1.9531, 2.7688, 1.8221, 2.8213, 2.7945, 1.7000, 1.7719],\n",
            "        [0.7904, 1.2600, 1.0552, 1.3418, 1.2139, 1.0620, 1.0062],\n",
            "        [1.7497, 2.5178, 1.7094, 2.5791, 2.5297, 1.6142, 1.6509],\n",
            "        [1.1266, 1.7141, 1.3111, 1.7930, 1.6864, 1.2923, 1.2501],\n",
            "        [2.4033, 3.2906, 2.0392, 3.3230, 3.3475, 1.8685, 2.0227]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "31\n",
            "tensor([[2.3475, 3.2454, 2.0270, 3.2745, 3.2996, 1.8409, 1.9902],\n",
            "        [2.3340, 3.2048, 2.0091, 3.2382, 3.2542, 1.8596, 1.9836],\n",
            "        [1.8269, 2.6156, 1.7555, 2.6698, 2.6327, 1.6483, 1.6944],\n",
            "        [2.3569, 3.2730, 2.0398, 3.2975, 3.3297, 1.8254, 1.9941],\n",
            "        [2.7678, 3.6214, 2.1677, 3.6340, 3.6797, 2.0528, 2.2152]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "32\n",
            "tensor([[2.3202, 3.2201, 2.0219, 3.2491, 3.2717, 1.8303, 1.9740],\n",
            "        [3.0359, 3.8312, 2.2503, 3.8376, 3.8881, 2.2356, 2.3641],\n",
            "        [2.1443, 3.0278, 1.9481, 3.0655, 3.0704, 1.7604, 1.8806],\n",
            "        [2.6937, 3.5624, 2.1485, 3.5727, 3.6211, 2.0061, 2.1697],\n",
            "        [1.8200, 2.6166, 1.7622, 2.6704, 2.6327, 1.6461, 1.6914]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "33\n",
            "tensor([[3.3130, 4.0647, 2.3360, 4.0537, 4.1042, 2.4243, 2.5335],\n",
            "        [1.6901, 2.4579, 1.6903, 2.5163, 2.4638, 1.5890, 1.6131],\n",
            "        [3.1382, 3.9326, 2.2931, 3.9311, 3.9848, 2.2926, 2.4233],\n",
            "        [0.9143, 1.4386, 1.1681, 1.5188, 1.3973, 1.1595, 1.1008],\n",
            "        [2.8977, 3.7324, 2.2165, 3.7409, 3.7912, 2.1409, 2.2853]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "34\n",
            "tensor([[1.3722, 2.0521, 1.4966, 2.1192, 2.0352, 1.4361, 1.4126],\n",
            "        [1.2049, 1.8222, 1.3711, 1.8909, 1.7934, 1.3403, 1.2968],\n",
            "        [0.7108, 1.1551, 0.9955, 1.2319, 1.1023, 1.0023, 0.9426],\n",
            "        [2.3219, 3.2042, 2.0151, 3.2302, 3.2472, 1.8480, 1.9713],\n",
            "        [2.1675, 3.0389, 1.9507, 3.0719, 3.0761, 1.7824, 1.8878]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "35\n",
            "tensor([[1.2034, 1.8224, 1.3708, 1.8894, 1.7935, 1.3372, 1.2951],\n",
            "        [1.2987, 1.9465, 1.4378, 2.0114, 1.9220, 1.3959, 1.3596],\n",
            "        [3.2299, 4.0102, 2.3272, 3.9977, 4.0520, 2.3599, 2.4731],\n",
            "        [0.7856, 1.2614, 1.0649, 1.3386, 1.2120, 1.0642, 1.0014],\n",
            "        [3.3078, 4.0695, 2.3467, 4.0524, 4.1049, 2.4034, 2.5211]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "36\n",
            "tensor([[1.5718, 2.3027, 1.6191, 2.3569, 2.2934, 1.5392, 1.5340],\n",
            "        [3.3056, 4.0601, 2.3418, 4.0392, 4.0912, 2.4079, 2.5174],\n",
            "        [1.9643, 2.7991, 1.8524, 2.8380, 2.8173, 1.7076, 1.7694],\n",
            "        [0.6781, 1.1126, 0.9754, 1.1893, 1.0588, 0.9794, 0.9174],\n",
            "        [2.3262, 3.2311, 2.0363, 3.2502, 3.2753, 1.8356, 1.9702]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "37\n",
            "tensor([[1.4418, 2.1336, 1.5364, 2.1930, 2.1166, 1.4734, 1.4514],\n",
            "        [2.0222, 2.8632, 1.8833, 2.9016, 2.8863, 1.7318, 1.8022],\n",
            "        [1.2944, 1.9463, 1.4458, 2.0113, 1.9209, 1.3962, 1.3582],\n",
            "        [0.7670, 1.2365, 1.0535, 1.3138, 1.1857, 1.0508, 0.9871],\n",
            "        [2.4432, 3.3455, 2.0841, 3.3611, 3.3955, 1.8906, 2.0330]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "38\n",
            "tensor([[3.2489, 4.0252, 2.3412, 4.0101, 4.0622, 2.3622, 2.4842],\n",
            "        [1.9579, 2.7810, 1.8455, 2.8217, 2.8026, 1.7070, 1.7631],\n",
            "        [2.8093, 3.6520, 2.1955, 3.6564, 3.7039, 2.0809, 2.2258],\n",
            "        [3.3299, 4.0820, 2.3564, 4.0600, 4.1108, 2.4405, 2.5364],\n",
            "        [1.9985, 2.8382, 1.8761, 2.8777, 2.8624, 1.7256, 1.7905]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "39\n",
            "tensor([[0.8701, 1.3770, 1.1390, 1.4548, 1.3315, 1.1302, 1.0648],\n",
            "        [3.2746, 4.0412, 2.3447, 4.0258, 4.0757, 2.3930, 2.5020],\n",
            "        [1.0060, 1.5628, 1.2428, 1.6364, 1.5218, 1.2206, 1.1618],\n",
            "        [0.7456, 1.2071, 1.0395, 1.2858, 1.1567, 1.0381, 0.9727],\n",
            "        [2.1034, 2.9581, 1.9272, 2.9947, 2.9889, 1.7700, 1.8493]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "40\n",
            "tensor([[1.5482, 2.2813, 1.6243, 2.3430, 2.2759, 1.5319, 1.5247],\n",
            "        [1.8418, 2.6444, 1.7915, 2.6943, 2.6585, 1.6643, 1.7011],\n",
            "        [1.1098, 1.7065, 1.3305, 1.7834, 1.6744, 1.2916, 1.2393],\n",
            "        [1.2301, 1.8571, 1.4010, 1.9266, 1.8283, 1.3656, 1.3159],\n",
            "        [2.9222, 3.7492, 2.2391, 3.7499, 3.8048, 2.1444, 2.2889]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "41\n",
            "tensor([[1.8809, 2.7083, 1.8308, 2.7578, 2.7278, 1.6723, 1.7276],\n",
            "        [3.2983, 4.0599, 2.3549, 4.0469, 4.0934, 2.4051, 2.5154],\n",
            "        [2.9317, 3.7617, 2.2447, 3.7647, 3.8118, 2.1548, 2.2993],\n",
            "        [2.5697, 3.4602, 2.1304, 3.4713, 3.5139, 1.9357, 2.0972],\n",
            "        [2.5296, 3.4128, 2.1140, 3.4329, 3.4635, 1.9457, 2.0819]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "42\n",
            "tensor([[0.9316, 1.4648, 1.1928, 1.5456, 1.4210, 1.1763, 1.1134],\n",
            "        [3.3060, 4.0636, 2.3528, 4.0480, 4.0921, 2.4214, 2.5230],\n",
            "        [0.7627, 1.2322, 1.0553, 1.3134, 1.1812, 1.0522, 0.9873],\n",
            "        [3.3114, 4.0724, 2.3604, 4.0560, 4.1020, 2.4203, 2.5260],\n",
            "        [0.7811, 1.2582, 1.0707, 1.3402, 1.2082, 1.0674, 1.0019]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "43\n",
            "tensor([[3.2482, 4.0238, 2.3418, 4.0175, 4.0628, 2.3718, 2.4871],\n",
            "        [1.2463, 1.8895, 1.4265, 1.9634, 1.8625, 1.3742, 1.3322],\n",
            "        [1.2789, 1.9212, 1.4318, 1.9911, 1.8920, 1.3933, 1.3480],\n",
            "        [0.7356, 1.1943, 1.0326, 1.2764, 1.1417, 1.0327, 0.9669],\n",
            "        [2.5156, 3.4065, 2.1132, 3.4280, 3.4551, 1.9425, 2.0749]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "44\n",
            "tensor([[0.8777, 1.3895, 1.1452, 1.4701, 1.3416, 1.1372, 1.0725],\n",
            "        [3.0801, 3.8856, 2.2884, 3.8831, 3.9262, 2.2526, 2.3831],\n",
            "        [3.2820, 4.0459, 2.3461, 4.0359, 4.0722, 2.4036, 2.5096],\n",
            "        [0.9777, 1.5218, 1.2183, 1.6003, 1.4766, 1.2082, 1.1439],\n",
            "        [3.3194, 4.0671, 2.3434, 4.0514, 4.0844, 2.4396, 2.5348]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "45\n",
            "tensor([[1.2979, 1.9629, 1.4663, 2.0396, 1.9379, 1.4106, 1.3721],\n",
            "        [2.3222, 3.2334, 2.0487, 3.2648, 3.2752, 1.8460, 1.9774],\n",
            "        [1.1877, 1.8111, 1.3836, 1.8892, 1.7773, 1.3460, 1.2952],\n",
            "        [2.3797, 3.2904, 2.0688, 3.3192, 3.3341, 1.8690, 2.0066],\n",
            "        [3.1525, 3.9477, 2.3182, 3.9479, 3.9854, 2.3058, 2.4324]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "46\n",
            "tensor([[0.7241, 1.1802, 1.0215, 1.2635, 1.1254, 1.0262, 0.9598],\n",
            "        [3.2135, 3.9965, 2.3339, 3.9977, 4.0338, 2.3492, 2.4689],\n",
            "        [3.3007, 4.0609, 2.3511, 4.0524, 4.0849, 2.4238, 2.5230],\n",
            "        [1.1977, 1.8256, 1.3907, 1.9036, 1.7919, 1.3533, 1.3026],\n",
            "        [2.6393, 3.5214, 2.1569, 3.5405, 3.5689, 2.0029, 2.1440]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "47\n",
            "tensor([[0.9841, 1.5371, 1.2292, 1.6198, 1.4913, 1.2170, 1.1536],\n",
            "        [2.3058, 3.1970, 2.0282, 3.2365, 3.2327, 1.8558, 1.9710],\n",
            "        [1.4085, 2.1110, 1.5421, 2.1856, 2.0896, 1.4723, 1.4454],\n",
            "        [2.0661, 2.9193, 1.9096, 2.9689, 2.9370, 1.7655, 1.8384],\n",
            "        [1.4009, 2.0935, 1.5283, 2.1673, 2.0726, 1.4639, 1.4368]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "48\n",
            "tensor([[1.6940, 2.4712, 1.7090, 2.5380, 2.4657, 1.6121, 1.6241],\n",
            "        [0.9272, 1.4663, 1.1980, 1.5550, 1.4196, 1.1836, 1.1192],\n",
            "        [2.3899, 3.2983, 2.0677, 3.3298, 3.3349, 1.8845, 2.0186],\n",
            "        [0.7604, 1.2348, 1.0581, 1.3219, 1.1805, 1.0599, 0.9926],\n",
            "        [3.0615, 3.8750, 2.2850, 3.8840, 3.9156, 2.2622, 2.3848]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "49\n",
            "tensor([[3.2198, 4.0069, 2.3307, 4.0101, 4.0326, 2.3731, 2.4889],\n",
            "        [3.3037, 4.0767, 2.3631, 4.0756, 4.0998, 2.4364, 2.5376],\n",
            "        [1.4915, 2.2200, 1.5924, 2.2951, 2.2034, 1.5125, 1.5017],\n",
            "        [1.3893, 2.0900, 1.5319, 2.1675, 2.0669, 1.4615, 1.4378],\n",
            "        [1.8733, 2.6949, 1.8121, 2.7557, 2.6994, 1.6915, 1.7343]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "50\n",
            "tensor([[0.9260, 1.4554, 1.1752, 1.5383, 1.4027, 1.1767, 1.1131],\n",
            "        [1.7926, 2.4906, 1.6512, 2.5362, 2.4651, 1.6741, 1.6491],\n",
            "        [3.2952, 4.0442, 2.3206, 4.0350, 4.0542, 2.4248, 2.5282],\n",
            "        [3.3204, 4.0858, 2.3552, 4.0849, 4.1045, 2.4483, 2.5489],\n",
            "        [0.8935, 1.4124, 1.1524, 1.4976, 1.3612, 1.1552, 1.0892]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "51\n",
            "tensor([[2.3260, 3.2325, 2.0320, 3.2715, 3.2599, 1.8590, 1.9896],\n",
            "        [0.7863, 1.2654, 1.0659, 1.3513, 1.2086, 1.0756, 1.0101],\n",
            "        [2.4284, 3.3489, 2.0778, 3.3813, 3.3858, 1.8886, 2.0429],\n",
            "        [2.2855, 3.1680, 2.0030, 3.2111, 3.1935, 1.8632, 1.9674],\n",
            "        [1.0834, 1.6700, 1.2939, 1.7525, 1.6260, 1.2821, 1.2260]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "52\n",
            "tensor([[1.6677, 2.4468, 1.6887, 2.5175, 2.4358, 1.6004, 1.6151],\n",
            "        [1.8478, 2.6709, 1.7876, 2.7329, 2.6683, 1.6720, 1.7205],\n",
            "        [2.7908, 3.6580, 2.1891, 3.6785, 3.6920, 2.0886, 2.2357],\n",
            "        [1.0375, 1.6125, 1.2647, 1.6986, 1.5654, 1.2558, 1.1981],\n",
            "        [1.5298, 2.2652, 1.5972, 2.3370, 2.2432, 1.5359, 1.5261]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "53\n",
            "tensor([[0.7557, 1.2284, 1.0434, 1.3167, 1.1694, 1.0542, 0.9907],\n",
            "        [1.6272, 2.3874, 1.6523, 2.4579, 2.3704, 1.5796, 1.5868],\n",
            "        [1.4692, 2.2000, 1.5727, 2.2776, 2.1761, 1.4998, 1.4922],\n",
            "        [2.3387, 3.2725, 2.0439, 3.3098, 3.3030, 1.8469, 1.9990],\n",
            "        [0.7299, 1.1933, 1.0227, 1.2825, 1.1341, 1.0343, 0.9709]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "54\n",
            "tensor([[0.8836, 1.4107, 1.1536, 1.5023, 1.3581, 1.1515, 1.0902],\n",
            "        [0.6755, 1.1226, 0.9840, 1.2148, 1.0642, 0.9930, 0.9323],\n",
            "        [2.1912, 3.1050, 1.9767, 3.1541, 3.1271, 1.7953, 1.9209],\n",
            "        [0.9833, 1.5442, 1.2252, 1.6327, 1.4945, 1.2172, 1.1608],\n",
            "        [1.3131, 1.9913, 1.4662, 2.0762, 1.9597, 1.4199, 1.3913]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "55\n",
            "tensor([[2.1830, 3.0976, 1.9745, 3.1482, 3.1213, 1.7902, 1.9182],\n",
            "        [1.4769, 2.2039, 1.5691, 2.2829, 2.1808, 1.5064, 1.4968],\n",
            "        [2.2687, 3.2119, 2.0210, 3.2553, 3.2421, 1.8095, 1.9648],\n",
            "        [1.1490, 1.7668, 1.3401, 1.8512, 1.7232, 1.3161, 1.2743],\n",
            "        [2.4940, 3.3941, 2.0851, 3.4346, 3.4264, 1.9475, 2.0845]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "56\n",
            "tensor([[1.6000, 2.3620, 1.6412, 2.4374, 2.3461, 1.5588, 1.5709],\n",
            "        [1.2752, 1.9474, 1.4439, 2.0331, 1.9138, 1.3982, 1.3672],\n",
            "        [2.5397, 3.4543, 2.1055, 3.4859, 3.4884, 1.9438, 2.1029],\n",
            "        [2.1296, 3.0270, 1.9423, 3.0823, 3.0475, 1.7769, 1.8870],\n",
            "        [3.2027, 4.0006, 2.3152, 4.0141, 4.0297, 2.3472, 2.4758]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "57\n",
            "tensor([[1.7137, 2.5192, 1.7235, 2.5911, 2.5134, 1.6098, 1.6447],\n",
            "        [2.4966, 3.4183, 2.0944, 3.4542, 3.4551, 1.9245, 2.0816],\n",
            "        [3.2752, 4.0531, 2.3275, 4.0566, 4.0691, 2.4095, 2.5177],\n",
            "        [2.3505, 3.2799, 2.0424, 3.3213, 3.3126, 1.8540, 2.0043],\n",
            "        [3.0806, 3.9043, 2.2732, 3.9204, 3.9327, 2.2576, 2.4020]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "58\n",
            "tensor([[3.3093, 4.0921, 2.3461, 4.0989, 4.1107, 2.4214, 2.5386],\n",
            "        [1.1988, 1.8373, 1.3802, 1.9227, 1.7996, 1.3484, 1.3091],\n",
            "        [3.3141, 4.0812, 2.3303, 4.0801, 4.0877, 2.4244, 2.5404],\n",
            "        [3.0193, 3.8573, 2.2584, 3.8766, 3.8904, 2.2261, 2.3661],\n",
            "        [3.2943, 4.0713, 2.3353, 4.0764, 4.0891, 2.4103, 2.5279]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "59\n",
            "tensor([[3.3321, 4.1043, 2.3439, 4.1049, 4.1147, 2.4414, 2.5525],\n",
            "        [0.9908, 1.5591, 1.2299, 1.6468, 1.5097, 1.2175, 1.1638],\n",
            "        [2.9733, 3.8195, 2.2385, 3.8382, 3.8481, 2.1806, 2.3341],\n",
            "        [0.9592, 1.5187, 1.2125, 1.6092, 1.4694, 1.1965, 1.1431],\n",
            "        [1.7011, 2.4981, 1.7043, 2.5684, 2.4885, 1.5990, 1.6316]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "60\n",
            "tensor([[1.7717, 2.5152, 1.6728, 2.5755, 2.4969, 1.6441, 1.6495],\n",
            "        [1.8287, 2.6607, 1.7819, 2.7274, 2.6598, 1.6553, 1.7090],\n",
            "        [2.0888, 2.9074, 1.8602, 2.9615, 2.9110, 1.7913, 1.8448],\n",
            "        [0.6703, 1.1157, 0.9740, 1.2049, 1.0562, 0.9799, 0.9233],\n",
            "        [0.9882, 1.5572, 1.2335, 1.6479, 1.5083, 1.2146, 1.1638]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "61\n",
            "tensor([[2.2954, 3.2230, 2.0193, 3.2671, 3.2501, 1.8316, 1.9713],\n",
            "        [1.0256, 1.6037, 1.2523, 1.6892, 1.5535, 1.2352, 1.1852],\n",
            "        [2.1359, 2.9751, 1.8935, 3.0239, 2.9796, 1.8040, 1.8708],\n",
            "        [3.2937, 4.0789, 2.3366, 4.0817, 4.0906, 2.3993, 2.5245],\n",
            "        [1.9315, 2.7795, 1.8288, 2.8408, 2.7811, 1.7023, 1.7677]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "62\n",
            "tensor([[2.9779, 3.8213, 2.2462, 3.8408, 3.8537, 2.1976, 2.3371],\n",
            "        [1.9547, 2.8209, 1.8523, 2.8789, 2.8261, 1.6981, 1.7800],\n",
            "        [1.8158, 2.6515, 1.7810, 2.7171, 2.6477, 1.6437, 1.6997],\n",
            "        [1.4310, 2.1551, 1.5453, 2.2328, 2.1270, 1.4708, 1.4622],\n",
            "        [1.5876, 2.3506, 1.6312, 2.4192, 2.3277, 1.5393, 1.5558]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "63\n",
            "tensor([[1.1692, 1.8135, 1.3747, 1.9001, 1.7715, 1.3255, 1.2913],\n",
            "        [3.1584, 3.9768, 2.2986, 3.9831, 3.9918, 2.2938, 2.4381],\n",
            "        [0.9838, 1.5517, 1.2262, 1.6377, 1.4985, 1.2077, 1.1567],\n",
            "        [1.8630, 2.6863, 1.7824, 2.7466, 2.6778, 1.6765, 1.7214],\n",
            "        [3.3089, 4.0811, 2.3233, 4.0785, 4.0825, 2.4069, 2.5297]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "64\n",
            "tensor([[0.6994, 1.1627, 1.0064, 1.2520, 1.0999, 1.0051, 0.9482],\n",
            "        [2.3389, 3.2928, 2.0424, 3.3245, 3.3152, 1.8220, 1.9903],\n",
            "        [3.2292, 4.0376, 2.3228, 4.0402, 4.0522, 2.3563, 2.4834],\n",
            "        [3.1190, 3.9480, 2.2807, 3.9519, 3.9625, 2.2730, 2.4163],\n",
            "        [2.7301, 3.6227, 2.1631, 3.6440, 3.6489, 2.0411, 2.1961]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "65\n",
            "tensor([[1.7725, 2.6039, 1.7528, 2.6666, 2.5907, 1.6225, 1.6735],\n",
            "        [3.3078, 4.0982, 2.3388, 4.0969, 4.1051, 2.4057, 2.5301],\n",
            "        [1.6413, 2.4227, 1.6604, 2.4869, 2.3972, 1.5680, 1.5894],\n",
            "        [0.8697, 1.3973, 1.1384, 1.4830, 1.3354, 1.1307, 1.0748],\n",
            "        [3.2965, 4.0906, 2.3377, 4.0895, 4.0969, 2.3957, 2.5247]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "66\n",
            "tensor([[3.2058, 4.0244, 2.3104, 4.0267, 4.0344, 2.3382, 2.4732],\n",
            "        [1.9302, 2.8045, 1.8369, 2.8591, 2.7987, 1.6798, 1.7661],\n",
            "        [3.2055, 4.0204, 2.3072, 4.0228, 4.0262, 2.3334, 2.4733],\n",
            "        [0.7961, 1.2914, 1.0714, 1.3756, 1.2261, 1.0740, 1.0172],\n",
            "        [3.2567, 4.0634, 2.3240, 4.0645, 4.0719, 2.3769, 2.5043]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "67\n",
            "tensor([[0.7941, 1.2933, 1.0719, 1.3773, 1.2260, 1.0732, 1.0193],\n",
            "        [3.1998, 4.0206, 2.3010, 4.0247, 4.0272, 2.3289, 2.4731],\n",
            "        [2.8475, 3.7250, 2.1865, 3.7353, 3.7378, 2.1043, 2.2655],\n",
            "        [1.3276, 2.0218, 1.4638, 2.0956, 1.9768, 1.4116, 1.3945],\n",
            "        [1.1679, 1.7987, 1.3424, 1.8749, 1.7448, 1.3205, 1.2839]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "68\n",
            "tensor([[0.8583, 1.3852, 1.1243, 1.4696, 1.3200, 1.1220, 1.0687],\n",
            "        [3.2475, 4.0587, 2.3132, 4.0579, 4.0593, 2.3677, 2.5056],\n",
            "        [1.6507, 2.4463, 1.6652, 2.5076, 2.4151, 1.5716, 1.6026],\n",
            "        [3.1959, 4.0154, 2.2958, 4.0145, 4.0178, 2.3323, 2.4706],\n",
            "        [3.2434, 4.0577, 2.3138, 4.0539, 4.0558, 2.3643, 2.5015]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "69\n",
            "tensor([[1.2785, 1.9608, 1.4309, 2.0351, 1.9111, 1.3868, 1.3657],\n",
            "        [1.5989, 2.3781, 1.6280, 2.4414, 2.3435, 1.5536, 1.5714],\n",
            "        [3.3068, 4.1057, 2.3238, 4.0985, 4.0980, 2.4079, 2.5435],\n",
            "        [1.9398, 2.8162, 1.8281, 2.8658, 2.8024, 1.6921, 1.7774],\n",
            "        [2.2412, 3.1870, 1.9834, 3.2203, 3.1922, 1.7957, 1.9473]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "70\n",
            "tensor([[3.0940, 3.9314, 2.2521, 3.9329, 3.9338, 2.2471, 2.4107],\n",
            "        [0.8812, 1.4140, 1.1342, 1.4953, 1.3472, 1.1367, 1.0850],\n",
            "        [2.2911, 3.2340, 1.9944, 3.2641, 3.2380, 1.8187, 1.9749],\n",
            "        [2.9685, 3.8280, 2.2129, 3.8324, 3.8313, 2.1620, 2.3372],\n",
            "        [2.6315, 3.5539, 2.1118, 3.5694, 3.5658, 1.9768, 2.1527]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "71\n",
            "tensor([[0.8284, 1.3428, 1.0932, 1.4240, 1.2727, 1.0981, 1.0466],\n",
            "        [0.8643, 1.3911, 1.1189, 1.4725, 1.3233, 1.1246, 1.0730],\n",
            "        [2.0510, 2.9478, 1.8771, 2.9906, 2.9392, 1.7293, 1.8413],\n",
            "        [2.2235, 3.1589, 1.9626, 3.1925, 3.1594, 1.7919, 1.9392],\n",
            "        [2.2362, 3.1853, 1.9773, 3.2173, 3.1888, 1.7851, 1.9456]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "72\n",
            "tensor([[0.9896, 1.5600, 1.2066, 1.6375, 1.4945, 1.2057, 1.1614],\n",
            "        [3.2448, 4.0595, 2.2973, 4.0537, 4.0556, 2.3606, 2.5042],\n",
            "        [2.8054, 3.6982, 2.1575, 3.7077, 3.7078, 2.0691, 2.2478],\n",
            "        [1.0282, 1.6195, 1.2432, 1.6978, 1.5566, 1.2348, 1.1923],\n",
            "        [0.7997, 1.3043, 1.0698, 1.3875, 1.2348, 1.0767, 1.0261]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "73\n",
            "tensor([[2.3550, 3.3094, 2.0127, 3.3315, 3.3150, 1.8288, 2.0075],\n",
            "        [2.3900, 3.3413, 2.0237, 3.3630, 3.3495, 1.8438, 2.0252],\n",
            "        [1.0261, 1.6175, 1.2423, 1.6975, 1.5555, 1.2319, 1.1919],\n",
            "        [0.9876, 1.5611, 1.2068, 1.6381, 1.4955, 1.2050, 1.1609],\n",
            "        [1.6357, 2.4216, 1.6328, 2.4782, 2.3836, 1.5598, 1.5921]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "74\n",
            "tensor([[1.7507, 2.5788, 1.7089, 2.6343, 2.5539, 1.6024, 1.6641],\n",
            "        [1.9408, 2.7909, 1.7924, 2.8376, 2.7722, 1.7000, 1.7730],\n",
            "        [0.9470, 1.5119, 1.1859, 1.5924, 1.4469, 1.1803, 1.1357],\n",
            "        [1.5158, 2.2676, 1.5584, 2.3283, 2.2258, 1.4986, 1.5150],\n",
            "        [3.0351, 3.8837, 2.2226, 3.8863, 3.8917, 2.2091, 2.3770]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "75\n",
            "tensor([[2.6895, 3.6014, 2.1082, 3.6121, 3.6137, 1.9926, 2.1823],\n",
            "        [3.2426, 4.0547, 2.2787, 4.0466, 4.0495, 2.3477, 2.5018],\n",
            "        [3.0996, 3.9399, 2.2360, 3.9369, 3.9414, 2.2468, 2.4176],\n",
            "        [2.4641, 3.4166, 2.0422, 3.4287, 3.4247, 1.8648, 2.0607],\n",
            "        [1.2503, 1.9152, 1.3846, 1.9835, 1.8591, 1.3624, 1.3423]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "76\n",
            "tensor([[1.5359, 2.2988, 1.5706, 2.3598, 2.2596, 1.5109, 1.5320],\n",
            "        [1.8226, 2.6643, 1.7359, 2.7137, 2.6389, 1.6375, 1.7068],\n",
            "        [1.0938, 1.7147, 1.2874, 1.7903, 1.6542, 1.2711, 1.2394],\n",
            "        [2.2501, 3.1891, 1.9511, 3.2154, 3.1898, 1.7867, 1.9489],\n",
            "        [2.0455, 2.9421, 1.8540, 2.9827, 2.9312, 1.7219, 1.8372]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "77\n",
            "tensor([[2.2688, 3.2292, 1.9663, 3.2522, 3.2314, 1.7818, 1.9621],\n",
            "        [1.5934, 2.3833, 1.6076, 2.4423, 2.3469, 1.5311, 1.5697],\n",
            "        [3.1712, 3.9962, 2.2453, 3.9923, 3.9945, 2.2907, 2.4597],\n",
            "        [0.8681, 1.4042, 1.1175, 1.4853, 1.3363, 1.1249, 1.0787],\n",
            "        [0.8534, 1.3767, 1.0953, 1.4547, 1.3061, 1.1115, 1.0631]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "78\n",
            "tensor([[2.9015, 3.7837, 2.1556, 3.7855, 3.7845, 2.1201, 2.3051],\n",
            "        [1.7678, 2.6076, 1.7022, 2.6583, 2.5771, 1.6084, 1.6763],\n",
            "        [3.2487, 4.0549, 2.2574, 4.0418, 4.0445, 2.3403, 2.5020],\n",
            "        [0.9990, 1.5872, 1.2120, 1.6631, 1.5189, 1.2127, 1.1741],\n",
            "        [1.4341, 2.1759, 1.5059, 2.2385, 2.1274, 1.4584, 1.4691]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "79\n",
            "tensor([[3.2096, 4.0312, 2.2451, 4.0192, 4.0212, 2.3281, 2.4824],\n",
            "        [2.3985, 3.3393, 1.9884, 3.3590, 3.3397, 1.8643, 2.0324],\n",
            "        [3.1139, 3.9525, 2.2172, 3.9472, 3.9456, 2.2796, 2.4310],\n",
            "        [2.6722, 3.5971, 2.0829, 3.6021, 3.5970, 1.9761, 2.1763],\n",
            "        [3.3102, 4.1094, 2.2685, 4.0932, 4.0894, 2.3971, 2.5471]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "80\n",
            "tensor([[0.8895, 1.4390, 1.1247, 1.5166, 1.3668, 1.1438, 1.0958],\n",
            "        [3.3032, 4.1062, 2.2638, 4.0905, 4.0893, 2.3906, 2.5436],\n",
            "        [0.7870, 1.2998, 1.0523, 1.3818, 1.2274, 1.0705, 1.0218],\n",
            "        [2.2116, 3.1564, 1.9154, 3.1821, 3.1478, 1.7742, 1.9328],\n",
            "        [1.4641, 2.2173, 1.5158, 2.2788, 2.1685, 1.4770, 1.4899]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "81\n",
            "tensor([[0.7610, 1.2599, 1.0232, 1.3389, 1.1849, 1.0508, 0.9999],\n",
            "        [0.9727, 1.5576, 1.1875, 1.6327, 1.4878, 1.1999, 1.1575],\n",
            "        [3.0843, 3.9260, 2.1958, 3.9185, 3.9186, 2.2635, 2.4126],\n",
            "        [1.5311, 2.3038, 1.5484, 2.3612, 2.2561, 1.5087, 1.5322],\n",
            "        [1.5064, 2.2765, 1.5411, 2.3357, 2.2288, 1.4975, 1.5182]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "82\n",
            "tensor([[2.6529, 3.5831, 2.0589, 3.5885, 3.5838, 1.9667, 2.1666],\n",
            "        [1.9665, 2.8672, 1.7936, 2.9058, 2.8440, 1.6933, 1.7977],\n",
            "        [1.3645, 2.0949, 1.4534, 2.1574, 2.0395, 1.4305, 1.4265],\n",
            "        [1.6215, 2.4236, 1.5983, 2.4748, 2.3784, 1.5523, 1.5871],\n",
            "        [2.3537, 3.3399, 1.9772, 3.3485, 3.3380, 1.8079, 2.0079]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "83\n",
            "tensor([[0.8415, 1.3789, 1.0910, 1.4592, 1.3075, 1.1118, 1.0634],\n",
            "        [2.4195, 3.3883, 1.9922, 3.3977, 3.3861, 1.8551, 2.0424],\n",
            "        [3.0268, 3.8924, 2.1758, 3.8871, 3.8910, 2.2048, 2.3767],\n",
            "        [2.8877, 3.7769, 2.1325, 3.7782, 3.7766, 2.1235, 2.2981],\n",
            "        [3.3152, 4.1184, 2.2560, 4.0993, 4.0958, 2.4029, 2.5526]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "84\n",
            "tensor([[1.4644, 2.2135, 1.4958, 2.2707, 2.1609, 1.4827, 1.4869],\n",
            "        [3.1019, 3.9530, 2.1961, 3.9483, 3.9477, 2.2560, 2.4221],\n",
            "        [3.0166, 3.8850, 2.1704, 3.8808, 3.8824, 2.2003, 2.3703],\n",
            "        [1.7789, 2.6375, 1.6933, 2.6849, 2.6046, 1.6162, 1.6863],\n",
            "        [1.3164, 2.0308, 1.4186, 2.0952, 1.9739, 1.4089, 1.3950]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "85\n",
            "tensor([[2.2170, 3.1552, 1.8981, 3.1813, 3.1485, 1.7920, 1.9349],\n",
            "        [2.3894, 3.3656, 1.9789, 3.3768, 3.3673, 1.8359, 2.0268],\n",
            "        [0.7641, 1.2653, 1.0210, 1.3445, 1.1917, 1.0578, 1.0022],\n",
            "        [3.3321, 4.1290, 2.2541, 4.1126, 4.1076, 2.4205, 2.5617],\n",
            "        [2.3294, 3.3159, 1.9605, 3.3271, 3.3167, 1.8007, 1.9945]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "86\n",
            "tensor([[2.4001, 3.3640, 1.9743, 3.3774, 3.3652, 1.8518, 2.0312],\n",
            "        [2.6179, 3.5556, 2.0422, 3.5620, 3.5599, 1.9573, 2.1449],\n",
            "        [2.9607, 3.8327, 2.1489, 3.8351, 3.8371, 2.1784, 2.3403],\n",
            "        [0.8999, 1.4570, 1.1230, 1.5332, 1.3849, 1.1526, 1.1025],\n",
            "        [2.8736, 3.7628, 2.1168, 3.7617, 3.7646, 2.0981, 2.2851]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "87\n",
            "tensor([[2.0596, 2.9783, 1.8232, 3.0124, 2.9635, 1.7328, 1.8471],\n",
            "        [0.9644, 1.5526, 1.1768, 1.6298, 1.4844, 1.2006, 1.1529],\n",
            "        [3.1049, 3.9515, 2.1814, 3.9469, 3.9494, 2.2537, 2.4198],\n",
            "        [1.6655, 2.4746, 1.6051, 2.5249, 2.4334, 1.5812, 1.6117],\n",
            "        [2.1454, 3.0806, 1.8617, 3.1101, 3.0711, 1.7595, 1.8932]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "88\n",
            "tensor([[0.7108, 1.1905, 0.9719, 1.2682, 1.1155, 1.0132, 0.9577],\n",
            "        [1.6482, 2.4449, 1.5811, 2.4929, 2.4025, 1.5649, 1.5932],\n",
            "        [2.9144, 3.7987, 2.1199, 3.7953, 3.7988, 2.1229, 2.3043],\n",
            "        [0.8049, 1.3224, 1.0449, 1.3996, 1.2486, 1.0873, 1.0298],\n",
            "        [3.1895, 4.0213, 2.2051, 4.0094, 4.0157, 2.3158, 2.4672]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "89\n",
            "tensor([[1.9681, 2.8397, 1.7453, 2.8734, 2.8150, 1.6995, 1.7810],\n",
            "        [1.1459, 1.7928, 1.2850, 1.8605, 1.7291, 1.3055, 1.2716],\n",
            "        [1.2908, 1.9728, 1.3588, 2.0312, 1.9110, 1.3846, 1.3627],\n",
            "        [2.5385, 3.4915, 2.0011, 3.4965, 3.4940, 1.9105, 2.0972],\n",
            "        [1.6164, 2.4217, 1.5806, 2.4756, 2.3819, 1.5515, 1.5809]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "90\n",
            "tensor([[2.6586, 3.5854, 2.0297, 3.5882, 3.5867, 1.9638, 2.1542],\n",
            "        [0.8456, 1.3750, 1.0675, 1.4493, 1.3014, 1.1126, 1.0553],\n",
            "        [2.0982, 2.9266, 1.7572, 2.9587, 2.9000, 1.7808, 1.8447],\n",
            "        [0.7770, 1.2862, 1.0256, 1.3659, 1.2133, 1.0667, 1.0087],\n",
            "        [3.2686, 4.0798, 2.2177, 4.0674, 4.0717, 2.3698, 2.5101]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "91\n",
            "tensor([[3.3492, 4.1358, 2.2266, 4.1127, 4.1146, 2.4293, 2.5558],\n",
            "        [1.3511, 2.0635, 1.4056, 2.1239, 2.0061, 1.4217, 1.4041],\n",
            "        [1.1657, 1.8193, 1.2953, 1.8877, 1.7574, 1.3219, 1.2844],\n",
            "        [2.2637, 3.2220, 1.8988, 3.2397, 3.2189, 1.7863, 1.9453],\n",
            "        [0.7568, 1.2535, 1.0021, 1.3303, 1.1783, 1.0486, 0.9892]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "92\n",
            "tensor([[1.0727, 1.6911, 1.2285, 1.7623, 1.6256, 1.2642, 1.2162],\n",
            "        [1.6227, 2.4218, 1.5663, 2.4727, 2.3805, 1.5510, 1.5733],\n",
            "        [2.9016, 3.7803, 2.0946, 3.7803, 3.7877, 2.1290, 2.2862],\n",
            "        [0.6983, 1.1698, 0.9523, 1.2472, 1.0951, 1.0031, 0.9426],\n",
            "        [2.7334, 3.6017, 2.0248, 3.6121, 3.6032, 2.0692, 2.1967]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "93\n",
            "tensor([[0.9284, 1.4895, 1.1196, 1.5628, 1.4180, 1.1700, 1.1113],\n",
            "        [1.8243, 2.6677, 1.6667, 2.7111, 2.6379, 1.6420, 1.6918],\n",
            "        [1.2695, 1.9648, 1.3648, 2.0298, 1.9090, 1.3771, 1.3513],\n",
            "        [3.3104, 4.1072, 2.2105, 4.0895, 4.0927, 2.3889, 2.5237],\n",
            "        [1.5633, 2.3426, 1.5288, 2.3969, 2.2994, 1.5260, 1.5352]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "94\n",
            "tensor([[2.6953, 3.6159, 2.0243, 3.6162, 3.6224, 1.9833, 2.1630],\n",
            "        [0.7039, 1.1809, 0.9591, 1.2609, 1.1094, 1.0103, 0.9467],\n",
            "        [3.3597, 4.1447, 2.2190, 4.1247, 4.1284, 2.4335, 2.5531],\n",
            "        [2.3782, 3.3246, 1.9208, 3.3389, 3.3270, 1.8440, 1.9981],\n",
            "        [1.5475, 2.3332, 1.5279, 2.3901, 2.2925, 1.5167, 1.5276]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "95\n",
            "tensor([[0.8930, 1.4443, 1.0976, 1.5215, 1.3753, 1.1505, 1.0858],\n",
            "        [3.2615, 4.0705, 2.1926, 4.0610, 4.0632, 2.3537, 2.4867],\n",
            "        [1.4263, 2.1718, 1.4529, 2.2332, 2.1234, 1.4632, 1.4491],\n",
            "        [2.8891, 3.7760, 2.0829, 3.7754, 3.7812, 2.1106, 2.2702],\n",
            "        [1.4069, 2.1284, 1.4222, 2.1866, 2.0784, 1.4501, 1.4275]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "96\n",
            "tensor([[3.1482, 3.9826, 2.1563, 3.9750, 3.9834, 2.2751, 2.4163],\n",
            "        [2.1100, 3.0130, 1.7972, 3.0455, 3.0057, 1.7481, 1.8441],\n",
            "        [2.8605, 3.7467, 2.0699, 3.7459, 3.7563, 2.0795, 2.2456],\n",
            "        [2.1792, 3.1331, 1.8546, 3.1595, 3.1336, 1.7526, 1.8875],\n",
            "        [1.3123, 2.0077, 1.3664, 2.0709, 1.9525, 1.3975, 1.3660]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "97\n",
            "tensor([[1.1286, 1.7667, 1.2575, 1.8398, 1.7097, 1.2976, 1.2460],\n",
            "        [1.3691, 2.0906, 1.4114, 2.1572, 2.0437, 1.4348, 1.4064],\n",
            "        [0.9501, 1.5281, 1.1438, 1.6079, 1.4645, 1.1879, 1.1258],\n",
            "        [2.9967, 3.8564, 2.1077, 3.8584, 3.8675, 2.1715, 2.3209],\n",
            "        [2.8602, 3.7456, 2.0691, 3.7487, 3.7554, 2.0947, 2.2447]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "98\n",
            "tensor([[0.8855, 1.4385, 1.0959, 1.5196, 1.3732, 1.1445, 1.0785],\n",
            "        [3.2730, 4.0796, 2.1912, 4.0708, 4.0808, 2.3656, 2.4832],\n",
            "        [0.7656, 1.2629, 0.9952, 1.3426, 1.1936, 1.0552, 0.9859],\n",
            "        [0.8065, 1.3199, 1.0252, 1.3982, 1.2513, 1.0866, 1.0154],\n",
            "        [1.1867, 1.8430, 1.2898, 1.9130, 1.7866, 1.3324, 1.2825]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "99\n",
            "tensor([[1.6595, 2.4720, 1.5786, 2.5266, 2.4428, 1.5668, 1.5817],\n",
            "        [2.8634, 3.7474, 2.0627, 3.7482, 3.7584, 2.0908, 2.2399],\n",
            "        [0.9918, 1.5819, 1.1630, 1.6591, 1.5201, 1.2128, 1.1498],\n",
            "        [2.9295, 3.8051, 2.0794, 3.8098, 3.8171, 2.1135, 2.2781],\n",
            "        [2.4061, 3.3522, 1.9207, 3.3708, 3.3641, 1.8563, 1.9955]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "100\n",
            "tensor([[1.0070, 1.6025, 1.1720, 1.6791, 1.5429, 1.2237, 1.1579],\n",
            "        [2.3635, 3.3402, 1.9138, 3.3534, 3.3566, 1.8068, 1.9690],\n",
            "        [3.0731, 3.9209, 2.1246, 3.9196, 3.9327, 2.2143, 2.3553],\n",
            "        [3.3172, 4.0922, 2.1731, 4.0779, 4.0876, 2.3914, 2.5018],\n",
            "        [2.2043, 3.1368, 1.8381, 3.1657, 3.1413, 1.7746, 1.8867]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "101\n",
            "tensor([[2.3667, 3.3409, 1.9103, 3.3572, 3.3574, 1.8150, 1.9707],\n",
            "        [1.3752, 2.1031, 1.4090, 2.1690, 2.0607, 1.4366, 1.4037],\n",
            "        [3.3239, 4.1003, 2.1771, 4.0864, 4.0950, 2.4042, 2.5050],\n",
            "        [1.6135, 2.4117, 1.5410, 2.4671, 2.3798, 1.5425, 1.5471],\n",
            "        [1.1837, 1.8366, 1.2772, 1.9072, 1.7838, 1.3253, 1.2739]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "102\n",
            "tensor([[2.6979, 3.6165, 2.0031, 3.6288, 3.6383, 1.9759, 2.1413],\n",
            "        [0.8520, 1.3853, 1.0555, 1.4660, 1.3219, 1.1192, 1.0461],\n",
            "        [3.2183, 4.0395, 2.1645, 4.0375, 4.0509, 2.3291, 2.4432],\n",
            "        [1.2800, 1.9820, 1.3575, 2.0553, 1.9392, 1.3852, 1.3438],\n",
            "        [0.8165, 1.3407, 1.0366, 1.4239, 1.2781, 1.0956, 1.0229]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "103\n",
            "tensor([[2.2409, 3.2023, 1.8581, 3.2297, 3.2186, 1.7758, 1.9038],\n",
            "        [2.7765, 3.6769, 2.0268, 3.6877, 3.7033, 2.0465, 2.1840],\n",
            "        [3.2273, 4.0414, 2.1559, 4.0376, 4.0481, 2.3235, 2.4445],\n",
            "        [3.1979, 4.0265, 2.1571, 4.0254, 4.0405, 2.3115, 2.4303],\n",
            "        [0.8459, 1.3821, 1.0584, 1.4657, 1.3205, 1.1182, 1.0439]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "104\n",
            "tensor([[3.2299, 4.0523, 2.1611, 4.0478, 4.0605, 2.3329, 2.4466],\n",
            "        [1.3904, 2.0480, 1.3304, 2.1041, 2.0007, 1.4340, 1.3800],\n",
            "        [3.1809, 4.0109, 2.1486, 4.0084, 4.0260, 2.2919, 2.4155],\n",
            "        [0.8342, 1.3691, 1.0526, 1.4543, 1.3094, 1.1118, 1.0369],\n",
            "        [2.2175, 3.1730, 1.8459, 3.2048, 3.1886, 1.7734, 1.8905]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "105\n",
            "tensor([[2.0785, 3.0197, 1.7923, 3.0602, 3.0297, 1.7223, 1.8176],\n",
            "        [0.7773, 1.2878, 1.0066, 1.3735, 1.2268, 1.0691, 0.9927],\n",
            "        [2.8663, 3.7582, 2.0527, 3.7692, 3.7846, 2.0882, 2.2343],\n",
            "        [2.9748, 3.8463, 2.0843, 3.8538, 3.8711, 2.1770, 2.2974],\n",
            "        [2.3351, 3.3027, 1.8906, 3.3279, 3.3261, 1.8177, 1.9510]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "106\n",
            "tensor([[1.9008, 2.7752, 1.6855, 2.8257, 2.7713, 1.6738, 1.7134],\n",
            "        [2.0054, 2.9134, 1.7449, 2.9595, 2.9174, 1.7063, 1.7732],\n",
            "        [2.5837, 3.5312, 1.9646, 3.5457, 3.5563, 1.9335, 2.0771],\n",
            "        [3.3152, 4.1125, 2.1808, 4.1058, 4.1169, 2.4026, 2.4965],\n",
            "        [0.9925, 1.5847, 1.1545, 1.6654, 1.5313, 1.2166, 1.1447]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "107\n",
            "tensor([[1.4172, 2.1551, 1.4212, 2.2237, 2.1226, 1.4607, 1.4231],\n",
            "        [0.8030, 1.3225, 1.0248, 1.4081, 1.2633, 1.0908, 1.0111],\n",
            "        [3.3037, 4.1089, 2.1843, 4.1066, 4.1211, 2.3998, 2.4888],\n",
            "        [0.9789, 1.5720, 1.1545, 1.6546, 1.5184, 1.2149, 1.1381],\n",
            "        [1.5610, 2.3560, 1.5151, 2.4212, 2.3325, 1.5259, 1.5152]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "108\n",
            "tensor([[0.8159, 1.3426, 1.0393, 1.4306, 1.2852, 1.1027, 1.0219],\n",
            "        [2.2266, 3.2006, 1.8573, 3.2332, 3.2233, 1.7678, 1.8906],\n",
            "        [1.0055, 1.6066, 1.1708, 1.6895, 1.5556, 1.2303, 1.1545],\n",
            "        [3.0338, 3.8924, 2.1020, 3.9025, 3.9177, 2.2091, 2.3252],\n",
            "        [1.0323, 1.6406, 1.1849, 1.7220, 1.5894, 1.2455, 1.1724]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "109\n",
            "tensor([[1.3469, 2.0683, 1.3901, 2.1414, 2.0347, 1.4293, 1.3799],\n",
            "        [3.3244, 4.1031, 2.1749, 4.0981, 4.1107, 2.4206, 2.4964],\n",
            "        [1.8162, 2.6862, 1.6579, 2.7415, 2.6817, 1.6334, 1.6639],\n",
            "        [1.5087, 2.2839, 1.4852, 2.3521, 2.2592, 1.5049, 1.4811],\n",
            "        [1.3471, 2.0745, 1.3964, 2.1498, 2.0418, 1.4258, 1.3818]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "110\n",
            "tensor([[0.7356, 1.2286, 0.9780, 1.3170, 1.1682, 1.0426, 0.9613],\n",
            "        [3.1929, 4.0202, 2.1534, 4.0220, 4.0386, 2.3152, 2.4142],\n",
            "        [3.2984, 4.0967, 2.1770, 4.0969, 4.1114, 2.3984, 2.4817],\n",
            "        [1.3169, 2.0263, 1.3697, 2.1005, 1.9899, 1.4123, 1.3593],\n",
            "        [1.7786, 2.6220, 1.6282, 2.6796, 2.6143, 1.6251, 1.6386]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "111\n",
            "tensor([[1.5150, 2.2870, 1.4841, 2.3562, 2.2625, 1.5102, 1.4822],\n",
            "        [1.8543, 2.7219, 1.6698, 2.7775, 2.7180, 1.6591, 1.6839],\n",
            "        [3.2438, 4.0561, 2.1641, 4.0577, 4.0748, 2.3561, 2.4435],\n",
            "        [0.8814, 1.4282, 1.0786, 1.5136, 1.3722, 1.1484, 1.0647],\n",
            "        [2.0008, 2.8988, 1.7404, 2.9491, 2.9057, 1.7181, 1.7658]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "112\n",
            "tensor([[3.0394, 3.8991, 2.1050, 3.9079, 3.9236, 2.2209, 2.3247],\n",
            "        [1.3399, 2.0570, 1.3807, 2.1311, 2.0218, 1.4244, 1.3738],\n",
            "        [2.1991, 3.1538, 1.8386, 3.1930, 3.1737, 1.7771, 1.8740],\n",
            "        [2.9921, 3.8493, 2.0916, 3.8649, 3.8826, 2.2011, 2.2969],\n",
            "        [0.8391, 1.3747, 1.0566, 1.4633, 1.3174, 1.1228, 1.0379]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "113\n",
            "tensor([[0.8544, 1.3967, 1.0665, 1.4867, 1.3409, 1.1326, 1.0484],\n",
            "        [1.7963, 2.6544, 1.6405, 2.7130, 2.6472, 1.6334, 1.6476],\n",
            "        [1.0710, 1.6991, 1.2188, 1.7833, 1.6515, 1.2766, 1.2000],\n",
            "        [2.6238, 3.5477, 1.9779, 3.5749, 3.5820, 1.9921, 2.0942],\n",
            "        [0.8626, 1.4072, 1.0724, 1.4958, 1.3498, 1.1397, 1.0542]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "114\n",
            "tensor([[1.4262, 2.1767, 1.4383, 2.2522, 2.1476, 1.4714, 1.4281],\n",
            "        [0.9426, 1.5232, 1.1334, 1.6135, 1.4706, 1.1975, 1.1131],\n",
            "        [1.2446, 1.9288, 1.3222, 2.0086, 1.8892, 1.3752, 1.3110],\n",
            "        [2.1676, 3.1007, 1.8123, 3.1456, 3.1171, 1.7798, 1.8538],\n",
            "        [3.0515, 3.9089, 2.1058, 3.9186, 3.9339, 2.2230, 2.3276]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "115\n",
            "tensor([[2.2667, 3.2445, 1.8694, 3.2794, 3.2716, 1.7953, 1.9044],\n",
            "        [1.7224, 2.5618, 1.6030, 2.6260, 2.5513, 1.6147, 1.6059],\n",
            "        [2.7181, 3.6415, 2.0033, 3.6596, 3.6689, 2.0153, 2.1384],\n",
            "        [1.5413, 2.3163, 1.4922, 2.3866, 2.2912, 1.5303, 1.4936],\n",
            "        [3.2696, 4.0766, 2.1667, 4.0812, 4.0899, 2.3913, 2.4579]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "116\n",
            "tensor([[1.0178, 1.5858, 1.1246, 1.6602, 1.5314, 1.2132, 1.1353],\n",
            "        [3.3079, 4.0971, 2.1707, 4.0969, 4.1043, 2.4151, 2.4785],\n",
            "        [3.2514, 4.0584, 2.1608, 4.0649, 4.0763, 2.3680, 2.4413],\n",
            "        [0.9408, 1.5120, 1.1208, 1.6003, 1.4584, 1.1927, 1.1052],\n",
            "        [2.2594, 3.2321, 1.8657, 3.2706, 3.2590, 1.7978, 1.9001]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "117\n",
            "tensor([[0.7867, 1.2942, 1.0087, 1.3851, 1.2353, 1.0829, 0.9934],\n",
            "        [2.1898, 3.1467, 1.8372, 3.1914, 3.1685, 1.7748, 1.8609],\n",
            "        [2.9384, 3.8113, 2.0745, 3.8332, 3.8449, 2.1675, 2.2556],\n",
            "        [1.7912, 2.6373, 1.6335, 2.7021, 2.6311, 1.6426, 1.6401],\n",
            "        [0.8533, 1.3903, 1.0632, 1.4826, 1.3356, 1.1344, 1.0434]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "118\n",
            "tensor([[3.3130, 4.1092, 2.1860, 4.1158, 4.1227, 2.4225, 2.4773],\n",
            "        [1.7210, 2.5656, 1.6176, 2.6349, 2.5582, 1.6061, 1.6025],\n",
            "        [0.9467, 1.5206, 1.1309, 1.6117, 1.4684, 1.1969, 1.1091],\n",
            "        [2.2953, 3.2535, 1.8799, 3.2943, 3.2802, 1.8227, 1.9148],\n",
            "        [1.8182, 2.6906, 1.6667, 2.7567, 2.6907, 1.6405, 1.6578]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "119\n",
            "tensor([[2.4919, 3.4470, 1.9510, 3.4793, 3.4815, 1.8976, 2.0134],\n",
            "        [2.2880, 3.2403, 1.8786, 3.2835, 3.2676, 1.8186, 1.9096],\n",
            "        [2.0041, 2.9085, 1.7536, 2.9656, 2.9192, 1.7169, 1.7593],\n",
            "        [3.0927, 3.9364, 2.1325, 3.9544, 3.9645, 2.2717, 2.3452],\n",
            "        [0.8314, 1.3625, 1.0568, 1.4582, 1.3093, 1.1209, 1.0305]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "120\n",
            "tensor([[1.3316, 2.0285, 1.3719, 2.1105, 1.9942, 1.4273, 1.3605],\n",
            "        [0.8380, 1.3681, 1.0584, 1.4636, 1.3147, 1.1233, 1.0339],\n",
            "        [3.3359, 4.1179, 2.1983, 4.1284, 4.1359, 2.4384, 2.4904],\n",
            "        [1.7937, 2.6483, 1.6548, 2.7179, 2.6472, 1.6381, 1.6436],\n",
            "        [3.0656, 3.9063, 2.1207, 3.9288, 3.9415, 2.2442, 2.3271]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "121\n",
            "tensor([[2.6199, 3.5476, 1.9904, 3.5767, 3.5826, 1.9654, 2.0770],\n",
            "        [2.7887, 3.6864, 2.0400, 3.7115, 3.7164, 2.0581, 2.1704],\n",
            "        [1.4815, 2.2325, 1.4704, 2.3125, 2.2100, 1.5004, 1.4539],\n",
            "        [2.9873, 3.8428, 2.0969, 3.8667, 3.8793, 2.1812, 2.2787],\n",
            "        [2.9230, 3.7918, 2.0835, 3.8174, 3.8280, 2.1471, 2.2435]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "122\n",
            "tensor([[2.3112, 3.2683, 1.8953, 3.3131, 3.3013, 1.8234, 1.9205],\n",
            "        [0.8006, 1.3143, 1.0352, 1.4118, 1.2604, 1.0992, 1.0070],\n",
            "        [3.0145, 3.8668, 2.1075, 3.8895, 3.8982, 2.2003, 2.2934],\n",
            "        [1.7431, 2.5667, 1.6175, 2.6404, 2.5621, 1.6224, 1.6102],\n",
            "        [3.1126, 3.9465, 2.1416, 3.9702, 3.9804, 2.2756, 2.3533]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "123\n",
            "tensor([[2.6185, 3.5473, 1.9933, 3.5771, 3.5826, 1.9551, 2.0742],\n",
            "        [0.9726, 1.5461, 1.1507, 1.6403, 1.4984, 1.2147, 1.1255],\n",
            "        [0.8478, 1.3772, 1.0664, 1.4741, 1.3250, 1.1325, 1.0397],\n",
            "        [2.1770, 3.1180, 1.8432, 3.1708, 3.1430, 1.7709, 1.8504],\n",
            "        [2.2303, 3.1851, 1.8686, 3.2340, 3.2158, 1.7804, 1.8762]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "124\n",
            "tensor([[2.4055, 3.3569, 1.9282, 3.3999, 3.3941, 1.8595, 1.9652],\n",
            "        [3.1590, 3.9776, 2.1585, 4.0016, 4.0103, 2.3027, 2.3753],\n",
            "        [0.9108, 1.4585, 1.1064, 1.5536, 1.4073, 1.1722, 1.0810],\n",
            "        [1.6598, 2.4637, 1.5785, 2.5399, 2.4530, 1.5803, 1.5604],\n",
            "        [2.4418, 3.3610, 1.9271, 3.4056, 3.3949, 1.8989, 1.9834]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "125\n",
            "tensor([[2.0263, 2.9186, 1.7659, 2.9801, 2.9314, 1.7176, 1.7647],\n",
            "        [3.2159, 4.0174, 2.1659, 4.0328, 4.0398, 2.3287, 2.4069],\n",
            "        [3.3485, 4.1180, 2.2008, 4.1279, 4.1342, 2.4375, 2.4888],\n",
            "        [1.5156, 2.2439, 1.4576, 2.3164, 2.2152, 1.5070, 1.4589],\n",
            "        [1.3577, 2.0647, 1.3984, 2.1480, 2.0343, 1.4312, 1.3738]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "126\n",
            "tensor([[1.9149, 2.6569, 1.6061, 2.7104, 2.6382, 1.7229, 1.6765],\n",
            "        [3.3035, 4.0839, 2.1933, 4.0948, 4.1041, 2.3891, 2.4567],\n",
            "        [1.1496, 1.7903, 1.2761, 1.8820, 1.7511, 1.3207, 1.2432],\n",
            "        [2.6097, 3.5331, 1.9883, 3.5636, 3.5715, 1.9472, 2.0619],\n",
            "        [3.2410, 4.0370, 2.1777, 4.0529, 4.0677, 2.3469, 2.4166]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "127\n",
            "tensor([[1.3085, 1.9943, 1.3677, 2.0759, 1.9606, 1.4005, 1.3382],\n",
            "        [2.4996, 3.4287, 1.9560, 3.4655, 3.4668, 1.9023, 2.0071],\n",
            "        [0.8460, 1.3642, 1.0586, 1.4567, 1.3092, 1.1218, 1.0311],\n",
            "        [3.2870, 4.0744, 2.1880, 4.0810, 4.0890, 2.3712, 2.4427],\n",
            "        [0.8359, 1.3503, 1.0489, 1.4421, 1.2954, 1.1124, 1.0225]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "128\n",
            "tensor([[2.6551, 3.5583, 2.0002, 3.5888, 3.5996, 1.9836, 2.0852],\n",
            "        [1.3096, 2.0042, 1.3785, 2.0891, 1.9731, 1.4047, 1.3429],\n",
            "        [2.9883, 3.8329, 2.0971, 3.8534, 3.8640, 2.1727, 2.2649],\n",
            "        [3.0870, 3.9166, 2.1314, 3.9329, 3.9472, 2.2390, 2.3239],\n",
            "        [3.2342, 4.0312, 2.1728, 4.0430, 4.0553, 2.3315, 2.4084]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "129\n",
            "tensor([[3.3561, 4.1186, 2.2059, 4.1199, 4.1345, 2.4343, 2.4824],\n",
            "        [2.4684, 3.3709, 1.9357, 3.4063, 3.4023, 1.9047, 1.9866],\n",
            "        [2.1041, 2.9997, 1.7967, 3.0520, 3.0167, 1.7459, 1.7977],\n",
            "        [1.6001, 2.3683, 1.5364, 2.4389, 2.3497, 1.5484, 1.5131],\n",
            "        [2.6655, 3.5725, 2.0061, 3.5960, 3.6080, 1.9692, 2.0852]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "130\n",
            "tensor([[3.3036, 4.0747, 2.1893, 4.0759, 4.0906, 2.3683, 2.4417],\n",
            "        [2.3759, 3.3179, 1.9202, 3.3522, 3.3491, 1.8265, 1.9361],\n",
            "        [1.6779, 2.4623, 1.5759, 2.5284, 2.4471, 1.5810, 1.5557],\n",
            "        [2.3870, 3.3158, 1.9182, 3.3509, 3.3477, 1.8459, 1.9420],\n",
            "        [0.7327, 1.2016, 0.9687, 1.2921, 1.1416, 1.0318, 0.9442]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "131\n",
            "tensor([[3.3175, 4.0863, 2.1908, 4.0853, 4.0991, 2.3834, 2.4495],\n",
            "        [3.0685, 3.8874, 2.1211, 3.8959, 3.9171, 2.2062, 2.3023],\n",
            "        [0.8012, 1.3024, 1.0291, 1.3946, 1.2461, 1.0876, 0.9972],\n",
            "        [2.3606, 3.3185, 1.9204, 3.3456, 3.3503, 1.8062, 1.9244],\n",
            "        [3.3557, 4.0987, 2.1891, 4.0925, 4.1055, 2.4298, 2.4750]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "132\n",
            "tensor([[3.1221, 3.9359, 2.1400, 3.9430, 3.9646, 2.2462, 2.3292],\n",
            "        [1.0846, 1.6924, 1.2284, 1.7767, 1.6446, 1.2749, 1.1911],\n",
            "        [2.8770, 3.7369, 2.0643, 3.7533, 3.7726, 2.1082, 2.1943],\n",
            "        [3.3260, 4.0940, 2.1931, 4.0882, 4.1101, 2.4015, 2.4516],\n",
            "        [0.9706, 1.5306, 1.1407, 1.6155, 1.4758, 1.1998, 1.1107]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "133\n",
            "tensor([[1.6408, 2.4189, 1.5569, 2.4838, 2.3999, 1.5632, 1.5325],\n",
            "        [3.3097, 4.0843, 2.1913, 4.0786, 4.0974, 2.3887, 2.4415],\n",
            "        [0.9255, 1.4698, 1.1130, 1.5555, 1.4150, 1.1757, 1.0798],\n",
            "        [2.7553, 3.6440, 2.0300, 3.6578, 3.6713, 2.0246, 2.1253],\n",
            "        [1.6312, 2.4132, 1.5591, 2.4805, 2.3943, 1.5598, 1.5289]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "134\n",
            "tensor([[2.4500, 3.3915, 1.9386, 3.4108, 3.4209, 1.8534, 1.9636],\n",
            "        [2.3041, 3.2477, 1.8916, 3.2753, 3.2711, 1.7941, 1.8927],\n",
            "        [3.0694, 3.8872, 2.1187, 3.8937, 3.9145, 2.2290, 2.3011],\n",
            "        [1.6926, 2.4883, 1.5897, 2.5492, 2.4686, 1.5890, 1.5638],\n",
            "        [0.7402, 1.2133, 0.9757, 1.2999, 1.1511, 1.0408, 0.9473]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "135\n",
            "tensor([[2.3321, 3.2590, 1.8894, 3.2884, 3.2799, 1.8265, 1.9087],\n",
            "        [2.6256, 3.5348, 1.9882, 3.5497, 3.5648, 1.9482, 2.0551],\n",
            "        [1.6210, 2.3980, 1.5480, 2.4638, 2.3754, 1.5560, 1.5220],\n",
            "        [0.7660, 1.2489, 0.9941, 1.3373, 1.1869, 1.0629, 0.9676],\n",
            "        [2.3809, 3.2873, 1.9008, 3.3170, 3.3105, 1.8600, 1.9323]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "136\n",
            "tensor([[3.3457, 4.1006, 2.1900, 4.0916, 4.1049, 2.4286, 2.4659],\n",
            "        [2.2415, 3.1418, 1.8438, 3.1806, 3.1550, 1.8103, 1.8654],\n",
            "        [1.4991, 2.2415, 1.4801, 2.3130, 2.2119, 1.5036, 1.4508],\n",
            "        [1.0416, 1.6314, 1.1967, 1.7178, 1.5793, 1.2569, 1.1632],\n",
            "        [1.5435, 2.2986, 1.5056, 2.3678, 2.2716, 1.5288, 1.4776]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "137\n",
            "tensor([[3.2247, 4.0123, 2.1614, 4.0155, 4.0318, 2.3323, 2.3937],\n",
            "        [0.7928, 1.2843, 1.0122, 1.3737, 1.2230, 1.0836, 0.9881],\n",
            "        [0.7846, 1.2802, 1.0171, 1.3721, 1.2193, 1.0860, 0.9871],\n",
            "        [0.8238, 1.3286, 1.0354, 1.4172, 1.2669, 1.1090, 1.0114],\n",
            "        [2.6079, 3.5079, 1.9765, 3.5305, 3.5369, 1.9747, 2.0556]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "138\n",
            "tensor([[1.2268, 1.8866, 1.3199, 1.9725, 1.8458, 1.3716, 1.2877],\n",
            "        [1.6925, 2.4914, 1.5891, 2.5577, 2.4737, 1.5980, 1.5681],\n",
            "        [3.2330, 4.0140, 2.1628, 4.0169, 4.0350, 2.3486, 2.3974],\n",
            "        [3.3047, 4.0756, 2.1781, 4.0746, 4.0828, 2.3916, 2.4431],\n",
            "        [3.3472, 4.1016, 2.1856, 4.0973, 4.1091, 2.4254, 2.4669]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "139\n",
            "tensor([[1.7265, 2.5304, 1.6032, 2.5979, 2.5144, 1.6177, 1.5890],\n",
            "        [1.2104, 1.8597, 1.3025, 1.9422, 1.8126, 1.3617, 1.2755],\n",
            "        [3.1884, 3.9738, 2.1399, 3.9771, 3.9914, 2.3029, 2.3666],\n",
            "        [2.2737, 3.1658, 1.8482, 3.2065, 3.1812, 1.8436, 1.8840],\n",
            "        [0.9744, 1.5428, 1.1535, 1.6333, 1.4869, 1.2210, 1.1214]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "140\n",
            "tensor([[2.4412, 3.3815, 1.9272, 3.4046, 3.4077, 1.8619, 1.9648],\n",
            "        [2.4691, 3.4018, 1.9336, 3.4279, 3.4289, 1.8839, 1.9801],\n",
            "        [1.8997, 2.7227, 1.6705, 2.7806, 2.7135, 1.7012, 1.6824],\n",
            "        [3.3306, 4.0889, 2.1794, 4.0883, 4.0977, 2.4225, 2.4590],\n",
            "        [0.8018, 1.2981, 1.0193, 1.3895, 1.2359, 1.0990, 0.9972]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "141\n",
            "tensor([[1.1355, 1.7585, 1.2545, 1.8476, 1.7118, 1.3262, 1.2300],\n",
            "        [3.3411, 4.0887, 2.1808, 4.0929, 4.1047, 2.4435, 2.4682],\n",
            "        [2.7991, 3.6655, 2.0231, 3.6860, 3.6959, 2.0681, 2.1544],\n",
            "        [2.0161, 2.9005, 1.7563, 2.9558, 2.9070, 1.7260, 1.7533],\n",
            "        [1.4900, 2.2082, 1.4514, 2.2822, 2.1774, 1.5148, 1.4444]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "142\n",
            "tensor([[0.8116, 1.3088, 1.0267, 1.4029, 1.2504, 1.1105, 1.0059],\n",
            "        [0.9351, 1.4771, 1.1124, 1.5679, 1.4207, 1.1977, 1.0925],\n",
            "        [2.8346, 3.6867, 2.0357, 3.7116, 3.7214, 2.1116, 2.1765],\n",
            "        [0.7258, 1.1881, 0.9593, 1.2808, 1.1266, 1.0450, 0.9419],\n",
            "        [0.8392, 1.3476, 1.0482, 1.4413, 1.2903, 1.1315, 1.0261]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "143\n",
            "tensor([[3.2599, 4.0248, 2.1620, 4.0365, 4.0494, 2.3815, 2.4192],\n",
            "        [3.3470, 4.0883, 2.1787, 4.0944, 4.1041, 2.4485, 2.4740],\n",
            "        [0.9942, 1.5630, 1.1631, 1.6580, 1.5130, 1.2403, 1.1372],\n",
            "        [1.7872, 2.5861, 1.6206, 2.6546, 2.5777, 1.6581, 1.6244],\n",
            "        [2.9140, 3.6961, 2.0336, 3.7256, 3.7214, 2.2306, 2.2324]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "144\n",
            "tensor([[1.8564, 2.6746, 1.6616, 2.7442, 2.6744, 1.6906, 1.6681],\n",
            "        [2.3704, 3.3119, 1.9070, 3.3494, 3.3480, 1.8450, 1.9395],\n",
            "        [2.0230, 2.8734, 1.7377, 2.9346, 2.8820, 1.7547, 1.7583],\n",
            "        [2.0403, 2.9197, 1.7660, 2.9819, 2.9346, 1.7512, 1.7726],\n",
            "        [2.7467, 3.6105, 2.0093, 3.6439, 3.6536, 2.0710, 2.1360]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "145\n",
            "tensor([[1.8072, 2.6091, 1.6295, 2.6807, 2.6056, 1.6753, 1.6414],\n",
            "        [1.7942, 2.6163, 1.6437, 2.6899, 2.6161, 1.6575, 1.6380],\n",
            "        [3.0730, 3.8746, 2.1033, 3.8965, 3.9107, 2.2591, 2.3158],\n",
            "        [3.3426, 4.0543, 2.1485, 4.0579, 4.0652, 2.4655, 2.4789],\n",
            "        [3.3593, 4.0923, 2.1790, 4.0994, 4.1088, 2.4776, 2.4885]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "146\n",
            "tensor([[2.8480, 3.6815, 2.0320, 3.7093, 3.7293, 2.1220, 2.1895],\n",
            "        [1.3907, 2.0957, 1.4170, 2.1814, 2.0671, 1.4801, 1.3995],\n",
            "        [3.1942, 3.9672, 2.1389, 3.9844, 4.0001, 2.3591, 2.3877],\n",
            "        [1.1525, 1.7680, 1.2570, 1.8601, 1.7259, 1.3437, 1.2437],\n",
            "        [3.3592, 4.0922, 2.1799, 4.1026, 4.1146, 2.4687, 2.4877]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "147\n",
            "tensor([[1.8590, 2.6622, 1.6490, 2.7322, 2.6625, 1.7017, 1.6711],\n",
            "        [1.1641, 1.7896, 1.2743, 1.8822, 1.7502, 1.3516, 1.2541],\n",
            "        [0.9392, 1.4792, 1.1178, 1.5752, 1.4276, 1.2117, 1.1020],\n",
            "        [1.0126, 1.5776, 1.1657, 1.6714, 1.5307, 1.2586, 1.1501],\n",
            "        [0.7194, 1.1763, 0.9569, 1.2733, 1.1185, 1.0481, 0.9430]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "148\n",
            "tensor([[1.3530, 2.0372, 1.3900, 2.1244, 2.0086, 1.4600, 1.3760],\n",
            "        [2.4846, 3.3771, 1.9250, 3.4190, 3.4160, 1.9469, 2.0075],\n",
            "        [0.9479, 1.4728, 1.0998, 1.5640, 1.4201, 1.2107, 1.0993],\n",
            "        [1.9802, 2.8161, 1.7160, 2.8820, 2.8267, 1.7495, 1.7418],\n",
            "        [3.1253, 3.8972, 2.1075, 3.9188, 3.9336, 2.3071, 2.3463]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "149\n",
            "tensor([[0.8404, 1.3327, 1.0309, 1.4260, 1.2770, 1.1318, 1.0250],\n",
            "        [2.2796, 3.1860, 1.8575, 3.2348, 3.2176, 1.8460, 1.9028],\n",
            "        [3.3431, 4.0654, 2.1671, 4.0754, 4.0862, 2.4697, 2.4833],\n",
            "        [0.8033, 1.2825, 1.0075, 1.3773, 1.2265, 1.1122, 1.0017],\n",
            "        [3.1461, 3.9263, 2.1192, 3.9442, 3.9587, 2.3174, 2.3622]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "150\n",
            "tensor([[1.8873, 2.7093, 1.6756, 2.7806, 2.7150, 1.7142, 1.6940],\n",
            "        [1.8903, 2.7140, 1.6748, 2.7831, 2.7189, 1.7093, 1.6926],\n",
            "        [2.6992, 3.5663, 1.9881, 3.5956, 3.6081, 2.0327, 2.1126],\n",
            "        [3.1430, 3.9164, 2.1146, 3.9372, 3.9562, 2.3240, 2.3617],\n",
            "        [1.0866, 1.6731, 1.2120, 1.7676, 1.6300, 1.3128, 1.2035]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "151\n",
            "tensor([[2.2601, 3.1568, 1.8479, 3.2067, 3.1879, 1.8447, 1.8932],\n",
            "        [0.7511, 1.2166, 0.9788, 1.3133, 1.1597, 1.0756, 0.9677],\n",
            "        [3.1072, 3.8862, 2.1075, 3.9040, 3.9250, 2.2914, 2.3398],\n",
            "        [2.1441, 2.9990, 1.7863, 3.0571, 3.0194, 1.8254, 1.8322],\n",
            "        [1.8113, 2.6044, 1.6272, 2.6747, 2.6032, 1.6843, 1.6467]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "152\n",
            "tensor([[3.3585, 4.0705, 2.1677, 4.0752, 4.0902, 2.4871, 2.4922],\n",
            "        [3.3604, 4.0836, 2.1780, 4.0894, 4.1068, 2.4752, 2.4907],\n",
            "        [3.0515, 3.8454, 2.0934, 3.8654, 3.8846, 2.2610, 2.3077],\n",
            "        [0.8283, 1.3184, 1.0290, 1.4128, 1.2628, 1.1319, 1.0210],\n",
            "        [1.4485, 2.1536, 1.4408, 2.2391, 2.1317, 1.5141, 1.4353]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "153\n",
            "tensor([[2.2743, 3.1701, 1.8556, 3.2177, 3.2031, 1.8528, 1.8990],\n",
            "        [2.2594, 3.1557, 1.8520, 3.2028, 3.1862, 1.8454, 1.8916],\n",
            "        [2.2560, 3.1650, 1.8547, 3.2103, 3.1983, 1.8302, 1.8878],\n",
            "        [2.1603, 3.0119, 1.7910, 3.0678, 3.0319, 1.8328, 1.8394],\n",
            "        [2.8502, 3.6663, 2.0246, 3.6873, 3.7070, 2.1281, 2.1864]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "154\n",
            "tensor([[3.0135, 3.8080, 2.0818, 3.8254, 3.8518, 2.2310, 2.2811],\n",
            "        [2.6522, 3.5128, 1.9779, 3.5420, 3.5592, 2.0231, 2.0870],\n",
            "        [3.1310, 3.8939, 2.1105, 3.9034, 3.9306, 2.3032, 2.3458],\n",
            "        [0.8490, 1.3483, 1.0530, 1.4435, 1.2934, 1.1536, 1.0386],\n",
            "        [0.7839, 1.2535, 0.9971, 1.3474, 1.1967, 1.0983, 0.9878]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "155\n",
            "tensor([[2.4471, 3.3452, 1.9207, 3.3796, 3.3851, 1.9142, 1.9829],\n",
            "        [1.5528, 2.2876, 1.5067, 2.3675, 2.2732, 1.5621, 1.4962],\n",
            "        [1.0020, 1.5510, 1.1515, 1.6409, 1.4995, 1.2520, 1.1403],\n",
            "        [3.1771, 3.9237, 2.1296, 3.9411, 3.9653, 2.3719, 2.3807],\n",
            "        [1.1139, 1.7065, 1.2375, 1.7982, 1.6635, 1.3296, 1.2205]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "156\n",
            "tensor([[1.4113, 2.0948, 1.4152, 2.1744, 2.0657, 1.4919, 1.4057],\n",
            "        [1.2375, 1.8676, 1.3129, 1.9559, 1.8311, 1.4014, 1.2996],\n",
            "        [3.2873, 4.0110, 2.1617, 4.0195, 4.0462, 2.4296, 2.4431],\n",
            "        [1.8876, 2.6959, 1.6749, 2.7595, 2.6989, 1.7138, 1.6875],\n",
            "        [1.6662, 2.3794, 1.5182, 2.4469, 2.3621, 1.6221, 1.5467]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "157\n",
            "tensor([[3.3463, 4.0527, 2.1695, 4.0521, 4.0745, 2.4768, 2.4784],\n",
            "        [2.7573, 3.5886, 2.0043, 3.6122, 3.6278, 2.0927, 2.1422],\n",
            "        [0.8315, 1.3102, 1.0262, 1.4028, 1.2552, 1.1336, 1.0186],\n",
            "        [1.6991, 2.4653, 1.5815, 2.5361, 2.4556, 1.6364, 1.5806],\n",
            "        [1.2351, 1.8659, 1.3145, 1.9548, 1.8309, 1.4015, 1.2987]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "158\n",
            "tensor([[3.1168, 3.8785, 2.1086, 3.8890, 3.9179, 2.2924, 2.3353],\n",
            "        [2.9346, 3.7029, 2.0439, 3.7259, 3.7384, 2.2471, 2.2462],\n",
            "        [0.8569, 1.3497, 1.0512, 1.4435, 1.2958, 1.1530, 1.0397],\n",
            "        [1.5071, 2.2253, 1.4826, 2.3043, 2.2063, 1.5483, 1.4688],\n",
            "        [1.5929, 2.3331, 1.5257, 2.4100, 2.3194, 1.5831, 1.5178]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "159\n",
            "tensor([[2.6248, 3.4902, 1.9753, 3.5153, 3.5329, 2.0121, 2.0698],\n",
            "        [1.5255, 2.2390, 1.4863, 2.3177, 2.2211, 1.5588, 1.4774],\n",
            "        [0.8423, 1.3274, 1.0398, 1.4203, 1.2733, 1.1431, 1.0277],\n",
            "        [0.8033, 1.2820, 1.0228, 1.3794, 1.2279, 1.1194, 1.0048],\n",
            "        [3.3789, 4.0736, 2.1764, 4.0707, 4.0953, 2.4990, 2.4972]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "160\n",
            "tensor([[3.0802, 3.8456, 2.1005, 3.8567, 3.8826, 2.2675, 2.3116],\n",
            "        [1.6529, 2.3494, 1.5055, 2.4149, 2.3306, 1.6160, 1.5330],\n",
            "        [1.0697, 1.6349, 1.1988, 1.7247, 1.5908, 1.2980, 1.1837],\n",
            "        [2.6752, 3.5293, 1.9895, 3.5497, 3.5736, 2.0203, 2.0906],\n",
            "        [1.3350, 1.9925, 1.3789, 2.0788, 1.9657, 1.4604, 1.3602]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "161\n",
            "tensor([[2.1370, 3.0088, 1.8148, 3.0576, 3.0345, 1.7904, 1.8193],\n",
            "        [1.3039, 1.9293, 1.3299, 2.0073, 1.8953, 1.4262, 1.3259],\n",
            "        [2.2382, 3.0870, 1.8338, 3.1333, 3.1159, 1.8504, 1.8695],\n",
            "        [3.0934, 3.8616, 2.1140, 3.8747, 3.9042, 2.2904, 2.3242],\n",
            "        [1.0405, 1.6007, 1.1939, 1.6926, 1.5552, 1.2837, 1.1679]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "162\n",
            "tensor([[2.9060, 3.7078, 2.0622, 3.7290, 3.7547, 2.1772, 2.2173],\n",
            "        [2.0858, 2.9172, 1.7702, 2.9704, 2.9346, 1.7894, 1.7880],\n",
            "        [3.2548, 3.9852, 2.1632, 3.9891, 4.0177, 2.4065, 2.4166],\n",
            "        [1.3386, 1.9967, 1.3851, 2.0811, 1.9681, 1.4569, 1.3598],\n",
            "        [2.0593, 2.8915, 1.7619, 2.9451, 2.9097, 1.7786, 1.7730]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "163\n",
            "tensor([[2.3221, 3.2074, 1.8848, 3.2467, 3.2429, 1.8574, 1.9106],\n",
            "        [2.6872, 3.5395, 1.9982, 3.5607, 3.5827, 2.0345, 2.0954],\n",
            "        [3.3803, 4.0751, 2.1874, 4.0685, 4.0941, 2.4864, 2.4906],\n",
            "        [1.8670, 2.6499, 1.6612, 2.7116, 2.6511, 1.7059, 1.6652],\n",
            "        [2.1734, 3.0186, 1.8122, 3.0660, 3.0423, 1.8239, 1.8332]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "164\n",
            "tensor([[3.3278, 4.0383, 2.1847, 4.0372, 4.0668, 2.4612, 2.4574],\n",
            "        [2.3104, 3.1757, 1.8734, 3.2155, 3.2060, 1.8653, 1.9027],\n",
            "        [2.7911, 3.6225, 2.0295, 3.6403, 3.6675, 2.0807, 2.1459],\n",
            "        [1.9940, 2.8200, 1.7403, 2.8790, 2.8338, 1.7525, 1.7390],\n",
            "        [2.8288, 3.6477, 2.0409, 3.6647, 3.6863, 2.1076, 2.1676]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "165\n",
            "tensor([[0.8041, 1.2774, 1.0237, 1.3712, 1.2228, 1.1130, 0.9988],\n",
            "        [1.0250, 1.5695, 1.1715, 1.6580, 1.5219, 1.2669, 1.1477],\n",
            "        [2.4518, 3.3533, 1.9410, 3.3771, 3.3937, 1.8943, 1.9703],\n",
            "        [1.3721, 2.0376, 1.4025, 2.1165, 2.0075, 1.4719, 1.3743],\n",
            "        [3.3868, 4.0753, 2.1894, 4.0653, 4.0908, 2.5007, 2.4951]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "166\n",
            "tensor([[2.9396, 3.7372, 2.0788, 3.7475, 3.7776, 2.1894, 2.2298],\n",
            "        [1.6043, 2.3152, 1.5226, 2.3839, 2.2968, 1.5969, 1.5104],\n",
            "        [1.2988, 1.9504, 1.3733, 2.0352, 1.9204, 1.4351, 1.3333],\n",
            "        [2.5955, 3.4426, 1.9763, 3.4661, 3.4841, 2.0059, 2.0460],\n",
            "        [3.2349, 3.9627, 2.1628, 3.9676, 3.9966, 2.4124, 2.4046]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "167\n",
            "tensor([[2.7933, 3.6293, 2.0448, 3.6397, 3.6712, 2.0859, 2.1433],\n",
            "        [3.0943, 3.8664, 2.1357, 3.8723, 3.9078, 2.2927, 2.3182],\n",
            "        [2.2524, 3.1437, 1.8771, 3.1784, 3.1765, 1.8276, 1.8708],\n",
            "        [2.0529, 2.8881, 1.7755, 2.9382, 2.9043, 1.7820, 1.7665],\n",
            "        [2.3809, 3.2515, 1.9131, 3.2845, 3.2866, 1.9076, 1.9382]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "168\n",
            "tensor([[3.3836, 4.0881, 2.2117, 4.0763, 4.1113, 2.4960, 2.4881],\n",
            "        [1.1200, 1.7090, 1.2567, 1.7942, 1.6683, 1.3296, 1.2147],\n",
            "        [2.1072, 2.9376, 1.7920, 2.9826, 2.9561, 1.8058, 1.7928],\n",
            "        [2.6592, 3.5146, 2.0100, 3.5320, 3.5604, 2.0305, 2.0760],\n",
            "        [0.7950, 1.2650, 1.0202, 1.3538, 1.2108, 1.1033, 0.9880]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "169\n",
            "tensor([[1.8002, 2.5891, 1.6617, 2.6502, 2.5915, 1.6693, 1.6273],\n",
            "        [1.5048, 2.2095, 1.4926, 2.2807, 2.1915, 1.5370, 1.4523],\n",
            "        [3.3192, 4.0415, 2.1989, 4.0332, 4.0724, 2.4291, 2.4421],\n",
            "        [1.4047, 2.0797, 1.4288, 2.1550, 2.0556, 1.4849, 1.3913],\n",
            "        [3.3206, 4.0390, 2.1978, 4.0298, 4.0650, 2.4337, 2.4451]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "170\n",
            "tensor([[1.9039, 2.7128, 1.7130, 2.7686, 2.7223, 1.7102, 1.6834],\n",
            "        [1.8474, 2.6459, 1.6894, 2.7028, 2.6511, 1.6881, 1.6520],\n",
            "        [3.3700, 4.0808, 2.2186, 4.0688, 4.1062, 2.4698, 2.4736],\n",
            "        [1.8211, 2.5917, 1.6511, 2.6454, 2.5879, 1.6765, 1.6297],\n",
            "        [2.7190, 3.5681, 2.0348, 3.5802, 3.6145, 2.0425, 2.1017]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "171\n",
            "tensor([[3.3620, 4.0700, 2.2206, 4.0614, 4.0982, 2.4654, 2.4705],\n",
            "        [3.3999, 4.0864, 2.2160, 4.0700, 4.1043, 2.4998, 2.4934],\n",
            "        [0.7372, 1.1823, 0.9810, 1.2750, 1.1287, 1.0584, 0.9475],\n",
            "        [2.5738, 3.4426, 1.9981, 3.4635, 3.4919, 1.9680, 2.0283],\n",
            "        [3.2998, 3.9702, 2.1486, 3.9556, 3.9817, 2.4495, 2.4369]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "172\n",
            "tensor([[2.4664, 3.3600, 1.9744, 3.3833, 3.4060, 1.9040, 1.9763],\n",
            "        [0.7186, 1.1544, 0.9667, 1.2465, 1.1003, 1.0439, 0.9340],\n",
            "        [3.2972, 4.0170, 2.2101, 4.0138, 4.0548, 2.4076, 2.4293],\n",
            "        [1.0060, 1.5503, 1.1856, 1.6409, 1.5083, 1.2518, 1.1389],\n",
            "        [2.4183, 3.3044, 1.9563, 3.3345, 3.3509, 1.8929, 1.9525]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "173\n",
            "tensor([[1.8056, 2.5838, 1.6725, 2.6487, 2.5915, 1.6672, 1.6306],\n",
            "        [2.3312, 3.2020, 1.9219, 3.2397, 3.2436, 1.8685, 1.9125],\n",
            "        [2.8026, 3.6301, 2.0743, 3.6475, 3.6840, 2.0866, 2.1529],\n",
            "        [3.2241, 3.9537, 2.1944, 3.9567, 4.0037, 2.3606, 2.3876],\n",
            "        [3.1526, 3.9060, 2.1731, 3.9124, 3.9471, 2.2976, 2.3463]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "174\n",
            "tensor([[3.3762, 4.0530, 2.2167, 4.0443, 4.0791, 2.5034, 2.4895],\n",
            "        [3.3329, 4.0326, 2.2240, 4.0328, 4.0698, 2.4669, 2.4640],\n",
            "        [0.8552, 1.3460, 1.0840, 1.4428, 1.3006, 1.1524, 1.0387],\n",
            "        [2.5204, 3.4033, 1.9958, 3.4294, 3.4560, 1.9339, 2.0083],\n",
            "        [1.4801, 2.1497, 1.4705, 2.2258, 2.1337, 1.5282, 1.4371]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "175\n",
            "tensor([[1.1086, 1.6851, 1.2600, 1.7761, 1.6518, 1.3212, 1.2118],\n",
            "        [0.8423, 1.3280, 1.0731, 1.4245, 1.2826, 1.1410, 1.0307],\n",
            "        [2.3936, 3.2683, 1.9537, 3.3079, 3.3183, 1.9019, 1.9531],\n",
            "        [3.3880, 4.0852, 2.2439, 4.0825, 4.1200, 2.4974, 2.5005],\n",
            "        [3.3838, 4.0628, 2.2242, 4.0579, 4.0896, 2.4952, 2.4977]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "176\n",
            "tensor([[0.7401, 1.1867, 0.9924, 1.2822, 1.1380, 1.0636, 0.9566],\n",
            "        [1.7780, 2.5673, 1.6839, 2.6387, 2.5817, 1.6578, 1.6290],\n",
            "        [2.7816, 3.6133, 2.0756, 3.6362, 3.6723, 2.0900, 2.1546],\n",
            "        [3.2690, 3.9927, 2.2214, 4.0019, 4.0468, 2.4171, 2.4322],\n",
            "        [2.1622, 3.0120, 1.8556, 3.0642, 3.0496, 1.8153, 1.8373]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "177\n",
            "tensor([[0.8199, 1.2970, 1.0572, 1.3951, 1.2526, 1.1297, 1.0196],\n",
            "        [0.9115, 1.4225, 1.1270, 1.5212, 1.3838, 1.1951, 1.0846],\n",
            "        [3.3990, 4.0929, 2.2471, 4.0934, 4.1274, 2.5065, 2.5197],\n",
            "        [1.7782, 2.5590, 1.6734, 2.6310, 2.5735, 1.6646, 1.6312],\n",
            "        [0.6748, 1.0975, 0.9424, 1.1954, 1.0486, 1.0125, 0.9112]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "178\n",
            "tensor([[2.3700, 3.2690, 1.9578, 3.3122, 3.3285, 1.8740, 1.9551],\n",
            "        [0.7120, 1.1539, 0.9796, 1.2542, 1.1080, 1.0478, 0.9442],\n",
            "        [3.1339, 3.8847, 2.1755, 3.8985, 3.9473, 2.3104, 2.3560],\n",
            "        [3.3457, 4.0572, 2.2373, 4.0631, 4.1030, 2.4618, 2.4886],\n",
            "        [0.7513, 1.2010, 1.0002, 1.2993, 1.1550, 1.0762, 0.9701]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "179\n",
            "tensor([[1.3956, 2.0738, 1.4539, 2.1628, 2.0659, 1.4901, 1.4120],\n",
            "        [3.3607, 4.0572, 2.2360, 4.0622, 4.1039, 2.4804, 2.4989],\n",
            "        [1.3698, 2.0358, 1.4341, 2.1242, 2.0244, 1.4772, 1.3939],\n",
            "        [0.9510, 1.4808, 1.1608, 1.5813, 1.4466, 1.2247, 1.1193],\n",
            "        [1.1306, 1.7271, 1.2887, 1.8210, 1.7012, 1.3398, 1.2410]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "180\n",
            "tensor([[3.3554, 4.0653, 2.2472, 4.0750, 4.1161, 2.4891, 2.5071],\n",
            "        [1.1617, 1.7659, 1.3064, 1.8626, 1.7437, 1.3613, 1.2652],\n",
            "        [2.9962, 3.7899, 2.1461, 3.8122, 3.8534, 2.2214, 2.2939],\n",
            "        [0.7607, 1.2177, 1.0130, 1.3179, 1.1745, 1.0853, 0.9822],\n",
            "        [0.7562, 1.2180, 1.0200, 1.3209, 1.1757, 1.0884, 0.9830]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "181\n",
            "tensor([[2.0738, 2.9167, 1.8230, 2.9815, 2.9601, 1.7871, 1.8115],\n",
            "        [1.1044, 1.6961, 1.2805, 1.7983, 1.6745, 1.3288, 1.2331],\n",
            "        [1.0536, 1.6201, 1.2356, 1.7213, 1.5938, 1.2945, 1.1952],\n",
            "        [1.4098, 2.0863, 1.4599, 2.1767, 2.0803, 1.5003, 1.4253],\n",
            "        [3.3392, 4.0490, 2.2368, 4.0604, 4.0975, 2.4597, 2.5002]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "182\n",
            "tensor([[2.4488, 3.3401, 1.9861, 3.3864, 3.4100, 1.9195, 2.0119],\n",
            "        [0.9035, 1.4112, 1.1231, 1.5140, 1.3769, 1.1943, 1.0906],\n",
            "        [1.7076, 2.4820, 1.6499, 2.5661, 2.5039, 1.6371, 1.6123],\n",
            "        [1.2413, 1.8740, 1.3657, 1.9710, 1.8605, 1.4086, 1.3231],\n",
            "        [0.8282, 1.3150, 1.0747, 1.4194, 1.2786, 1.1401, 1.0389]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "183\n",
            "tensor([[-0.1200,  0.0122, -0.0660, -0.0770,  0.0107, -0.2108,  0.0443],\n",
            "        [ 2.1242,  2.9858,  1.8586,  3.0550,  3.0409,  1.8005,  1.8489],\n",
            "        [ 2.2682,  3.1648,  1.9263,  3.2205,  3.2291,  1.8373,  1.9218],\n",
            "        [ 1.3821,  2.0621,  1.4612,  2.1587,  2.0611,  1.4902,  1.4178],\n",
            "        [ 1.2079,  1.8262,  1.3378,  1.9232,  1.8112,  1.3798,  1.2983]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "184\n",
            "tensor([[2.4149, 3.3242, 1.9870, 3.3721, 3.4017, 1.8814, 2.0003],\n",
            "        [1.2991, 1.9549, 1.4150, 2.0572, 1.9522, 1.4435, 1.3684],\n",
            "        [0.8617, 1.3593, 1.1030, 1.4655, 1.3270, 1.1673, 1.0657],\n",
            "        [2.7498, 3.5857, 2.0767, 3.6263, 3.6647, 2.0698, 2.1726],\n",
            "        [0.8869, 1.3982, 1.1285, 1.5085, 1.3706, 1.1873, 1.0882]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "185\n",
            "tensor([[1.7030, 2.4816, 1.6648, 2.5749, 2.5113, 1.6362, 1.6212],\n",
            "        [2.2687, 3.1680, 1.9367, 3.2297, 3.2416, 1.8378, 1.9302],\n",
            "        [3.2973, 4.0170, 2.2401, 4.0470, 4.0873, 2.4504, 2.4948],\n",
            "        [0.9063, 1.4253, 1.1480, 1.5379, 1.3996, 1.2035, 1.1051],\n",
            "        [3.3234, 4.0312, 2.2418, 4.0590, 4.0977, 2.4586, 2.5066]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "186\n",
            "tensor([[0.8614, 1.3618, 1.1091, 1.4741, 1.3343, 1.1709, 1.0714],\n",
            "        [2.1868, 3.0711, 1.9006, 3.1430, 3.1408, 1.8147, 1.8915],\n",
            "        [0.8996, 1.4117, 1.1364, 1.5228, 1.3856, 1.1965, 1.0986],\n",
            "        [1.4388, 2.1296, 1.4920, 2.2312, 2.1392, 1.5111, 1.4561],\n",
            "        [3.3664, 4.0440, 2.2326, 4.0646, 4.0983, 2.5087, 2.5405]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "187\n",
            "tensor([[0.8953, 1.4016, 1.1273, 1.5131, 1.3756, 1.1911, 1.0946],\n",
            "        [2.5572, 3.4349, 2.0278, 3.4926, 3.5220, 1.9616, 2.0819],\n",
            "        [2.8384, 3.6538, 2.1065, 3.7026, 3.7404, 2.1329, 2.2288],\n",
            "        [3.3104, 4.0237, 2.2374, 4.0566, 4.0941, 2.4513, 2.5089],\n",
            "        [1.5408, 2.2469, 1.5389, 2.3446, 2.2621, 1.5677, 1.5180]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "188\n",
            "tensor([[1.7937, 2.5857, 1.6980, 2.6808, 2.6254, 1.6735, 1.6775],\n",
            "        [3.3162, 4.0316, 2.2423, 4.0698, 4.1084, 2.4559, 2.5148],\n",
            "        [3.2929, 4.0151, 2.2359, 4.0521, 4.0907, 2.4375, 2.4970],\n",
            "        [1.8289, 2.6287, 1.7213, 2.7244, 2.6733, 1.6984, 1.7009],\n",
            "        [2.9685, 3.7593, 2.1398, 3.8056, 3.8431, 2.2048, 2.3078]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "189\n",
            "tensor([[1.7383, 2.5274, 1.6830, 2.6305, 2.5689, 1.6460, 1.6511],\n",
            "        [1.3756, 2.0490, 1.4588, 2.1582, 2.0570, 1.4852, 1.4264],\n",
            "        [3.3319, 4.0294, 2.2338, 4.0635, 4.0934, 2.4732, 2.5259],\n",
            "        [3.1359, 3.8919, 2.1931, 3.9385, 3.9778, 2.3196, 2.4080],\n",
            "        [0.7156, 1.1561, 0.9910, 1.2687, 1.1215, 1.0558, 0.9640]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "190\n",
            "tensor([[0.7041, 1.1456, 0.9910, 1.2618, 1.1143, 1.0477, 0.9598],\n",
            "        [2.1627, 3.0290, 1.8819, 3.1146, 3.1013, 1.8112, 1.8901],\n",
            "        [0.9784, 1.5108, 1.1840, 1.6248, 1.4914, 1.2451, 1.1567],\n",
            "        [3.1609, 3.9071, 2.1928, 3.9538, 3.9916, 2.3247, 2.4219],\n",
            "        [1.6865, 2.4354, 1.6275, 2.5356, 2.4678, 1.6313, 1.6136]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "191\n",
            "tensor([[1.9398, 2.7638, 1.7756, 2.8607, 2.8193, 1.7251, 1.7688],\n",
            "        [2.3042, 3.1669, 1.9255, 3.2454, 3.2433, 1.8679, 1.9631],\n",
            "        [0.9049, 1.4147, 1.1355, 1.5298, 1.3908, 1.1914, 1.1060],\n",
            "        [2.7444, 3.5848, 2.0775, 3.6440, 3.6746, 2.0619, 2.1922],\n",
            "        [1.5304, 2.2446, 1.5470, 2.3529, 2.2684, 1.5513, 1.5241]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "192\n",
            "tensor([[0.9494, 1.4747, 1.1656, 1.5905, 1.4546, 1.2194, 1.1375],\n",
            "        [3.1385, 3.8935, 2.1923, 3.9434, 3.9790, 2.3051, 2.4143],\n",
            "        [3.1931, 3.9199, 2.1898, 3.9671, 3.9973, 2.3505, 2.4431],\n",
            "        [1.7646, 2.5533, 1.6912, 2.6587, 2.5982, 1.6499, 1.6691],\n",
            "        [2.5814, 3.3780, 1.9957, 3.4531, 3.4565, 2.0403, 2.1131]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "193\n",
            "tensor([[2.8696, 3.6780, 2.1076, 3.7382, 3.7686, 2.1111, 2.2597],\n",
            "        [2.5780, 3.4389, 2.0248, 3.5100, 3.5310, 1.9607, 2.1049],\n",
            "        [2.8704, 3.6777, 2.1053, 3.7362, 3.7702, 2.1186, 2.2576],\n",
            "        [0.9413, 1.4767, 1.1822, 1.6010, 1.4609, 1.2197, 1.1420],\n",
            "        [3.2992, 4.0175, 2.2351, 4.0639, 4.0944, 2.4251, 2.5141]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "194\n",
            "tensor([[1.6726, 2.4315, 1.6318, 2.5387, 2.4650, 1.6087, 1.6152],\n",
            "        [2.1526, 3.0297, 1.8775, 3.1170, 3.1062, 1.7800, 1.8876],\n",
            "        [2.2738, 3.1804, 1.9367, 3.2599, 3.2646, 1.8073, 1.9526],\n",
            "        [2.1218, 2.9137, 1.8081, 3.0021, 2.9702, 1.8117, 1.8608],\n",
            "        [2.7763, 3.5997, 2.0780, 3.6650, 3.6963, 2.0625, 2.2122]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "195\n",
            "tensor([[3.2459, 3.9710, 2.2133, 4.0242, 4.0544, 2.3717, 2.4826],\n",
            "        [0.7625, 1.2193, 1.0270, 1.3385, 1.1900, 1.0856, 1.0057],\n",
            "        [1.9480, 2.7869, 1.7863, 2.8886, 2.8471, 1.7073, 1.7808],\n",
            "        [3.2045, 3.9328, 2.1911, 3.9816, 4.0114, 2.3435, 2.4580],\n",
            "        [0.9680, 1.5078, 1.1901, 1.6310, 1.4918, 1.2328, 1.1599]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "196\n",
            "tensor([[2.8443, 3.6567, 2.0993, 3.7217, 3.7473, 2.1018, 2.2530],\n",
            "        [1.6712, 2.4307, 1.6351, 2.5448, 2.4695, 1.6023, 1.6186],\n",
            "        [2.0732, 2.9277, 1.8395, 3.0259, 2.9971, 1.7536, 1.8494],\n",
            "        [0.6830, 1.1119, 0.9673, 1.2300, 1.0786, 1.0214, 0.9452],\n",
            "        [0.7823, 1.2503, 1.0488, 1.3720, 1.2233, 1.1019, 1.0231]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "197\n",
            "tensor([[2.4610, 3.3417, 1.9931, 3.4248, 3.4361, 1.8946, 2.0542],\n",
            "        [1.6992, 2.4633, 1.6503, 2.5798, 2.5055, 1.6230, 1.6385],\n",
            "        [0.8914, 1.3988, 1.1313, 1.5236, 1.3781, 1.1784, 1.1047],\n",
            "        [2.3453, 3.2172, 1.9472, 3.3085, 3.3054, 1.8635, 1.9971],\n",
            "        [1.2608, 1.8774, 1.3648, 1.9972, 1.8791, 1.4071, 1.3546]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "198\n",
            "tensor([[2.9994, 3.7772, 2.1487, 3.8528, 3.8750, 2.2159, 2.3496],\n",
            "        [2.3859, 3.1674, 1.9087, 3.2636, 3.2391, 1.9519, 2.0158],\n",
            "        [1.6120, 2.3552, 1.6048, 2.4792, 2.3929, 1.5803, 1.5883],\n",
            "        [2.4455, 3.3347, 1.9910, 3.4201, 3.4324, 1.8724, 2.0458],\n",
            "        [3.2544, 3.9778, 2.2206, 4.0439, 4.0616, 2.3871, 2.5016]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "199\n",
            "tensor([[0.9174, 1.4282, 1.1480, 1.5574, 1.4122, 1.2003, 1.1259],\n",
            "        [1.2063, 1.8143, 1.3456, 1.9422, 1.8161, 1.3800, 1.3268],\n",
            "        [0.9032, 1.4144, 1.1467, 1.5465, 1.3998, 1.1953, 1.1196],\n",
            "        [2.4325, 3.3121, 1.9865, 3.4075, 3.4104, 1.8902, 2.0473],\n",
            "        [0.9925, 1.5349, 1.2092, 1.6666, 1.5245, 1.2534, 1.1828]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "200\n",
            "tensor([[0.7948, 1.2617, 1.0608, 1.3920, 1.2388, 1.1160, 1.0379],\n",
            "        [3.3072, 4.0067, 2.2369, 4.0820, 4.0974, 2.4333, 2.5379],\n",
            "        [2.3973, 3.2696, 1.9742, 3.3727, 3.3677, 1.8940, 2.0333],\n",
            "        [2.8297, 3.6454, 2.1041, 3.7295, 3.7420, 2.1022, 2.2584],\n",
            "        [3.2334, 3.9542, 2.2213, 4.0324, 4.0506, 2.3745, 2.4915]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "201\n",
            "tensor([[1.3967, 2.0702, 1.4786, 2.2074, 2.0947, 1.4903, 1.4601],\n",
            "        [3.3155, 4.0157, 2.2384, 4.0926, 4.1008, 2.4359, 2.5460],\n",
            "        [0.6330, 1.0390, 0.9289, 1.1647, 1.0094, 0.9856, 0.9105],\n",
            "        [3.0773, 3.8285, 2.1725, 3.9170, 3.9280, 2.2655, 2.4016],\n",
            "        [3.1236, 3.8635, 2.1833, 3.9475, 3.9629, 2.3006, 2.4285]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "202\n",
            "tensor([[3.3441, 4.0333, 2.2449, 4.1141, 4.1208, 2.4722, 2.5679],\n",
            "        [0.7634, 1.2165, 1.0321, 1.3491, 1.1952, 1.0935, 1.0138],\n",
            "        [0.8502, 1.3354, 1.1015, 1.4697, 1.3199, 1.1578, 1.0795],\n",
            "        [3.3818, 4.0652, 2.2612, 4.1443, 4.1498, 2.5012, 2.5929],\n",
            "        [3.0345, 3.7904, 2.1603, 3.8833, 3.8992, 2.2368, 2.3760]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "203\n",
            "tensor([[0.7806, 1.2423, 1.0542, 1.3787, 1.2234, 1.1109, 1.0305],\n",
            "        [2.2405, 3.0672, 1.9007, 3.1934, 3.1579, 1.8736, 1.9570],\n",
            "        [3.1284, 3.8689, 2.1914, 3.9671, 3.9761, 2.3152, 2.4381],\n",
            "        [0.7464, 1.1910, 1.0205, 1.3246, 1.1693, 1.0811, 1.0011],\n",
            "        [2.6738, 3.5068, 2.0597, 3.6124, 3.6161, 2.0249, 2.1785]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "204\n",
            "tensor([[2.1416, 2.9766, 1.8717, 3.1066, 3.0662, 1.8110, 1.9028],\n",
            "        [2.4188, 3.2936, 1.9940, 3.4108, 3.4029, 1.9089, 2.0514],\n",
            "        [2.9754, 3.7477, 2.1509, 3.8468, 3.8564, 2.2033, 2.3484],\n",
            "        [2.3401, 3.1892, 1.9528, 3.3130, 3.2901, 1.8976, 2.0108],\n",
            "        [3.1096, 3.8425, 2.1907, 3.9412, 3.9481, 2.3356, 2.4322]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "205\n",
            "tensor([[3.2742, 3.9758, 2.2360, 4.0713, 4.0754, 2.4267, 2.5269],\n",
            "        [3.2675, 3.9619, 2.2227, 4.0569, 4.0564, 2.4348, 2.5252],\n",
            "        [3.2165, 3.9327, 2.2294, 4.0307, 4.0379, 2.3896, 2.4931],\n",
            "        [0.8996, 1.4046, 1.1487, 1.5484, 1.3966, 1.2061, 1.1232],\n",
            "        [0.7763, 1.2392, 1.0578, 1.3796, 1.2232, 1.1138, 1.0309]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "206\n",
            "tensor([[1.6519, 2.3960, 1.6439, 2.5445, 2.4509, 1.6285, 1.6268],\n",
            "        [0.8832, 1.3696, 1.1210, 1.5089, 1.3581, 1.1899, 1.1033],\n",
            "        [2.9056, 3.6924, 2.1425, 3.8058, 3.8128, 2.1844, 2.3134],\n",
            "        [0.7548, 1.2038, 1.0348, 1.3420, 1.1857, 1.0959, 1.0110],\n",
            "        [0.7191, 1.1526, 1.0034, 1.2893, 1.1320, 1.0687, 0.9829]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "207\n",
            "tensor([[0.6677, 1.0857, 0.9701, 1.2224, 1.0638, 1.0282, 0.9445],\n",
            "        [0.7266, 1.1697, 1.0249, 1.3116, 1.1514, 1.0828, 0.9950],\n",
            "        [0.9000, 1.4086, 1.1631, 1.5573, 1.4046, 1.2124, 1.1262],\n",
            "        [2.8997, 3.6849, 2.1427, 3.8015, 3.8062, 2.1840, 2.3113],\n",
            "        [0.8604, 1.3516, 1.1274, 1.4984, 1.3433, 1.1819, 1.0958]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "208\n",
            "tensor([[3.1941, 3.9157, 2.2336, 4.0197, 4.0302, 2.3798, 2.4779],\n",
            "        [0.9007, 1.4030, 1.1555, 1.5502, 1.3979, 1.2112, 1.1243],\n",
            "        [2.6913, 3.5105, 2.0826, 3.6319, 3.6340, 2.0562, 2.1922],\n",
            "        [2.4235, 3.2760, 2.0034, 3.4095, 3.3917, 1.9450, 2.0585],\n",
            "        [1.1610, 1.7434, 1.3250, 1.8905, 1.7567, 1.3715, 1.3007]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "209\n",
            "tensor([[0.6522, 1.0645, 0.9628, 1.2034, 1.0434, 1.0185, 0.9336],\n",
            "        [1.1839, 1.7687, 1.3387, 1.9171, 1.7824, 1.3928, 1.3167],\n",
            "        [0.9669, 1.4943, 1.2084, 1.6444, 1.4944, 1.2561, 1.1723],\n",
            "        [1.7789, 2.5454, 1.7132, 2.6946, 2.6137, 1.6898, 1.6982],\n",
            "        [0.7845, 1.2436, 1.0633, 1.3853, 1.2290, 1.1250, 1.0349]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "210\n",
            "tensor([[1.8958, 2.6733, 1.7662, 2.8208, 2.7482, 1.7469, 1.7647],\n",
            "        [0.7786, 1.2439, 1.0795, 1.3931, 1.2337, 1.1277, 1.0377],\n",
            "        [1.0075, 1.5493, 1.2414, 1.6996, 1.5543, 1.2867, 1.2007],\n",
            "        [3.2276, 3.9375, 2.2482, 4.0458, 4.0498, 2.4139, 2.4986],\n",
            "        [0.8274, 1.3008, 1.1002, 1.4453, 1.2899, 1.1593, 1.0677]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "211\n",
            "tensor([[3.1689, 3.8878, 2.2362, 4.0021, 4.0009, 2.3882, 2.4630],\n",
            "        [2.9736, 3.7410, 2.1806, 3.8601, 3.8619, 2.2385, 2.3494],\n",
            "        [1.6329, 2.3704, 1.6514, 2.5279, 2.4299, 1.6329, 1.6170],\n",
            "        [1.2077, 1.8134, 1.3808, 1.9692, 1.8338, 1.4118, 1.3413],\n",
            "        [2.5175, 3.3460, 2.0362, 3.4803, 3.4604, 2.0109, 2.1083]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "212\n",
            "tensor([[2.3435, 3.2007, 1.9923, 3.3405, 3.3170, 1.9160, 2.0174],\n",
            "        [2.5175, 3.3705, 2.0547, 3.5022, 3.4958, 1.9706, 2.1017],\n",
            "        [1.1997, 1.8021, 1.3732, 1.9561, 1.8199, 1.4105, 1.3357],\n",
            "        [0.8960, 1.3950, 1.1549, 1.5418, 1.3884, 1.2054, 1.1186],\n",
            "        [3.1868, 3.9109, 2.2474, 4.0232, 4.0243, 2.3936, 2.4792]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "213\n",
            "tensor([[0.9467, 1.4645, 1.1947, 1.6119, 1.4606, 1.2424, 1.1563],\n",
            "        [0.9292, 1.4436, 1.1881, 1.5947, 1.4412, 1.2321, 1.1459],\n",
            "        [3.2177, 3.9389, 2.2640, 4.0555, 4.0532, 2.4159, 2.5008],\n",
            "        [0.8622, 1.3559, 1.1433, 1.5081, 1.3513, 1.1892, 1.1000],\n",
            "        [1.6542, 2.3900, 1.6568, 2.5455, 2.4478, 1.6458, 1.6287]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "214\n",
            "tensor([[1.5505, 2.2662, 1.6070, 2.4246, 2.3166, 1.5944, 1.5660],\n",
            "        [1.8899, 2.6731, 1.7832, 2.8284, 2.7511, 1.7549, 1.7686],\n",
            "        [1.1580, 1.7456, 1.3469, 1.8987, 1.7592, 1.3808, 1.3061],\n",
            "        [2.4064, 3.2476, 2.0134, 3.3907, 3.3617, 1.9665, 2.0535],\n",
            "        [3.2204, 3.9412, 2.2653, 4.0576, 4.0552, 2.4139, 2.4996]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "215\n",
            "tensor([[2.1045, 2.9421, 1.9052, 3.0961, 3.0416, 1.8331, 1.8930],\n",
            "        [0.7911, 1.2573, 1.0854, 1.4053, 1.2454, 1.1347, 1.0446],\n",
            "        [0.9217, 1.4324, 1.1845, 1.5842, 1.4295, 1.2304, 1.1415],\n",
            "        [1.3896, 2.0633, 1.5190, 2.2261, 2.1021, 1.5177, 1.4678],\n",
            "        [3.3870, 4.0612, 2.3031, 4.1688, 4.1551, 2.5509, 2.6082]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "216\n",
            "tensor([[1.5062, 2.1108, 1.4672, 2.2459, 2.1292, 1.5737, 1.4999],\n",
            "        [2.8029, 3.6166, 2.1583, 3.7502, 3.7432, 2.1540, 2.2652],\n",
            "        [0.7630, 1.2178, 1.0647, 1.3655, 1.2035, 1.1146, 1.0231],\n",
            "        [2.3004, 3.1738, 2.0002, 3.3231, 3.2884, 1.9016, 2.0008],\n",
            "        [1.1167, 1.6973, 1.3321, 1.8557, 1.7099, 1.3603, 1.2819]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "217\n",
            "tensor([[1.1379, 1.7166, 1.3308, 1.8706, 1.7263, 1.3707, 1.2902],\n",
            "        [3.3138, 4.0200, 2.3139, 4.1426, 4.1314, 2.4925, 2.5636],\n",
            "        [1.0842, 1.6633, 1.3257, 1.8251, 1.6743, 1.3461, 1.2651],\n",
            "        [3.3935, 4.0719, 2.3204, 4.1822, 4.1647, 2.5595, 2.6151],\n",
            "        [0.8658, 1.3563, 1.1430, 1.5059, 1.3468, 1.1904, 1.0989]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "218\n",
            "tensor([[3.0916, 3.8444, 2.2501, 3.9743, 3.9640, 2.3463, 2.4315],\n",
            "        [1.2110, 1.8303, 1.4129, 1.9933, 1.8525, 1.4189, 1.3508],\n",
            "        [3.2346, 3.9502, 2.2831, 4.0704, 4.0593, 2.4316, 2.5140],\n",
            "        [1.3280, 1.9778, 1.4819, 2.1409, 2.0061, 1.4874, 1.4271],\n",
            "        [1.0649, 1.6219, 1.2882, 1.7769, 1.6262, 1.3278, 1.2418]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "219\n",
            "tensor([[2.5175, 3.3761, 2.0843, 3.5214, 3.4930, 2.0144, 2.1197],\n",
            "        [3.3439, 4.0411, 2.3255, 4.1598, 4.1399, 2.5286, 2.5864],\n",
            "        [1.7904, 2.5476, 1.7416, 2.7094, 2.6100, 1.7227, 1.7128],\n",
            "        [2.2978, 3.1517, 1.9992, 3.3053, 3.2570, 1.9251, 2.0040],\n",
            "        [2.0746, 2.9064, 1.9024, 3.0651, 2.9971, 1.8326, 1.8809]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "220\n",
            "tensor([[1.6628, 2.3859, 1.6716, 2.5501, 2.4377, 1.6671, 1.6376],\n",
            "        [2.2172, 3.0620, 1.9666, 3.2216, 3.1617, 1.8919, 1.9615],\n",
            "        [3.0832, 3.8398, 2.2565, 3.9741, 3.9544, 2.3313, 2.4310],\n",
            "        [0.8524, 1.3328, 1.1328, 1.4852, 1.3213, 1.1812, 1.0901],\n",
            "        [3.3640, 4.0579, 2.3327, 4.1764, 4.1511, 2.5416, 2.6025]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "221\n",
            "tensor([[2.4564, 3.3452, 2.0804, 3.4919, 3.4644, 1.9564, 2.0856],\n",
            "        [3.2419, 3.9620, 2.3012, 4.0940, 4.0691, 2.4555, 2.5298],\n",
            "        [2.7752, 3.5901, 2.1677, 3.7355, 3.7128, 2.1481, 2.2563],\n",
            "        [2.7108, 3.5469, 2.1513, 3.6902, 3.6646, 2.1135, 2.2246],\n",
            "        [2.2533, 3.1320, 2.0031, 3.2898, 3.2407, 1.8840, 1.9830]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "222\n",
            "tensor([[1.0098, 1.5430, 1.2518, 1.7002, 1.5413, 1.2894, 1.2035],\n",
            "        [1.0805, 1.6490, 1.3218, 1.8130, 1.6557, 1.3446, 1.2620],\n",
            "        [3.0218, 3.7945, 2.2432, 3.9314, 3.9066, 2.2986, 2.3977],\n",
            "        [1.9679, 2.7778, 1.8584, 2.9452, 2.8603, 1.7938, 1.8237],\n",
            "        [3.3944, 4.0645, 2.3274, 4.1791, 4.1479, 2.5767, 2.6222]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "223\n",
            "tensor([[1.4547, 2.1288, 1.5558, 2.2929, 2.1609, 1.5582, 1.5067],\n",
            "        [2.3511, 3.2107, 2.0316, 3.3661, 3.3191, 1.9376, 2.0306],\n",
            "        [1.4950, 2.1950, 1.5994, 2.3655, 2.2374, 1.5777, 1.5383],\n",
            "        [3.2113, 3.9412, 2.3016, 4.0703, 4.0487, 2.4278, 2.5046],\n",
            "        [1.9668, 2.7630, 1.8443, 2.9267, 2.8388, 1.7982, 1.8181]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "224\n",
            "tensor([[2.1273, 2.9164, 1.8984, 3.0728, 2.9974, 1.8787, 1.9012],\n",
            "        [1.3764, 2.0288, 1.4996, 2.1891, 2.0532, 1.5140, 1.4524],\n",
            "        [3.0276, 3.7949, 2.2417, 3.9269, 3.9106, 2.2918, 2.3919],\n",
            "        [3.1410, 3.8856, 2.2778, 4.0166, 3.9929, 2.3769, 2.4587],\n",
            "        [1.7526, 2.5198, 1.7451, 2.6860, 2.5814, 1.7016, 1.6950]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "225\n",
            "tensor([[1.4328, 2.1105, 1.5499, 2.2755, 2.1427, 1.5489, 1.4940],\n",
            "        [0.9869, 1.5193, 1.2438, 1.6751, 1.5134, 1.2788, 1.1895],\n",
            "        [2.4019, 3.2951, 2.0671, 3.4417, 3.4063, 1.9393, 2.0549],\n",
            "        [2.3470, 3.2216, 2.0364, 3.3711, 3.3273, 1.9316, 2.0265],\n",
            "        [3.2603, 3.9843, 2.3158, 4.1052, 4.0823, 2.4697, 2.5317]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "226\n",
            "tensor([[1.0350, 1.5770, 1.2655, 1.7301, 1.5728, 1.3110, 1.2187],\n",
            "        [1.0029, 1.5493, 1.2681, 1.7090, 1.5475, 1.2948, 1.2058],\n",
            "        [0.9398, 1.4557, 1.2075, 1.6099, 1.4474, 1.2471, 1.1543],\n",
            "        [2.3209, 3.2122, 2.0363, 3.3606, 3.3187, 1.9072, 2.0122],\n",
            "        [0.8827, 1.3820, 1.1678, 1.5359, 1.3704, 1.2077, 1.1149]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "227\n",
            "tensor([[2.9585, 3.7486, 2.2292, 3.8769, 3.8597, 2.2597, 2.3525],\n",
            "        [1.2989, 1.9397, 1.4669, 2.1015, 1.9597, 1.4745, 1.4061],\n",
            "        [0.7221, 1.1611, 1.0376, 1.3065, 1.1384, 1.0822, 0.9912],\n",
            "        [0.9917, 1.5284, 1.2487, 1.6834, 1.5229, 1.2834, 1.1932],\n",
            "        [3.2382, 3.9685, 2.3123, 4.0893, 4.0678, 2.4614, 2.5193]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "228\n",
            "tensor([[3.2882, 4.0040, 2.3227, 4.1171, 4.0963, 2.4806, 2.5446],\n",
            "        [1.2051, 1.8146, 1.4021, 1.9717, 1.8244, 1.4238, 1.3425],\n",
            "        [3.0143, 3.7912, 2.2493, 3.9180, 3.8998, 2.3058, 2.3866],\n",
            "        [1.4949, 2.2032, 1.6023, 2.3644, 2.2397, 1.5822, 1.5356],\n",
            "        [3.1363, 3.8907, 2.2838, 4.0116, 3.9925, 2.3856, 2.4582]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "229\n",
            "tensor([[3.3838, 4.0746, 2.3492, 4.1800, 4.1553, 2.5764, 2.6132],\n",
            "        [2.9166, 3.7176, 2.2245, 3.8453, 3.8260, 2.2408, 2.3325],\n",
            "        [3.2221, 3.9569, 2.3118, 4.0742, 4.0539, 2.4427, 2.5079],\n",
            "        [1.4038, 2.0735, 1.5324, 2.2304, 2.0984, 1.5353, 1.4735],\n",
            "        [2.2565, 3.1047, 1.9892, 3.2522, 3.1965, 1.9202, 1.9785]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "230\n",
            "tensor([[0.7790, 1.2438, 1.0918, 1.3911, 1.2236, 1.1304, 1.0387],\n",
            "        [0.9945, 1.5402, 1.2600, 1.6938, 1.5343, 1.2872, 1.1989],\n",
            "        [2.8005, 3.6240, 2.1856, 3.7504, 3.7268, 2.1592, 2.2658],\n",
            "        [1.6005, 2.3393, 1.6635, 2.4965, 2.3815, 1.6320, 1.6025],\n",
            "        [1.1064, 1.6918, 1.3426, 1.8474, 1.6940, 1.3633, 1.2788]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "231\n",
            "tensor([[3.0321, 3.8084, 2.2547, 3.9266, 3.9105, 2.3063, 2.3981],\n",
            "        [3.3592, 4.0344, 2.3132, 4.1292, 4.0986, 2.5574, 2.5969],\n",
            "        [0.9959, 1.5394, 1.2559, 1.6908, 1.5311, 1.2863, 1.1979],\n",
            "        [1.3143, 1.9731, 1.4902, 2.1298, 1.9905, 1.4862, 1.4216],\n",
            "        [1.7810, 2.5761, 1.7792, 2.7330, 2.6353, 1.7103, 1.7151]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "232\n",
            "tensor([[0.7999, 1.2738, 1.1103, 1.4220, 1.2542, 1.1494, 1.0569],\n",
            "        [1.1724, 1.7690, 1.3744, 1.9201, 1.7713, 1.4021, 1.3201],\n",
            "        [2.3242, 3.2147, 2.0394, 3.3533, 3.3121, 1.9173, 2.0175],\n",
            "        [3.3541, 4.0591, 2.3445, 4.1612, 4.1359, 2.5480, 2.5954],\n",
            "        [1.3619, 2.0224, 1.5039, 2.1759, 2.0410, 1.5083, 1.4472]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "233\n",
            "tensor([[1.5695, 2.2792, 1.6201, 2.4280, 2.3099, 1.6145, 1.5760],\n",
            "        [1.3236, 1.9704, 1.4802, 2.1226, 1.9852, 1.4903, 1.4229],\n",
            "        [2.2065, 3.0723, 1.9778, 3.2141, 3.1591, 1.8803, 1.9552],\n",
            "        [3.3163, 4.0231, 2.3314, 4.1258, 4.1034, 2.5121, 2.5715],\n",
            "        [2.7318, 3.5722, 2.1654, 3.6947, 3.6745, 2.1207, 2.2320]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "234\n",
            "tensor([[1.6207, 2.3689, 1.6816, 2.5228, 2.4107, 1.6380, 1.6188],\n",
            "        [1.0163, 1.5646, 1.2679, 1.7127, 1.5563, 1.3028, 1.2136],\n",
            "        [2.3616, 3.2778, 2.0607, 3.4040, 3.3779, 1.9027, 2.0354],\n",
            "        [0.8168, 1.2913, 1.1083, 1.4325, 1.2683, 1.1535, 1.0630],\n",
            "        [2.0789, 2.9256, 1.9191, 3.0697, 3.0011, 1.8313, 1.8849]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "235\n",
            "tensor([[2.2188, 3.0777, 1.9756, 3.2153, 3.1596, 1.8918, 1.9621],\n",
            "        [1.7792, 2.5536, 1.7519, 2.6992, 2.5999, 1.7136, 1.7109],\n",
            "        [2.8413, 3.6579, 2.1983, 3.7768, 3.7578, 2.2044, 2.2998],\n",
            "        [0.9270, 1.4462, 1.2039, 1.5932, 1.4319, 1.2381, 1.1500],\n",
            "        [0.7318, 1.1772, 1.0465, 1.3176, 1.1506, 1.0904, 1.0015]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "236\n",
            "tensor([[3.2379, 3.9781, 2.3107, 4.0752, 4.0549, 2.4453, 2.5230],\n",
            "        [2.1550, 2.9990, 1.9417, 3.1343, 3.0716, 1.8748, 1.9290],\n",
            "        [1.6552, 2.4143, 1.6945, 2.5622, 2.4541, 1.6520, 1.6390],\n",
            "        [0.6979, 1.1293, 1.0124, 1.2640, 1.0983, 1.0590, 0.9715],\n",
            "        [0.9280, 1.4305, 1.1737, 1.5671, 1.4097, 1.2273, 1.1383]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "237\n",
            "tensor([[1.3022, 1.9520, 1.4651, 2.0960, 1.9589, 1.4693, 1.4107],\n",
            "        [1.2557, 1.8895, 1.4335, 2.0333, 1.8924, 1.4479, 1.3803],\n",
            "        [2.1270, 2.9651, 1.9229, 3.0981, 3.0330, 1.8651, 1.9114],\n",
            "        [2.2153, 3.0796, 1.9733, 3.2099, 3.1566, 1.8882, 1.9616],\n",
            "        [1.0737, 1.6482, 1.3113, 1.7923, 1.6409, 1.3308, 1.2544]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "238\n",
            "tensor([[2.4726, 3.3640, 2.0811, 3.4782, 3.4522, 1.9796, 2.0962],\n",
            "        [0.7985, 1.2778, 1.1078, 1.4176, 1.2530, 1.1427, 1.0556],\n",
            "        [1.5724, 2.3128, 1.6460, 2.4537, 2.3433, 1.6069, 1.5855],\n",
            "        [2.6751, 3.5406, 2.1471, 3.6473, 3.6272, 2.0770, 2.2038],\n",
            "        [2.6471, 3.5109, 2.1369, 3.6226, 3.6019, 2.0771, 2.1896]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "239\n",
            "tensor([[1.9862, 2.8172, 1.8581, 2.9450, 2.8693, 1.7915, 1.8315],\n",
            "        [3.1276, 3.8994, 2.2794, 3.9904, 3.9744, 2.3677, 2.4580],\n",
            "        [2.0268, 2.8946, 1.9026, 3.0226, 2.9567, 1.7910, 1.8587],\n",
            "        [3.3881, 4.0912, 2.3411, 4.1686, 4.1472, 2.5644, 2.6183],\n",
            "        [2.5473, 3.4405, 2.1069, 3.5471, 3.5278, 1.9899, 2.1316]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "240\n",
            "tensor([[3.3763, 4.0943, 2.3381, 4.1655, 4.1496, 2.5474, 2.6096],\n",
            "        [2.7300, 3.5836, 2.1511, 3.6836, 3.6643, 2.1150, 2.2329],\n",
            "        [0.8178, 1.2982, 1.1021, 1.4267, 1.2673, 1.1460, 1.0617],\n",
            "        [2.3587, 3.2159, 2.0094, 3.3291, 3.2866, 1.9583, 2.0356],\n",
            "        [2.9068, 3.7352, 2.2076, 3.8246, 3.8113, 2.1997, 2.3291]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "241\n",
            "tensor([[3.3095, 4.0431, 2.3194, 4.1199, 4.1082, 2.4880, 2.5654],\n",
            "        [1.4539, 2.1542, 1.5515, 2.2844, 2.1640, 1.5450, 1.5064],\n",
            "        [1.5558, 2.2795, 1.6036, 2.4063, 2.2950, 1.5940, 1.5669],\n",
            "        [0.8408, 1.3330, 1.1227, 1.4621, 1.3032, 1.1658, 1.0810],\n",
            "        [2.8727, 3.7132, 2.1938, 3.7982, 3.7865, 2.1853, 2.3103]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "242\n",
            "tensor([[3.3706, 4.0610, 2.2873, 4.1159, 4.0968, 2.5399, 2.6007],\n",
            "        [2.3407, 3.2557, 2.0220, 3.3559, 3.3284, 1.8969, 2.0229],\n",
            "        [2.8944, 3.7289, 2.1937, 3.8127, 3.8031, 2.2006, 2.3199],\n",
            "        [3.3609, 4.0868, 2.3244, 4.1519, 4.1381, 2.5142, 2.5955],\n",
            "        [2.9238, 3.7499, 2.2019, 3.8361, 3.8266, 2.2077, 2.3356]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "243\n",
            "tensor([[1.9421, 2.7839, 1.8281, 2.8985, 2.8261, 1.7511, 1.8021],\n",
            "        [2.6214, 3.5035, 2.1077, 3.5907, 3.5780, 2.0333, 2.1666],\n",
            "        [1.1195, 1.7050, 1.3104, 1.8292, 1.6864, 1.3444, 1.2748],\n",
            "        [2.7980, 3.6537, 2.1585, 3.7350, 3.7267, 2.1340, 2.2638],\n",
            "        [3.2863, 4.0322, 2.3014, 4.0996, 4.0945, 2.4502, 2.5458]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "244\n",
            "tensor([[2.6447, 3.5275, 2.1100, 3.6108, 3.6044, 2.0375, 2.1789],\n",
            "        [3.3974, 4.1143, 2.3206, 4.1733, 4.1632, 2.5473, 2.6176],\n",
            "        [1.5892, 2.3434, 1.6339, 2.4656, 2.3635, 1.5931, 1.5896],\n",
            "        [3.3730, 4.0676, 2.2832, 4.1199, 4.1018, 2.5341, 2.6018],\n",
            "        [1.8786, 2.7012, 1.7879, 2.8176, 2.7391, 1.7269, 1.7643]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "245\n",
            "tensor([[0.9941, 1.5411, 1.2227, 1.6645, 1.5164, 1.2597, 1.1858],\n",
            "        [1.0686, 1.6488, 1.2878, 1.7770, 1.6320, 1.3115, 1.2442],\n",
            "        [2.6834, 3.5602, 2.1148, 3.6407, 3.6350, 2.0590, 2.1965],\n",
            "        [1.7473, 2.5286, 1.7027, 2.6438, 2.5542, 1.6669, 1.6802],\n",
            "        [1.0663, 1.6455, 1.2851, 1.7715, 1.6276, 1.3066, 1.2414]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "246\n",
            "tensor([[3.3769, 4.1009, 2.3075, 4.1593, 4.1511, 2.5012, 2.5944],\n",
            "        [0.8057, 1.2856, 1.0835, 1.4088, 1.2528, 1.1252, 1.0490],\n",
            "        [2.7003, 3.5736, 2.1149, 3.6506, 3.6495, 2.0492, 2.1988],\n",
            "        [0.8142, 1.2892, 1.0768, 1.4079, 1.2548, 1.1244, 1.0487],\n",
            "        [3.3557, 4.0828, 2.3014, 4.1394, 4.1326, 2.5004, 2.5829]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "247\n",
            "tensor([[0.8246, 1.3043, 1.0876, 1.4243, 1.2711, 1.1337, 1.0578],\n",
            "        [0.7862, 1.2493, 1.0528, 1.3674, 1.2140, 1.1010, 1.0265],\n",
            "        [3.3928, 4.1057, 2.3002, 4.1591, 4.1550, 2.5210, 2.6049],\n",
            "        [1.5767, 2.3041, 1.5876, 2.4166, 2.3157, 1.5783, 1.5673],\n",
            "        [2.4744, 3.3384, 2.0170, 3.4256, 3.4041, 1.9686, 2.0819]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "248\n",
            "tensor([[3.3655, 4.0869, 2.2818, 4.1377, 4.1350, 2.4842, 2.5791],\n",
            "        [1.6002, 2.3351, 1.5975, 2.4472, 2.3482, 1.5860, 1.5807],\n",
            "        [3.4021, 4.1168, 2.2948, 4.1645, 4.1654, 2.5163, 2.6019],\n",
            "        [1.2901, 1.9469, 1.4256, 2.0669, 1.9435, 1.4241, 1.3871],\n",
            "        [2.7408, 3.6005, 2.1078, 3.6717, 3.6719, 2.0649, 2.2154]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "249\n",
            "tensor([[1.4676, 2.1665, 1.5155, 2.2772, 2.1714, 1.5111, 1.4932],\n",
            "        [3.3917, 4.0933, 2.2653, 4.1368, 4.1319, 2.5063, 2.5942],\n",
            "        [1.1315, 1.7082, 1.2831, 1.8201, 1.6878, 1.3308, 1.2663],\n",
            "        [0.7313, 1.1821, 1.0174, 1.3003, 1.1466, 1.0577, 0.9865],\n",
            "        [0.8542, 1.3544, 1.1172, 1.4751, 1.3241, 1.1519, 1.0815]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "250\n",
            "tensor([[3.2137, 3.9750, 2.2310, 4.0249, 4.0348, 2.3596, 2.4782],\n",
            "        [1.6124, 2.3665, 1.6098, 2.4744, 2.3847, 1.5730, 1.5846],\n",
            "        [1.0463, 1.6123, 1.2455, 1.7276, 1.5908, 1.2738, 1.2134],\n",
            "        [3.0283, 3.8272, 2.1755, 3.8794, 3.8991, 2.2230, 2.3622],\n",
            "        [1.5343, 2.2480, 1.5436, 2.3522, 2.2542, 1.5421, 1.5302]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "251\n",
            "tensor([[2.4436, 3.3432, 1.9956, 3.4129, 3.4137, 1.8937, 2.0455],\n",
            "        [0.8187, 1.2955, 1.0668, 1.4068, 1.2616, 1.1097, 1.0425],\n",
            "        [0.8512, 1.3405, 1.0932, 1.4516, 1.3069, 1.1362, 1.0665],\n",
            "        [3.4028, 4.1003, 2.2595, 4.1331, 4.1370, 2.5062, 2.5912],\n",
            "        [3.3871, 4.0876, 2.2588, 4.1228, 4.1335, 2.4797, 2.5757]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "252\n",
            "tensor([[3.0753, 3.8608, 2.1788, 3.9080, 3.9255, 2.2416, 2.3842],\n",
            "        [2.6527, 3.5202, 2.0521, 3.5808, 3.5932, 1.9845, 2.1459],\n",
            "        [1.7312, 2.5225, 1.6734, 2.6201, 2.5487, 1.6147, 1.6505],\n",
            "        [2.5554, 3.4376, 2.0218, 3.5005, 3.5064, 1.9514, 2.0996],\n",
            "        [1.1992, 1.8178, 1.3405, 1.9260, 1.8025, 1.3568, 1.3121]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "253\n",
            "tensor([[3.3168, 4.0453, 2.2398, 4.0806, 4.0989, 2.4121, 2.5208],\n",
            "        [3.3718, 4.0921, 2.2568, 4.1228, 4.1379, 2.4623, 2.5589],\n",
            "        [1.2682, 1.9150, 1.3898, 2.0233, 1.9073, 1.3903, 1.3569],\n",
            "        [0.7358, 1.1827, 1.0024, 1.2906, 1.1430, 1.0456, 0.9772],\n",
            "        [2.2193, 3.0770, 1.8847, 3.1543, 3.1286, 1.8145, 1.9172]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "254\n",
            "tensor([[0.8455, 1.3363, 1.0884, 1.4452, 1.3027, 1.1254, 1.0587],\n",
            "        [2.4996, 3.2766, 1.9353, 3.3413, 3.3231, 1.9980, 2.0590],\n",
            "        [0.9999, 1.5419, 1.1887, 1.6461, 1.5134, 1.2241, 1.1644],\n",
            "        [0.9811, 1.5230, 1.1876, 1.6300, 1.4951, 1.2195, 1.1561],\n",
            "        [2.8912, 3.7022, 2.1065, 3.7554, 3.7711, 2.1396, 2.2720]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "255\n",
            "tensor([[1.2602, 1.9018, 1.3772, 2.0035, 1.8904, 1.3840, 1.3442],\n",
            "        [1.3708, 2.0487, 1.4447, 2.1485, 2.0444, 1.4404, 1.4155],\n",
            "        [1.9711, 2.8107, 1.7765, 2.8919, 2.8495, 1.6952, 1.7730],\n",
            "        [1.4568, 2.1443, 1.4751, 2.2361, 2.1420, 1.4791, 1.4615],\n",
            "        [3.1328, 3.9074, 2.1844, 3.9446, 3.9726, 2.2680, 2.3978]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "256\n",
            "tensor([[0.8388, 1.3205, 1.0706, 1.4247, 1.2834, 1.1165, 1.0466],\n",
            "        [3.3189, 4.0535, 2.2392, 4.0846, 4.1062, 2.4066, 2.5116],\n",
            "        [2.5763, 3.4723, 2.0251, 3.5192, 3.5425, 1.9130, 2.0869],\n",
            "        [3.1270, 3.8995, 2.1777, 3.9342, 3.9596, 2.2488, 2.3891],\n",
            "        [1.9418, 2.7844, 1.7689, 2.8640, 2.8222, 1.6783, 1.7552]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "257\n",
            "tensor([[2.7414, 3.6024, 2.0699, 3.6476, 3.6719, 2.0267, 2.1776],\n",
            "        [3.3786, 4.0940, 2.2490, 4.1180, 4.1409, 2.4417, 2.5425],\n",
            "        [1.0806, 1.6601, 1.2555, 1.7629, 1.6366, 1.2732, 1.2203],\n",
            "        [3.3825, 4.1009, 2.2541, 4.1235, 4.1472, 2.4546, 2.5465],\n",
            "        [1.9731, 2.8100, 1.7738, 2.8884, 2.8476, 1.6956, 1.7693]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "258\n",
            "tensor([[3.3781, 4.0975, 2.2521, 4.1181, 4.1445, 2.4480, 2.5404],\n",
            "        [0.9271, 1.4372, 1.1279, 1.5367, 1.4026, 1.1740, 1.1045],\n",
            "        [1.1762, 1.7824, 1.3079, 1.8799, 1.7626, 1.3290, 1.2793],\n",
            "        [1.9059, 2.7069, 1.7187, 2.7808, 2.7329, 1.6664, 1.7202],\n",
            "        [2.0262, 2.8634, 1.7899, 2.9365, 2.9006, 1.7187, 1.7937]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "259\n",
            "tensor([[2.5946, 3.4892, 2.0244, 3.5310, 3.5557, 1.9229, 2.0914],\n",
            "        [3.3336, 4.0463, 2.2165, 4.0658, 4.0845, 2.4058, 2.5126],\n",
            "        [0.6571, 1.0765, 0.9352, 1.1773, 1.0328, 0.9748, 0.9093],\n",
            "        [0.7892, 1.2565, 1.0349, 1.3579, 1.2170, 1.0755, 1.0078],\n",
            "        [2.2096, 3.0502, 1.8550, 3.1140, 3.0954, 1.8053, 1.8898]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "260\n",
            "tensor([[2.3276, 3.2432, 1.9390, 3.2968, 3.3069, 1.8008, 1.9538],\n",
            "        [1.2072, 1.8245, 1.3239, 1.9179, 1.8055, 1.3398, 1.2963],\n",
            "        [2.1401, 3.0041, 1.8446, 3.0691, 3.0512, 1.7571, 1.8548],\n",
            "        [1.2984, 1.9479, 1.3854, 2.0407, 1.9356, 1.3946, 1.3585],\n",
            "        [2.3505, 3.2968, 1.9582, 3.3418, 3.3639, 1.7786, 1.9623]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "261\n",
            "tensor([[2.5458, 3.4475, 2.0059, 3.4899, 3.5130, 1.8954, 2.0630],\n",
            "        [1.3596, 2.0373, 1.4321, 2.1305, 2.0320, 1.4203, 1.3981],\n",
            "        [3.2870, 4.0281, 2.2241, 4.0545, 4.0841, 2.3709, 2.4768],\n",
            "        [3.3499, 4.0747, 2.2365, 4.0964, 4.1230, 2.4161, 2.5165],\n",
            "        [1.9439, 2.7792, 1.7557, 2.8538, 2.8133, 1.6749, 1.7461]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "262\n",
            "tensor([[1.5292, 2.2580, 1.5312, 2.3451, 2.2627, 1.5033, 1.5013],\n",
            "        [3.0242, 3.8297, 2.1432, 3.8579, 3.8941, 2.1783, 2.3188],\n",
            "        [3.4000, 4.1120, 2.2471, 4.1297, 4.1563, 2.4572, 2.5460],\n",
            "        [3.2376, 3.9879, 2.1994, 4.0114, 4.0387, 2.3282, 2.4459],\n",
            "        [1.4764, 2.1557, 1.4619, 2.2360, 2.1504, 1.4688, 1.4531]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "263\n",
            "tensor([[1.6982, 2.4566, 1.6035, 2.5331, 2.4696, 1.5826, 1.5946],\n",
            "        [0.9691, 1.5076, 1.1629, 1.6042, 1.4757, 1.1932, 1.1333],\n",
            "        [1.7229, 2.4989, 1.6269, 2.5763, 2.5153, 1.5788, 1.6093],\n",
            "        [0.9319, 1.4693, 1.1538, 1.5705, 1.4393, 1.1706, 1.1121],\n",
            "        [2.3712, 3.2583, 1.9328, 3.3098, 3.3161, 1.8353, 1.9690]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "264\n",
            "tensor([[2.8799, 3.7196, 2.0984, 3.7498, 3.7865, 2.0941, 2.2385],\n",
            "        [1.6309, 2.3939, 1.5859, 2.4730, 2.4048, 1.5480, 1.5602],\n",
            "        [0.8033, 1.2841, 1.0437, 1.3808, 1.2434, 1.0808, 1.0144],\n",
            "        [1.9039, 2.7559, 1.7487, 2.8248, 2.7896, 1.6462, 1.7207],\n",
            "        [1.4085, 2.0994, 1.4485, 2.1847, 2.0938, 1.4448, 1.4224]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "265\n",
            "tensor([[2.3880, 3.3379, 1.9590, 3.3688, 3.4020, 1.7890, 1.9713],\n",
            "        [1.9243, 2.7700, 1.7421, 2.8349, 2.8001, 1.6614, 1.7300],\n",
            "        [3.1661, 3.9401, 2.1736, 3.9569, 3.9994, 2.2707, 2.3947],\n",
            "        [0.7891, 1.2670, 1.0347, 1.3629, 1.2263, 1.0682, 1.0043],\n",
            "        [2.9881, 3.8054, 2.1191, 3.8263, 3.8659, 2.1436, 2.2924]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "266\n",
            "tensor([[0.8808, 1.4001, 1.1074, 1.4951, 1.3638, 1.1368, 1.0734],\n",
            "        [0.9352, 1.4713, 1.1397, 1.5628, 1.4377, 1.1700, 1.1082],\n",
            "        [0.8852, 1.4049, 1.1096, 1.4988, 1.3687, 1.1422, 1.0768],\n",
            "        [0.8897, 1.4087, 1.1096, 1.5019, 1.3721, 1.1436, 1.0781],\n",
            "        [2.9433, 3.7740, 2.1050, 3.7936, 3.8378, 2.1189, 2.2662]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "267\n",
            "tensor([[3.3795, 4.1042, 2.2240, 4.1089, 4.1468, 2.4401, 2.5267],\n",
            "        [2.3511, 3.3096, 1.9431, 3.3368, 3.3716, 1.7754, 1.9521],\n",
            "        [1.1161, 1.7268, 1.2696, 1.8130, 1.7013, 1.2838, 1.2347],\n",
            "        [3.2412, 4.0009, 2.1853, 4.0073, 4.0512, 2.3365, 2.4412],\n",
            "        [2.8842, 3.7349, 2.0864, 3.7500, 3.7909, 2.0909, 2.2338]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "268\n",
            "tensor([[1.8810, 2.7196, 1.7100, 2.7770, 2.7426, 1.6470, 1.7034],\n",
            "        [0.8097, 1.3079, 1.0608, 1.4030, 1.2683, 1.0919, 1.0253],\n",
            "        [2.6408, 3.5297, 2.0120, 3.5537, 3.5883, 1.9572, 2.1039],\n",
            "        [2.8024, 3.6684, 2.0615, 3.6855, 3.7295, 2.0310, 2.1875],\n",
            "        [0.9766, 1.5396, 1.1803, 1.6294, 1.5071, 1.2016, 1.1423]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "269\n",
            "tensor([[1.3598, 2.0424, 1.4115, 2.1158, 2.0275, 1.4213, 1.3874],\n",
            "        [0.8271, 1.3254, 1.0606, 1.4144, 1.2827, 1.0984, 1.0312],\n",
            "        [3.3743, 4.1015, 2.2204, 4.0953, 4.1361, 2.4446, 2.5209],\n",
            "        [2.1328, 3.0409, 1.8404, 3.0817, 3.0844, 1.7265, 1.8393],\n",
            "        [1.8587, 2.7005, 1.7079, 2.7554, 2.7229, 1.6345, 1.6894]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "270\n",
            "tensor([[1.0478, 1.6399, 1.2295, 1.7262, 1.6106, 1.2456, 1.1889],\n",
            "        [2.8711, 3.7250, 2.0870, 3.7335, 3.7817, 2.0895, 2.2244],\n",
            "        [0.8357, 1.3402, 1.0728, 1.4288, 1.2992, 1.1071, 1.0387],\n",
            "        [2.7368, 3.6197, 2.0485, 3.6300, 3.6777, 1.9971, 2.1479],\n",
            "        [1.3301, 2.0220, 1.4162, 2.0984, 2.0091, 1.4036, 1.3741]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "271\n",
            "tensor([[2.2250, 3.1679, 1.8929, 3.1979, 3.2206, 1.7474, 1.8847],\n",
            "        [0.8410, 1.3553, 1.0879, 1.4455, 1.3159, 1.1126, 1.0450],\n",
            "        [1.1646, 1.7942, 1.3041, 1.8734, 1.7687, 1.3152, 1.2634],\n",
            "        [1.9030, 2.7591, 1.7298, 2.8097, 2.7849, 1.6499, 1.7108],\n",
            "        [3.2438, 4.0161, 2.1920, 4.0122, 4.0641, 2.3427, 2.4362]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "272\n",
            "tensor([[0.9305, 1.4817, 1.1546, 1.5710, 1.4478, 1.1735, 1.1086],\n",
            "        [2.8535, 3.7139, 2.0825, 3.7170, 3.7720, 2.0740, 2.2066],\n",
            "        [0.9690, 1.5328, 1.1769, 1.6194, 1.4997, 1.2008, 1.1352],\n",
            "        [1.7033, 2.5283, 1.6469, 2.5861, 2.5434, 1.5661, 1.5994],\n",
            "        [1.7203, 2.5337, 1.6364, 2.5901, 2.5472, 1.5815, 1.6062]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "273\n",
            "tensor([[2.4354, 3.3841, 1.9631, 3.3982, 3.4432, 1.8314, 1.9867],\n",
            "        [2.3330, 3.2847, 1.9313, 3.3056, 3.3422, 1.7981, 1.9372],\n",
            "        [1.2376, 1.8993, 1.3534, 1.9743, 1.8815, 1.3563, 1.3097],\n",
            "        [0.7339, 1.1968, 0.9886, 1.2803, 1.1487, 1.0311, 0.9584],\n",
            "        [0.8876, 1.4160, 1.1127, 1.5006, 1.3765, 1.1461, 1.0733]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "274\n",
            "tensor([[1.5538, 2.3375, 1.5619, 2.4002, 2.3414, 1.5102, 1.5094],\n",
            "        [3.1238, 3.9319, 2.1575, 3.9264, 3.9820, 2.2640, 2.3605],\n",
            "        [2.1469, 3.0747, 1.8537, 3.1062, 3.1194, 1.7360, 1.8398],\n",
            "        [1.4492, 2.1871, 1.4871, 2.2540, 2.1806, 1.4691, 1.4437],\n",
            "        [1.4746, 2.2207, 1.5019, 2.2854, 2.2159, 1.4767, 1.4581]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "275\n",
            "tensor([[2.8098, 3.6842, 2.0679, 3.6877, 3.7443, 2.0718, 2.1801],\n",
            "        [2.1495, 3.0527, 1.8422, 3.0842, 3.0938, 1.7548, 1.8374],\n",
            "        [1.5773, 2.3453, 1.5510, 2.4036, 2.3456, 1.5332, 1.5164],\n",
            "        [3.0663, 3.8853, 2.1375, 3.8796, 3.9315, 2.2236, 2.3269],\n",
            "        [1.3458, 2.0460, 1.4193, 2.1149, 2.0322, 1.4108, 1.3740]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "276\n",
            "tensor([[1.5304, 2.2858, 1.5252, 2.3461, 2.2825, 1.5080, 1.4874],\n",
            "        [2.7940, 3.6754, 2.0592, 3.6741, 3.7329, 2.0306, 2.1652],\n",
            "        [2.0636, 2.9580, 1.8054, 2.9952, 2.9933, 1.7260, 1.7924],\n",
            "        [2.4214, 3.3824, 1.9612, 3.3918, 3.4408, 1.8293, 1.9744],\n",
            "        [1.1411, 1.7743, 1.2934, 1.8507, 1.7474, 1.3037, 1.2443]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "277\n",
            "tensor([[1.0493, 1.6548, 1.2411, 1.7354, 1.6239, 1.2532, 1.1869],\n",
            "        [2.4780, 3.4211, 1.9701, 3.4254, 3.4735, 1.8463, 1.9985],\n",
            "        [1.3955, 2.1150, 1.4464, 2.1781, 2.1009, 1.4350, 1.4036],\n",
            "        [2.3860, 3.3441, 1.9449, 3.3545, 3.3976, 1.8159, 1.9559],\n",
            "        [0.9244, 1.4750, 1.1429, 1.5568, 1.4362, 1.1720, 1.0979]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "278\n",
            "tensor([[3.1962, 3.9734, 2.1602, 3.9582, 4.0150, 2.3252, 2.3926],\n",
            "        [0.8576, 1.3755, 1.0854, 1.4548, 1.3304, 1.1248, 1.0466],\n",
            "        [1.0580, 1.6571, 1.2307, 1.7290, 1.6229, 1.2501, 1.1833],\n",
            "        [1.2474, 1.9266, 1.3662, 1.9975, 1.9054, 1.3658, 1.3139],\n",
            "        [2.4460, 3.4024, 1.9620, 3.4078, 3.4566, 1.8462, 1.9847]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "279\n",
            "tensor([[3.3521, 4.0886, 2.1916, 4.0601, 4.1074, 2.4463, 2.4953],\n",
            "        [2.1697, 3.0941, 1.8526, 3.1159, 3.1300, 1.7610, 1.8452],\n",
            "        [2.2148, 3.1667, 1.8786, 3.1829, 3.2082, 1.7557, 1.8677],\n",
            "        [3.0677, 3.8924, 2.1370, 3.8798, 3.9404, 2.2273, 2.3225],\n",
            "        [0.7448, 1.2231, 1.0036, 1.3049, 1.1733, 1.0422, 0.9665]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "280\n",
            "tensor([[0.8393, 1.3544, 1.0729, 1.4321, 1.3063, 1.1125, 1.0328],\n",
            "        [1.6233, 2.4148, 1.5718, 2.4614, 2.4106, 1.5412, 1.5368],\n",
            "        [0.9458, 1.5033, 1.1509, 1.5785, 1.4591, 1.1867, 1.1087],\n",
            "        [3.0818, 3.9111, 2.1418, 3.8960, 3.9543, 2.2335, 2.3278],\n",
            "        [2.9455, 3.8080, 2.1002, 3.7935, 3.8543, 2.1325, 2.2484]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "281\n",
            "tensor([[3.2097, 4.0102, 2.1753, 3.9888, 4.0476, 2.3293, 2.4029],\n",
            "        [3.3338, 4.0914, 2.1981, 4.0651, 4.1140, 2.4231, 2.4813],\n",
            "        [2.2666, 3.2313, 1.9013, 3.2397, 3.2708, 1.7750, 1.8929],\n",
            "        [2.5748, 3.5166, 1.9972, 3.5113, 3.5659, 1.9083, 2.0462],\n",
            "        [2.2119, 3.1385, 1.8632, 3.1544, 3.1713, 1.7787, 1.8645]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "282\n",
            "tensor([[3.3647, 4.1205, 2.2168, 4.0916, 4.1412, 2.4530, 2.5003],\n",
            "        [2.4318, 3.4035, 1.9623, 3.4004, 3.4462, 1.8343, 1.9741],\n",
            "        [0.7826, 1.2723, 1.0263, 1.3493, 1.2183, 1.0694, 0.9893],\n",
            "        [0.8875, 1.4250, 1.1117, 1.5016, 1.3775, 1.1452, 1.0681],\n",
            "        [2.3591, 3.3308, 1.9370, 3.3311, 3.3713, 1.8050, 1.9377]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "283\n",
            "tensor([[3.3683, 4.1241, 2.2162, 4.0928, 4.1407, 2.4522, 2.5010],\n",
            "        [0.8484, 1.3654, 1.0783, 1.4404, 1.3144, 1.1155, 1.0370],\n",
            "        [1.5864, 2.3805, 1.5656, 2.4254, 2.3686, 1.5276, 1.5161],\n",
            "        [0.9387, 1.4830, 1.1292, 1.5527, 1.4318, 1.1736, 1.0955],\n",
            "        [2.4424, 3.4198, 1.9686, 3.4125, 3.4624, 1.8275, 1.9776]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "284\n",
            "tensor([[2.8720, 3.7530, 2.0844, 3.7374, 3.7928, 2.0931, 2.2077],\n",
            "        [0.9326, 1.4841, 1.1423, 1.5570, 1.4349, 1.1742, 1.0970],\n",
            "        [3.3841, 4.1185, 2.2033, 4.0801, 4.1209, 2.4795, 2.5132],\n",
            "        [1.6882, 2.5120, 1.6240, 2.5531, 2.5042, 1.5746, 1.5784],\n",
            "        [2.9414, 3.8088, 2.1005, 3.7911, 3.8417, 2.1307, 2.2446]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "285\n",
            "tensor([[1.0360, 1.6284, 1.2123, 1.6960, 1.5813, 1.2378, 1.1666],\n",
            "        [1.9018, 2.7709, 1.7226, 2.7995, 2.7736, 1.6662, 1.6975],\n",
            "        [2.1400, 3.0710, 1.8451, 3.0865, 3.0901, 1.7453, 1.8274],\n",
            "        [2.2809, 3.2220, 1.8985, 3.2292, 3.2493, 1.8006, 1.8992],\n",
            "        [3.3445, 4.1065, 2.2128, 4.0757, 4.1241, 2.4281, 2.4828]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "286\n",
            "tensor([[1.8504, 2.7067, 1.6992, 2.7392, 2.7060, 1.6491, 1.6695],\n",
            "        [1.6298, 2.4285, 1.5820, 2.4712, 2.4135, 1.5524, 1.5423],\n",
            "        [2.1540, 3.0627, 1.8338, 3.0765, 3.0797, 1.7609, 1.8302],\n",
            "        [3.3162, 4.0954, 2.2145, 4.0654, 4.1111, 2.4044, 2.4672],\n",
            "        [3.3486, 4.1102, 2.2116, 4.0774, 4.1176, 2.4320, 2.4886]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "287\n",
            "tensor([[1.4250, 2.1693, 1.4750, 2.2230, 2.1438, 1.4562, 1.4234],\n",
            "        [2.4246, 3.3975, 1.9605, 3.3877, 3.4282, 1.8378, 1.9720],\n",
            "        [0.7671, 1.2458, 1.0079, 1.3194, 1.1875, 1.0562, 0.9758],\n",
            "        [3.1866, 4.0006, 2.1738, 3.9735, 4.0243, 2.3092, 2.3884],\n",
            "        [1.4246, 2.1598, 1.4635, 2.2100, 2.1336, 1.4551, 1.4194]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "288\n",
            "tensor([[3.3429, 4.1084, 2.2169, 4.0773, 4.1247, 2.4331, 2.4862],\n",
            "        [2.0187, 2.8958, 1.7673, 2.9151, 2.8982, 1.7269, 1.7631],\n",
            "        [2.4001, 3.3434, 1.9417, 3.3407, 3.3690, 1.8564, 1.9633],\n",
            "        [0.7460, 1.2231, 1.0010, 1.2984, 1.1642, 1.0436, 0.9645],\n",
            "        [1.5380, 2.3131, 1.5354, 2.3562, 2.2893, 1.5112, 1.4911]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "289\n",
            "tensor([[3.3791, 4.1314, 2.2187, 4.0911, 4.1370, 2.4749, 2.5136],\n",
            "        [2.2240, 3.1636, 1.8742, 3.1676, 3.1796, 1.7802, 1.8732],\n",
            "        [3.1457, 3.9630, 2.1662, 3.9353, 3.9871, 2.3028, 2.3726],\n",
            "        [3.0913, 3.9301, 2.1509, 3.8992, 3.9492, 2.2386, 2.3370],\n",
            "        [2.7953, 3.6971, 2.0673, 3.6746, 3.7236, 2.0515, 2.1695]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "290\n",
            "tensor([[3.3643, 4.1252, 2.2190, 4.0817, 4.1250, 2.4560, 2.5037],\n",
            "        [2.4486, 3.4287, 1.9731, 3.4081, 3.4568, 1.8371, 1.9844],\n",
            "        [2.4232, 3.3785, 1.9530, 3.3692, 3.4007, 1.8664, 1.9788],\n",
            "        [2.1653, 3.0996, 1.8535, 3.1038, 3.1095, 1.7609, 1.8446],\n",
            "        [0.7662, 1.2519, 1.0185, 1.3243, 1.1923, 1.0607, 0.9805]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "291\n",
            "tensor([[2.0346, 2.9512, 1.8007, 2.9613, 2.9555, 1.7068, 1.7738],\n",
            "        [0.7704, 1.2624, 1.0299, 1.3353, 1.2031, 1.0650, 0.9859],\n",
            "        [3.1300, 3.9566, 2.1609, 3.9201, 3.9733, 2.2741, 2.3581],\n",
            "        [0.7608, 1.2364, 1.0001, 1.3046, 1.1753, 1.0462, 0.9695],\n",
            "        [1.4249, 2.1586, 1.4630, 2.2026, 2.1242, 1.4586, 1.4209]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "292\n",
            "tensor([[0.6718, 1.1221, 0.9526, 1.1971, 1.0597, 0.9883, 0.9122],\n",
            "        [1.5311, 2.3135, 1.5401, 2.3518, 2.2873, 1.4974, 1.4862],\n",
            "        [3.3036, 4.0847, 2.2101, 4.0399, 4.0909, 2.4018, 2.4617],\n",
            "        [1.1087, 1.7249, 1.2598, 1.7815, 1.6743, 1.2857, 1.2162],\n",
            "        [3.3688, 4.1089, 2.2040, 4.0567, 4.0974, 2.4663, 2.5057]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "293\n",
            "tensor([[3.0920, 3.9169, 2.1468, 3.8747, 3.9287, 2.2301, 2.3310],\n",
            "        [0.9122, 1.4524, 1.1233, 1.5158, 1.3928, 1.1584, 1.0811],\n",
            "        [3.3774, 4.1193, 2.2121, 4.0669, 4.1111, 2.4700, 2.5110],\n",
            "        [2.6292, 3.5692, 2.0251, 3.5401, 3.5896, 1.9353, 2.0752],\n",
            "        [2.9137, 3.7841, 2.0993, 3.7475, 3.8004, 2.1227, 2.2316]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "294\n",
            "tensor([[1.6693, 2.4630, 1.5983, 2.4911, 2.4377, 1.5699, 1.5621],\n",
            "        [3.3556, 4.0887, 2.2006, 4.0364, 4.0780, 2.4535, 2.4939],\n",
            "        [0.5944, 1.0034, 0.8801, 1.0747, 0.9380, 0.9177, 0.8471],\n",
            "        [3.3115, 4.0762, 2.2045, 4.0278, 4.0721, 2.3975, 2.4629],\n",
            "        [2.8256, 3.6354, 2.0404, 3.6149, 3.6458, 2.1570, 2.1937]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "295\n",
            "tensor([[1.4857, 2.2399, 1.5103, 2.2768, 2.2068, 1.4784, 1.4544],\n",
            "        [0.7463, 1.2210, 1.0102, 1.2922, 1.1586, 1.0436, 0.9651],\n",
            "        [2.1719, 3.0944, 1.8560, 3.0909, 3.0978, 1.7574, 1.8403],\n",
            "        [0.7429, 1.2109, 0.9973, 1.2790, 1.1470, 1.0354, 0.9582],\n",
            "        [2.8942, 3.7696, 2.0992, 3.7336, 3.7858, 2.0998, 2.2175]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "296\n",
            "tensor([[0.7465, 1.2234, 1.0128, 1.2943, 1.1617, 1.0417, 0.9653],\n",
            "        [3.3790, 4.1264, 2.2290, 4.0719, 4.1167, 2.4636, 2.5076],\n",
            "        [2.8242, 3.7059, 2.0724, 3.6731, 3.7257, 2.0491, 2.1765],\n",
            "        [0.6741, 1.1175, 0.9513, 1.1897, 1.0544, 0.9845, 0.9096],\n",
            "        [2.8133, 3.6986, 2.0752, 3.6636, 3.7177, 2.0668, 2.1744]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "297\n",
            "tensor([[3.3257, 4.0856, 2.2104, 4.0332, 4.0774, 2.4074, 2.4716],\n",
            "        [0.9031, 1.4378, 1.1221, 1.4999, 1.3769, 1.1455, 1.0731],\n",
            "        [1.9516, 2.8103, 1.7440, 2.8190, 2.7988, 1.6783, 1.7172],\n",
            "        [2.2497, 3.1969, 1.8991, 3.1853, 3.2074, 1.7692, 1.8804],\n",
            "        [0.9072, 1.4200, 1.0881, 1.4767, 1.3618, 1.1322, 1.0600]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "298\n",
            "tensor([[3.2385, 4.0303, 2.2025, 3.9812, 4.0354, 2.3296, 2.4146],\n",
            "        [0.7750, 1.2618, 1.0364, 1.3308, 1.1995, 1.0611, 0.9850],\n",
            "        [2.6715, 3.5758, 2.0370, 3.5437, 3.5948, 1.9751, 2.0948],\n",
            "        [1.6580, 2.4464, 1.5957, 2.4709, 2.4182, 1.5551, 1.5504],\n",
            "        [2.7389, 3.6414, 2.0610, 3.6099, 3.6608, 2.0074, 2.1307]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "299\n",
            "tensor([[0.7052, 1.1566, 0.9739, 1.2247, 1.0922, 1.0063, 0.9295],\n",
            "        [3.3822, 4.1154, 2.2242, 4.0555, 4.1009, 2.4560, 2.5037],\n",
            "        [2.5132, 3.4538, 1.9941, 3.4232, 3.4670, 1.8809, 2.0094],\n",
            "        [3.3920, 4.1282, 2.2305, 4.0700, 4.1135, 2.4744, 2.5137],\n",
            "        [0.6535, 1.0862, 0.9366, 1.1568, 1.0221, 0.9657, 0.8917]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "300\n",
            "tensor([[2.6233, 3.5268, 2.0195, 3.4975, 3.5435, 1.9606, 2.0695],\n",
            "        [3.3744, 4.1239, 2.2335, 4.0678, 4.1165, 2.4372, 2.4970],\n",
            "        [2.1687, 3.0823, 1.8612, 3.0730, 3.0840, 1.7511, 1.8341],\n",
            "        [3.2361, 4.0228, 2.1981, 3.9710, 4.0268, 2.3272, 2.4080],\n",
            "        [2.1153, 3.0086, 1.8281, 3.0049, 3.0042, 1.7328, 1.8034]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "301\n",
            "tensor([[2.9166, 3.7762, 2.1052, 3.7328, 3.7903, 2.0960, 2.2218],\n",
            "        [3.1712, 3.9626, 2.1775, 3.9097, 3.9698, 2.2721, 2.3649],\n",
            "        [3.3876, 4.1324, 2.2392, 4.0746, 4.1231, 2.4457, 2.5035],\n",
            "        [2.3454, 3.2628, 1.9255, 3.2452, 3.2693, 1.8285, 1.9259],\n",
            "        [2.0553, 2.9302, 1.7981, 2.9298, 2.9222, 1.7185, 1.7711]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "302\n",
            "tensor([[1.4677, 2.2035, 1.4961, 2.2335, 2.1655, 1.4607, 1.4350],\n",
            "        [0.7364, 1.2008, 1.0019, 1.2681, 1.1364, 1.0274, 0.9526],\n",
            "        [0.9267, 1.4685, 1.1450, 1.5287, 1.4094, 1.1625, 1.0887],\n",
            "        [0.7895, 1.2764, 1.0446, 1.3415, 1.2128, 1.0680, 0.9917],\n",
            "        [2.0666, 2.9496, 1.8070, 2.9453, 2.9422, 1.7126, 1.7760]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "303\n",
            "tensor([[2.4580, 3.4025, 1.9787, 3.3699, 3.4161, 1.8417, 1.9779],\n",
            "        [3.3599, 4.1130, 2.2317, 4.0517, 4.1030, 2.4172, 2.4837],\n",
            "        [0.9944, 1.5455, 1.1706, 1.5977, 1.4843, 1.1991, 1.1260],\n",
            "        [3.3590, 4.0952, 2.2169, 4.0351, 4.0837, 2.4136, 2.4844],\n",
            "        [3.3730, 4.1101, 2.2257, 4.0446, 4.0955, 2.4243, 2.4895]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "304\n",
            "tensor([[0.8460, 1.3466, 1.0733, 1.4057, 1.2828, 1.0987, 1.0258],\n",
            "        [0.8092, 1.2976, 1.0502, 1.3595, 1.2338, 1.0737, 1.0016],\n",
            "        [3.1406, 3.9499, 2.1717, 3.8967, 3.9522, 2.2316, 2.3471],\n",
            "        [2.9411, 3.7984, 2.1166, 3.7480, 3.8072, 2.1132, 2.2323],\n",
            "        [1.1107, 1.7069, 1.2569, 1.7551, 1.6519, 1.2710, 1.2056]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "305\n",
            "tensor([[1.5815, 2.3528, 1.5613, 2.3740, 2.3203, 1.5044, 1.5023],\n",
            "        [1.4271, 2.1395, 1.4618, 2.1687, 2.0961, 1.4369, 1.4081],\n",
            "        [0.8924, 1.4163, 1.1154, 1.4739, 1.3547, 1.1296, 1.0609],\n",
            "        [1.9841, 2.8421, 1.7608, 2.8405, 2.8293, 1.6763, 1.7292],\n",
            "        [3.1973, 3.9857, 2.1878, 3.9303, 3.9908, 2.2711, 2.3782]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "306\n",
            "tensor([[2.9741, 3.8166, 2.1290, 3.7667, 3.8323, 2.1272, 2.2520],\n",
            "        [0.6443, 1.0617, 0.9116, 1.1249, 0.9943, 0.9429, 0.8766],\n",
            "        [3.3869, 4.1294, 2.2375, 4.0634, 4.1178, 2.4359, 2.5020],\n",
            "        [1.0567, 1.6395, 1.2237, 1.6885, 1.5804, 1.2339, 1.1718],\n",
            "        [3.3579, 4.1072, 2.2306, 4.0469, 4.1040, 2.4159, 2.4826]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "307\n",
            "tensor([[2.2996, 3.2047, 1.9054, 3.1841, 3.2083, 1.7960, 1.9001],\n",
            "        [3.2928, 4.0597, 2.2116, 3.9977, 4.0546, 2.3523, 2.4396],\n",
            "        [0.9215, 1.4486, 1.1269, 1.5036, 1.3859, 1.1461, 1.0796],\n",
            "        [1.7753, 2.5932, 1.6633, 2.6039, 2.5707, 1.5901, 1.6167],\n",
            "        [2.7786, 3.6650, 2.0731, 3.6178, 3.6819, 2.0104, 2.1461]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "308\n",
            "tensor([[0.7692, 1.2449, 1.0298, 1.3102, 1.1823, 1.0472, 0.9784],\n",
            "        [2.1408, 3.0555, 1.8551, 3.0421, 3.0592, 1.7135, 1.8192],\n",
            "        [2.2609, 3.1805, 1.8989, 3.1592, 3.1868, 1.7684, 1.8820],\n",
            "        [2.4647, 3.4239, 1.9872, 3.3831, 3.4396, 1.8095, 1.9791],\n",
            "        [3.2934, 4.0625, 2.2150, 4.0029, 4.0626, 2.3418, 2.4428]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "309\n",
            "tensor([[2.8984, 3.7613, 2.1071, 3.7146, 3.7798, 2.0716, 2.2174],\n",
            "        [2.9952, 3.8425, 2.1365, 3.7879, 3.8558, 2.1273, 2.2683],\n",
            "        [1.0586, 1.6442, 1.2363, 1.6945, 1.5892, 1.2318, 1.1777],\n",
            "        [2.0602, 2.9290, 1.7976, 2.9211, 2.9221, 1.7043, 1.7747],\n",
            "        [2.3508, 3.2744, 1.9334, 3.2467, 3.2838, 1.7931, 1.9257]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "310\n",
            "tensor([[0.8120, 1.2965, 1.0545, 1.3574, 1.2341, 1.0746, 1.0059],\n",
            "        [2.3715, 3.3490, 1.9672, 3.3087, 3.3677, 1.7561, 1.9337],\n",
            "        [1.4336, 2.1559, 1.4833, 2.1857, 2.1179, 1.4308, 1.4186],\n",
            "        [2.1209, 3.0384, 1.8556, 3.0215, 3.0429, 1.6914, 1.8066],\n",
            "        [0.9828, 1.5399, 1.1858, 1.5948, 1.4833, 1.1882, 1.1277]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "311\n",
            "tensor([[2.3954, 3.3339, 1.9608, 3.2998, 3.3505, 1.8056, 1.9507],\n",
            "        [0.9724, 1.5275, 1.1805, 1.5827, 1.4731, 1.1808, 1.1210],\n",
            "        [2.7256, 3.6277, 2.0619, 3.5730, 3.6446, 1.9516, 2.1134],\n",
            "        [3.3923, 4.1034, 2.2219, 4.0330, 4.0890, 2.4423, 2.5111],\n",
            "        [2.1277, 3.0285, 1.8491, 3.0142, 3.0305, 1.7127, 1.8126]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "312\n",
            "tensor([[2.3396, 3.2941, 1.9468, 3.2593, 3.3107, 1.7543, 1.9182],\n",
            "        [3.3314, 4.0820, 2.2293, 4.0167, 4.0818, 2.3722, 2.4691],\n",
            "        [2.8556, 3.7260, 2.0979, 3.6750, 3.7456, 2.0353, 2.1899],\n",
            "        [1.0974, 1.7045, 1.2702, 1.7510, 1.6518, 1.2524, 1.2058],\n",
            "        [1.3210, 1.9492, 1.3438, 1.9726, 1.8933, 1.3659, 1.3271]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "313\n",
            "tensor([[3.2999, 4.0549, 2.2172, 3.9897, 4.0565, 2.3390, 2.4507],\n",
            "        [2.0332, 2.9307, 1.8137, 2.9184, 2.9301, 1.6589, 1.7612],\n",
            "        [1.7486, 2.5514, 1.6474, 2.5578, 2.5281, 1.5694, 1.6013],\n",
            "        [1.5676, 2.3251, 1.5544, 2.3428, 2.2934, 1.4931, 1.4992],\n",
            "        [0.8672, 1.3830, 1.1058, 1.4412, 1.3237, 1.1105, 1.0505]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "314\n",
            "tensor([[1.1402, 1.7537, 1.2871, 1.7955, 1.7007, 1.2780, 1.2329],\n",
            "        [3.2481, 4.0194, 2.2000, 3.9545, 4.0184, 2.3005, 2.4208],\n",
            "        [1.8989, 2.7502, 1.7304, 2.7469, 2.7361, 1.6237, 1.6897],\n",
            "        [0.9356, 1.4861, 1.1638, 1.5432, 1.4303, 1.1544, 1.1016],\n",
            "        [0.8247, 1.3227, 1.0696, 1.3817, 1.2610, 1.0789, 1.0194]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "315\n",
            "tensor([[0.9163, 1.4578, 1.1423, 1.5140, 1.3986, 1.1418, 1.0882],\n",
            "        [1.5212, 2.2774, 1.5309, 2.2961, 2.2419, 1.4670, 1.4757],\n",
            "        [3.3661, 4.0916, 2.2190, 4.0184, 4.0761, 2.4038, 2.5024],\n",
            "        [0.9271, 1.4679, 1.1438, 1.5202, 1.4065, 1.1499, 1.0925],\n",
            "        [1.7259, 2.5427, 1.6459, 2.5506, 2.5196, 1.5491, 1.5946]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "316\n",
            "tensor([[1.7690, 2.6183, 1.6848, 2.6202, 2.5975, 1.5602, 1.6252],\n",
            "        [1.9086, 2.7926, 1.7556, 2.7859, 2.7794, 1.6132, 1.7029],\n",
            "        [1.3777, 2.0925, 1.4499, 2.1199, 2.0488, 1.3988, 1.3908],\n",
            "        [1.2135, 1.8819, 1.3609, 1.9199, 1.8320, 1.3149, 1.2904],\n",
            "        [2.0427, 2.9388, 1.8069, 2.9234, 2.9302, 1.6734, 1.7742]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "317\n",
            "tensor([[3.2566, 4.0202, 2.2015, 3.9559, 4.0141, 2.3550, 2.4429],\n",
            "        [2.6341, 3.5677, 2.0385, 3.5103, 3.5790, 1.8809, 2.0767],\n",
            "        [1.8915, 2.7642, 1.7359, 2.7552, 2.7460, 1.6076, 1.6909],\n",
            "        [1.1887, 1.8332, 1.3248, 1.8693, 1.7775, 1.3065, 1.2711],\n",
            "        [2.3055, 3.2585, 1.9284, 3.2225, 3.2649, 1.7499, 1.9125]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "318\n",
            "tensor([[3.3117, 4.0898, 2.2268, 4.0164, 4.0829, 2.3545, 2.4684],\n",
            "        [2.8786, 3.7465, 2.1000, 3.6891, 3.7566, 2.0659, 2.2159],\n",
            "        [3.0430, 3.8845, 2.1454, 3.8168, 3.8867, 2.1602, 2.3070],\n",
            "        [2.7292, 3.6431, 2.0629, 3.5825, 3.6540, 1.9500, 2.1298],\n",
            "        [3.0587, 3.8903, 2.1448, 3.8233, 3.8880, 2.1659, 2.3147]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "319\n",
            "tensor([[0.8001, 1.3042, 1.0597, 1.3609, 1.2358, 1.0657, 1.0088],\n",
            "        [2.3021, 3.2505, 1.9175, 3.2110, 3.2492, 1.7615, 1.9116],\n",
            "        [2.0840, 3.0039, 1.8288, 2.9799, 2.9923, 1.6831, 1.7985],\n",
            "        [1.7906, 2.6516, 1.6912, 2.6464, 2.6266, 1.5672, 1.6368],\n",
            "        [0.9975, 1.5859, 1.2079, 1.6330, 1.5237, 1.1962, 1.1485]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "320\n",
            "tensor([[2.4601, 3.4155, 1.9755, 3.3652, 3.4155, 1.8283, 1.9943],\n",
            "        [1.0970, 1.7265, 1.2747, 1.7666, 1.6662, 1.2547, 1.2153],\n",
            "        [3.2593, 4.0506, 2.2055, 3.9748, 4.0408, 2.3112, 2.4364],\n",
            "        [3.3243, 4.0856, 2.2123, 4.0087, 4.0668, 2.3717, 2.4775],\n",
            "        [2.9437, 3.8157, 2.1181, 3.7471, 3.8121, 2.0891, 2.2525]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "321\n",
            "tensor([[2.3420, 3.3430, 1.9528, 3.2902, 3.3442, 1.7402, 1.9306],\n",
            "        [1.4376, 2.1934, 1.4895, 2.2102, 2.1458, 1.4306, 1.4324],\n",
            "        [0.7690, 1.2575, 1.0251, 1.3120, 1.1847, 1.0463, 0.9835],\n",
            "        [3.2879, 4.0696, 2.2113, 3.9934, 4.0533, 2.3458, 2.4591],\n",
            "        [1.3976, 2.1364, 1.4614, 2.1541, 2.0842, 1.4115, 1.4071]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "322\n",
            "tensor([[2.6784, 3.6186, 2.0437, 3.5540, 3.6165, 1.9173, 2.1042],\n",
            "        [3.2590, 4.0555, 2.2021, 3.9787, 4.0376, 2.3220, 2.4394],\n",
            "        [3.2001, 4.0170, 2.1934, 3.9469, 4.0111, 2.2883, 2.4037],\n",
            "        [2.1350, 3.1126, 1.8727, 3.0785, 3.1044, 1.6857, 1.8304],\n",
            "        [3.1675, 3.9773, 2.1761, 3.9083, 3.9681, 2.2894, 2.3903]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "323\n",
            "tensor([[1.6998, 2.5634, 1.6508, 2.5619, 2.5259, 1.5429, 1.5958],\n",
            "        [1.7576, 2.6497, 1.6929, 2.6432, 2.6174, 1.5599, 1.6305],\n",
            "        [3.0236, 3.8900, 2.1418, 3.8230, 3.8827, 2.1749, 2.3085],\n",
            "        [0.8235, 1.3550, 1.0871, 1.4101, 1.2821, 1.0916, 1.0332],\n",
            "        [0.8781, 1.4297, 1.1210, 1.4808, 1.3572, 1.1253, 1.0702]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "324\n",
            "tensor([[1.1908, 1.8731, 1.3373, 1.9048, 1.8081, 1.3160, 1.2845],\n",
            "        [2.3931, 3.3816, 1.9569, 3.3324, 3.3750, 1.8062, 1.9705],\n",
            "        [1.2827, 2.0042, 1.4036, 2.0313, 1.9432, 1.3631, 1.3448],\n",
            "        [2.1949, 3.1864, 1.8904, 3.1485, 3.1744, 1.7158, 1.8681],\n",
            "        [1.2212, 1.9184, 1.3618, 1.9503, 1.8572, 1.3341, 1.3063]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "325\n",
            "tensor([[2.8048, 3.7338, 2.0738, 3.6689, 3.7237, 2.0194, 2.1860],\n",
            "        [1.0874, 1.7395, 1.2769, 1.7788, 1.6700, 1.2581, 1.2197],\n",
            "        [0.8816, 1.4429, 1.1261, 1.4938, 1.3678, 1.1341, 1.0759],\n",
            "        [2.7620, 3.7028, 2.0674, 3.6362, 3.6920, 1.9826, 2.1604],\n",
            "        [2.1309, 3.1317, 1.8685, 3.0940, 3.1168, 1.6824, 1.8340]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "326\n",
            "tensor([[1.2789, 2.0077, 1.3997, 2.0325, 1.9409, 1.3635, 1.3437],\n",
            "        [0.7751, 1.2861, 1.0372, 1.3387, 1.2065, 1.0581, 0.9950],\n",
            "        [2.7838, 3.7205, 2.0680, 3.6564, 3.7034, 2.0009, 2.1754],\n",
            "        [2.6039, 3.5855, 2.0221, 3.5225, 3.5733, 1.8969, 2.0754],\n",
            "        [1.6304, 2.4734, 1.6010, 2.4784, 2.4244, 1.5302, 1.5581]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "327\n",
            "tensor([[0.9555, 1.5530, 1.1827, 1.5998, 1.4754, 1.1873, 1.1289],\n",
            "        [1.2614, 1.9851, 1.3878, 2.0127, 1.9184, 1.3593, 1.3321],\n",
            "        [2.3103, 3.3257, 1.9321, 3.2786, 3.3107, 1.7645, 1.9277],\n",
            "        [3.2380, 4.0593, 2.1888, 3.9853, 4.0271, 2.3258, 2.4400],\n",
            "        [3.2475, 4.0466, 2.1783, 3.9738, 4.0163, 2.3421, 2.4464]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "328\n",
            "tensor([[0.8142, 1.3464, 1.0699, 1.4013, 1.2659, 1.0924, 1.0259],\n",
            "        [1.4361, 2.2316, 1.4985, 2.2492, 2.1713, 1.4394, 1.4404],\n",
            "        [2.4173, 3.4435, 1.9710, 3.3870, 3.4302, 1.7952, 1.9774],\n",
            "        [1.9696, 2.9069, 1.7719, 2.8877, 2.8701, 1.6654, 1.7472],\n",
            "        [1.1582, 1.8398, 1.3190, 1.8754, 1.7694, 1.3034, 1.2629]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "329\n",
            "tensor([[0.9892, 1.5978, 1.1955, 1.6423, 1.5187, 1.2063, 1.1469],\n",
            "        [1.1588, 1.8294, 1.3051, 1.8622, 1.7535, 1.3053, 1.2589],\n",
            "        [1.5919, 2.4228, 1.5725, 2.4291, 2.3680, 1.5187, 1.5291],\n",
            "        [2.9207, 3.8302, 2.1050, 3.7620, 3.8054, 2.0950, 2.2478],\n",
            "        [3.2693, 4.0810, 2.2011, 4.0112, 4.0571, 2.3673, 2.4563]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "330\n",
            "tensor([[2.8050, 3.7306, 2.0753, 3.6732, 3.7155, 2.0589, 2.1855],\n",
            "        [2.8875, 3.8084, 2.0973, 3.7441, 3.7862, 2.0964, 2.2300],\n",
            "        [1.3383, 2.1016, 1.4426, 2.1254, 2.0339, 1.4056, 1.3798],\n",
            "        [2.4858, 3.4989, 1.9902, 3.4436, 3.4832, 1.8439, 2.0113],\n",
            "        [2.5864, 3.5642, 2.0104, 3.5117, 3.5469, 1.9267, 2.0684]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "331\n",
            "tensor([[2.1205, 3.1308, 1.8639, 3.0986, 3.1042, 1.7044, 1.8255],\n",
            "        [2.1194, 3.1024, 1.8514, 3.0776, 3.0723, 1.7298, 1.8278],\n",
            "        [3.3480, 4.1108, 2.1951, 4.0358, 4.0626, 2.4542, 2.5096],\n",
            "        [1.5375, 2.3742, 1.5683, 2.3878, 2.3155, 1.5009, 1.5034],\n",
            "        [2.2074, 3.2336, 1.9013, 3.1961, 3.2110, 1.7337, 1.8709]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "332\n",
            "tensor([[3.3564, 4.1528, 2.2317, 4.0851, 4.1174, 2.4565, 2.5111],\n",
            "        [0.7177, 1.2048, 0.9887, 1.2636, 1.1208, 1.0280, 0.9503],\n",
            "        [2.4278, 3.4573, 1.9774, 3.4030, 3.4391, 1.8158, 1.9783],\n",
            "        [3.0595, 3.9271, 2.1388, 3.8614, 3.8907, 2.2172, 2.3259],\n",
            "        [2.0568, 3.0610, 1.8436, 3.0358, 3.0320, 1.6833, 1.7924]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "333\n",
            "tensor([[2.8861, 3.8095, 2.1038, 3.7578, 3.7916, 2.1014, 2.2284],\n",
            "        [2.8356, 3.7354, 2.0793, 3.6876, 3.7182, 2.1244, 2.2042],\n",
            "        [3.0371, 3.9214, 2.1404, 3.8631, 3.8941, 2.2031, 2.3144],\n",
            "        [0.7511, 1.2552, 1.0178, 1.3135, 1.1696, 1.0579, 0.9761],\n",
            "        [1.3420, 2.0970, 1.4383, 2.1270, 2.0275, 1.4187, 1.3806]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "334\n",
            "tensor([[3.1782, 4.0316, 2.1910, 3.9711, 3.9969, 2.3112, 2.4000],\n",
            "        [0.7024, 1.1855, 0.9827, 1.2467, 1.0999, 1.0218, 0.9395],\n",
            "        [3.3452, 4.1521, 2.2377, 4.0859, 4.1148, 2.4503, 2.5051],\n",
            "        [0.8138, 1.3485, 1.0734, 1.4064, 1.2627, 1.1081, 1.0238],\n",
            "        [3.3447, 4.1457, 2.2338, 4.0792, 4.1056, 2.4591, 2.5053]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "335\n",
            "tensor([[3.0967, 3.9722, 2.1772, 3.9162, 3.9522, 2.2700, 2.3479],\n",
            "        [3.2636, 4.0971, 2.2244, 4.0371, 4.0635, 2.3912, 2.4525],\n",
            "        [3.1603, 4.0184, 2.1915, 3.9609, 3.9891, 2.3110, 2.3868],\n",
            "        [2.3054, 3.2808, 1.9254, 3.2557, 3.2568, 1.8424, 1.9230],\n",
            "        [0.8401, 1.3817, 1.0893, 1.4383, 1.2969, 1.1283, 1.0402]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "336\n",
            "tensor([[2.4817, 3.4899, 2.0022, 3.4445, 3.4722, 1.8662, 2.0023],\n",
            "        [2.0423, 3.0356, 1.8440, 3.0213, 3.0054, 1.7010, 1.7839],\n",
            "        [1.2472, 1.9530, 1.3702, 1.9885, 1.8763, 1.3824, 1.3151],\n",
            "        [1.5295, 2.3643, 1.5718, 2.3858, 2.3051, 1.5140, 1.4952],\n",
            "        [2.4373, 3.4671, 1.9948, 3.4201, 3.4503, 1.8417, 1.9809]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "337\n",
            "tensor([[2.7676, 3.7163, 2.0850, 3.6731, 3.7048, 2.0494, 2.1613],\n",
            "        [0.8128, 1.3474, 1.0775, 1.4079, 1.2641, 1.1111, 1.0227],\n",
            "        [2.6489, 3.5026, 1.9913, 3.4746, 3.4693, 2.1037, 2.1100],\n",
            "        [0.9146, 1.4900, 1.1474, 1.5444, 1.4067, 1.1788, 1.0928],\n",
            "        [2.4557, 3.4743, 1.9998, 3.4350, 3.4578, 1.8667, 1.9941]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "338\n",
            "tensor([[3.3464, 4.1150, 2.2198, 4.0499, 4.0670, 2.4893, 2.5075],\n",
            "        [2.0357, 3.0096, 1.8343, 3.0010, 2.9806, 1.7151, 1.7783],\n",
            "        [1.0877, 1.7503, 1.2910, 1.8013, 1.6748, 1.2974, 1.2187],\n",
            "        [3.0652, 3.9438, 2.1716, 3.8921, 3.9229, 2.2611, 2.3285],\n",
            "        [1.4117, 2.1985, 1.5002, 2.2314, 2.1361, 1.4688, 1.4246]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "339\n",
            "tensor([[3.3582, 4.1539, 2.2514, 4.0983, 4.1202, 2.4820, 2.5149],\n",
            "        [3.2374, 4.0730, 2.2261, 4.0236, 4.0519, 2.3967, 2.4390],\n",
            "        [3.1422, 4.0022, 2.2009, 3.9563, 3.9852, 2.3167, 2.3801],\n",
            "        [2.2270, 3.1945, 1.9013, 3.1798, 3.1731, 1.8185, 1.8815],\n",
            "        [3.1567, 4.0108, 2.2030, 3.9633, 3.9908, 2.3315, 2.3902]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "340\n",
            "tensor([[1.6513, 2.5243, 1.6462, 2.5484, 2.4782, 1.5847, 1.5725],\n",
            "        [1.7804, 2.6920, 1.7148, 2.7081, 2.6528, 1.6352, 1.6454],\n",
            "        [0.9531, 1.5542, 1.1906, 1.6132, 1.4749, 1.2198, 1.1274],\n",
            "        [2.3970, 3.4225, 1.9940, 3.3970, 3.4146, 1.8627, 1.9728],\n",
            "        [2.5340, 3.5315, 2.0304, 3.4980, 3.5193, 1.9353, 2.0436]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "341\n",
            "tensor([[3.3091, 4.1134, 2.2435, 4.0654, 4.0843, 2.4742, 2.4927],\n",
            "        [1.0877, 1.7568, 1.3002, 1.8132, 1.6848, 1.3081, 1.2249],\n",
            "        [2.0229, 2.9954, 1.8377, 2.9977, 2.9697, 1.7352, 1.7803],\n",
            "        [1.9560, 2.8943, 1.7957, 2.9030, 2.8659, 1.7274, 1.7444],\n",
            "        [0.7916, 1.3215, 1.0696, 1.3891, 1.2419, 1.1107, 1.0134]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "342\n",
            "tensor([[0.7619, 1.2815, 1.0499, 1.3511, 1.2023, 1.0904, 0.9933],\n",
            "        [3.2846, 4.0856, 2.2327, 4.0426, 4.0570, 2.4465, 2.4738],\n",
            "        [3.2857, 4.0966, 2.2425, 4.0516, 4.0712, 2.4533, 2.4770],\n",
            "        [1.1342, 1.8287, 1.3414, 1.8845, 1.7604, 1.3377, 1.2579],\n",
            "        [1.0237, 1.6710, 1.2617, 1.7326, 1.6002, 1.2716, 1.1835]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "343\n",
            "tensor([[0.8755, 1.4500, 1.1444, 1.5167, 1.3741, 1.1764, 1.0783],\n",
            "        [2.7690, 3.7249, 2.1076, 3.6956, 3.7223, 2.0898, 2.1735],\n",
            "        [1.7029, 2.5866, 1.6758, 2.6093, 2.5468, 1.6193, 1.6023],\n",
            "        [2.6555, 3.6351, 2.0766, 3.6058, 3.6339, 2.0024, 2.1075],\n",
            "        [3.0174, 3.9113, 2.1822, 3.8749, 3.9028, 2.2618, 2.3161]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "344\n",
            "tensor([[1.3279, 2.0792, 1.4527, 2.1246, 2.0213, 1.4527, 1.3788],\n",
            "        [2.4477, 3.4681, 2.0227, 3.4475, 3.4696, 1.9083, 2.0037],\n",
            "        [2.9474, 3.8540, 2.1599, 3.8233, 3.8496, 2.1922, 2.2718],\n",
            "        [3.3180, 4.1083, 2.2475, 4.0603, 4.0801, 2.5070, 2.5036],\n",
            "        [0.8918, 1.4721, 1.1552, 1.5397, 1.3977, 1.1871, 1.0902]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "345\n",
            "tensor([[1.2810, 2.0153, 1.4198, 2.0649, 1.9561, 1.4256, 1.3489],\n",
            "        [1.0741, 1.7410, 1.2987, 1.8034, 1.6769, 1.3073, 1.2199],\n",
            "        [2.8810, 3.8067, 2.1473, 3.7750, 3.8091, 2.1499, 2.2327],\n",
            "        [3.3300, 4.1104, 2.2468, 4.0648, 4.0847, 2.5121, 2.5105],\n",
            "        [3.3301, 4.1050, 2.2413, 4.0580, 4.0766, 2.5143, 2.5109]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "346\n",
            "tensor([[1.7649, 2.6649, 1.7113, 2.6900, 2.6364, 1.6527, 1.6408],\n",
            "        [2.7348, 3.6954, 2.1047, 3.6652, 3.6996, 2.0553, 2.1481],\n",
            "        [1.8783, 2.8493, 1.8014, 2.8665, 2.8339, 1.6750, 1.7083],\n",
            "        [3.2185, 4.0567, 2.2413, 4.0186, 4.0468, 2.4021, 2.4327],\n",
            "        [2.1098, 3.0688, 1.8723, 3.0773, 3.0581, 1.8058, 1.8310]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "347\n",
            "tensor([[0.8308, 1.3874, 1.1153, 1.4599, 1.3154, 1.1480, 1.0482],\n",
            "        [3.0834, 3.9588, 2.2094, 3.9326, 3.9662, 2.3074, 2.3513],\n",
            "        [0.8376, 1.3936, 1.1138, 1.4652, 1.3224, 1.1484, 1.0502],\n",
            "        [0.7781, 1.3123, 1.0765, 1.3876, 1.2403, 1.1112, 1.0111],\n",
            "        [0.8206, 1.3713, 1.1050, 1.4452, 1.3009, 1.1410, 1.0404]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "348\n",
            "tensor([[2.2482, 3.3004, 1.9715, 3.2913, 3.3135, 1.7930, 1.8970],\n",
            "        [0.6284, 1.0928, 0.9515, 1.1717, 1.0194, 0.9919, 0.8971],\n",
            "        [1.7215, 2.6120, 1.6924, 2.6440, 2.5860, 1.6378, 1.6169],\n",
            "        [3.2113, 4.0478, 2.2381, 4.0157, 4.0446, 2.4024, 2.4294],\n",
            "        [1.1316, 1.8159, 1.3325, 1.8753, 1.7565, 1.3396, 1.2539]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "349\n",
            "tensor([[0.6968, 1.1904, 1.0067, 1.2685, 1.1194, 1.0476, 0.9487],\n",
            "        [0.8266, 1.3673, 1.0961, 1.4382, 1.2962, 1.1406, 1.0392],\n",
            "        [0.8610, 1.4347, 1.1455, 1.5090, 1.3672, 1.1730, 1.0720],\n",
            "        [1.6184, 2.5012, 1.6569, 2.5398, 2.4731, 1.5801, 1.5603],\n",
            "        [0.6209, 1.0807, 0.9447, 1.1606, 1.0090, 0.9855, 0.8911]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "350\n",
            "tensor([[1.8218, 2.7652, 1.7705, 2.7932, 2.7519, 1.6654, 1.6764],\n",
            "        [0.9389, 1.5328, 1.1874, 1.6027, 1.4659, 1.2218, 1.1217],\n",
            "        [1.3054, 2.0620, 1.4540, 2.1167, 2.0140, 1.4375, 1.3674],\n",
            "        [0.7287, 1.2300, 1.0243, 1.3052, 1.1592, 1.0677, 0.9682],\n",
            "        [3.1043, 3.9781, 2.2196, 3.9539, 3.9842, 2.3247, 2.3682]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "351\n",
            "tensor([[2.7484, 3.6939, 2.1127, 3.6831, 3.7148, 2.0980, 2.1602],\n",
            "        [1.3949, 2.1835, 1.5157, 2.2374, 2.1444, 1.4831, 1.4244],\n",
            "        [3.2757, 4.0852, 2.2618, 4.0562, 4.0868, 2.4842, 2.4723],\n",
            "        [1.0502, 1.6949, 1.2744, 1.7625, 1.6355, 1.2919, 1.1986],\n",
            "        [2.4924, 3.5102, 2.0459, 3.4968, 3.5327, 1.9092, 2.0199]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "352\n",
            "tensor([[1.1314, 1.7914, 1.3127, 1.8549, 1.7354, 1.3448, 1.2466],\n",
            "        [2.2504, 3.2859, 1.9671, 3.2876, 3.3052, 1.8051, 1.8977],\n",
            "        [2.9898, 3.8852, 2.1830, 3.8650, 3.9016, 2.2327, 2.2919],\n",
            "        [1.2144, 1.9327, 1.3947, 1.9967, 1.8864, 1.3906, 1.3097],\n",
            "        [3.0580, 3.9230, 2.1912, 3.9012, 3.9321, 2.2835, 2.3342]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "353\n",
            "tensor([[0.7930, 1.3266, 1.0827, 1.4073, 1.2627, 1.1174, 1.0184],\n",
            "        [3.1051, 3.9656, 2.2119, 3.9459, 3.9816, 2.3203, 2.3591],\n",
            "        [2.2763, 3.3162, 1.9791, 3.3178, 3.3422, 1.8072, 1.9074],\n",
            "        [3.3330, 4.1301, 2.2750, 4.1057, 4.1363, 2.4978, 2.5031],\n",
            "        [1.6264, 2.4701, 1.6324, 2.5155, 2.4475, 1.5973, 1.5563]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "354\n",
            "tensor([[3.0192, 3.8999, 2.1904, 3.8901, 3.9301, 2.2641, 2.3080],\n",
            "        [0.8480, 1.4030, 1.1201, 1.4813, 1.3410, 1.1547, 1.0560],\n",
            "        [3.0133, 3.8847, 2.1751, 3.8688, 3.9088, 2.2335, 2.2984],\n",
            "        [0.9928, 1.6096, 1.2296, 1.6836, 1.5546, 1.2508, 1.1567],\n",
            "        [2.2439, 3.2675, 1.9567, 3.2751, 3.2941, 1.8016, 1.8899]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "355\n",
            "tensor([[1.9113, 2.8600, 1.8020, 2.8921, 2.8654, 1.6983, 1.7173],\n",
            "        [2.4702, 3.4816, 2.0295, 3.4807, 3.5171, 1.8936, 2.0008],\n",
            "        [3.1350, 3.9829, 2.2151, 3.9685, 4.0095, 2.3405, 2.3723],\n",
            "        [1.4601, 2.2758, 1.5573, 2.3355, 2.2532, 1.5078, 1.4625],\n",
            "        [1.4965, 2.3042, 1.5578, 2.3578, 2.2775, 1.5299, 1.4787]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "356\n",
            "tensor([[2.8160, 3.7521, 2.1268, 3.7411, 3.7799, 2.1124, 2.1888],\n",
            "        [0.9256, 1.5204, 1.1881, 1.6007, 1.4655, 1.2089, 1.1141],\n",
            "        [2.3959, 3.4247, 2.0106, 3.4268, 3.4617, 1.8615, 1.9651],\n",
            "        [3.1312, 3.9852, 2.2189, 3.9741, 4.0128, 2.3259, 2.3691],\n",
            "        [2.2999, 3.3182, 1.9716, 3.3275, 3.3502, 1.8299, 1.9177]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "357\n",
            "tensor([[1.8233, 2.7416, 1.7452, 2.7817, 2.7429, 1.6609, 1.6667],\n",
            "        [0.8395, 1.3941, 1.1173, 1.4777, 1.3367, 1.1484, 1.0509],\n",
            "        [3.3161, 4.0989, 2.2455, 4.0755, 4.1039, 2.5000, 2.4904],\n",
            "        [2.2105, 3.2185, 1.9317, 3.2331, 3.2457, 1.7978, 1.8709],\n",
            "        [0.8064, 1.3353, 1.0798, 1.4179, 1.2765, 1.1229, 1.0234]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "358\n",
            "tensor([[3.1797, 4.0192, 2.2249, 4.0068, 4.0473, 2.3660, 2.3986],\n",
            "        [2.3225, 3.3357, 1.9698, 3.3441, 3.3686, 1.8465, 1.9279],\n",
            "        [1.9138, 2.8624, 1.7890, 2.8960, 2.8718, 1.6887, 1.7131],\n",
            "        [2.0173, 2.9611, 1.8246, 2.9919, 2.9752, 1.7475, 1.7685],\n",
            "        [2.3777, 3.4048, 1.9962, 3.4075, 3.4402, 1.8562, 1.9546]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "359\n",
            "tensor([[3.2863, 4.1004, 2.2466, 4.0812, 4.1198, 2.4578, 2.4647],\n",
            "        [2.5017, 3.5115, 2.0285, 3.5095, 3.5494, 1.9094, 2.0126],\n",
            "        [0.6766, 1.1473, 0.9681, 1.2297, 1.0836, 1.0155, 0.9225],\n",
            "        [3.0717, 3.9500, 2.1895, 3.9356, 3.9785, 2.2829, 2.3297],\n",
            "        [2.2626, 3.3210, 1.9624, 3.3242, 3.3597, 1.7758, 1.8910]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "360\n",
            "tensor([[1.9835, 2.9780, 1.8382, 3.0063, 2.9985, 1.6984, 1.7513],\n",
            "        [1.4854, 2.2981, 1.5463, 2.3555, 2.2781, 1.5200, 1.4694],\n",
            "        [0.8934, 1.4696, 1.1477, 1.5500, 1.4148, 1.1842, 1.0869],\n",
            "        [1.1832, 1.8967, 1.3651, 1.9669, 1.8582, 1.3557, 1.2831],\n",
            "        [3.0498, 3.9290, 2.1833, 3.9162, 3.9613, 2.2838, 2.3208]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "361\n",
            "tensor([[1.0723, 1.7359, 1.2872, 1.8131, 1.6935, 1.2970, 1.2113],\n",
            "        [2.3966, 3.4333, 1.9936, 3.4313, 3.4747, 1.8365, 1.9551],\n",
            "        [3.3251, 4.1069, 2.2379, 4.0828, 4.1181, 2.5012, 2.4905],\n",
            "        [2.9674, 3.8656, 2.1577, 3.8560, 3.9054, 2.2077, 2.2665],\n",
            "        [3.2691, 4.0822, 2.2344, 4.0675, 4.1067, 2.4279, 2.4514]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "362\n",
            "tensor([[2.1062, 3.0694, 1.8499, 3.0948, 3.0938, 1.7742, 1.8115],\n",
            "        [0.9395, 1.5439, 1.1882, 1.6257, 1.4937, 1.2148, 1.1213],\n",
            "        [3.1699, 4.0066, 2.1996, 3.9927, 4.0328, 2.3601, 2.3865],\n",
            "        [1.3196, 2.0797, 1.4434, 2.1455, 2.0504, 1.4344, 1.3689],\n",
            "        [2.0054, 2.9708, 1.8200, 3.0004, 2.9897, 1.7280, 1.7606]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "363\n",
            "tensor([[0.9200, 1.5173, 1.1732, 1.5996, 1.4663, 1.1976, 1.1073],\n",
            "        [2.6237, 3.6085, 2.0510, 3.6077, 3.6515, 1.9881, 2.0781],\n",
            "        [2.7833, 3.7023, 2.0897, 3.7051, 3.7477, 2.1034, 2.1633],\n",
            "        [0.8045, 1.3146, 1.0363, 1.3919, 1.2614, 1.0918, 1.0006],\n",
            "        [3.1623, 4.0094, 2.2038, 3.9975, 4.0396, 2.3567, 2.3842]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "364\n",
            "tensor([[1.2180, 1.9459, 1.3856, 2.0182, 1.9123, 1.3781, 1.3079],\n",
            "        [2.6147, 3.5987, 2.0443, 3.5933, 3.6370, 1.9605, 2.0680],\n",
            "        [3.1571, 4.0058, 2.2003, 3.9927, 4.0349, 2.3407, 2.3780],\n",
            "        [1.5903, 2.4399, 1.5972, 2.4902, 2.4268, 1.5558, 1.5290],\n",
            "        [1.6863, 2.5941, 1.6754, 2.6409, 2.5942, 1.5853, 1.5875]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "365\n",
            "tensor([[1.6538, 2.5092, 1.6207, 2.5583, 2.5025, 1.5851, 1.5632],\n",
            "        [2.4610, 3.4733, 2.0008, 3.4783, 3.5203, 1.8728, 1.9877],\n",
            "        [3.0628, 3.9293, 2.1712, 3.9229, 3.9688, 2.2654, 2.3216],\n",
            "        [3.2771, 4.0941, 2.2378, 4.0783, 4.1204, 2.4461, 2.4572],\n",
            "        [3.3084, 4.0713, 2.2070, 4.0486, 4.0840, 2.4847, 2.4798]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "366\n",
            "tensor([[3.0833, 3.9474, 2.1745, 3.9397, 3.9813, 2.2900, 2.3398],\n",
            "        [1.7911, 2.6971, 1.7046, 2.7428, 2.7054, 1.6376, 1.6453],\n",
            "        [3.0285, 3.9065, 2.1611, 3.8978, 3.9460, 2.2346, 2.3007],\n",
            "        [1.4792, 2.2882, 1.5324, 2.3488, 2.2745, 1.5097, 1.4657],\n",
            "        [2.1733, 3.2069, 1.9080, 3.2247, 3.2471, 1.7444, 1.8476]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "367\n",
            "tensor([[2.9643, 3.8575, 2.1375, 3.8543, 3.9045, 2.1826, 2.2687],\n",
            "        [0.8270, 1.3664, 1.0839, 1.4527, 1.3153, 1.1276, 1.0381],\n",
            "        [2.2652, 3.3190, 1.9438, 3.3280, 3.3680, 1.7619, 1.8918],\n",
            "        [0.6124, 1.0552, 0.9135, 1.1439, 0.9966, 0.9625, 0.8781],\n",
            "        [2.6469, 3.6212, 2.0522, 3.6242, 3.6698, 1.9860, 2.0935]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "368\n",
            "tensor([[3.2978, 4.0802, 2.2131, 4.0710, 4.1072, 2.4584, 2.4744],\n",
            "        [2.0749, 3.0882, 1.8628, 3.1174, 3.1266, 1.7114, 1.8006],\n",
            "        [1.6629, 2.5285, 1.6335, 2.5849, 2.5318, 1.5844, 1.5753],\n",
            "        [2.3644, 3.3968, 1.9687, 3.4074, 3.4496, 1.8208, 1.9445],\n",
            "        [2.0709, 3.0433, 1.8392, 3.0779, 3.0753, 1.7417, 1.7996]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "369\n",
            "tensor([[3.3103, 4.1023, 2.2311, 4.0978, 4.1339, 2.4631, 2.4851],\n",
            "        [2.2873, 3.3270, 1.9462, 3.3422, 3.3802, 1.7821, 1.9056],\n",
            "        [3.0926, 3.9527, 2.1763, 3.9560, 3.9991, 2.2850, 2.3470],\n",
            "        [3.1255, 3.9728, 2.1819, 3.9694, 4.0196, 2.3048, 2.3634],\n",
            "        [1.9929, 2.9149, 1.7808, 2.9566, 2.9390, 1.7302, 1.7553]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "370\n",
            "tensor([[1.7656, 2.6569, 1.6845, 2.7104, 2.6693, 1.6257, 1.6333],\n",
            "        [1.6274, 2.4547, 1.5954, 2.5154, 2.4540, 1.5772, 1.5517],\n",
            "        [1.7524, 2.6325, 1.6724, 2.6877, 2.6448, 1.6192, 1.6230],\n",
            "        [3.3472, 4.1229, 2.2366, 4.1175, 4.1534, 2.4886, 2.5058],\n",
            "        [2.7690, 3.7091, 2.0834, 3.7172, 3.7642, 2.0625, 2.1605]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "371\n",
            "tensor([[1.5929, 2.4114, 1.5755, 2.4756, 2.4103, 1.5576, 1.5327],\n",
            "        [3.1183, 3.9673, 2.1812, 3.9723, 4.0179, 2.3021, 2.3640],\n",
            "        [2.4869, 3.4865, 1.9990, 3.5039, 3.5471, 1.8804, 2.0093],\n",
            "        [3.3029, 4.0947, 2.2311, 4.0971, 4.1341, 2.4630, 2.4812],\n",
            "        [0.8970, 1.4601, 1.1332, 1.5496, 1.4154, 1.1772, 1.0898]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "372\n",
            "tensor([[2.6279, 3.5943, 2.0428, 3.6147, 3.6553, 1.9712, 2.0883],\n",
            "        [1.1671, 1.8510, 1.3372, 1.9371, 1.8262, 1.3415, 1.2766],\n",
            "        [3.3339, 4.0916, 2.2200, 4.0930, 4.1259, 2.4817, 2.5031],\n",
            "        [0.7478, 1.2458, 1.0212, 1.3410, 1.1961, 1.0701, 0.9834],\n",
            "        [2.0245, 2.9635, 1.8047, 3.0111, 2.9967, 1.7233, 1.7752]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "373\n",
            "tensor([[2.9991, 3.8676, 2.1423, 3.8830, 3.9262, 2.2069, 2.2958],\n",
            "        [3.3582, 4.1158, 2.2330, 4.1212, 4.1556, 2.5019, 2.5226],\n",
            "        [0.8356, 1.3770, 1.0986, 1.4752, 1.3353, 1.1375, 1.0524],\n",
            "        [1.6391, 2.4900, 1.6203, 2.5596, 2.5024, 1.5700, 1.5665],\n",
            "        [3.3298, 4.0947, 2.2266, 4.1028, 4.1406, 2.4760, 2.4995]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "374\n",
            "tensor([[2.3179, 3.3259, 1.9493, 3.3601, 3.3918, 1.8091, 1.9326],\n",
            "        [1.5297, 2.3467, 1.5653, 2.4236, 2.3519, 1.5227, 1.5072],\n",
            "        [3.2832, 4.0697, 2.2245, 4.0826, 4.1206, 2.4261, 2.4741],\n",
            "        [1.2815, 1.9924, 1.3971, 2.0772, 1.9766, 1.4075, 1.3504],\n",
            "        [3.0899, 3.9327, 2.1731, 3.9513, 3.9950, 2.2830, 2.3551]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "375\n",
            "tensor([[2.4309, 3.4364, 1.9837, 3.4635, 3.5044, 1.8491, 1.9889],\n",
            "        [2.8018, 3.7142, 2.0887, 3.7417, 3.7887, 2.0947, 2.1915],\n",
            "        [2.7620, 3.6870, 2.0794, 3.7128, 3.7561, 2.0580, 2.1686],\n",
            "        [3.2239, 4.0235, 2.2068, 4.0414, 4.0798, 2.3751, 2.4375],\n",
            "        [0.8333, 1.3550, 1.0755, 1.4498, 1.3108, 1.1284, 1.0446]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "376\n",
            "tensor([[2.1504, 3.1081, 1.8691, 3.1604, 3.1598, 1.7756, 1.8551],\n",
            "        [3.3379, 4.0965, 2.2328, 4.1107, 4.1441, 2.4844, 2.5156],\n",
            "        [0.8015, 1.3049, 1.0487, 1.4015, 1.2591, 1.1103, 1.0236],\n",
            "        [3.3230, 4.0948, 2.2369, 4.1147, 4.1471, 2.4638, 2.5034],\n",
            "        [0.8396, 1.3661, 1.0839, 1.4630, 1.3255, 1.1316, 1.0512]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "377\n",
            "tensor([[0.9008, 1.4606, 1.1439, 1.5606, 1.4222, 1.1816, 1.1027],\n",
            "        [2.3618, 3.3802, 1.9745, 3.4146, 3.4509, 1.8124, 1.9606],\n",
            "        [1.4634, 2.2414, 1.5130, 2.3230, 2.2392, 1.4949, 1.4700],\n",
            "        [1.8943, 2.7676, 1.7322, 2.8362, 2.7961, 1.7041, 1.7189],\n",
            "        [0.8930, 1.4394, 1.1216, 1.5355, 1.3989, 1.1702, 1.0908]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "378\n",
            "tensor([[3.3302, 4.0533, 2.2023, 4.0682, 4.0886, 2.4964, 2.5207],\n",
            "        [3.3010, 4.0773, 2.2403, 4.1035, 4.1359, 2.4462, 2.4966],\n",
            "        [2.0574, 2.9990, 1.8330, 3.0613, 3.0460, 1.7385, 1.8116],\n",
            "        [3.3544, 4.0852, 2.2238, 4.1015, 4.1250, 2.5154, 2.5358],\n",
            "        [2.2049, 3.1783, 1.9036, 3.2309, 3.2358, 1.7923, 1.8901]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "379\n",
            "tensor([[2.7067, 3.6435, 2.0726, 3.6786, 3.7145, 2.0269, 2.1489],\n",
            "        [1.2139, 1.8929, 1.3539, 1.9847, 1.8712, 1.3741, 1.3149],\n",
            "        [1.6410, 2.4744, 1.6235, 2.5528, 2.4860, 1.5821, 1.5789],\n",
            "        [2.2696, 3.3015, 1.9536, 3.3393, 3.3708, 1.7647, 1.9168],\n",
            "        [3.0222, 3.8749, 2.1592, 3.9059, 3.9372, 2.2181, 2.3263]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "380\n",
            "tensor([[0.6724, 1.1276, 0.9600, 1.2259, 1.0753, 1.0098, 0.9321],\n",
            "        [2.1630, 3.1213, 1.8844, 3.1769, 3.1729, 1.7747, 1.8658],\n",
            "        [1.8274, 2.7086, 1.7227, 2.7811, 2.7353, 1.6586, 1.6855],\n",
            "        [3.2938, 4.0646, 2.2324, 4.0879, 4.1114, 2.4438, 2.4943],\n",
            "        [3.3490, 4.0938, 2.2424, 4.1135, 4.1386, 2.4898, 2.5249]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "381\n",
            "tensor([[0.8327, 1.3596, 1.0919, 1.4600, 1.3155, 1.1312, 1.0525],\n",
            "        [1.0351, 1.6376, 1.2307, 1.7315, 1.6013, 1.2653, 1.1921],\n",
            "        [1.1597, 1.8083, 1.3154, 1.9010, 1.7802, 1.3442, 1.2759],\n",
            "        [1.9088, 2.8313, 1.7810, 2.8979, 2.8659, 1.6700, 1.7296],\n",
            "        [2.9259, 3.8038, 2.1370, 3.8350, 3.8664, 2.1496, 2.2653]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "382\n",
            "tensor([[1.2590, 1.9033, 1.3305, 1.9794, 1.8732, 1.3767, 1.3178],\n",
            "        [3.2632, 4.0342, 2.2265, 4.0605, 4.0805, 2.4076, 2.4667],\n",
            "        [1.9413, 2.8583, 1.7915, 2.9252, 2.8905, 1.6884, 1.7473],\n",
            "        [0.8092, 1.3125, 1.0574, 1.4094, 1.2641, 1.1075, 1.0296],\n",
            "        [0.7124, 1.1796, 0.9900, 1.2777, 1.1270, 1.0374, 0.9598]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "383\n",
            "tensor([[2.7570, 3.6673, 2.0888, 3.6997, 3.7335, 2.0423, 2.1671],\n",
            "        [3.3630, 4.1035, 2.2558, 4.1212, 4.1429, 2.4914, 2.5304],\n",
            "        [2.1178, 3.0632, 1.8687, 3.1189, 3.1037, 1.7488, 1.8388],\n",
            "        [1.5111, 2.2926, 1.5467, 2.3747, 2.2878, 1.5065, 1.4960],\n",
            "        [1.7140, 2.5413, 1.6484, 2.6139, 2.5478, 1.6057, 1.6127]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "384\n",
            "tensor([[3.0732, 3.9022, 2.1827, 3.9295, 3.9584, 2.2508, 2.3485],\n",
            "        [2.3280, 3.3282, 1.9707, 3.3670, 3.3868, 1.7909, 1.9410],\n",
            "        [3.3663, 4.0960, 2.2546, 4.1146, 4.1372, 2.4756, 2.5280],\n",
            "        [2.2008, 3.1721, 1.9139, 3.2219, 3.2227, 1.7600, 1.8796],\n",
            "        [0.6759, 1.1252, 0.9597, 1.2230, 1.0699, 1.0034, 0.9305]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "385\n",
            "tensor([[2.6650, 3.5894, 2.0615, 3.6249, 3.6507, 1.9789, 2.1128],\n",
            "        [2.2844, 3.2858, 1.9560, 3.3254, 3.3431, 1.7621, 1.9173],\n",
            "        [1.2027, 1.8803, 1.3656, 1.9748, 1.8545, 1.3498, 1.3054],\n",
            "        [2.3419, 3.3506, 1.9780, 3.3857, 3.4113, 1.7777, 1.9449],\n",
            "        [3.1010, 3.9132, 2.1835, 3.9363, 3.9687, 2.2508, 2.3550]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "386\n",
            "tensor([[1.4362, 2.1679, 1.4829, 2.2522, 2.1545, 1.4731, 1.4439],\n",
            "        [3.1847, 3.9745, 2.2086, 4.0019, 4.0235, 2.3115, 2.4061],\n",
            "        [0.8155, 1.3173, 1.0660, 1.4162, 1.2667, 1.1061, 1.0336],\n",
            "        [3.3120, 4.0671, 2.2495, 4.0939, 4.1175, 2.4234, 2.4875],\n",
            "        [1.4454, 2.1932, 1.5006, 2.2789, 2.1826, 1.4717, 1.4527]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "387\n",
            "tensor([[3.3922, 4.1071, 2.2590, 4.1309, 4.1486, 2.4848, 2.5377],\n",
            "        [1.6193, 2.4352, 1.6215, 2.5175, 2.4418, 1.5359, 1.5584],\n",
            "        [1.6364, 2.4436, 1.6167, 2.5229, 2.4453, 1.5507, 1.5676],\n",
            "        [1.3266, 2.0171, 1.4132, 2.1052, 1.9940, 1.4089, 1.3743],\n",
            "        [1.2040, 1.8440, 1.3308, 1.9368, 1.8137, 1.3495, 1.2972]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "388\n",
            "tensor([[2.0651, 3.0009, 1.8565, 3.0677, 3.0419, 1.6991, 1.8074],\n",
            "        [1.8812, 2.7539, 1.7469, 2.8267, 2.7741, 1.6425, 1.7060],\n",
            "        [1.1198, 1.7465, 1.2952, 1.8446, 1.7130, 1.2933, 1.2467],\n",
            "        [3.3946, 4.1142, 2.2641, 4.1419, 4.1580, 2.4762, 2.5392],\n",
            "        [0.6875, 1.1324, 0.9649, 1.2336, 1.0782, 1.0040, 0.9374]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "389\n",
            "tensor([[0.9404, 1.4813, 1.1528, 1.5818, 1.4358, 1.1807, 1.1197],\n",
            "        [0.8040, 1.2903, 1.0513, 1.3917, 1.2393, 1.0901, 1.0234],\n",
            "        [3.1604, 3.9397, 2.2014, 3.9779, 4.0008, 2.2792, 2.3884],\n",
            "        [2.4307, 3.3940, 1.9976, 3.4405, 3.4556, 1.8216, 1.9890],\n",
            "        [1.8044, 2.6567, 1.7145, 2.7367, 2.6729, 1.6115, 1.6649]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "390\n",
            "tensor([[2.4312, 3.3635, 1.9876, 3.4196, 3.4233, 1.8490, 1.9954],\n",
            "        [1.3817, 2.0935, 1.4600, 2.1876, 2.0765, 1.4278, 1.4136],\n",
            "        [3.3817, 4.0882, 2.2623, 4.1229, 4.1383, 2.4646, 2.5294],\n",
            "        [2.5094, 3.4589, 2.0235, 3.5048, 3.5193, 1.8521, 2.0300],\n",
            "        [3.2337, 3.9927, 2.2267, 4.0314, 4.0492, 2.3290, 2.4348]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "391\n",
            "tensor([[3.3703, 4.0843, 2.2634, 4.1210, 4.1295, 2.4466, 2.5259],\n",
            "        [2.9119, 3.7505, 2.1376, 3.7958, 3.8185, 2.1030, 2.2454],\n",
            "        [0.9047, 1.4263, 1.1263, 1.5302, 1.3804, 1.1586, 1.0966],\n",
            "        [2.6681, 3.5774, 2.0708, 3.6208, 3.6418, 1.9387, 2.1122],\n",
            "        [1.5254, 2.2655, 1.5320, 2.3547, 2.2579, 1.4943, 1.4962]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "392\n",
            "tensor([[3.3447, 4.0130, 2.2190, 4.0468, 4.0532, 2.4241, 2.5014],\n",
            "        [2.5478, 3.4629, 2.0347, 3.5185, 3.5299, 1.8924, 2.0557],\n",
            "        [1.2855, 1.9518, 1.3992, 2.0530, 1.9298, 1.3804, 1.3547],\n",
            "        [2.4977, 3.4439, 2.0283, 3.4983, 3.5113, 1.8421, 2.0280],\n",
            "        [2.2958, 3.2333, 1.9502, 3.2990, 3.2892, 1.7735, 1.9289]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "393\n",
            "tensor([[1.4500, 2.1718, 1.5062, 2.2726, 2.1632, 1.4617, 1.4602],\n",
            "        [2.4805, 3.4212, 2.0244, 3.4800, 3.4901, 1.8313, 2.0199],\n",
            "        [0.9294, 1.4595, 1.1520, 1.5659, 1.4178, 1.1732, 1.1163],\n",
            "        [0.7154, 1.1557, 0.9801, 1.2598, 1.1023, 1.0175, 0.9576],\n",
            "        [3.3946, 4.0912, 2.2774, 4.1328, 4.1434, 2.4556, 2.5383]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "394\n",
            "tensor([[2.9029, 3.7428, 2.1420, 3.7993, 3.8131, 2.0809, 2.2468],\n",
            "        [1.4154, 2.1166, 1.4769, 2.2164, 2.1039, 1.4373, 1.4349],\n",
            "        [1.2305, 1.8696, 1.3603, 1.9733, 1.8437, 1.3497, 1.3200],\n",
            "        [0.8419, 1.3394, 1.0911, 1.4499, 1.2943, 1.1118, 1.0565],\n",
            "        [3.3405, 4.0606, 2.2721, 4.1087, 4.1166, 2.4061, 2.5078]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "395\n",
            "tensor([[2.6605, 3.5170, 2.0636, 3.5834, 3.5826, 1.9915, 2.1265],\n",
            "        [3.2797, 4.0155, 2.2547, 4.0678, 4.0756, 2.3582, 2.4736],\n",
            "        [2.6109, 3.5273, 2.0673, 3.5875, 3.5983, 1.9063, 2.0942],\n",
            "        [1.7682, 2.5816, 1.6932, 2.6783, 2.6010, 1.5955, 1.6516],\n",
            "        [1.0100, 1.5715, 1.2143, 1.6815, 1.5352, 1.2213, 1.1762]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "396\n",
            "tensor([[1.9808, 2.8306, 1.7987, 2.9213, 2.8633, 1.6887, 1.7739],\n",
            "        [2.5030, 3.4335, 2.0358, 3.4997, 3.5066, 1.8460, 2.0410],\n",
            "        [2.5437, 3.4746, 2.0516, 3.5352, 3.5464, 1.8569, 2.0591],\n",
            "        [1.7099, 2.5020, 1.6572, 2.5991, 2.5136, 1.5639, 1.6165],\n",
            "        [3.3640, 4.0011, 2.2154, 4.0407, 4.0396, 2.4642, 2.5328]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "397\n",
            "tensor([[1.8996, 2.7419, 1.7666, 2.8353, 2.7716, 1.6428, 1.7288],\n",
            "        [3.4240, 4.0803, 2.2706, 4.1245, 4.1228, 2.5023, 2.5742],\n",
            "        [0.9046, 1.4127, 1.1247, 1.5229, 1.3686, 1.1568, 1.1016],\n",
            "        [2.7860, 3.6476, 2.1190, 3.7142, 3.7244, 2.0222, 2.1920],\n",
            "        [3.4054, 4.0591, 2.2546, 4.1051, 4.0993, 2.4816, 2.5599]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "398\n",
            "tensor([[0.8775, 1.3887, 1.1267, 1.5049, 1.3460, 1.1453, 1.0915],\n",
            "        [3.3866, 4.0797, 2.2896, 4.1364, 4.1410, 2.4502, 2.5456],\n",
            "        [3.2851, 4.0033, 2.2561, 4.0549, 4.0634, 2.3581, 2.4778],\n",
            "        [2.4962, 3.4358, 2.0407, 3.5013, 3.5039, 1.8424, 2.0420],\n",
            "        [2.1392, 3.0179, 1.8821, 3.1050, 3.0667, 1.7403, 1.8606]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "399\n",
            "tensor([[3.2236, 3.9715, 2.2485, 4.0321, 4.0393, 2.3122, 2.4488],\n",
            "        [0.7857, 1.2473, 1.0379, 1.3593, 1.1979, 1.0785, 1.0188],\n",
            "        [0.7780, 1.2351, 1.0263, 1.3445, 1.1835, 1.0695, 1.0102],\n",
            "        [1.2007, 1.8086, 1.3234, 1.9176, 1.7837, 1.3356, 1.3012],\n",
            "        [1.4071, 2.1010, 1.4779, 2.2088, 2.0903, 1.4475, 1.4421]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "400\n",
            "tensor([[0.9077, 1.4207, 1.1338, 1.5349, 1.3789, 1.1613, 1.1079],\n",
            "        [0.9776, 1.5107, 1.1781, 1.6225, 1.4703, 1.2128, 1.1561],\n",
            "        [1.3110, 1.9402, 1.3860, 2.0459, 1.9236, 1.3837, 1.3662],\n",
            "        [0.9051, 1.4175, 1.1312, 1.5301, 1.3737, 1.1638, 1.1072],\n",
            "        [0.7852, 1.2528, 1.0448, 1.3667, 1.2042, 1.0813, 1.0220]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "401\n",
            "tensor([[2.4032, 3.3543, 2.0203, 3.4303, 3.4260, 1.8139, 2.0037],\n",
            "        [2.0337, 2.9233, 1.8558, 3.0209, 2.9680, 1.7036, 1.8161],\n",
            "        [2.4947, 3.4260, 2.0453, 3.4998, 3.4999, 1.8677, 2.0497],\n",
            "        [1.8315, 2.6678, 1.7479, 2.7694, 2.6950, 1.6316, 1.7011],\n",
            "        [1.3775, 2.0650, 1.4668, 2.1771, 2.0521, 1.4428, 1.4291]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "402\n",
            "tensor([[0.7390, 1.1873, 1.0089, 1.3011, 1.1368, 1.0505, 0.9891],\n",
            "        [1.7409, 2.5509, 1.6976, 2.6593, 2.5718, 1.6036, 1.6529],\n",
            "        [3.4253, 4.0892, 2.2976, 4.1516, 4.1449, 2.5053, 2.5818],\n",
            "        [3.4251, 4.1025, 2.3076, 4.1644, 4.1577, 2.5023, 2.5811],\n",
            "        [2.5422, 3.4648, 2.0611, 3.5422, 3.5397, 1.8960, 2.0791]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "403\n",
            "tensor([[3.3839, 4.0238, 2.2533, 4.0770, 4.0659, 2.5010, 2.5607],\n",
            "        [1.6474, 2.4221, 1.6399, 2.5341, 2.4347, 1.5740, 1.5994],\n",
            "        [2.1712, 3.0444, 1.8995, 3.1427, 3.0961, 1.7915, 1.8928],\n",
            "        [1.1850, 1.8043, 1.3379, 1.9201, 1.7789, 1.3453, 1.3068],\n",
            "        [3.4212, 4.0721, 2.2865, 4.1338, 4.1221, 2.5162, 2.5832]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "404\n",
            "tensor([[2.8983, 3.7275, 2.1706, 3.8065, 3.8082, 2.1307, 2.2782],\n",
            "        [0.8246, 1.3058, 1.0784, 1.4228, 1.2606, 1.1210, 1.0560],\n",
            "        [0.8552, 1.3454, 1.0994, 1.4628, 1.3011, 1.1453, 1.0787],\n",
            "        [3.2640, 3.9898, 2.2736, 4.0666, 4.0637, 2.4024, 2.4925],\n",
            "        [3.1328, 3.8883, 2.2270, 3.9634, 3.9638, 2.2750, 2.4038]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "405\n",
            "tensor([[3.2765, 3.9938, 2.2783, 4.0687, 4.0639, 2.4033, 2.4986],\n",
            "        [3.4087, 4.0952, 2.3205, 4.1637, 4.1604, 2.5141, 2.5814],\n",
            "        [1.0916, 1.6756, 1.2774, 1.7933, 1.6444, 1.2987, 1.2467],\n",
            "        [0.8297, 1.3129, 1.0858, 1.4313, 1.2686, 1.1300, 1.0625],\n",
            "        [0.9488, 1.4796, 1.1762, 1.5989, 1.4423, 1.2129, 1.1493]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "406\n",
            "tensor([[1.3814, 2.0685, 1.4822, 2.1871, 2.0605, 1.4700, 1.4437],\n",
            "        [0.6730, 1.0960, 0.9630, 1.2136, 1.0472, 1.0146, 0.9452],\n",
            "        [2.8658, 3.6987, 2.1608, 3.7808, 3.7799, 2.1173, 2.2612],\n",
            "        [0.6149, 1.0079, 0.9028, 1.1184, 0.9545, 0.9601, 0.8930],\n",
            "        [1.0383, 1.6075, 1.2529, 1.7318, 1.5777, 1.2771, 1.2176]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "407\n",
            "tensor([[2.8624, 3.6940, 2.1639, 3.7744, 3.7762, 2.1247, 2.2615],\n",
            "        [1.0406, 1.6036, 1.2453, 1.7237, 1.5710, 1.2804, 1.2157],\n",
            "        [2.9499, 3.7457, 2.1864, 3.8223, 3.8283, 2.1679, 2.3089],\n",
            "        [3.4000, 4.0396, 2.2883, 4.1029, 4.0915, 2.5428, 2.5826],\n",
            "        [1.9280, 2.7858, 1.8191, 2.8964, 2.8276, 1.7054, 1.7738]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "408\n",
            "tensor([[2.4536, 3.3883, 2.0531, 3.4742, 3.4681, 1.8840, 2.0497],\n",
            "        [0.9195, 1.4350, 1.1556, 1.5547, 1.3963, 1.2072, 1.1315],\n",
            "        [1.0722, 1.6545, 1.2760, 1.7773, 1.6276, 1.3060, 1.2435],\n",
            "        [3.1389, 3.8949, 2.2447, 3.9726, 3.9761, 2.3121, 2.4219],\n",
            "        [0.9927, 1.5375, 1.2134, 1.6598, 1.5044, 1.2602, 1.1864]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "409\n",
            "tensor([[3.3909, 4.0758, 2.3215, 4.1478, 4.1461, 2.5332, 2.5832],\n",
            "        [3.3651, 4.0474, 2.3078, 4.1253, 4.1213, 2.5071, 2.5638],\n",
            "        [0.8210, 1.2999, 1.0801, 1.4192, 1.2553, 1.1404, 1.0614],\n",
            "        [0.7610, 1.2195, 1.0381, 1.3396, 1.1730, 1.0975, 1.0184],\n",
            "        [1.6924, 2.4493, 1.6481, 2.5608, 2.4641, 1.6337, 1.6322]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "410\n",
            "tensor([[1.9661, 2.7966, 1.8085, 2.9078, 2.8376, 1.7634, 1.7996],\n",
            "        [0.9265, 1.4510, 1.1644, 1.5705, 1.4107, 1.2159, 1.1400],\n",
            "        [0.8056, 1.2823, 1.0729, 1.4032, 1.2387, 1.1308, 1.0516],\n",
            "        [0.7824, 1.2497, 1.0567, 1.3716, 1.2053, 1.1152, 1.0357],\n",
            "        [1.0749, 1.6642, 1.2879, 1.7914, 1.6385, 1.3186, 1.2524]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "411\n",
            "tensor([[2.3106, 3.2497, 2.0022, 3.3456, 3.3264, 1.8511, 1.9852],\n",
            "        [3.1236, 3.8863, 2.2427, 3.9652, 3.9654, 2.3224, 2.4229],\n",
            "        [1.8637, 2.7089, 1.7847, 2.8223, 2.7462, 1.7026, 1.7465],\n",
            "        [2.2783, 3.2224, 1.9913, 3.3182, 3.2980, 1.8344, 1.9696],\n",
            "        [0.7833, 1.2531, 1.0585, 1.3747, 1.2082, 1.1202, 1.0377]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "412\n",
            "tensor([[3.3052, 4.0116, 2.2944, 4.0904, 4.0871, 2.4682, 2.5338],\n",
            "        [1.4452, 2.1500, 1.5216, 2.2727, 2.1499, 1.5349, 1.4948],\n",
            "        [1.7173, 2.5067, 1.6876, 2.6250, 2.5303, 1.6594, 1.6614],\n",
            "        [0.9169, 1.4396, 1.1646, 1.5662, 1.4038, 1.2199, 1.1390],\n",
            "        [1.3837, 2.0842, 1.4981, 2.2079, 2.0801, 1.4998, 1.4590]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "413\n",
            "tensor([[2.5428, 3.4378, 2.0735, 3.5314, 3.5205, 2.0001, 2.1102],\n",
            "        [3.4009, 4.0303, 2.2873, 4.1030, 4.0934, 2.5877, 2.5990],\n",
            "        [2.4641, 3.4015, 2.0602, 3.4910, 3.4866, 1.9159, 2.0648],\n",
            "        [3.1228, 3.8853, 2.2447, 3.9683, 3.9676, 2.3480, 2.4265],\n",
            "        [3.3135, 4.0182, 2.3051, 4.1020, 4.0998, 2.5042, 2.5453]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "414\n",
            "tensor([[3.4031, 4.0734, 2.3178, 4.1487, 4.1448, 2.5714, 2.6008],\n",
            "        [0.7985, 1.2711, 1.0668, 1.3932, 1.2277, 1.1395, 1.0496],\n",
            "        [3.4161, 4.0695, 2.3157, 4.1429, 4.1367, 2.5842, 2.6069],\n",
            "        [0.8198, 1.3014, 1.0847, 1.4238, 1.2596, 1.1550, 1.0656],\n",
            "        [3.4039, 4.0525, 2.2983, 4.1209, 4.1090, 2.5873, 2.6016]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "415\n",
            "tensor([[2.8038, 3.6490, 2.1529, 3.7320, 3.7355, 2.1270, 2.2462],\n",
            "        [1.8854, 2.7105, 1.7775, 2.8257, 2.7470, 1.7473, 1.7629],\n",
            "        [1.1788, 1.8071, 1.3635, 1.9368, 1.7922, 1.4001, 1.3285],\n",
            "        [3.3500, 4.0419, 2.3099, 4.1204, 4.1169, 2.5294, 2.5680],\n",
            "        [1.2235, 1.8725, 1.3996, 2.0007, 1.8585, 1.4256, 1.3605]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "416\n",
            "tensor([[2.4312, 3.3719, 2.0527, 3.4642, 3.4580, 1.9249, 2.0573],\n",
            "        [3.1893, 3.9190, 2.2590, 4.0033, 4.0032, 2.3948, 2.4674],\n",
            "        [1.0795, 1.6433, 1.2602, 1.7645, 1.6162, 1.3360, 1.2472],\n",
            "        [1.2139, 1.8607, 1.3970, 1.9890, 1.8473, 1.4250, 1.3561],\n",
            "        [1.3861, 2.0919, 1.5098, 2.2183, 2.0920, 1.5152, 1.4682]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "417\n",
            "tensor([[1.3467, 2.0276, 1.4749, 2.1542, 2.0224, 1.5003, 1.4417],\n",
            "        [0.8443, 1.3364, 1.1117, 1.4620, 1.2970, 1.1839, 1.0898],\n",
            "        [1.6658, 2.4403, 1.6659, 2.5613, 2.4605, 1.6584, 1.6399],\n",
            "        [3.0553, 3.8299, 2.2344, 3.9196, 3.9221, 2.3317, 2.4026],\n",
            "        [2.4620, 3.3503, 2.0461, 3.4485, 3.4316, 1.9835, 2.0783]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "418\n",
            "tensor([[3.3804, 4.0629, 2.3302, 4.1417, 4.1421, 2.5586, 2.5923],\n",
            "        [1.0160, 1.5728, 1.2417, 1.7008, 1.5451, 1.3016, 1.2149],\n",
            "        [0.7751, 1.2390, 1.0583, 1.3625, 1.1958, 1.1295, 1.0366],\n",
            "        [2.4748, 3.3989, 2.0670, 3.4910, 3.4883, 1.9442, 2.0810],\n",
            "        [0.9896, 1.5421, 1.2312, 1.6716, 1.5134, 1.2878, 1.1996]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "419\n",
            "tensor([[2.8841, 3.7041, 2.1874, 3.7910, 3.7915, 2.2065, 2.3021],\n",
            "        [1.0365, 1.5992, 1.2551, 1.7253, 1.5721, 1.3108, 1.2256],\n",
            "        [1.6595, 2.4295, 1.6701, 2.5535, 2.4512, 1.6592, 1.6380],\n",
            "        [0.7792, 1.2451, 1.0673, 1.3716, 1.2035, 1.1379, 1.0425],\n",
            "        [3.4220, 4.0607, 2.3281, 4.1368, 4.1302, 2.6114, 2.6216]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "420\n",
            "tensor([[3.3304, 4.0102, 2.3169, 4.0901, 4.0867, 2.5353, 2.5637],\n",
            "        [2.6196, 3.5080, 2.1155, 3.5993, 3.5988, 2.0311, 2.1553],\n",
            "        [1.2823, 1.9320, 1.4328, 2.0598, 1.9208, 1.4697, 1.3987],\n",
            "        [3.4203, 4.0739, 2.3405, 4.1502, 4.1481, 2.5961, 2.6187],\n",
            "        [3.1261, 3.8793, 2.2620, 3.9620, 3.9638, 2.3653, 2.4383]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "421\n",
            "tensor([[2.4886, 3.4090, 2.0839, 3.5018, 3.4966, 1.9553, 2.0868],\n",
            "        [3.3541, 4.0311, 2.3262, 4.1100, 4.1084, 2.5558, 2.5786],\n",
            "        [3.2726, 3.9745, 2.3022, 4.0583, 4.0578, 2.4802, 2.5257],\n",
            "        [1.8632, 2.7011, 1.8076, 2.8237, 2.7439, 1.7439, 1.7626],\n",
            "        [2.5400, 3.4298, 2.0924, 3.5283, 3.5145, 2.0202, 2.1205]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "422\n",
            "tensor([[0.9468, 1.4610, 1.1881, 1.5890, 1.4269, 1.2589, 1.1590],\n",
            "        [2.1430, 3.0295, 1.9438, 3.1432, 3.0931, 1.8521, 1.9138],\n",
            "        [0.7893, 1.2529, 1.0751, 1.3799, 1.2104, 1.1481, 1.0473],\n",
            "        [1.3104, 1.9574, 1.4464, 2.0849, 1.9477, 1.4886, 1.4121],\n",
            "        [3.0441, 3.8150, 2.2447, 3.9054, 3.9008, 2.3211, 2.3920]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "423\n",
            "tensor([[0.9052, 1.4241, 1.1825, 1.5567, 1.3881, 1.2432, 1.1400],\n",
            "        [3.3300, 4.0189, 2.3333, 4.0988, 4.0958, 2.5343, 2.5579],\n",
            "        [3.4109, 4.0670, 2.3498, 4.1415, 4.1360, 2.6050, 2.6094],\n",
            "        [0.8353, 1.3195, 1.1207, 1.4496, 1.2797, 1.1921, 1.0850],\n",
            "        [3.3296, 4.0175, 2.3322, 4.0959, 4.0967, 2.5234, 2.5546]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "424\n",
            "tensor([[2.4969, 3.4020, 2.0946, 3.4987, 3.4873, 1.9951, 2.0932],\n",
            "        [1.2482, 1.8770, 1.4100, 2.0027, 1.8589, 1.4582, 1.3690],\n",
            "        [1.9022, 2.7086, 1.8074, 2.8293, 2.7461, 1.7915, 1.7763],\n",
            "        [1.6634, 2.4358, 1.6919, 2.5636, 2.4584, 1.6779, 1.6414],\n",
            "        [2.9795, 3.7681, 2.2374, 3.8526, 3.8514, 2.2925, 2.3528]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "425\n",
            "tensor([[0.7496, 1.2017, 1.0549, 1.3289, 1.1562, 1.1323, 1.0200],\n",
            "        [2.3954, 3.3435, 2.0757, 3.4339, 3.4259, 1.9252, 2.0401],\n",
            "        [1.3522, 2.0221, 1.4930, 2.1507, 2.0156, 1.5296, 1.4433],\n",
            "        [0.7362, 1.1832, 1.0419, 1.3105, 1.1385, 1.1180, 1.0088],\n",
            "        [3.2211, 3.9430, 2.3089, 4.0202, 4.0161, 2.4611, 2.4933]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "426\n",
            "tensor([[1.0440, 1.6218, 1.2989, 1.7558, 1.5951, 1.3526, 1.2439],\n",
            "        [2.0966, 3.0033, 1.9507, 3.1153, 3.0641, 1.8451, 1.8921],\n",
            "        [1.0710, 1.6467, 1.3013, 1.7760, 1.6187, 1.3675, 1.2558],\n",
            "        [1.2809, 1.9334, 1.4477, 2.0593, 1.9178, 1.4886, 1.3970],\n",
            "        [0.7475, 1.1983, 1.0531, 1.3252, 1.1524, 1.1351, 1.0192]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "427\n",
            "tensor([[2.4638, 3.3814, 2.0934, 3.4705, 3.4619, 1.9939, 2.0776],\n",
            "        [1.8405, 2.6529, 1.7886, 2.7700, 2.6814, 1.7758, 1.7442],\n",
            "        [3.2812, 3.9653, 2.3204, 4.0436, 4.0342, 2.5779, 2.5428],\n",
            "        [1.0661, 1.6369, 1.2931, 1.7621, 1.6057, 1.3644, 1.2493],\n",
            "        [0.8740, 1.3727, 1.1483, 1.4985, 1.3302, 1.2348, 1.1127]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "428\n",
            "tensor([[1.2031, 1.8357, 1.4046, 1.9647, 1.8175, 1.4578, 1.3502],\n",
            "        [0.9661, 1.5018, 1.2220, 1.6276, 1.4637, 1.3029, 1.1805],\n",
            "        [2.9007, 3.7206, 2.2200, 3.7971, 3.7971, 2.2682, 2.3121],\n",
            "        [1.9117, 2.7615, 1.8407, 2.8773, 2.7985, 1.8042, 1.7902],\n",
            "        [1.1900, 1.8169, 1.3942, 1.9449, 1.7961, 1.4503, 1.3400]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "429\n",
            "tensor([[2.4282, 3.3720, 2.0885, 3.4556, 3.4470, 1.9757, 2.0611],\n",
            "        [0.9283, 1.4596, 1.2030, 1.5873, 1.4209, 1.2823, 1.1575],\n",
            "        [3.4071, 4.0660, 2.3554, 4.1292, 4.1250, 2.6521, 2.6142],\n",
            "        [1.4302, 2.1135, 1.5249, 2.2307, 2.1028, 1.5934, 1.4891],\n",
            "        [2.3557, 3.3205, 2.0698, 3.4049, 3.3937, 1.9328, 2.0233]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "430\n",
            "tensor([[0.9162, 1.4323, 1.1779, 1.5541, 1.3889, 1.2720, 1.1424],\n",
            "        [2.5028, 3.4301, 2.1094, 3.5119, 3.5020, 2.0279, 2.1014],\n",
            "        [2.6366, 3.5335, 2.1489, 3.6127, 3.6108, 2.1025, 2.1696],\n",
            "        [0.8343, 1.3282, 1.1284, 1.4528, 1.2832, 1.2117, 1.0865],\n",
            "        [3.1759, 3.9153, 2.2979, 3.9853, 3.9872, 2.4750, 2.4705]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "431\n",
            "tensor([[3.2532, 3.9748, 2.3169, 4.0385, 4.0411, 2.5145, 2.5163],\n",
            "        [3.2950, 4.0027, 2.3292, 4.0654, 4.0666, 2.5544, 2.5432],\n",
            "        [1.7791, 2.5932, 1.7599, 2.7030, 2.6143, 1.7602, 1.7104],\n",
            "        [2.8084, 3.5916, 2.1664, 3.6737, 3.6572, 2.3073, 2.2735],\n",
            "        [3.3809, 4.0704, 2.3608, 4.1275, 4.1290, 2.6264, 2.5949]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "432\n",
            "tensor([[1.3921, 2.1060, 1.5401, 2.2262, 2.0990, 1.5709, 1.4779],\n",
            "        [2.4673, 3.4146, 2.1010, 3.4895, 3.4876, 1.9956, 2.0802],\n",
            "        [0.6165, 1.0183, 0.9369, 1.1319, 0.9632, 1.0264, 0.9112],\n",
            "        [2.6645, 3.5572, 2.1579, 3.6330, 3.6363, 2.1187, 2.1842],\n",
            "        [2.7335, 3.6088, 2.1778, 3.6849, 3.6879, 2.1638, 2.2220]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "433\n",
            "tensor([[2.2181, 3.1800, 2.0170, 3.2681, 3.2450, 1.8987, 1.9593],\n",
            "        [3.3900, 4.0664, 2.3570, 4.1201, 4.1241, 2.6488, 2.6056],\n",
            "        [1.1495, 1.6672, 1.2471, 1.7637, 1.6265, 1.4009, 1.2649],\n",
            "        [0.6744, 1.1036, 0.9944, 1.2220, 1.0520, 1.0866, 0.9628],\n",
            "        [2.3409, 3.2717, 2.0486, 3.3581, 3.3388, 1.9788, 2.0233]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "434\n",
            "tensor([[2.0548, 2.9658, 1.9293, 3.0645, 3.0171, 1.8625, 1.8738],\n",
            "        [0.7155, 1.1609, 1.0256, 1.2785, 1.1101, 1.1206, 0.9936],\n",
            "        [1.9620, 2.8118, 1.8517, 2.9120, 2.8451, 1.8550, 1.8187],\n",
            "        [1.1099, 1.7127, 1.3351, 1.8332, 1.6833, 1.4135, 1.2871],\n",
            "        [1.6778, 2.5039, 1.7371, 2.6175, 2.5247, 1.7145, 1.6621]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "435\n",
            "tensor([[3.3914, 4.0505, 2.3382, 4.0971, 4.0996, 2.6588, 2.6070],\n",
            "        [0.7764, 1.2585, 1.0920, 1.3804, 1.2129, 1.1759, 1.0477],\n",
            "        [1.0924, 1.6931, 1.3257, 1.8130, 1.6641, 1.4048, 1.2761],\n",
            "        [1.2919, 1.9661, 1.4654, 2.0839, 1.9512, 1.5265, 1.4126],\n",
            "        [0.8955, 1.4199, 1.1756, 1.5406, 1.3795, 1.2635, 1.1331]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "436\n",
            "tensor([[1.4248, 2.1471, 1.5542, 2.2624, 2.1413, 1.6029, 1.5003],\n",
            "        [1.1778, 1.8203, 1.3960, 1.9415, 1.7988, 1.4590, 1.3384],\n",
            "        [1.7654, 2.5861, 1.7559, 2.6915, 2.6092, 1.7612, 1.7053],\n",
            "        [0.6884, 1.1291, 1.0089, 1.2467, 1.0788, 1.1013, 0.9754],\n",
            "        [3.0582, 3.8540, 2.2710, 3.9145, 3.9263, 2.3871, 2.4074]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "437\n",
            "tensor([[1.3699, 2.0680, 1.5130, 2.1820, 2.0590, 1.5741, 1.4618],\n",
            "        [2.3421, 3.2858, 2.0572, 3.3679, 3.3576, 1.9881, 2.0276],\n",
            "        [1.2022, 1.7500, 1.2924, 1.8440, 1.7153, 1.4523, 1.3079],\n",
            "        [2.3696, 3.3093, 2.0635, 3.3907, 3.3811, 1.9991, 2.0417],\n",
            "        [1.7455, 2.5803, 1.7613, 2.6869, 2.6036, 1.7525, 1.6993]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "438\n",
            "tensor([[1.1187, 1.7427, 1.3570, 1.8629, 1.7194, 1.4303, 1.3006],\n",
            "        [0.9383, 1.4902, 1.2182, 1.6106, 1.4548, 1.3009, 1.1689],\n",
            "        [3.2848, 4.0049, 2.3363, 4.0625, 4.0816, 2.5682, 2.5415],\n",
            "        [1.3803, 2.1108, 1.5470, 2.2274, 2.1097, 1.5767, 1.4767],\n",
            "        [3.0784, 3.8660, 2.2832, 3.9323, 3.9494, 2.4295, 2.4267]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "439\n",
            "tensor([[3.2566, 3.9951, 2.3375, 4.0493, 4.0727, 2.5481, 2.5298],\n",
            "        [2.2112, 3.1809, 2.0227, 3.2660, 3.2554, 1.9208, 1.9637],\n",
            "        [3.3859, 4.0524, 2.3401, 4.0968, 4.1074, 2.6755, 2.6135],\n",
            "        [2.1289, 3.0309, 1.9523, 3.1226, 3.0885, 1.9315, 1.9176],\n",
            "        [3.3232, 4.0313, 2.3453, 4.0858, 4.1002, 2.6012, 2.5707]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "440\n",
            "tensor([[2.3327, 3.3211, 2.0717, 3.3938, 3.4039, 1.9567, 2.0255],\n",
            "        [0.9061, 1.4543, 1.2037, 1.5743, 1.4195, 1.2868, 1.1520],\n",
            "        [2.3550, 3.3119, 2.0698, 3.3900, 3.3936, 1.9972, 2.0389],\n",
            "        [1.7027, 2.5240, 1.7312, 2.6269, 2.5484, 1.7414, 1.6753],\n",
            "        [1.7099, 2.4743, 1.6825, 2.5681, 2.4910, 1.7561, 1.6610]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "441\n",
            "tensor([[0.7286, 1.1968, 1.0489, 1.3120, 1.1513, 1.1467, 1.0128],\n",
            "        [1.9113, 2.8036, 1.8599, 2.8979, 2.8501, 1.8287, 1.8025],\n",
            "        [3.3712, 4.0406, 2.3307, 4.0796, 4.0961, 2.6761, 2.6094],\n",
            "        [2.0278, 2.9682, 1.9350, 3.0592, 3.0276, 1.8662, 1.8713],\n",
            "        [1.1501, 1.8023, 1.3897, 1.9211, 1.7868, 1.4519, 1.3286]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "442\n",
            "tensor([[3.3326, 4.0448, 2.3486, 4.0932, 4.1232, 2.6375, 2.5889],\n",
            "        [2.8054, 3.6845, 2.2008, 3.7404, 3.7716, 2.2280, 2.2734],\n",
            "        [1.1986, 1.8685, 1.4183, 1.9833, 1.8550, 1.4855, 1.3618],\n",
            "        [3.3259, 4.0439, 2.3424, 4.0872, 4.1098, 2.6271, 2.5837],\n",
            "        [2.8478, 3.7194, 2.2146, 3.7771, 3.8050, 2.2656, 2.3038]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "443\n",
            "tensor([[2.7497, 3.6491, 2.1867, 3.7075, 3.7389, 2.2100, 2.2471],\n",
            "        [3.2476, 4.0054, 2.3280, 4.0517, 4.0819, 2.5494, 2.5334],\n",
            "        [1.6168, 2.4446, 1.6981, 2.5480, 2.4670, 1.7043, 1.6337],\n",
            "        [1.6040, 2.4251, 1.6874, 2.5275, 2.4470, 1.6937, 1.6236],\n",
            "        [3.3022, 4.0459, 2.3511, 4.0916, 4.1233, 2.6172, 2.5715]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "444\n",
            "tensor([[1.0528, 1.6720, 1.3160, 1.7876, 1.6500, 1.3972, 1.2620],\n",
            "        [3.3478, 4.0550, 2.3383, 4.0974, 4.1238, 2.6505, 2.5985],\n",
            "        [1.2730, 1.9772, 1.4700, 2.0878, 1.9702, 1.5292, 1.4124],\n",
            "        [1.6323, 2.4668, 1.7054, 2.5679, 2.4924, 1.7112, 1.6433],\n",
            "        [0.8770, 1.4202, 1.1755, 1.5358, 1.3857, 1.2690, 1.1318]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "445\n",
            "tensor([[3.3622, 4.0673, 2.3379, 4.1053, 4.1341, 2.6634, 2.6088],\n",
            "        [2.0145, 2.9570, 1.9090, 3.0418, 3.0183, 1.8587, 1.8623],\n",
            "        [0.8567, 1.3903, 1.1558, 1.5060, 1.3556, 1.2515, 1.1155],\n",
            "        [1.9512, 2.8784, 1.8827, 2.9699, 2.9356, 1.8453, 1.8312],\n",
            "        [1.7271, 2.5919, 1.7568, 2.6899, 2.6254, 1.7503, 1.6997]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "446\n",
            "tensor([[3.3385, 4.0728, 2.3469, 4.1167, 4.1554, 2.6299, 2.5925],\n",
            "        [2.7620, 3.6611, 2.1781, 3.7134, 3.7577, 2.1963, 2.2508],\n",
            "        [2.1380, 3.1122, 1.9714, 3.1907, 3.1862, 1.9019, 1.9319],\n",
            "        [0.9626, 1.5424, 1.2385, 1.6564, 1.5139, 1.3302, 1.1945],\n",
            "        [3.3649, 4.0737, 2.3380, 4.1168, 4.1482, 2.6726, 2.6151]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "447\n",
            "tensor([[2.2459, 3.2563, 2.0262, 3.3250, 3.3445, 1.9254, 1.9884],\n",
            "        [1.3211, 2.0316, 1.4785, 2.1377, 2.0312, 1.5528, 1.4391],\n",
            "        [3.3751, 4.0788, 2.3353, 4.1199, 4.1534, 2.6754, 2.6172],\n",
            "        [1.7757, 2.6497, 1.7756, 2.7462, 2.6921, 1.7741, 1.7292],\n",
            "        [3.2876, 4.0412, 2.3281, 4.0885, 4.1246, 2.5958, 2.5663]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "Loss at epoch 7: 194.3859\n",
            "Pearson correlation for aspect 1: 0.6928\n",
            "Pearson correlation for aspect 2: 0.8180\n",
            "Pearson correlation for aspect 3: 0.3307\n",
            "Pearson correlation for aspect 4: 0.7821\n",
            "Pearson correlation for aspect 5: 0.8115\n",
            "Pearson correlation for aspect 6: 0.4144\n",
            "Pearson correlation for aspect 7: 0.4498\n",
            "Mean Pearson correlation: 0.6142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization of the Training and Validation losses values."
      ],
      "metadata": {
        "id": "fx1wF74rbX08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing  matplotlib library for plotting and visualzing the values.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the loss curves\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, marker='o', label='Training Loss')\n",
        "\n",
        "plt.plot(range(1, num_epochs + 1), val_losses, marker='o', label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Avg Loss per batch')\n",
        "plt.title('Training and Validation Loss over Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "PyKv4AN9bTYt",
        "outputId": "49a16528-ef17-469c-a959-b728b22f5672"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization of the Pearson Values over epoch"
      ],
      "metadata": {
        "id": "VE99Mmh-bikh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# plotting and visualzing the loss curves.\n",
        "plt.plot(range(1, num_epochs + 1), pearson_scores, marker='o', label='Training Loss')\n",
        "\n",
        "# plt.plot(range(1, num_epochs + 1), val_losses, marker='o', label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Pearson Scores per batch')\n",
        "plt.title('Pearson Scores over Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "nJ7GEMAXbfeK",
        "outputId": "c6656e3f-62b0-4d13-b89c-f812197c7a1f"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Evaluation on test data"
      ],
      "metadata": {
        "id": "086c2bYfbuMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining function predict() to predit the model\n",
        "def predict(model, data_loader):\n",
        "  model.eval() #model.eval() setting the model into evaluation mode to ensure stable pridiction.\n",
        "  overall_pred, overall_true = [], [] #lists will be storing the prediction and true value of for all the batches.\n",
        "  with torch.no_grad(): # temporarily desabling the graidant calculation to reduce the memory consumption.\n",
        "    val_loss_sum=0\n",
        "    for idx, (ids, att_msks, y) in enumerate(data_loader): # iteration through the dataset where data_loader providing the data batches, ids is the inputIDs, att_mask is corrsponding which toekn should be used or ignore, and y is the true lable for the current batch.\n",
        "      ids, att_msks, y = ids.to(device), att_msks.to(device), y.to(device) #moving the data to the device which is using for the computaion.\n",
        "      y_pred = model(ids, att_msks) #model is running and  generating the prediction\n",
        "\n",
        "\n",
        "      y_pred, y = torch.squeeze(y_pred).cpu().numpy().tolist(), torch.squeeze(y).cpu().numpy().tolist() # torch.seweeze () ensuring the shape of the tensor is appropriate for further process, .cpu() shifting the GPU to CPU bcs NumPy calculation cannot be done on GPU,.NumPy()converting the tensor into NumPy array and .tolist() is converting the NumPy array into Python list.\n",
        "      overall_pred.append(y_pred)\n",
        "      overall_true.append(y)\n",
        "\n",
        "  return overall_pred, overall_true\n"
      ],
      "metadata": {
        "id": "clxPQ3Nwbphm"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pridiction on Test Dataset"
      ],
      "metadata": {
        "id": "WForBLnJb1vA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the test data\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/enriched_test_data.csv\")\n",
        "test_data = test_data[test_data['lang1'] == test_data['lang2']]  # Filtering rows where lang1 == lang2\n",
        "\n",
        "\n",
        "# Preprocessing the test data\n",
        "test_data = test_data.rename(columns={'text1': 'merge1', 'text2': 'merge2'})\n",
        "\n",
        "# Createing DataLoader for the test dataset\n",
        "test_data_loader = get_data_loader(test_data, False)\n",
        "\n",
        "# Loading the model weights\n",
        "model.load_state_dict(torch.load(\"BERT_Multilingual_0.25_overall_loss.pth\"), strict=False)\n",
        "model.to(device)\n",
        "\n",
        "# Get predictions on the test dataset\n",
        "test_pred_overall, test_true_overall = predict(model, test_data_loader)\n",
        "\n",
        "# Converting lists to NumPy arrays for indexing\n",
        "test_pred_overall = np.array(test_pred_overall)\n",
        "test_true_overall = np.array(test_true_overall)\n",
        "\n",
        "# Calculating Pearson correlations for each aspect\n",
        "pearson_correlations = calculate_pearson_per_aspect(test_pred_overall, test_true_overall)\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Createing scatter plot\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(test_true_overall, test_pred_overall, alpha=0.3, color='b', label='Predictions')\n",
        "\n",
        "# Plot a line for perfect predictions (y = x)\n",
        "min_val = min(test_true_overall.min(), test_pred_overall.min())\n",
        "max_val = max(test_true_overall.max(), test_pred_overall.max())\n",
        "plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='Perfect Prediction')\n",
        "# Adding labels and title\n",
        "plt.xlabel('True Labels')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Model Evaluation: True vs Predicted')\n",
        "plt.legend()\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n",
        "\n",
        "# Calculate and print the mean Pearson correlation across all aspects\n",
        "curr_pearson = np.mean(pearson_correlations)\n",
        "print(f\"Mean Pearson correlation for test dataset: {curr_pearson:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "Ing9FA3AbyXK",
        "outputId": "4fadef24-5fea-4f5b-90a4-c668967441e7"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-87-085a0fec26c7>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"BERT_Multilingual_0.25_overall_loss.pth\"), strict=False)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Pearson correlation for test dataset: 0.5606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pearson_correlations = calculate_pearson_per_aspect(test_pred_overall, test_true_overall)#calculate_pearson_per_aspect() fuction for computing pearson correlation for each aspect and assigning to the pearson_correlation object.\n",
        "for i, r in enumerate(pearson_correlations):\n",
        "        print(f\"Pearson correlation for aspect {i+1}: {r:.4f}\")\n",
        "\n",
        "curr_pearson = np.mean(pearson_correlations)#np.mean() calculating the mean of the correlation of all 7 aspects and assigning to the curr_pearson object.\n",
        "print(f\"Mean Pearson correlation for test dataset: {curr_pearson:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ukr6iPp_b79Z",
        "outputId": "353bd90d-284c-4178-f066-251e82b62541"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearson correlation for aspect 1: 0.6169\n",
            "Pearson correlation for aspect 2: 0.7699\n",
            "Pearson correlation for aspect 3: 0.2524\n",
            "Pearson correlation for aspect 4: 0.7447\n",
            "Pearson correlation for aspect 5: 0.7836\n",
            "Pearson correlation for aspect 6: 0.3400\n",
            "Pearson correlation for aspect 7: 0.4171\n",
            "Mean Pearson correlation for test dataset: 0.5606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred_overall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxWSAWO1b_wF",
        "outputId": "fa16947a-44c1-474a-9c92-6d5f38fae986"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.12025046, 1.76466012, 1.34943998, ..., 1.75495875, 1.43369985,\n",
              "        1.30833733],\n",
              "       [0.93070114, 1.49389148, 1.20385337, ..., 1.46675837, 1.30220377,\n",
              "        1.16894329],\n",
              "       [0.94853008, 1.51158476, 1.20264351, ..., 1.48423398, 1.30475187,\n",
              "        1.17532909],\n",
              "       ...,\n",
              "       [0.84903485, 1.37679565, 1.13846457, ..., 1.34489262, 1.23724055,\n",
              "        1.10647476],\n",
              "       [2.20063043, 3.1830256 , 1.99168277, ..., 3.26463223, 1.92745757,\n",
              "        1.9661237 ],\n",
              "       [2.42476392, 3.36626148, 2.06017995, ..., 3.45602822, 2.05983615,\n",
              "        2.0837822 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}